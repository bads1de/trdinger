#!/usr/bin/env python3
"""
é‡è¤‡ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import re
import os
from collections import defaultdict
from pathlib import Path


def extract_indicators_from_file(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡æ¨™åã‚’æŠ½å‡º"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # æŒ‡æ¨™åã‚’æŠ½å‡ºï¼ˆã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ï¼‰
        patterns = [
            r'"([A-Z_]+)"',  # ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ
            r"'([A-Z_]+)'",  # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ
        ]

        indicators = set()
        for pattern in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                # æŒ‡æ¨™åã‚‰ã—ã„ã‚‚ã®ï¼ˆå¤§æ–‡å­—ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ï¼‰
                if re.match(r"^[A-Z][A-Z_]*$", match) and len(match) >= 2:
                    indicators.add(match)

        return list(indicators)
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        return []


def detect_duplicate_indicators():
    """æŒ‡æ¨™ãƒªã‚¹ãƒˆã®é‡è¤‡ã‚’æ¤œå‡º"""
    print("ğŸ” æŒ‡æ¨™ãƒªã‚¹ãƒˆé‡è¤‡æ¤œå‡ºé–‹å§‹")
    print("=" * 50)

    # æ¤œç´¢å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
    files_to_check = [
        "backend/app/core/services/auto_strategy/generators/random_gene_generator.py",
        "backend/app/core/services/auto_strategy/models/ga_config.py",
        "frontend/components/backtest/GAConfigForm.tsx",
    ]

    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡æ¨™ãƒªã‚¹ãƒˆã‚’æŠ½å‡º
    file_indicators = {}
    for file_path in files_to_check:
        if os.path.exists(file_path):
            indicators = extract_indicators_from_file(file_path)
            file_indicators[file_path] = indicators
            print(f"ğŸ“ {os.path.basename(file_path)}: {len(indicators)}å€‹ã®æŒ‡æ¨™")
        else:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

    # é‡è¤‡æŒ‡æ¨™ã®æ¤œå‡º
    all_indicators = []
    for indicators in file_indicators.values():
        all_indicators.extend(indicators)

    indicator_count = defaultdict(int)
    for indicator in all_indicators:
        indicator_count[indicator] += 1

    print(f"\nğŸ“Š é‡è¤‡æŒ‡æ¨™åˆ†æ:")
    duplicates = {k: v for k, v in indicator_count.items() if v > 1}
    if duplicates:
        for indicator, count in sorted(duplicates.items()):
            print(f"  ğŸ”„ {indicator}: {count}ç®‡æ‰€ã§å®šç¾©")
    else:
        print("  âœ… é‡è¤‡æŒ‡æ¨™ãªã—")

    print(f"\nğŸ“ˆ çµ±è¨ˆ:")
    print(f"  - ç·æŒ‡æ¨™æ•°: {len(set(all_indicators))}")
    print(f"  - é‡è¤‡æŒ‡æ¨™æ•°: {len(duplicates)}")
    if len(set(all_indicators)) > 0:
        print(f"  - é‡è¤‡ç‡: {len(duplicates)/len(set(all_indicators))*100:.1f}%")

    return file_indicators, duplicates


def detect_duplicate_imports():
    """é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ¤œå‡º"""
    print("\nğŸ” é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œå‡ºé–‹å§‹")
    print("=" * 50)

    # æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    search_dirs = [
        "backend/app/core/services/indicators/",
        "backend/app/core/services/auto_strategy/",
    ]

    import_count = defaultdict(int)
    file_imports = {}

    for search_dir in search_dirs:
        if os.path.exists(search_dir):
            for root, dirs, files in os.walk(search_dir):
                for file in files:
                    if file.endswith(".py"):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, "r", encoding="utf-8") as f:
                                content = f.read()

                            # importæ–‡ã‚’æŠ½å‡º
                            import_lines = re.findall(
                                r"^(import .*|from .* import .*)$",
                                content,
                                re.MULTILINE,
                            )
                            file_imports[file_path] = import_lines

                            for imp in import_lines:
                                import_count[imp] += 1

                        except Exception as e:
                            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

    # é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æ¤œå‡º
    duplicate_imports = {k: v for k, v in import_count.items() if v > 1}

    if duplicate_imports:
        print(f"ğŸ”„ é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ({len(duplicate_imports)}å€‹):")
        for imp, count in sorted(duplicate_imports.items()):
            print(f"  - {imp} ({count}ç®‡æ‰€)")
    else:
        print("âœ… é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆãªã—")

    return duplicate_imports


def detect_parameter_logic_duplicates():
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®é‡è¤‡ã‚’æ¤œå‡º"""
    print("\nğŸ” ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯é‡è¤‡æ¤œå‡ºé–‹å§‹")
    print("=" * 50)

    file_path = (
        "backend/app/core/services/auto_strategy/generators/random_gene_generator.py"
    )

    if not os.path.exists(file_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return {}

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # elif indicator_type == ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        elif_patterns = re.findall(
            r'elif indicator_type == ["\']([^"\']+)["\']:(.*?)(?=elif|else:|return)',
            content,
            re.DOTALL,
        )

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        parameter_patterns = defaultdict(list)
        for indicator, logic in elif_patterns:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆã®ç¨®é¡ã‚’åˆ†æ
            if "random.randint" in logic:
                if "period" in logic:
                    parameter_patterns["period_randint"].append(indicator)
                if "fast_period" in logic and "slow_period" in logic:
                    parameter_patterns["fast_slow_periods"].append(indicator)
            if "random.uniform" in logic:
                parameter_patterns["uniform_params"].append(indicator)
            if "random.choice" in logic:
                parameter_patterns["choice_params"].append(indicator)

        print("ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        for pattern, indicators in parameter_patterns.items():
            if len(indicators) > 1:
                print(f"  ğŸ”„ {pattern}: {len(indicators)}å€‹ã®æŒ‡æ¨™")
                for indicator in indicators[:5]:  # æœ€åˆã®5å€‹ã‚’è¡¨ç¤º
                    print(f"    - {indicator}")
                if len(indicators) > 5:
                    print(f"    ... ä»–{len(indicators)-5}å€‹")

        return parameter_patterns

    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}


def detect_threshold_logic_duplicates():
    """é–¾å€¤ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®é‡è¤‡ã‚’æ¤œå‡º"""
    print("\nğŸ” é–¾å€¤ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯é‡è¤‡æ¤œå‡ºé–‹å§‹")
    print("=" * 50)

    file_path = (
        "backend/app/core/services/auto_strategy/generators/random_gene_generator.py"
    )

    if not os.path.exists(file_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return {}

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # é–¾å€¤ç”Ÿæˆé–¢æ•°å†…ã®elifæ–‡ã‚’æŠ½å‡º
        threshold_function = re.search(
            r"def _generate_threshold_value.*?(?=def|\Z)", content, re.DOTALL
        )
        if not threshold_function:
            print("âŒ é–¾å€¤ç”Ÿæˆé–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}

        threshold_content = threshold_function.group(0)
        elif_patterns = re.findall(
            r'elif ["\']([^"\']+)["\'] in operand:(.*?)(?=elif|else:|return)',
            threshold_content,
            re.DOTALL,
        )

        # é–¾å€¤ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        threshold_patterns = defaultdict(list)
        for indicator, logic in elif_patterns:
            if "random.uniform(0, 100)" in logic or "random.uniform(20, 80)" in logic:
                threshold_patterns["percentage_0_100"].append(indicator)
            elif "random.uniform(-100, 100)" in logic:
                threshold_patterns["percentage_neg100_100"].append(indicator)
            elif (
                "random.uniform(0.9, 1.1)" in logic
                or "random.uniform(0.95, 1.05)" in logic
            ):
                threshold_patterns["price_ratio"].append(indicator)
            elif "random.uniform(-" in logic and ", 0)" in logic:
                threshold_patterns["negative_range"].append(indicator)

        print("ğŸ“Š é–¾å€¤ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:")
        for pattern, indicators in threshold_patterns.items():
            if len(indicators) > 1:
                print(f"  ğŸ”„ {pattern}: {len(indicators)}å€‹ã®æŒ‡æ¨™")
                for indicator in indicators:
                    print(f"    - {indicator}")

        return threshold_patterns

    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}


if __name__ == "__main__":
    # æŒ‡æ¨™ãƒªã‚¹ãƒˆã®é‡è¤‡æ¤œå‡º
    file_indicators, duplicate_indicators = detect_duplicate_indicators()

    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®é‡è¤‡æ¤œå‡º
    duplicate_imports = detect_duplicate_imports()

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®é‡è¤‡æ¤œå‡º
    parameter_duplicates = detect_parameter_logic_duplicates()

    # é–¾å€¤ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®é‡è¤‡æ¤œå‡º
    threshold_duplicates = detect_threshold_logic_duplicates()

    print(f"\nğŸ¯ æ¤œå‡ºçµæœã‚µãƒãƒªãƒ¼:")
    print(f"  - é‡è¤‡æŒ‡æ¨™: {len(duplicate_indicators)}å€‹")
    print(f"  - é‡è¤‡ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {len(duplicate_imports)}å€‹")
    print(f"  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³: {len(parameter_duplicates)}ç¨®é¡")
    print(f"  - é–¾å€¤ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³: {len(threshold_duplicates)}ç¨®é¡")
