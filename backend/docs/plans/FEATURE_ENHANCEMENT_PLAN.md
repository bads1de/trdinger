# 特徴量拡張計画案 (詳細版)

## 1. 目的と背景

### 1.1. 現状の課題
現在の機械学習モデルは、主に分析対象銘柄のOHLCVデータから生成されるテクニカル指標や価格パターンに基づいている。これは市場の「内部状態」を捉える上では有効だが、以下の限界点を持つ。

- **外部要因への感応度の欠如:** 暗号資産市場は、マクロ経済の動向、規制のニュース、他市場のセンチメントなど、外部からの影響を強く受ける。現在のモデルはこれらの要因を直接的に捉えられない。
- **市場全体の文脈の欠落:** 単一銘柄の動きだけでは、市場全体の資金の流れや投資家心理の大きなうねりを捉えきれない。結果として、市場全体のドローダウンに巻き込まれるリスクがある。

### 1.2. 計画の目的
本計画は、**市場間相関**、**投資家センチメント**、**オンチェーンデータ**という3つの新たな情報源から特徴量を導入することにより、モデルの予測能力と頑健性を向上させることを目的とする。これにより、以下を実現する。

- **予測精度の向上:** これまでノイズとして扱われていた市場の外部要因をモデル化し、価格変動の新たな先行指標とする。
- **リスク管理の強化:** 市場全体の過熱感やリスクオフムードを検知し、大きなドローダウンを回避する能力を高める。
- **モデルの汎用性向上:** 特定の銘柄や相場状況への過剰適合（オーバーフィッティング）を抑制し、より多様な市場環境で安定したパフォーマンスを目指す。

---

## 2. 提案する特徴量カテゴリ（詳細）

### カテゴリ1：市場間・相関関係の特徴量

- **理論的背景:** グローバルな金融市場において、資産クラス間の資金移動は常に行われている。特に暗号資産はリスク資産として認識されており、株式市場や通貨の動向と強い相関・逆相関を示すことがある。これらの相関関係を特徴量とすることで、市場全体の資金の流れを捉える。
- **具体的な特徴量候補:**
    - `ETH_Return_1h`, `SOL_Return_1h`: 主要アルトコインの短期リターン。暗号資産市場内の資金循環を捉える。
    - `SP500_Return_1d`, `NASDAQ_Return_1d`: 米国株価指数の日次リターン。リスクオン/リスクオフのセンチメントを代表する指標。
    - `DXY_Return_1d`: ドルインデックスの日次リターン。ドルの強弱は、BTCをはじめとする資産の価格評価に影響する。
    - `VIX_Value`: VIX指数の絶対値。市場の恐怖感が高まるとVIXは上昇し、リスク資産からの資金流出を引き起こす可能性がある。
- **データソースと実装:**
    - **ライブラリ:** `yfinance` を利用するのが最も手軽でコスト効率が良い。
    - **実装パス:** `backend/data_collector/external_market_collector.py` を新規作成。
    - **処理フロー:**
        1. 定期実行（1時間ごと）のスクリプトとして実装。
        2. `yfinance.download()` を使用し、必要なシンボル（`^GSPC`, `^IXIC`, `DX-Y.NYB`など）のデータを取得。
        3. 取得したデータを整形し、リターンを計算後、専用のデータベーステーブル `external_market_data` に保存。
        4. `feature_engineering` パイプラインでこのテーブルを読み込み、OHLCVデータとタイムスタンプを基準にマージする。

### カテゴリ2：センチメント分析

- **理論的背景:** 市場価格は、ファンダメンタルズだけでなく、群集心理によっても大きく動かされる。特に暗号資産市場は個人投資家の参加が多く、SNSやニュースによるセンチメントの影響を受けやすい。
- **具体的な特徴量候補:**
    - `FearAndGreedIndex`: 市場全体の極端な恐怖（買いのチャンス）や強欲（調整のサイン）を捉える。
    - `Twitter_Sentiment_Score`, `Twitter_Volume`: 特定銘柄に関する言及量（注目度）と、そのポジ/ネガ比率（センチメント）。
- **データソースと実装:**
    - **Fear & Greed Index:**
        - **ソース:** [Alternative.me API](https://alternative.me/crypto/fear-and-greed-index/) (1日1回更新)
        - **実装:** `external_market_collector.py` にAPIリクエスト処理を追加。
    - **Twitter/X センチメント:**
        - **ソース:** Twitter API v2の利用を検討。ただし、コストと利用制限が厳しい。代替案として、関連キーワードのGoogle Trendsデータを `pytrends` ライブラリで取得する方法も有効。
        - **実装:**
            - `backend/data_collector/sentiment_collector.py` を新規作成。
            - 自然言語処理には、`transformers` ライブラリの事前学習済みモデル（例: `cardiffnlp/twitter-roberta-base-sentiment`）を利用し、センチメントをスコア化する。
            - 収集したスコアとボリュームを `sentiment_data` テーブルに保存。

### カテゴリ3：オンチェーンデータ

- **理論的背景:** ブロックチェーンは透明性の高い台帳であり、そのデータを分析することで、取引所を介さない投資家の行動やネットワークの健全性を直接的に把握できる。これは他の金融市場にはない、暗号資産特有の強力な情報源である。
- **具体的な特徴量候補:**
    - `Exchange_Netflow`: 取引所からの資金の純流出入。流出超過は長期保有（HODL）の兆候、流入超過は売り圧力の可能性を示す。
    - `Active_Addresses`: ネットワークを利用しているユーザー数。ネットワークの成長と活性度の指標。
    - `SOPR (Spent Output Profit Ratio)`: 売却されたコインが利益を出しているか損失を出しているかを示す。SOPR > 1は利益確定売り、SOPR < 1は損切りを示唆する。
    - `Whale_Transaction_Volume`: 大口投資家（クジラ）の取引量。市場を動かす可能性のある行動を捉える。
- **データソースと実装:**
    - **ソース:** [Glassnode API](https://glassnode.com/) または [CryptoQuant API](https://cryptoquant.com/)。高品質だが有料。無料プランの範囲で利用できる指標からスモールスタートする。
    - **実装パス:** `backend/data_collector/onchain_data_collector.py` を新規作成。
    - **処理フロー:**
        1. 各APIのクライアントライブラリを利用して、エンドポイントにリクエスト。
        2. 取得した時系列データを `onchain_data` テーブルに保存。
        3. `FeatureEngineeringService` で、このデータを価格データと結合して利用。

---

## 3. 実装計画とタイムライン

| フェーズ | タスク                                                               | 期間    | 担当部署/担当者（仮） | 成果物                                                                 |
| :------- | :------------------------------------------------------------------- | :------ | :-------------------- | :--------------------------------------------------------------------- |
| **1. 準備**  | **データソース調査とAPIキー取得**                                    | 1週間   | MLチーム              | 利用APIの仕様書、コスト見積もり、取得済みAPIキー                       |
|          | **DBスキーマ設計**                                                   | 3日間   | DBチーム, MLチーム    | `external_market_data`, `sentiment_data`, `onchain_data` のテーブル定義書 |
| **2. 実装**  | **データコレクター実装 (市場間・センチメント・オンチェーン)**        | 2週間   | MLエンジニア          | `backend/data_collector/` 以下の各コレクタースクリプト                 |
|          | **特徴量計算クラスの実装**                                           | 2週間   | MLエンジニア          | `backend/app/core/services/ml/feature_engineering/` 以下の各Calculatorクラス |
|          | **FeatureEngineeringServiceへの統合**                                | 1週間   | MLエンジニア          | 更新された `FeatureEngineeringService`                                   |
| **3. 検証**  | **バックテスト環境の整備**                                           | 1週間   | MLチーム              | 新旧特徴量セットを比較検証できるバックテスト用スクリプト               |
|          | **有効性検証と特徴量選択**                                           | 2週間   | データサイエンティスト  | バックテスト結果レポート、特徴量重要度分析、採用する特徴量リスト       |
|          | **最終モデルの評価とチューニング**                                   | 1週間   | データサイエンティスト  | 最終モデルのパフォーマンス評価レポート                                 |
| **4. 展開**  | **本番環境へのデプロイ**                                             | 1週間   | DevOpsチーム, MLチーム | 本番環境で動作する新しい特徴量パイプライン                             |

---

## 4. リスクと対策

| リスク分類       | 具体的なリスク内容                                                                                             | 発生確率 | 影響度 | 対策                                                                                                                                                                                          |
| :--------------- | :------------------------------------------------------------------------------------------------------------- | :------- | :----- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **データ品質**   | 外部APIのデータに欠損、遅延、異常値が含まれる。                                                                | 高       | 大     | - **データ検証層の実装:** データ取得後に必ずバリデーション処理（欠損値チェック、外れ値検出）を行う。<br>- **補間処理:** 欠損値は前方補完（ffill）や移動平均で補間する。<br>- **冗長化:** 複数のデータソースを契約し、一方に問題が発生した際に切り替えられる体制を検討する。 |
| **コスト**       | 高品質なセンチメントデータやオンチェーンデータのAPI利用料が予算を超える。                                        | 中       | 中     | - **スモールスタート:** まずは無料プランや低コストのAPIから導入し、費用対効果を検証する。<br>- **データキャッシュ:** 一度取得したデータはローカルDBにキャッシュし、不要なAPIコールを削減する。                                                              |
| **過学習**       | 特徴量の数が大幅に増えることで、モデルが訓練データに過剰適合し、実運用でのパフォーマンスが劣化する。             | 高       | 大     | - **厳密な特徴量選択:** バックテストにおいて、SHAPやPermutation Importanceを用いて、本当に有効な特徴量のみを選別する。<br>- **正則化の強化:** モデル学習時にL1/L2正則化のハイパーパラメータを調整し、モデルの複雑さにペナルティを課す。<br>- **Walk-Forward Validation:** 時間軸に沿ったウォークフォワード検証を行い、将来のデータに対する頑健性を評価する。 |
| **データリーク** | 特徴量を計算する際に、未来のデータ（本来その時点では利用不可能な情報）を誤って使用してしまう。                   | 中       | 大     | - **タイムスタンプの厳格な管理:** 全てのデータマージ処理において、タイムスタンプが完全に一致するか、過去のデータのみを参照していることをコードレビューで徹底的に確認する。<br>- **ラグの導入:** 外部データを特徴量として利用する際は、意図的に1期前のデータ（ラグ）を使用し、情報の伝達遅延を考慮する。 |

---

## 5. 評価指標

新しい特徴量セットの有効性は、以下の指標を用いて総合的に評価する。

- **モデル予測性能:**
    - **Accuracy / Precision / Recall / F1-Score:** 分類問題としてのシグナル（買い/売り/待機）の正解率。
    - **Log Loss:** 予測確率の正確性。
- **財務パフォーマンス:**
    - **Sharpe Ratio (シャープレシオ):** リスク調整後リターン。
    - **Calmar Ratio (カルマールレシオ):** 最大ドローダウンに対するリターン。
    - **Profit Factor:** 総利益 / 総損失。
    - **勝率 (Win Rate):** 全トレードのうち利益が出たトレードの割合。