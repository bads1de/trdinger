# モデル精度向上ガイド

**作成日**: 2025-11-23  
**現在の精度**: F1 スコア 42.72% (LightGBM)  
**目標精度**: F1 スコア 50-60%  
**最大の課題**: DOWN クラスの Recall 30.13% (致命的)

---

## 📊 現在の状況分析

### 実行結果サマリー

| 項目          | LightGBM  | XGBoost |
| ------------- | --------- | ------- |
| **Accuracy**  | 43.25%    | 41.70%  |
| **Precision** | 42.75%    | 41.07%  |
| **Recall**    | 43.26%    | 41.71%  |
| **F1 Score**  | 42.72% ✅ | 41.22%  |
| **ROC-AUC**   | 0.6195    | 0.6160  |

### クラス別詳細（LightGBM）

| クラス    | Precision | Recall        | F1-Score | 評価                   |
| --------- | --------- | ------------- | -------- | ---------------------- |
| **DOWN**  | 38.80%    | **30.13%** ❌ | 33.92%   | 最悪：70%を見逃し      |
| **RANGE** | 48.16%    | **54.95%** ✅ | 51.33%   | 最良：レンジ検出が得意 |
| **UP**    | 41.27%    | 44.68%        | 42.91%   | 中程度                 |

### 主要な問題点

1. **クラス不均衡**

   - DOWN 検出率が 30%と極端に低い
   - モデルが DOWN クラスの学習に失敗
   - 実トレードでは下落を見逃して損失拡大のリスク

2. **タスクの難易度**

   - 3 クラス分類（UP/RANGE/DOWN）は困難
   - 1 時間足で 4 時間先予測はノイズが多い
   - 固定閾値 0.2%は BTC/USDT には不適切

3. **クラスウェイトが無効**
   - `use_class_weight=False`で不均衡対策なし
   - SMOTE も無効化されている

---

## 🎯 優先度別改善策

### 🔴 **最優先（即座に実行可能、効果: 大）**

#### 1. クラス不均衡対策の有効化 ⭐⭐⭐⭐⭐

**現状**: 設定で無効化されている

```python
use_class_weight: bool = False  # 現在の設定
use_smote: bool = False         # 現在の設定
```

**改善策**: 環境変数で有効化

```bash
# .env ファイルまたはシステム環境変数
ML__TRAINING__USE_CLASS_WEIGHT=true
ML__TRAINING__CLASS_WEIGHT_MODE=balanced
ML__TRAINING__USE_SMOTE=true
ML__TRAINING__SMOTE_METHOD=adasyn  # smoteよりも柔軟
```

**期待効果**:

- DOWN クラスの Recall: 30% → 40-45%
- F1 スコア全体: +2-3%
- 実装時間: 2 分
- リスク: 極めて低い（設定変更のみ）

**理由**:

- `class_weight='balanced'`: 少数クラスに重みを付けて学習
- `ADASYN`: 難しいサンプル周辺に合成データを生成
- クラス不均衡対策の標準的なアプローチ

---

#### 2. 予測期間の延長 ⭐⭐⭐⭐⭐

**現状**: 4 時間先予測（horizon_n=4, timeframe=1h）

**改善策 A**: 8 時間先予測

```bash
ML__LABEL_GENERATION__DEFAULT_PRESET=1h_8bars_dynamic
```

**改善策 B**: 12 時間先予測（カスタム）

```bash
ML__LABEL_GENERATION__USE_PRESET=false
ML__LABEL_GENERATION__TIMEFRAME=1h
ML__LABEL_GENERATION__HORIZON_N=12
ML__LABEL_GENERATION__THRESHOLD_METHOD=KBINS_DISCRETIZER
```

**期待効果**:

- F1 スコア: +3-5%
- ノイズの大幅削減
- より明確なトレンドの検出
- 実装時間: 1 分
- リスク: 低い

**理由**:

- 短期予測（4 時間）はランダムウォークに近い
- 8-12 時間先なら意味のあるトレンドが形成される
- BTC 市場の典型的なトレンド持続時間に適合

---

#### 3. 動的閾値への変更 ⭐⭐⭐⭐

**現状**: 固定閾値 0.002 (0.2%)

**改善策**: 分位数ベースの動的閾値

```bash
ML__LABEL_GENERATION__THRESHOLD_METHOD=QUANTILE
ML__LABEL_GENERATION__THRESHOLD=0.33  # 上位33%、下位33%
```

または、現在の`KBINS_DISCRETIZER`を維持しつつ調整:

```bash
# 既存の動的手法を継続
ML__LABEL_GENERATION__DEFAULT_PRESET=4h_4bars_dynamic
# またはより大きな閾値を試す
ML__LABEL_GENERATION__DEFAULT_PRESET=4h_4bars_050  # 0.5%閾値
```

**期待効果**:

- クラス分布の均等化
- ラベルノイズの削減
- F1 スコア: +1-2%
- 実装時間: 1 分

---

### 🟠 **高優先度（1 時間以内、効果: 中〜大）**

#### 4. 2 クラス分類への変更 ⭐⭐⭐⭐⭐

**現状**: UP/RANGE/DOWN の 3 クラス分類（難易度: Hard）

**改善策**: 2 クラス分類に変更

**パターン A: TREND vs RANGE**（推奨）

```python
# train_optimized_models.py 内で変更
labels_3class = evaluator.create_labels_from_config(ohlcv_df, price_column="close")

# 2クラスに統合
labels = labels_3class.map({
    "UP": "TREND",
    "RANGE": "RANGE",
    "DOWN": "TREND"
})

# ラベルマッピングも変更
label_mapping = {"RANGE": 0, "TREND": 1}
```

**パターン B: UP vs NOT_UP**

```python
labels = labels_3class.map({
    "UP": "UP",
    "RANGE": "NOT_UP",
    "DOWN": "NOT_UP"
})

label_mapping = {"NOT_UP": 0, "UP": 1}
```

**期待効果**:

- Accuracy: 42% → 55-60%の大幅改善
- より実用的（レンジ判定 + トレンド判定）
- 実装時間: 30 分
- リスク: 中（コード変更が必要）

**実装手順**:

1. `backend/scripts/ml_optimization/train_2class_models.py`を作成
2. `train_optimized_models.py`をコピー
3. ラベル生成部分を上記のように変更
4. `num_class`を 2 に変更
5. 実行して比較

---

#### 5. ボラティリティ正規化特徴量の追加 ⭐⭐⭐⭐

**現状**: 市場環境によって特徴量の意味が変化

**改善策**: 既に作成済みの`volatility_normalized_features.py`を統合

**実装手順**:

1. `advanced_features.py`を修正（※現在エラーあり、修正必要）
2. `create_advanced_features`メソッド内で呼び出し

```python
# 5.5. ボラティリティ正規化特徴量（新規追加）
from .volatility_normalized_features import VolatilityNormalizedCalculator

vol_norm_calculator = VolatilityNormalizedCalculator(volatility_window=20)
features = vol_norm_calculator.calculate_features(features)
```

**追加される特徴量**:

- `vol_norm_momentum_1`, `vol_norm_momentum_5`, `vol_norm_momentum_20`
- `vol_norm_rsi`, `vol_norm_macd`
- `vol_regime_low`, `vol_regime_high`
- `vol_acceleration`
- `vol_norm_bb_position`
- `vol_adjusted_range`

**期待効果**:

- 市場環境に依存しない安定した特徴量
- F1 スコア: +2-4%
- 実装時間: 20 分（ファイル修正）
- リスク: 低（新規特徴量の追加のみ）

---

#### 6. アンサンブルモデルの構築 ⭐⭐⭐

**改善策**: LightGBM と XGBoost の予測を統合

**実装コード**:

```python
from sklearn.ensemble import VotingClassifier

# 最適化済みモデルを使用
lgb_model = lgb.LGBMClassifier(**lgb_best_params)
xgb_model = xgb.XGBClassifier(**xgb_best_params)

# ボーティング分類器
ensemble = VotingClassifier(
    estimators=[
        ('lgb', lgb_model),
        ('xgb', xgb_model)
    ],
    voting='soft',  # 確率ベース
    weights=[1.2, 1.0]  # LightGBMに若干重み
)

ensemble.fit(X_train, y_train)
```

**期待効果**:

- F1 スコア: +1-2%
- より安定した予測
- 実装時間: 30 分

---

### 🟡 **中優先度（1-2 時間、効果: 中）**

#### 7. 時系列分割によるクロスバリデーション ⭐⭐⭐

**現状**: ランダム分割（時系列性を無視）

**改善策**: TimeSeriesSplit

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_idx, val_idx in tscv.split(X):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
    # 学習と評価
```

**期待効果**:

- より正確なパフォーマンス評価
- 過学習の検出
- リークの防止

---

#### 8. 特徴量選択の最適化 ⭐⭐⭐

**現状**: 全特徴量を使用（一部は低寄与度）

**改善策**: SHAP 値ベースの特徴量選択

```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# 重要度の高い上位50個を選択
feature_importance = np.abs(shap_values).mean(axis=0)
top_features = np.argsort(feature_importance)[-50:]

X_train_selected = X_train.iloc[:, top_features]
X_test_selected = X_test.iloc[:, top_features]
```

**期待効果**:

- 計算速度の向上
- 過学習の抑制
- F1 スコア: +0-2%

---

#### 9. ハイパーパラメータ範囲の拡大 ⭐⭐

**現状**:

```python
"learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True)
"max_depth": trial.suggest_int("max_depth", 3, 10)
```

**改善策**: より広い範囲で探索

```python
"learning_rate": trial.suggest_float("learning_rate", 0.001, 0.5, log=True)
"max_depth": trial.suggest_int("max_depth", 3, 15)
"n_estimators": trial.suggest_int("n_estimators", 50, 1000)
```

**期待効果**:

- より良いパラメータの発見
- F1 スコア: +1-2%
- 実行時間: 増加（試行回数を調整）

---

## 📋 実装ロードマップ

### Phase 1: 即時改善（今日中）

**所要時間**: 10 分  
**期待改善**: F1 スコア 42.72% → 47-50%

1. ✅ クラスウェイト有効化
2. ✅ 予測期間を 8 時間に延長
3. ✅ 動的閾値の調整

**実行コマンド**:

```powershell
# 環境変数を設定
$env:ML__TRAINING__USE_CLASS_WEIGHT = "true"
$env:ML__TRAINING__USE_SMOTE = "true"
$env:ML__LABEL_GENERATION__DEFAULT_PRESET = "1h_8bars_dynamic"

# 再実行（試行回数を30に削減して高速化）
conda run -n trading python backend/scripts/ml_optimization/train_optimized_models.py --n-trials 30
```

---

### Phase 2: 構造改善（1-2 日）

**所要時間**: 2-3 時間  
**期待改善**: F1 スコア 47-50% → 55-60%

1. ✅ 2 クラス分類モデルの実装
2. ✅ ボラティリティ正規化特徴量の統合
3. ✅ アンサンブルモデルの構築

---

### Phase 3: 高度な最適化（1 週間）

**所要時間**: 1 週間  
**期待改善**: F1 スコア 55-60% → 60-65%

1. 時系列分割 CV
2. SHAP 値ベースの特徴量選択
3. ディープラーニングモデルの検討（LSTM, Transformer）
4. オンチェーンデータの追加
5. マクロ経済指標の統合

---

## 🔧 環境変数設定ガイド

### Windows PowerShell

```powershell
# 一時的な設定（現在のセッションのみ）
$env:ML__TRAINING__USE_CLASS_WEIGHT = "true"
$env:ML__TRAINING__USE_SMOTE = "true"
$env:ML__LABEL_GENERATION__DEFAULT_PRESET = "1h_8bars_dynamic"

# 永続的な設定（ユーザー環境変数）
[System.Environment]::SetEnvironmentVariable("ML__TRAINING__USE_CLASS_WEIGHT", "true", "User")
[System.Environment]::SetEnvironmentVariable("ML__TRAINING__USE_SMOTE", "true", "User")
[System.Environment]::SetEnvironmentVariable("ML__LABEL_GENERATION__DEFAULT_PRESET", "1h_8bars_dynamic", "User")
```

### .env ファイル

`backend/.env` を作成:

```bash
# クラス不均衡対策
ML__TRAINING__USE_CLASS_WEIGHT=true
ML__TRAINING__CLASS_WEIGHT_MODE=balanced
ML__TRAINING__USE_SMOTE=true
ML__TRAINING__SMOTE_METHOD=adasyn

# ラベル生成設定
ML__LABEL_GENERATION__DEFAULT_PRESET=1h_8bars_dynamic
ML__LABEL_GENERATION__USE_PRESET=true

# または、カスタム設定
# ML__LABEL_GENERATION__USE_PRESET=false
# ML__LABEL_GENERATION__TIMEFRAME=1h
# ML__LABEL_GENERATION__HORIZON_N=12
# ML__LABEL_GENERATION__THRESHOLD_METHOD=QUANTILE
# ML__LABEL_GENERATION__THRESHOLD=0.33
```

---

## 📊 期待される改善効果

### 保守的な見積もり

| Phase       | 施策         | F1 スコア | DOWN Recall | 所要時間 |
| ----------- | ------------ | --------- | ----------- | -------- |
| **現在**    | -            | 42.72%    | 30.13%      | -        |
| **Phase 1** | 環境変数設定 | 47-50%    | 40-45%      | 10 分    |
| **Phase 2** | コード変更   | 55-60%    | 45-50%      | 2-3 時間 |
| **Phase 3** | 高度な最適化 | 60-65%    | 50-55%      | 1 週間   |

### 楽観的な見積もり

| Phase       | F1 スコア | DOWN Recall |
| ----------- | --------- | ----------- |
| **Phase 1** | 50-52%    | 45-48%      |
| **Phase 2** | 58-62%    | 50-55%      |
| **Phase 3** | 65-70%    | 55-60%      |

---

## ⚠️ 注意事項とリスク

### 高リスク項目

1. **2 クラス分類への変更**

   - リスク: コード変更によるバグ
   - 対策: 段階的実装、テストの実施

2. **特徴量の大幅追加**
   - リスク: 過学習、計算時間増加
   - 対策: クロスバリデーション、特徴量選択

### 低リスク項目

1. **環境変数による設定変更**

   - リスク: ほぼなし
   - 即座に元に戻せる

2. **予測期間の延長**
   - リスク: 低い
   - トレード戦略の調整のみ

---

## 🎯 推奨アクション（今すぐ実行）

### ステップ 1: 環境変数設定

```powershell
# PowerShellで実行
$env:ML__TRAINING__USE_CLASS_WEIGHT = "true"
$env:ML__TRAINING__USE_SMOTE = "true"
$env:ML__LABEL_GENERATION__DEFAULT_PRESET = "1h_8bars_dynamic"
```

### ステップ 2: 高速実験実行

```powershell
# 試行回数を20に減らして高速検証
conda run -n trading python backend/scripts/ml_optimization/train_optimized_models.py --n-trials 20
```

### ステップ 3: 結果確認

```powershell
# 最新の結果を確認
Get-ChildItem backend\results\optimization | Sort-Object LastWriteTime -Descending | Select-Object -First 1 | ForEach-Object { Get-Content "$($_.FullName)\optimization_report.md" }
```

### ステップ 4: 改善確認

比較ポイント:

- F1 スコアが 47%以上になったか？
- DOWN クラスの Recall が 40%以上になったか？
- ROC-AUC スコアが 0.65 以上になったか？

---

## 📚 参考資料

### 利用可能なプリセット

現在のシステムで使用可能なラベル生成プリセット:

```python
"1h_4bars",           # 1時間足、4時間先、0.2%閾値
"1h_8bars",           # 1時間足、8時間先、0.3%閾値
"1h_16bars",          # 1時間足、16時間先、0.4%閾値
"1h_4bars_dynamic",   # 1時間足、4時間先、動的閾値 ← 現在使用中
"1h_8bars_dynamic",   # 1時間足、8時間先、動的閾値 ← 推奨
"4h_4bars",           # 4時間足、16時間先、0.2%閾値
"4h_4bars_dynamic",   # 4時間足、16時間先、動的閾値
"4h_4bars_050",       # 4時間足、16時間先、0.5%閾値
"4h_4bars_100",       # 4時間足、16時間先、1.0%閾値
```

### 閾値計算方法

```python
ThresholdMethod.FIXED             # 固定閾値
ThresholdMethod.STD_DEVIATION     # 標準偏差ベース
ThresholdMethod.QUANTILE          # 分位数ベース ← 推奨
ThresholdMethod.KBINS_DISCRETIZER # KBins（均等分割）← 現在使用中
ThresholdMethod.ADAPTIVE          # 適応的閾値
ThresholdMethod.DYNAMIC_VOLATILITY # 動的ボラティリティ
```

---

## 💡 FAQ

### Q1: なぜ DOWN クラスの精度が低いのか？

**A**: 主な原因は以下の通り:

1. クラス不均衡対策が無効化されている
2. モデルが多数派クラス（RANGE）に偏っている
3. 下落の特徴量が不十分

### Q2: 42%の F1 スコアは実用的か？

**A**: 実用性は低いです:

- 3 クラス分類のランダム baseline: 33%
- 現状は baseline+9% の改善のみ
- 実トレードには最低 50-55%が必要
- ただし、ROC-AUC=0.62 は「完全ランダムではない」ことを示す

### Q3: 最も効果的な単一施策は？

**A**: **2 クラス分類への変更**です:

- 期待改善: +10-15%
- タスクの難易度が大幅に下がる
- より実用的な判断（トレンドかレンジか）

### Q4: すぐに結果を見たい場合は？

**A**: Phase 1 を今すぐ実行してください:

- 所要時間: 約 20 分（設定 5 分+実行 15 分）
- 期待改善: +3-7%
- リスク: ほぼゼロ

---

## 📝 変更履歴

- **2025-11-23**: 初版作成
  - 現状分析と改善策を文書化
  - 優先度別アクションプランを策定
  - 環境変数設定ガイドを追加

---

**次のステップ**: Phase 1 の環境変数設定を今すぐ実行し、結果を確認してください！
