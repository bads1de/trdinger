"""
æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.services.ml.lightgbm_trainer import LightGBMTrainer
from app.core.services.ml.ml_training_service import (
    MLTrainingService,
    OptimizationSettings,
)


def create_test_data():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    np.random.seed(42)

    # 1000è¡Œã®OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    dates = pd.date_range(start="2023-01-01", periods=1000, freq="1H")

    data = {
        "timestamp": dates,
        "Open": np.random.uniform(40000, 50000, 1000),
        "High": np.random.uniform(40000, 50000, 1000),
        "Low": np.random.uniform(40000, 50000, 1000),
        "Close": np.random.uniform(40000, 50000, 1000),
        "Volume": np.random.uniform(100, 1000, 1000),
    }

    # Highã¨Lowã‚’èª¿æ•´
    for i in range(1000):
        data["High"][i] = max(data["Open"][i], data["Close"][i]) + np.random.uniform(
            0, 100
        )
        data["Low"][i] = min(data["Open"][i], data["Close"][i]) - np.random.uniform(
            0, 100
        )

    return pd.DataFrame(data)


def test_parameter_application():
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãé©ç”¨ã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é©ç”¨ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    training_data = create_test_data()

    # LightGBMTrainerã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
    trainer = LightGBMTrainer()

    # ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å­¦ç¿’
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    result1 = trainer.train_model(
        training_data=training_data, save_model=False, test_size=0.2, random_state=42
    )
    print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµæœ: ç²¾åº¦={result1.get('accuracy', 'N/A'):.4f}")

    # ãƒ†ã‚¹ãƒˆ2: ç•°ãªã‚‹learning_rateã§ã®å­¦ç¿’
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆ2: learning_rate=0.01")
    result2 = trainer.train_model(
        training_data=training_data,
        save_model=False,
        test_size=0.2,
        random_state=42,
        learning_rate=0.01,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ˆã‚Šå°ã•ã„å€¤
    )
    print(f"learning_rate=0.01çµæœ: ç²¾åº¦={result2.get('accuracy', 'N/A'):.4f}")

    # ãƒ†ã‚¹ãƒˆ3: ç•°ãªã‚‹num_leavesã§ã®å­¦ç¿’
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆ3: num_leaves=10")
    result3 = trainer.train_model(
        training_data=training_data,
        save_model=False,
        test_size=0.2,
        random_state=42,
        num_leaves=10,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ˆã‚Šå°ã•ã„å€¤
    )
    print(f"num_leaves=10çµæœ: ç²¾åº¦={result3.get('accuracy', 'N/A'):.4f}")

    # ãƒ†ã‚¹ãƒˆ4: è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒæ™‚å¤‰æ›´
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆ4: è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´")
    result4 = trainer.train_model(
        training_data=training_data,
        save_model=False,
        test_size=0.2,
        random_state=42,
        learning_rate=0.2,
        num_leaves=50,
        feature_fraction=0.7,
    )
    print(f"è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´çµæœ: ç²¾åº¦={result4.get('accuracy', 'N/A'):.4f}")

    # çµæœæ¯”è¼ƒ
    print("\nğŸ“ˆ çµæœæ¯”è¼ƒ:")
    results = [
        ("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", result1.get("accuracy", 0)),
        ("learning_rate=0.01", result2.get("accuracy", 0)),
        ("num_leaves=10", result3.get("accuracy", 0)),
        ("è¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿", result4.get("accuracy", 0)),
    ]

    for name, accuracy in results:
        print(f"  {name}: {accuracy:.4f}")

    # ç²¾åº¦ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¢ºèª
    accuracies = [r[1] for r in results]
    unique_accuracies = len(set(accuracies))

    if unique_accuracies > 1:
        print("âœ… ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãé©ç”¨ã•ã‚Œã¦ã„ã¾ã™ï¼ˆç²¾åº¦ãŒå¤‰åŒ–ã—ã¦ã„ã‚‹ï¼‰")
        return True
    else:
        print("âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆç²¾åº¦ãŒåŒã˜ï¼‰")
        return False


def test_optimization_service():
    """æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸš€ æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    training_data = create_test_data()

    # æœ€é©åŒ–è¨­å®š
    optimization_settings = OptimizationSettings(
        enabled=True,
        method="random",
        n_calls=3,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ãªãè¨­å®š
        parameter_space={
            "learning_rate": {"type": "real", "low": 0.01, "high": 0.2},
            "num_leaves": {"type": "integer", "low": 10, "high": 50},
        },
    )

    # MLTrainingServiceã§ãƒ†ã‚¹ãƒˆ
    service = MLTrainingService()

    try:
        result = service.train_model(
            training_data=training_data,
            save_model=False,
            optimization_settings=optimization_settings,
            random_state=42,
        )

        print(
            f"æœ€é©åŒ–çµæœ: {result.get('optimization_result', {}).get('best_score', 'N/A')}"
        )
        print("âœ… æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        return True

    except Exception as e:
        print(f"âŒ æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return False


if __name__ == "__main__":
    print("ğŸ”¬ MLæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")
    print("=" * 60)

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é©ç”¨ãƒ†ã‚¹ãƒˆ
    param_test_passed = test_parameter_application()

    # æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ
    optimization_test_passed = test_optimization_service()

    print("\n" + "=" * 60)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é©ç”¨ãƒ†ã‚¹ãƒˆ: {'âœ… PASS' if param_test_passed else 'âŒ FAIL'}")
    print(
        f"  æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ: {'âœ… PASS' if optimization_test_passed else 'âŒ FAIL'}"
    )

    if param_test_passed and optimization_test_passed:
        print("\nğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    else:
        print("\nâš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
