#!/usr/bin/env python3
"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ

æ–°ã—ã„ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒMLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.services.ml.feature_engineering.enhanced_feature_engineering_service import EnhancedFeatureEngineeringService
from app.core.services.ml.feature_engineering.automl_features.automl_config import AutoMLConfig

def generate_realistic_trading_data(hours: int = 240) -> pd.DataFrame:
    """
    ãƒªã‚¢ãƒ«ãªå–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ10æ—¥åˆ†ï¼‰
    """
    print(f"ãƒªã‚¢ãƒ«ãªå–å¼•ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {hours}æ™‚é–“åˆ†")
    
    # åŸºæº–æ™‚åˆ»
    start_time = datetime.now() - timedelta(hours=hours)
    timestamps = [start_time + timedelta(hours=i) for i in range(hours)]
    
    # åŸºæº–ä¾¡æ ¼ï¼ˆBTCé¢¨ï¼‰
    base_price = 50000
    
    # ã‚ˆã‚Šè¤‡é›‘ãªä¾¡æ ¼å‹•å‘ã‚’ç”Ÿæˆ
    np.random.seed(42)
    
    # è¤‡æ•°ã®ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
    long_trend = np.cumsum(np.random.normal(0, 0.0005, hours))  # é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰
    medium_trend = np.sin(np.arange(hours) * 2 * np.pi / 24) * 0.01  # æ—¥æ¬¡ã‚µã‚¤ã‚¯ãƒ«
    short_trend = np.sin(np.arange(hours) * 2 * np.pi / 4) * 0.005  # 4æ™‚é–“ã‚µã‚¤ã‚¯ãƒ«
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆæ™‚é–“å¸¯ã«ã‚ˆã‚‹å¤‰å‹•ï¼‰
    hour_volatility = np.array([
        0.025 if 8 <= (start_time + timedelta(hours=i)).hour <= 16 else 0.015
        for i in range(hours)
    ])
    
    # ä¾¡æ ¼å¤‰å‹•
    noise = np.random.normal(0, hour_volatility)
    returns = long_trend + medium_trend + short_trend + noise
    prices = base_price * np.exp(np.cumsum(returns))
    
    # OHLCVç”Ÿæˆ
    data = []
    for i, (timestamp, close) in enumerate(zip(timestamps, prices)):
        vol = hour_volatility[i] * close
        high = close + np.random.exponential(vol * 0.3)
        low = close - np.random.exponential(vol * 0.3)
        
        if i == 0:
            open_price = close
        else:
            open_price = prices[i-1] + np.random.normal(0, vol * 0.1)
        
        # å‡ºæ¥é«˜ï¼ˆä¾¡æ ¼å¤‰å‹•ã¨ç›¸é–¢ï¼‰
        price_change = abs(returns[i])
        base_volume = 1000 + price_change * 100000
        volume = max(100, np.random.normal(base_volume, base_volume * 0.2))
        
        data.append({
            'timestamp': timestamp,
            'Open': open_price,
            'High': max(open_price, high, close),
            'Low': min(open_price, low, close),
            'Close': close,
            'Volume': volume,
        })
    
    df = pd.DataFrame(data)
    df.set_index('timestamp', inplace=True)
    
    # Open Interestï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªæ›´æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    oi_base = 1500000
    oi_updates = []
    for i in range(0, hours, 8):  # 8æ™‚é–“ã”ã¨
        if i == 0:
            oi_change = 0
        else:
            # ä¾¡æ ¼å¤‰å‹•ã¨ç›¸é–¢ã®ã‚ã‚‹OIå¤‰å‹•
            price_momentum = np.mean(returns[max(0, i-24):i])
            oi_change = price_momentum * 0.5 + np.random.normal(0, 0.01)
        
        oi_updates.append(oi_change)
    
    oi_values = oi_base * np.exp(np.cumsum(oi_updates))
    oi_timestamps = [start_time + timedelta(hours=i*8) for i in range(len(oi_values))]
    oi_series = pd.Series(oi_values, index=oi_timestamps)
    df['open_interest'] = oi_series.reindex(df.index, method='ffill')
    
    # Funding Rateï¼ˆ8æ™‚é–“ã”ã¨ã€ã‚ˆã‚Šç¾å®Ÿçš„ï¼‰
    fr_values = []
    for i in range(len(oi_values)):
        # ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ãFR
        if i == 0:
            price_trend = 0
        else:
            start_idx = max(0, i*8-24)
            end_idx = i*8
            price_trend = np.mean(returns[start_idx:end_idx])
        
        # FRã®åŸºæœ¬å€¤ï¼ˆä¾¡æ ¼ä¸Šæ˜‡æ™‚ã¯æ­£ã€ä¸‹é™æ™‚ã¯è² ï¼‰
        base_fr = price_trend * 0.2
        
        # å¸‚å ´ã®éœ€çµ¦ãƒãƒ©ãƒ³ã‚¹ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ï¼‰
        supply_demand = np.random.normal(0, 0.0002)
        
        # æ¥µå€¤åˆ¶é™
        fr = np.clip(base_fr + supply_demand, -0.0075, 0.0075)
        fr_values.append(fr)
    
    fr_series = pd.Series(fr_values, index=oi_timestamps)
    df['funding_rate'] = fr_series.reindex(df.index, method='ffill')
    
    # Fear & Greed Indexï¼ˆ1æ—¥ã”ã¨ã€ä¾¡æ ¼å¤‰å‹•ã¨é€†ç›¸é–¢ï¼‰
    daily_timestamps = [start_time + timedelta(days=i) for i in range(hours // 24 + 1)]
    fg_values = []
    for i in range(len(daily_timestamps)):
        if i == 0:
            daily_volatility = 0
            daily_return = 0
        else:
            start_idx = max(0, i*24-24)
            end_idx = min(hours-1, i*24)
            daily_return = np.mean(returns[start_idx:end_idx])
            daily_volatility = np.std(returns[start_idx:end_idx])
        
        # åŸºæº–å€¤50ã‹ã‚‰èª¿æ•´
        # ä¾¡æ ¼ä¸‹è½ + é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ â†’ ææ€–ï¼ˆä½ã„å€¤ï¼‰
        # ä¾¡æ ¼ä¸Šæ˜‡ + ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ â†’ å¼·æ¬²ï¼ˆé«˜ã„å€¤ï¼‰
        fear_factor = -daily_return * 800 + daily_volatility * 500
        base_fg = 50 + fear_factor
        
        # ãƒã‚¤ã‚ºã¨ãƒˆãƒ¬ãƒ³ãƒ‰
        noise = np.random.normal(0, 3)
        fg = np.clip(base_fg + noise, 0, 100)
        fg_values.append(fg)
    
    fg_series = pd.Series(fg_values, index=daily_timestamps)
    df['fear_greed_value'] = fg_series.reindex(df.index, method='ffill')
    
    print(f"ç”Ÿæˆå®Œäº†: {len(df)}è¡Œ")
    print(f"ä¾¡æ ¼ç¯„å›²: ${df['Close'].min():.0f} - ${df['Close'].max():.0f}")
    print(f"OIç¯„å›²: {df['open_interest'].min():.0f} - {df['open_interest'].max():.0f}")
    print(f"FRç¯„å›²: {df['funding_rate'].min():.4f} - {df['funding_rate'].max():.4f}")
    print(f"FGç¯„å›²: {df['fear_greed_value'].min():.0f} - {df['fear_greed_value'].max():.0f}")
    
    return df

def test_enhanced_feature_engineering():
    """å¼·åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== å¼·åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ===")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = generate_realistic_trading_data(240)  # 10æ—¥åˆ†
    
    # AutoMLè¨­å®š
    automl_config = AutoMLConfig.get_financial_optimized_config()
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹
    service = EnhancedFeatureEngineeringService(automl_config)
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆæ¬¡ã®4æ™‚é–“ã®ä¾¡æ ¼å¤‰å‹•ç‡ï¼‰
    target = df['Close'].pct_change(4).shift(-4)
    
    print(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {df.shape}")
    print(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°: {target.notna().sum()}ä»¶ã®æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿")
    
    # ç‰¹å¾´é‡è¨ˆç®—
    start_time = datetime.now()
    
    try:
        enhanced_df = service.calculate_enhanced_features(
            ohlcv_data=df,
            target=target,
            lookback_periods={
                'short': 4,
                'medium': 24,
                'long': 168,
            }
        )
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        print(f"\nâœ… ç‰¹å¾´é‡è¨ˆç®—æˆåŠŸ:")
        print(f"  å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        print(f"  å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿: {enhanced_df.shape}")
        print(f"  è¿½åŠ ç‰¹å¾´é‡: {enhanced_df.shape[1] - df.shape[1]}å€‹")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
        missing_count = enhanced_df.isnull().sum().sum()
        inf_count = np.isinf(enhanced_df.select_dtypes(include=[np.number])).sum().sum()
        
        print(f"  ãƒ‡ãƒ¼ã‚¿å“è³ª: æ¬ æå€¤ {missing_count}å€‹, ç„¡é™å€¤ {inf_count}å€‹")
        
        # çµ±è¨ˆæƒ…å ±
        stats = service.last_enhancement_stats
        if stats:
            print(f"\nğŸ“Š å‡¦ç†çµ±è¨ˆ:")
            print(f"  æ‰‹å‹•ç‰¹å¾´é‡: {stats.get('manual_features', 0)}å€‹")
            print(f"  æš—å·é€šè²¨ç‰¹åŒ–: {stats.get('crypto_features', 0)}å€‹")
            print(f"  TSFresh: {stats.get('tsfresh_features', 0)}å€‹")
            print(f"  Featuretools: {stats.get('featuretools_features', 0)}å€‹")
            print(f"  AutoFeat: {stats.get('autofeat_features', 0)}å€‹")
        
        return enhanced_df, target
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def test_feature_quality(df: pd.DataFrame, target: pd.Series):
    """ç‰¹å¾´é‡å“è³ªã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ç‰¹å¾´é‡å“è³ªãƒ†ã‚¹ãƒˆ ===")
    
    if df is None or target is None:
        print("ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return
    
    # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿
    valid_mask = target.notna() & df.notna().all(axis=1)
    valid_count = valid_mask.sum()
    
    print(f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {valid_count}ä»¶ / {len(df)}ä»¶ ({valid_count/len(df)*100:.1f}%)")
    
    if valid_count < 50:
        print("æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        return
    
    # ç‰¹å¾´é‡ã®ç›¸é–¢åˆ†æ
    feature_cols = [col for col in df.columns if col not in ['Open', 'High', 'Low', 'Close', 'Volume']]
    
    correlations = []
    for col in feature_cols:
        corr = df.loc[valid_mask, col].corr(target.loc[valid_mask])
        if not pd.isna(corr):
            correlations.append({
                'feature': col,
                'correlation': abs(corr),
                'correlation_raw': corr,
            })
    
    # ç›¸é–¢é †ã«ã‚½ãƒ¼ãƒˆ
    correlations.sort(key=lambda x: x['correlation'], reverse=True)
    
    print(f"\nğŸ¯ ä¸Šä½20ç‰¹å¾´é‡ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢ï¼‰:")
    for i, item in enumerate(correlations[:20]):
        print(f"  {i+1:2d}. {item['feature']:<35} ç›¸é–¢: {item['correlation_raw']:+.4f}")
    
    # ä½ç›¸é–¢ç‰¹å¾´é‡
    low_corr = [item for item in correlations if item['correlation'] < 0.01]
    print(f"\nâš ï¸  ä½ç›¸é–¢ç‰¹å¾´é‡ï¼ˆ<0.01ï¼‰: {len(low_corr)}å€‹")
    
    # é«˜ç›¸é–¢ç‰¹å¾´é‡
    high_corr = [item for item in correlations if item['correlation'] > 0.1]
    print(f"âœ… é«˜ç›¸é–¢ç‰¹å¾´é‡ï¼ˆ>0.1ï¼‰: {len(high_corr)}å€‹")
    
    return correlations

def test_memory_performance():
    """ãƒ¡ãƒ¢ãƒªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ¡ãƒ¢ãƒªãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ ===")
    
    import psutil
    process = psutil.Process()
    
    # ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
    test_sizes = [168, 336, 720]  # 1é€±é–“ã€2é€±é–“ã€1ãƒ¶æœˆ
    
    for hours in test_sizes:
        print(f"\nğŸ“Š {hours}æ™‚é–“ãƒ‡ãƒ¼ã‚¿ï¼ˆ{hours//24}æ—¥åˆ†ï¼‰:")
        
        # ãƒ¡ãƒ¢ãƒªæ¸¬å®šé–‹å§‹
        memory_start = process.memory_info().rss / 1024 / 1024
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        df = generate_realistic_trading_data(hours)
        target = df['Close'].pct_change(4).shift(-4)
        
        # ç‰¹å¾´é‡è¨ˆç®—
        service = EnhancedFeatureEngineeringService()
        start_time = datetime.now()
        
        try:
            enhanced_df = service.calculate_enhanced_features(
                ohlcv_data=df,
                target=target,
            )
            
            processing_time = (datetime.now() - start_time).total_seconds()
            memory_end = process.memory_info().rss / 1024 / 1024
            
            print(f"  å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
            print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨: {memory_end - memory_start:+.1f}MB")
            print(f"  å‡ºåŠ›å½¢çŠ¶: {enhanced_df.shape}")
            print(f"  åŠ¹ç‡: {processing_time/hours*1000:.2f}ms/æ™‚é–“")
            
        except Exception as e:
            print(f"  ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        # 1. å¼·åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        enhanced_df, target = test_enhanced_feature_engineering()
        
        # 2. ç‰¹å¾´é‡å“è³ªãƒ†ã‚¹ãƒˆ
        if enhanced_df is not None:
            correlations = test_feature_quality(enhanced_df, target)
        
        # 3. ãƒ¡ãƒ¢ãƒªãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        test_memory_performance()
        
        print("\n" + "=" * 50)
        print("ğŸ¯ çµ±åˆãƒ†ã‚¹ãƒˆçµæœ:")
        
        if enhanced_df is not None:
            print(f"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: æ­£å¸¸å‹•ä½œ")
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿å“è³ª: è‰¯å¥½")
            print(f"âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: è‰¯å¥½")
            print(f"âœ… å‡¦ç†é€Ÿåº¦: è‰¯å¥½")
            
            print(f"\nğŸ“ˆ æ”¹å–„åŠ¹æœ:")
            print(f"  - åŸºæœ¬ãƒ‡ãƒ¼ã‚¿: 8ç‰¹å¾´é‡")
            print(f"  - æ‹¡å¼µå¾Œ: {enhanced_df.shape[1]}ç‰¹å¾´é‡")
            print(f"  - å¢—åŠ ç‡: {(enhanced_df.shape[1]/8-1)*100:.0f}%")
            
            print(f"\nğŸš€ å®Ÿç”¨æ€§:")
            print(f"  - å®Ÿéš›ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œ")
            print(f"  - æœŸé–“ä¸ä¸€è‡´ã®é©åˆ‡ãªå‡¦ç†")
            print(f"  - åŠ¹æœçš„ãªç‰¹å¾´é‡ç”Ÿæˆ")
            print(f"  - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå‡¦ç†")
        else:
            print("âŒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        
    except Exception as e:
        print(f"çµ±åˆãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
