#!/usr/bin/env python3
"""
Fear & Greed Index å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¨æœŸé–“ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿åé›†æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã€ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã¾ã™ã€‚
"""

import asyncio
import logging
import sys
import os
from datetime import datetime, timezone

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import SessionLocal, init_db
from database.repositories.fear_greed_repository import FearGreedIndexRepository
from data_collector.external_market_collector import ExternalMarketDataCollector

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def test_full_historical_collection():
    """å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ã®ãƒ†ã‚¹ãƒˆ"""
    logger.info("ğŸš€ Fear & Greed Index å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    init_db()
    
    with SessionLocal() as db:
        repository = FearGreedIndexRepository(db)
        
        # åé›†å‰ã®çŠ¶æ…‹ç¢ºèª
        logger.info("ğŸ“Š åé›†å‰ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹ç¢ºèª")
        before_status = repository.get_data_range()
        logger.info(f"åé›†å‰ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {before_status['total_count']}")
        logger.info(f"åé›†å‰ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {before_status['oldest_data']} ï½ {before_status['newest_data']}")
        
        # å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œ
        logger.info("\nğŸ“¥ å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œä¸­...")
        async with ExternalMarketDataCollector() as collector:
            result = await collector.collect_historical_fear_greed_data(
                limit=1000,  # æœ€å¤§1000ä»¶
                db_session=db
            )
        
        if not result["success"]:
            logger.error(f"âŒ å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—: {result.get('error', 'Unknown error')}")
            return False
        
        logger.info(f"âœ… å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†æˆåŠŸ!")
        logger.info(f"å–å¾—ä»¶æ•°: {result['fetched_count']}")
        logger.info(f"æŒ¿å…¥ä»¶æ•°: {result['inserted_count']}")
        logger.info(f"åé›†ã‚¿ã‚¤ãƒ—: {result.get('collection_type', 'unknown')}")
        
        # åé›†å¾Œã®çŠ¶æ…‹ç¢ºèª
        logger.info("\nğŸ“Š åé›†å¾Œã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ…‹ç¢ºèª")
        after_status = repository.get_data_range()
        logger.info(f"åé›†å¾Œãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {after_status['total_count']}")
        logger.info(f"åé›†å¾Œãƒ‡ãƒ¼ã‚¿ç¯„å›²: {after_status['oldest_data']} ï½ {after_status['newest_data']}")
        
        # ãƒ‡ãƒ¼ã‚¿å¢—åŠ é‡ã®ç¢ºèª
        data_increase = after_status['total_count'] - before_status['total_count']
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å¢—åŠ é‡: {data_increase}ä»¶")
        
        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª
        logger.info("\nğŸ“ˆ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª")
        latest_data = repository.get_latest_fear_greed_data(limit=5)
        
        if latest_data:
            logger.info(f"æœ€æ–°ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(latest_data)}")
            for i, data in enumerate(latest_data[:3]):  # æœ€æ–°3ä»¶ã‚’è¡¨ç¤º
                logger.info(f"  {i+1}. æ—¥ä»˜: {data.data_timestamp.strftime('%Y-%m-%d')}, "
                           f"å€¤: {data.value}, åˆ†é¡: {data.value_classification}")
        else:
            logger.warning("âš ï¸ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        logger.info("\nğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯")
        
        # 1. å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
        invalid_values = db.query(repository.model_class).filter(
            (repository.model_class.value < 0) | (repository.model_class.value > 100)
        ).count()
        
        if invalid_values > 0:
            logger.error(f"âŒ ç„¡åŠ¹ãªå€¤ã®ãƒ‡ãƒ¼ã‚¿ãŒ {invalid_values} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            return False
        else:
            logger.info("âœ… å…¨ã¦ã®å€¤ãŒæœ‰åŠ¹ç¯„å›²ï¼ˆ0-100ï¼‰å†…ã§ã™")
        
        # 2. åˆ†é¡ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        valid_classifications = [
            "Extreme Fear", "Fear", "Neutral", "Greed", "Extreme Greed"
        ]
        invalid_classifications = db.query(repository.model_class).filter(
            ~repository.model_class.value_classification.in_(valid_classifications)
        ).count()
        
        if invalid_classifications > 0:
            logger.error(f"âŒ ç„¡åŠ¹ãªåˆ†é¡ã®ãƒ‡ãƒ¼ã‚¿ãŒ {invalid_classifications} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            return False
        else:
            logger.info("âœ… å…¨ã¦ã®åˆ†é¡ãŒæœ‰åŠ¹ã§ã™")
        
        # 3. é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        from sqlalchemy import func
        duplicate_count = db.query(
            repository.model_class.data_timestamp,
            func.count(repository.model_class.id).label('count')
        ).group_by(
            repository.model_class.data_timestamp
        ).having(
            func.count(repository.model_class.id) > 1
        ).count()
        
        if duplicate_count > 0:
            logger.warning(f"âš ï¸ é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãŒ {duplicate_count} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        else:
            logger.info("âœ… é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        # 4. ãƒ‡ãƒ¼ã‚¿é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if after_status['total_count'] >= 2:
            # æœ€å¤ã¨æœ€æ–°ã®æ—¥ä»˜å·®ã‚’è¨ˆç®—
            try:
                oldest = datetime.fromisoformat(after_status['oldest_data'].replace('Z', '+00:00'))
                newest = datetime.fromisoformat(after_status['newest_data'].replace('Z', '+00:00'))
                date_diff = (newest - oldest).days
                
                logger.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {date_diff}æ—¥é–“")
                logger.info(f"ãƒ‡ãƒ¼ã‚¿å¯†åº¦: {after_status['total_count'] / max(date_diff, 1):.2f}ä»¶/æ—¥")
                
                # æœŸå¾…ã•ã‚Œã‚‹æœ€å°ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆ1æ—¥1ä»¶ã¨ã—ã¦ï¼‰
                expected_min_count = max(date_diff * 0.8, 1)  # 80%ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æœŸå¾…
                
                if after_status['total_count'] >= expected_min_count:
                    logger.info("âœ… ãƒ‡ãƒ¼ã‚¿å¯†åº¦ã¯é©åˆ‡ã§ã™")
                else:
                    logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å¯†åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆæœŸå¾…å€¤: {expected_min_count:.0f}ä»¶ä»¥ä¸Šï¼‰")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 5. æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®æ–°ã—ã•ãƒã‚§ãƒƒã‚¯
        if latest_data:
            latest_timestamp = latest_data[0].data_timestamp
            now = datetime.now(timezone.utc)
            hours_diff = (now - latest_timestamp.replace(tzinfo=timezone.utc)).total_seconds() / 3600
            
            if hours_diff <= 48:  # 48æ™‚é–“ä»¥å†…
                logger.info(f"âœ… æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã¯æ–°ã—ã„ã§ã™ï¼ˆ{hours_diff:.1f}æ™‚é–“å‰ï¼‰")
            else:
                logger.warning(f"âš ï¸ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆ{hours_diff:.1f}æ™‚é–“å‰ï¼‰")
        
        # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 80)
        logger.info(f"âœ… åé›†æˆåŠŸ: {result['success']}")
        logger.info(f"ğŸ“¥ å–å¾—ä»¶æ•°: {result['fetched_count']}")
        logger.info(f"ğŸ’¾ æŒ¿å…¥ä»¶æ•°: {result['inserted_count']}")
        logger.info(f"ğŸ“ˆ ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {after_status['total_count']}")
        logger.info(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {after_status['oldest_data']} ï½ {after_status['newest_data']}")
        logger.info(f"ğŸ”¢ ãƒ‡ãƒ¼ã‚¿å¢—åŠ : +{data_increase}ä»¶")
        
        if after_status['total_count'] > 0:
            logger.info("ğŸ‰ å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
            logger.info("Fear & Greed Index ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«åé›†ãƒ»ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            return True
        else:
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãŒåé›†ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return False


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        success = await test_full_historical_collection()
        
        if success:
            logger.info("\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            logger.info("1. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’ç¢ºèª")
            logger.info("2. å®šæœŸçš„ãªå·®åˆ†åé›†ã®è¨­å®š")
            logger.info("3. ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–æ©Ÿèƒ½ã®å®Ÿè£…")
            logger.info("4. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¸ã®çµ±åˆ")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
