#!/usr/bin/env python3
"""
15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰

æ©Ÿèƒ½:
- 15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ãªçŠ¶æ³ç¢ºèª
- ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—åˆ†æã¨ä»–ã®æ™‚é–“è»¸ã¨ã®æ¯”è¼ƒ
- æœŸé–“æŒ‡å®šãƒ‡ãƒ¼ã‚¿åé›†
- ä»–ã®æ™‚é–“è»¸ã¨ã®åŒæœŸæ©Ÿèƒ½
- åŠ¹ç‡çš„ãªå·®åˆ†ãƒ‡ãƒ¼ã‚¿åé›†
"""

import asyncio
import logging
import sys
import os
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Tuple


# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import SessionLocal, init_db
from database.repositories.ohlcv_repository import OHLCVRepository
from app.core.services.historical_data_service import HistoricalDataService
from app.core.services.market_data_service import BybitMarketDataService
from database.models import OHLCVData
from sqlalchemy import func

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class Enhanced15mDataManager:
    """15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®æ‹¡å¼µã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.symbol = "BTC/USDT:USDT"
        self.timeframe = "15m"
        self.all_timeframes = ["15m", "30m", "1h", "4h", "1d"]

    def get_timeframe_stats(self) -> Dict:
        """å…¨æ™‚é–“è»¸ã®ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚’å–å¾—"""
        db = SessionLocal()
        try:
            repo = OHLCVRepository(db)
            stats = {}

            for tf in self.all_timeframes:
                count = repo.get_data_count(self.symbol, tf)
                if count > 0:
                    oldest = repo.get_oldest_timestamp(self.symbol, tf)
                    latest = repo.get_latest_timestamp(self.symbol, tf)
                    duration = (latest - oldest).days if oldest and latest else 0
                    stats[tf] = {
                        "count": count,
                        "oldest": oldest,
                        "latest": latest,
                        "duration_days": duration,
                    }
                else:
                    stats[tf] = {
                        "count": 0,
                        "oldest": None,
                        "latest": None,
                        "duration_days": 0,
                    }

            return stats
        finally:
            db.close()

    def analyze_data_gaps(self) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—ã‚’åˆ†æ"""
        stats = self.get_timeframe_stats()

        # ä»–ã®æ™‚é–“è»¸ã®æœ€å¤ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§
        reference_oldest = None
        reference_latest = None

        for tf in ["1d", "4h", "1h", "30m"]:  # 15mä»¥å¤–ã®æ™‚é–“è»¸
            if stats[tf]["count"] > 0 and stats[tf]["oldest"]:
                if reference_oldest is None or stats[tf]["oldest"] < reference_oldest:
                    reference_oldest = stats[tf]["oldest"]
                if reference_latest is None or stats[tf]["latest"] > reference_latest:
                    reference_latest = stats[tf]["latest"]

        # 15åˆ†è¶³ã®çŠ¶æ³
        current_15m = stats["15m"]

        gaps = {
            "reference_period": {
                "oldest": reference_oldest,
                "latest": reference_latest,
                "duration_days": (
                    (reference_latest - reference_oldest).days
                    if reference_oldest and reference_latest
                    else 0
                ),
            },
            "current_15m": current_15m,
            "missing_periods": [],
        }

        if reference_oldest and current_15m["oldest"]:
            # é–‹å§‹æœŸé–“ã®ã‚®ãƒ£ãƒƒãƒ—
            if current_15m["oldest"] > reference_oldest:
                gap_days = (current_15m["oldest"] - reference_oldest).days
                gaps["missing_periods"].append(
                    {
                        "type": "historical_gap",
                        "start": reference_oldest,
                        "end": current_15m["oldest"],
                        "duration_days": gap_days,
                        "priority": "high",
                    }
                )

        return gaps

    async def collect_period_data(
        self, start_date: datetime, end_date: datetime, max_batches: int = 200
    ) -> Dict:
        """æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã®æ­£è¦åŒ–ï¼ˆoffset-naive ã‚’ offset-aware ã«å¤‰æ›ï¼‰
        if start_date.tzinfo is None:
            start_date = start_date.replace(tzinfo=timezone.utc)
        if end_date.tzinfo is None:
            end_date = end_date.replace(tzinfo=timezone.utc)

        logger.info(f"æœŸé–“æŒ‡å®šãƒ‡ãƒ¼ã‚¿åé›†: {start_date} ï½ {end_date}")

        market_service = BybitMarketDataService()
        db = SessionLocal()

        try:
            repo = OHLCVRepository(db)
            total_collected = 0

            # æœŸé–“ã‚’é€†é †ï¼ˆæ–°ã—ã„æ—¥ä»˜ã‹ã‚‰å¤ã„æ—¥ä»˜ã¸ï¼‰ã§å‡¦ç†
            current_end = end_date
            batch_size = 1000

            for batch_num in range(max_batches):
                # since ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—ï¼ˆç¾åœ¨ã®çµ‚äº†æ™‚åˆ»ã‹ã‚‰1000ä»¶åˆ†å‰ï¼‰
                since_timestamp = int(
                    (current_end - timedelta(minutes=15 * batch_size)).timestamp()
                    * 1000
                )

                try:
                    # ãƒ‡ãƒ¼ã‚¿å–å¾—
                    ohlcv_data = await asyncio.get_event_loop().run_in_executor(
                        None,
                        market_service.exchange.fetch_ohlcv,
                        market_service.normalize_symbol(self.symbol),
                        self.timeframe,
                        since_timestamp,
                        batch_size,
                    )

                    if not ohlcv_data or len(ohlcv_data) < 10:
                        logger.info(f"ãƒãƒƒãƒ {batch_num + 1}: ãƒ‡ãƒ¼ã‚¿çµ‚äº†")
                        break

                    # æŒ‡å®šæœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                    filtered_data = []
                    for candle in ohlcv_data:
                        candle_time = datetime.fromtimestamp(
                            candle[0] / 1000, tz=timezone.utc
                        )
                        if start_date <= candle_time <= end_date:
                            filtered_data.append(candle)

                    if filtered_data:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        records = []
                        for candle in filtered_data:
                            timestamp, open_price, high, low, close, volume = candle
                            records.append(
                                {
                                    "symbol": self.symbol,
                                    "timeframe": self.timeframe,
                                    "timestamp": datetime.fromtimestamp(
                                        timestamp / 1000, tz=timezone.utc
                                    ),
                                    "open": float(open_price),
                                    "high": float(high),
                                    "low": float(low),
                                    "close": float(close),
                                    "volume": float(volume),
                                }
                            )

                        saved_count = repo.insert_ohlcv_data(records)
                        total_collected += saved_count
                        logger.info(f"ãƒãƒƒãƒ {batch_num + 1}: {saved_count}ä»¶ä¿å­˜")

                    # æ¬¡ã®ãƒãƒƒãƒã®æº–å‚™
                    oldest_timestamp = min(candle[0] for candle in ohlcv_data)
                    current_end = datetime.fromtimestamp(
                        oldest_timestamp / 1000, tz=timezone.utc
                    )

                    # é–‹å§‹æ—¥æ™‚ã«åˆ°é”ã—ãŸã‚‰çµ‚äº†
                    if current_end <= start_date:
                        logger.info(f"æŒ‡å®šæœŸé–“ã®é–‹å§‹æ—¥æ™‚ã«åˆ°é”ã—ã¾ã—ãŸ")
                        break

                    await asyncio.sleep(0.1)  # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ

                except Exception as e:
                    logger.warning(f"ãƒãƒƒãƒ {batch_num + 1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

            logger.info(f"æœŸé–“æŒ‡å®šåé›†å®Œäº†: ç·è¨ˆ {total_collected}ä»¶")
            return {
                "success": True,
                "collected_count": total_collected,
                "period": f"{start_date} ï½ {end_date}",
            }

        except Exception as e:
            logger.error(f"æœŸé–“æŒ‡å®šåé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}
        finally:
            db.close()

    async def sync_with_other_timeframes(self) -> Dict:
        """ä»–ã®æ™‚é–“è»¸ã¨åŒã˜æœŸé–“ã¾ã§ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸ"""
        logger.info("ä»–ã®æ™‚é–“è»¸ã¨ã®åŒæœŸé–‹å§‹")

        gaps = self.analyze_data_gaps()

        if not gaps["missing_periods"]:
            logger.info("åŒæœŸã®å¿…è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return {"success": True, "message": "åŒæœŸæ¸ˆã¿"}

        total_collected = 0

        for gap in gaps["missing_periods"]:
            logger.info(
                f"ã‚®ãƒ£ãƒƒãƒ—åé›†: {gap['start']} ï½ {gap['end']} ({gap['duration_days']}æ—¥)"
            )

            result = await self.collect_period_data(gap["start"], gap["end"])

            if result["success"]:
                total_collected += result["collected_count"]
                logger.info(f"ã‚®ãƒ£ãƒƒãƒ—åé›†å®Œäº†: {result['collected_count']}ä»¶")
            else:
                logger.error(f"ã‚®ãƒ£ãƒƒãƒ—åé›†å¤±æ•—: {result.get('error')}")

        return {
            "success": True,
            "total_collected": total_collected,
            "gaps_processed": len(gaps["missing_periods"]),
        }


def show_data_details(symbol: str = "BTC/USDT:USDT"):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚·ãƒ³ãƒœãƒ«ã®ãƒ‡ãƒ¼ã‚¿è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    """
    logger.info(f"\n=== {symbol} ãƒ‡ãƒ¼ã‚¿è©³ç´°ç¢ºèª ===")

    manager = Enhanced15mDataManager()
    stats = manager.get_timeframe_stats()

    # å…¨ä½“çµ±è¨ˆ
    db = SessionLocal()
    try:
        total_count = db.query(OHLCVData).count()
        logger.info(f"ç·OHLCVãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {total_count}")
    finally:
        db.close()

    # æ™‚é–“è»¸åˆ¥è©³ç´°
    logger.info("\nğŸ“Š æ™‚é–“è»¸åˆ¥ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    for tf in manager.all_timeframes:
        stat = stats[tf]
        logger.info(f"  {tf}: {stat['count']}ä»¶")
        if stat["oldest"] and stat["latest"]:
            logger.info(
                f"    æœŸé–“: {stat['oldest']} ï½ {stat['latest']} ({stat['duration_days']}æ—¥)"
            )

    # ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
    gaps = manager.analyze_data_gaps()
    logger.info("\nğŸ” ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—åˆ†æ:")

    if gaps["reference_period"]["oldest"]:
        logger.info(
            f"å‚ç…§æœŸé–“ï¼ˆä»–ã®æ™‚é–“è»¸ï¼‰: {gaps['reference_period']['oldest']} ï½ {gaps['reference_period']['latest']} ({gaps['reference_period']['duration_days']}æ—¥)"
        )

        current = gaps["current_15m"]
        if current["oldest"]:
            logger.info(
                f"15åˆ†è¶³ç¾åœ¨æœŸé–“: {current['oldest']} ï½ {current['latest']} ({current['duration_days']}æ—¥)"
            )

            missing_days = (
                gaps["reference_period"]["duration_days"] - current["duration_days"]
            )
            logger.info(f"ä¸è¶³æœŸé–“: ç´„{missing_days}æ—¥")

            for gap in gaps["missing_periods"]:
                logger.info(
                    f"  ã‚®ãƒ£ãƒƒãƒ—: {gap['start']} ï½ {gap['end']} ({gap['duration_days']}æ—¥) - å„ªå…ˆåº¦: {gap['priority']}"
                )
        else:
            logger.info("15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    else:
        logger.info("å‚ç…§ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")


async def collect_gap_data(symbol: str = "BTC/USDT:USDT") -> dict:
    """ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦åé›†"""
    logger.info("=== ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—è‡ªå‹•åé›† ===")

    manager = Enhanced15mDataManager()
    result = await manager.sync_with_other_timeframes()

    return result


async def collect_specific_period(
    symbol: str = "BTC/USDT:USDT", days_back: int = 365
) -> dict:
    """æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
    logger.info(f"=== æŒ‡å®šæœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆéå»{days_back}æ—¥ï¼‰ ===")

    end_date = datetime.now(timezone.utc)
    start_date = end_date - timedelta(days=days_back)

    manager = Enhanced15mDataManager()
    result = await manager.collect_period_data(start_date, end_date)

    return result


async def collect_to_match_reference(symbol: str = "BTC/USDT:USDT") -> dict:
    """ä»–ã®æ™‚é–“è»¸ã®æœ€å¤ãƒ‡ãƒ¼ã‚¿ã¾ã§é¡ã£ã¦åé›†"""
    logger.info("=== å‚ç…§æœŸé–“ã¾ã§é¡ã‚Šåé›† ===")

    manager = Enhanced15mDataManager()
    gaps = manager.analyze_data_gaps()

    if not gaps["reference_period"]["oldest"]:
        return {"success": False, "message": "å‚ç…§æœŸé–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

    # å‚ç…§æœŸé–“ã®é–‹å§‹ã‹ã‚‰ç¾åœ¨ã¾ã§åé›†
    start_date = gaps["reference_period"]["oldest"]
    end_date = datetime.now(timezone.utc)

    logger.info(f"åé›†æœŸé–“: {start_date} ï½ {end_date}")

    result = await manager.collect_period_data(start_date, end_date, max_batches=500)

    return result


async def collect_full_historical_data(symbol: str = "BTC/USDT:USDT") -> dict:
    """
    15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å…¨æœŸé–“åé›†ï¼ˆ2020å¹´ã‹ã‚‰ç¾åœ¨ã¾ã§ï¼‰
    """
    timeframe = "15m"
    logger.info(f"=== {symbol} {timeframe} å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ ===")
    logger.info("åé›†æœŸé–“: 2020å¹´3æœˆ25æ—¥ã‹ã‚‰ç¾åœ¨ã¾ã§ï¼ˆä»–ã®æ™‚é–“è»¸ã¨åŒæœŸï¼‰")

    market_service = BybitMarketDataService()
    historical_service = HistoricalDataService(market_service)
    db = SessionLocal()
    ohlcv_repo = OHLCVRepository(db)

    try:
        count_before = ohlcv_repo.get_data_count(symbol, timeframe)
        logger.info(f"åé›†å‰ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {count_before}")
        if count_before > 0:
            logger.info(
                f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿æœŸé–“: {ohlcv_repo.get_oldest_timestamp(symbol, timeframe)} ï½ {ohlcv_repo.get_latest_timestamp(symbol, timeframe)}"
            )

        logger.info("\nğŸš€ å…¨æœŸé–“å±¥æ­´ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
        total_collected = 0
        max_iterations = 10  # é€£ç¶šã—ã¦å®Ÿè¡Œã—ã€å–ã‚Œã‚‹ã ã‘ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        for i in range(max_iterations):
            logger.info(f"--- åé›†ãƒ©ã‚¦ãƒ³ãƒ‰ {i + 1}/{max_iterations} ---")
            result = await historical_service.collect_historical_data(
                symbol=symbol, timeframe=timeframe, repository=ohlcv_repo
            )
            if result.get("success"):
                collected_count = result.get("saved_count", 0)
                total_collected += collected_count
                logger.info(f"ãƒ©ã‚¦ãƒ³ãƒ‰ {i + 1}: {collected_count}ä»¶åé›†")
                if collected_count < 50:  # æ–°è¦ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªããªã£ãŸã‚‰å®Œäº†ã¨ã¿ãªã™
                    logger.info("æ–°è¦ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªããªã£ãŸãŸã‚ã€åé›†ã‚’å®Œäº†ã—ã¾ã™ã€‚")
                    break
            else:
                logger.warning(f"ãƒ©ã‚¦ãƒ³ãƒ‰ {i + 1}: åé›†ã«å¤±æ•—ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
                break
            await asyncio.sleep(3)  # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãŸã‚ã®å¾…æ©Ÿ

        logger.info(f"âœ… å…¨æœŸé–“åé›†å®Œäº†: ç·è¨ˆ{total_collected}ä»¶")

        count_after = ohlcv_repo.get_data_count(symbol, timeframe)
        logger.info(f"åé›†å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {count_after}")
        logger.info(f"æ–°è¦è¿½åŠ ä»¶æ•°: {count_after - count_before}")
        if count_after > 0:
            logger.info(
                f"æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æœŸé–“: {ohlcv_repo.get_oldest_timestamp(symbol, timeframe)} ï½ {ohlcv_repo.get_latest_timestamp(symbol, timeframe)}"
            )

        return {
            "collected_count": total_collected,
            "total_count": count_after,
            "status": "success",
        }
    except Exception as e:
        logger.error(f"âŒ å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return {
            "collected_count": 0,
            "total_count": 0,
            "status": "error",
            "error": str(e),
        }
    finally:
        db.close()


async def collect_recent_data(
    symbol: str = "BTC/USDT:USDT", days_back: int = 90
) -> dict:
    """
    æŒ‡å®šã•ã‚ŒãŸæ—¥æ•°åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†ä¸­çš„ã«åé›†ã™ã‚‹
    æ³¨: ç¾çŠ¶ã®HistoricalDataServiceã¯å…¨æœŸé–“ã‚’å¯¾è±¡ã¨ã™ã‚‹ãŸã‚ã€days_backã¯å°†æ¥çš„ãªæ‹¡å¼µã®ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚
    """
    timeframe = "15m"
    logger.info(f"=== {symbol} {timeframe} éå»{days_back}æ—¥ãƒ‡ãƒ¼ã‚¿é›†ä¸­åé›†é–‹å§‹ ===")

    market_service = BybitMarketDataService()
    historical_service = HistoricalDataService(market_service)
    db = SessionLocal()
    ohlcv_repo = OHLCVRepository(db)

    try:
        count_before = ohlcv_repo.get_data_count(symbol, timeframe)
        logger.info(f"åé›†å‰ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {count_before}")

        logger.info(f"\nğŸš€ éå»{days_back}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")

        result = await historical_service.collect_historical_data(
            symbol=symbol, timeframe=timeframe, repository=ohlcv_repo
        )

        collected_count = result.get("saved_count", 0) if result.get("success") else 0
        logger.info(f"âœ… åé›†å®Œäº†: {collected_count}ä»¶")

        count_after = ohlcv_repo.get_data_count(symbol, timeframe)
        logger.info(f"åé›†å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {count_after}")
        logger.info(f"æ–°è¦è¿½åŠ ä»¶æ•°: {count_after - count_before}")

        return {
            "collected_count": collected_count,
            "total_count": count_after,
            "status": "success",
        }
    except Exception as e:
        logger.error(f"âŒ é›†ä¸­ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return {
            "collected_count": 0,
            "total_count": 0,
            "status": "error",
            "error": str(e),
        }
    finally:
        db.close()


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("=== 15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ===")

    try:
        init_db()
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    while True:
        print("\n" + "=" * 60)
        print("15åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆæ”¹è‰¯ç‰ˆï¼‰:")
        print("=" * 60)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
        print("  1. ãƒ‡ãƒ¼ã‚¿è©³ç´°ç¢ºèªï¼ˆã‚®ãƒ£ãƒƒãƒ—åˆ†æå«ã‚€ï¼‰")
        print("")
        print("ğŸ”„ è‡ªå‹•åé›†:")
        print("  2. ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—è‡ªå‹•åé›†ï¼ˆæ¨å¥¨ï¼‰")
        print("  3. ä»–ã®æ™‚é–“è»¸ã¨åŒæœŸï¼ˆå‚ç…§æœŸé–“ã¾ã§é¡ã‚Šï¼‰")
        print("")
        print("ğŸ“… æœŸé–“æŒ‡å®šåé›†:")
        print("  4. æœŸé–“æŒ‡å®šåé›†ï¼ˆéå»90æ—¥ï¼‰")
        print("  5. æœŸé–“æŒ‡å®šåé›†ï¼ˆéå»180æ—¥ï¼‰")
        print("  6. æœŸé–“æŒ‡å®šåé›†ï¼ˆéå»365æ—¥ï¼‰")
        print("  7. æœŸé–“æŒ‡å®šåé›†ï¼ˆéå»730æ—¥ï¼‰")
        print("")
        print("ğŸ”§ å¾“æ¥æ©Ÿèƒ½:")
        print("  8. å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆå¾“æ¥ç‰ˆï¼‰")
        print("  9. æœ€æ–°ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆéå»90æ—¥ï¼‰")
        print("")
        print("  0. çµ‚äº†")
        print("=" * 60)

        choice = input("é¸æŠ (0-9): ").strip()

        if choice == "1":
            show_data_details()
        elif choice == "2":
            result = await collect_gap_data()
            if result["success"]:
                logger.info(
                    f"âœ… ã‚®ãƒ£ãƒƒãƒ—åé›†å®Œäº†: {result.get('total_collected', 0)}ä»¶"
                )
            show_data_details()
        elif choice == "3":
            result = await collect_to_match_reference()
            if result["success"]:
                logger.info(
                    f"âœ… å‚ç…§æœŸé–“åŒæœŸå®Œäº†: {result.get('collected_count', 0)}ä»¶"
                )
            show_data_details()
        elif choice == "4":
            result = await collect_specific_period(days_back=90)
            if result["success"]:
                logger.info(f"âœ… 90æ—¥åé›†å®Œäº†: {result.get('collected_count', 0)}ä»¶")
            show_data_details()
        elif choice == "5":
            result = await collect_specific_period(days_back=180)
            if result["success"]:
                logger.info(f"âœ… 180æ—¥åé›†å®Œäº†: {result.get('collected_count', 0)}ä»¶")
            show_data_details()
        elif choice == "6":
            result = await collect_specific_period(days_back=365)
            if result["success"]:
                logger.info(f"âœ… 365æ—¥åé›†å®Œäº†: {result.get('collected_count', 0)}ä»¶")
            show_data_details()
        elif choice == "7":
            result = await collect_specific_period(days_back=730)
            if result["success"]:
                logger.info(f"âœ… 730æ—¥åé›†å®Œäº†: {result.get('collected_count', 0)}ä»¶")
            show_data_details()
        elif choice == "8":
            await collect_full_historical_data()
            show_data_details()
        elif choice == "9":
            await collect_recent_data(days_back=90)
            show_data_details()
        elif choice == "0":
            logger.info("ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        else:
            logger.error("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚ã‚‚ã†ä¸€åº¦é¸æŠã—ã¦ãã ã•ã„ã€‚")

        await asyncio.sleep(1)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\nã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        logger.error(
            f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True
        )
        sys.exit(1)
