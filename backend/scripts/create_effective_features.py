#!/usr/bin/env python3
"""
åŠ¹æœçš„ãªç‰¹å¾´é‡ã®å®Ÿè£…ã¨æ¤œè¨¼

å®Ÿéš›ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸã€ã‚ˆã‚ŠåŠ¹æœçš„ãªç‰¹å¾´é‡ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def generate_realistic_crypto_data(hours: int = 720) -> pd.DataFrame:
    """
    ãƒªã‚¢ãƒ«ãªæš—å·é€šè²¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ30æ—¥åˆ†ï¼‰
    
    Args:
        hours: ç”Ÿæˆã™ã‚‹æ™‚é–“æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 720æ™‚é–“ = 30æ—¥ï¼‰
        
    Returns:
        OHLCV + OI + FR + FGãƒ‡ãƒ¼ã‚¿
    """
    print(f"ãƒªã‚¢ãƒ«ãªæš—å·é€šè²¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {hours}æ™‚é–“åˆ†")
    
    # åŸºæº–æ™‚åˆ»
    start_time = datetime.now() - timedelta(hours=hours)
    timestamps = [start_time + timedelta(hours=i) for i in range(hours)]
    
    # åŸºæº–ä¾¡æ ¼ï¼ˆBTCé¢¨ï¼‰
    base_price = 50000
    
    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ + ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
    np.random.seed(42)
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰æˆåˆ†
    trend = np.cumsum(np.random.normal(0, 0.001, hours))
    
    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æˆåˆ†ï¼ˆæ™‚é–“å¸¯ã«ã‚ˆã‚‹å¤‰å‹•ï¼‰
    hour_volatility = np.array([
        0.02 if 8 <= (start_time + timedelta(hours=i)).hour <= 16 else 0.015
        for i in range(hours)
    ])
    
    # ä¾¡æ ¼å¤‰å‹•
    returns = np.random.normal(0, hour_volatility) + trend * 0.1
    prices = base_price * np.exp(np.cumsum(returns))
    
    # OHLCVç”Ÿæˆ
    ohlcv_data = []
    for i, (timestamp, close) in enumerate(zip(timestamps, prices)):
        # é«˜å€¤ãƒ»å®‰å€¤ã®ç”Ÿæˆ
        volatility = hour_volatility[i] * close
        high = close + np.random.exponential(volatility * 0.5)
        low = close - np.random.exponential(volatility * 0.5)
        
        # å§‹å€¤ï¼ˆå‰ã®çµ‚å€¤ + å°ã•ãªå¤‰å‹•ï¼‰
        if i == 0:
            open_price = close
        else:
            open_price = prices[i-1] + np.random.normal(0, volatility * 0.1)
        
        # å‡ºæ¥é«˜ï¼ˆä¾¡æ ¼å¤‰å‹•ã¨ç›¸é–¢ï¼‰
        price_change = abs(returns[i])
        base_volume = 1000 + price_change * 50000
        volume = max(100, np.random.normal(base_volume, base_volume * 0.3))
        
        ohlcv_data.append({
            'timestamp': timestamp,
            'Open': open_price,
            'High': max(open_price, high, close),
            'Low': min(open_price, low, close),
            'Close': close,
            'Volume': volume,
        })
    
    df = pd.DataFrame(ohlcv_data)
    df.set_index('timestamp', inplace=True)
    
    # Open Interestï¼ˆ8æ™‚é–“ã”ã¨ã«æ›´æ–°ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ç›¸é–¢ï¼‰
    oi_base = 1000000
    oi_trend = np.cumsum(np.random.normal(0, 0.005, hours // 8 + 1))
    oi_values = oi_base * (1 + oi_trend)
    
    # 8æ™‚é–“ã”ã¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    oi_timestamps = [start_time + timedelta(hours=i*8) for i in range(len(oi_values))]
    oi_series = pd.Series(oi_values, index=oi_timestamps)
    df['open_interest'] = oi_series.reindex(df.index, method='ffill')
    
    # Funding Rateï¼ˆ8æ™‚é–“ã”ã¨ã€ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ç›¸é–¢ï¼‰
    fr_values = []
    for i in range(len(oi_values)):
        # ä¾¡æ ¼ä¸Šæ˜‡æ™‚ã¯æ­£ã®FRã€ä¸‹é™æ™‚ã¯è² ã®FR
        price_momentum = np.mean(returns[max(0, i*8-24):i*8+1])  # éå»24æ™‚é–“ã®å¹³å‡
        base_fr = price_momentum * 0.1  # ä¾¡æ ¼å¤‰å‹•ã®10%
        noise = np.random.normal(0, 0.0001)  # ãƒã‚¤ã‚º
        fr = np.clip(base_fr + noise, -0.01, 0.01)  # -1%ã‹ã‚‰1%ã«åˆ¶é™
        fr_values.append(fr)
    
    fr_series = pd.Series(fr_values, index=oi_timestamps)
    df['funding_rate'] = fr_series.reindex(df.index, method='ffill')
    
    # Fear & Greed Indexï¼ˆ1æ—¥ã”ã¨ã€ä¾¡æ ¼å¤‰å‹•ã¨é€†ç›¸é–¢ï¼‰
    daily_timestamps = [start_time + timedelta(days=i) for i in range(hours // 24 + 1)]
    fg_values = []
    for i in range(len(daily_timestamps)):
        # ä¾¡æ ¼ä¸‹è½æ™‚ã¯ææ€–ï¼ˆä½ã„å€¤ï¼‰ã€ä¸Šæ˜‡æ™‚ã¯å¼·æ¬²ï¼ˆé«˜ã„å€¤ï¼‰
        if i == 0:
            daily_return = 0
        else:
            start_idx = max(0, i*24-24)
            end_idx = min(hours-1, i*24)
            daily_return = np.mean(returns[start_idx:end_idx])
        
        # åŸºæº–å€¤50ã‹ã‚‰ä¾¡æ ¼å¤‰å‹•ã«å¿œã˜ã¦èª¿æ•´
        base_fg = 50 + daily_return * 1000  # ä¾¡æ ¼å¤‰å‹•ã‚’1000å€ã—ã¦FGå€¤ã«
        noise = np.random.normal(0, 5)  # ãƒã‚¤ã‚º
        fg = np.clip(base_fg + noise, 0, 100)
        fg_values.append(fg)
    
    fg_series = pd.Series(fg_values, index=daily_timestamps)
    df['fear_greed_value'] = fg_series.reindex(df.index, method='ffill')
    
    print(f"ç”Ÿæˆå®Œäº†: {len(df)}è¡Œ, ã‚«ãƒ©ãƒ : {list(df.columns)}")
    return df

def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆ
    
    Args:
        df: åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
    """
    print("é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
    
    result_df = df.copy()
    
    # 1. ä¾¡æ ¼é–¢é€£ç‰¹å¾´é‡
    print("  ä¾¡æ ¼é–¢é€£ç‰¹å¾´é‡...")
    
    # ä¾¡æ ¼å¤‰å‹•ç‡ï¼ˆè¤‡æ•°æœŸé–“ï¼‰
    for period in [1, 4, 12, 24]:
        result_df[f'price_change_{period}h'] = result_df['Close'].pct_change(period)
        result_df[f'price_volatility_{period}h'] = result_df['Close'].rolling(period).std() / result_df['Close'].rolling(period).mean()
    
    # ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ç‰¹å¾´é‡
    result_df['price_range'] = (result_df['High'] - result_df['Low']) / result_df['Close']
    result_df['upper_shadow'] = (result_df['High'] - np.maximum(result_df['Open'], result_df['Close'])) / result_df['Close']
    result_df['lower_shadow'] = (np.minimum(result_df['Open'], result_df['Close']) - result_df['Low']) / result_df['Close']
    
    # 2. å‡ºæ¥é«˜é–¢é€£ç‰¹å¾´é‡
    print("  å‡ºæ¥é«˜é–¢é€£ç‰¹å¾´é‡...")
    
    # å‡ºæ¥é«˜å¤‰å‹•ç‡
    for period in [1, 4, 12, 24]:
        result_df[f'volume_change_{period}h'] = result_df['Volume'].pct_change(period)
        result_df[f'volume_ma_{period}h'] = result_df['Volume'].rolling(period).mean()
    
    # å‡ºæ¥é«˜åŠ é‡å¹³å‡ä¾¡æ ¼ï¼ˆVWAPï¼‰
    for period in [12, 24, 48]:
        typical_price = (result_df['High'] + result_df['Low'] + result_df['Close']) / 3
        vwap = (typical_price * result_df['Volume']).rolling(period).sum() / result_df['Volume'].rolling(period).sum()
        result_df[f'vwap_{period}h'] = vwap
        result_df[f'price_vs_vwap_{period}h'] = (result_df['Close'] - vwap) / vwap
    
    # 3. Open Interesté–¢é€£ç‰¹å¾´é‡
    print("  Open Interesté–¢é€£ç‰¹å¾´é‡...")
    
    # OIå¤‰å‹•ç‡
    for period in [1, 8, 24]:
        result_df[f'oi_change_{period}h'] = result_df['open_interest'].pct_change(period)
    
    # OI vs ä¾¡æ ¼ã®é–¢ä¿‚
    result_df['oi_price_divergence'] = (
        result_df['open_interest'].pct_change() - result_df['Close'].pct_change()
    )
    
    # OIå‹¢ã„
    result_df['oi_momentum_24h'] = result_df['open_interest'].rolling(24).apply(
        lambda x: (x.iloc[-1] - x.iloc[0]) / x.iloc[0] if x.iloc[0] != 0 else 0
    )
    
    # 4. Funding Rateé–¢é€£ç‰¹å¾´é‡
    print("  Funding Rateé–¢é€£ç‰¹å¾´é‡...")
    
    # FRå¤‰å‹•
    result_df['fr_change'] = result_df['funding_rate'].diff()
    result_df['fr_abs'] = result_df['funding_rate'].abs()
    
    # FRç´¯ç©ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·ã•ï¼‰
    for period in [24, 72, 168]:  # 1æ—¥ã€3æ—¥ã€1é€±é–“
        result_df[f'fr_cumsum_{period}h'] = result_df['funding_rate'].rolling(period).sum()
    
    # FRæ¥µå€¤æ¤œå‡º
    result_df['fr_extreme_positive'] = (result_df['funding_rate'] > 0.005).astype(int)
    result_df['fr_extreme_negative'] = (result_df['funding_rate'] < -0.005).astype(int)
    
    # 5. Fear & Greedé–¢é€£ç‰¹å¾´é‡
    print("  Fear & Greedé–¢é€£ç‰¹å¾´é‡...")
    
    # FGå¤‰å‹•
    result_df['fg_change'] = result_df['fear_greed_value'].diff()
    result_df['fg_change_24h'] = result_df['fear_greed_value'].diff(24)
    
    # FGæ¥µå€¤
    result_df['fg_extreme_fear'] = (result_df['fear_greed_value'] <= 25).astype(int)
    result_df['fg_extreme_greed'] = (result_df['fear_greed_value'] >= 75).astype(int)
    result_df['fg_neutral'] = ((result_df['fear_greed_value'] > 40) & (result_df['fear_greed_value'] < 60)).astype(int)
    
    # 6. è¤‡åˆç‰¹å¾´é‡ï¼ˆç›¸äº’ä½œç”¨ï¼‰
    print("  è¤‡åˆç‰¹å¾´é‡...")
    
    # ä¾¡æ ¼ vs OI ã®é–¢ä¿‚
    result_df['price_oi_correlation'] = result_df['Close'].rolling(24).corr(result_df['open_interest'])
    
    # FR vs ä¾¡æ ¼å¤‰å‹•ã®é–¢ä¿‚
    result_df['fr_price_alignment'] = (
        np.sign(result_df['funding_rate']) == np.sign(result_df['price_change_1h'])
    ).astype(int)
    
    # FG vs ä¾¡æ ¼å¤‰å‹•ã®é€†ç›¸é–¢
    result_df['fg_price_contrarian'] = (
        (result_df['fear_greed_value'] < 30) & (result_df['price_change_1h'] > 0)
    ).astype(int)
    
    # 7. ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
    print("  ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™...")
    
    # RSI
    for period in [14, 24]:
        delta = result_df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
        rs = gain / loss
        result_df[f'rsi_{period}'] = 100 - (100 / (1 + rs))
    
    # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
    for period in [20, 48]:
        ma = result_df['Close'].rolling(period).mean()
        std = result_df['Close'].rolling(period).std()
        result_df[f'bb_upper_{period}'] = ma + (std * 2)
        result_df[f'bb_lower_{period}'] = ma - (std * 2)
        result_df[f'bb_position_{period}'] = (result_df['Close'] - result_df[f'bb_lower_{period}']) / (result_df[f'bb_upper_{period}'] - result_df[f'bb_lower_{period}'])
    
    # 8. æ™‚é–“é–¢é€£ç‰¹å¾´é‡
    print("  æ™‚é–“é–¢é€£ç‰¹å¾´é‡...")
    
    # æ™‚é–“å¸¯
    result_df['hour'] = result_df.index.hour
    result_df['day_of_week'] = result_df.index.dayofweek
    result_df['is_weekend'] = (result_df.index.dayofweek >= 5).astype(int)
    
    # ã‚¢ã‚¸ã‚¢æ™‚é–“ã€æ¬§å·æ™‚é–“ã€ç±³å›½æ™‚é–“
    result_df['asia_hours'] = ((result_df['hour'] >= 0) & (result_df['hour'] < 8)).astype(int)
    result_df['europe_hours'] = ((result_df['hour'] >= 8) & (result_df['hour'] < 16)).astype(int)
    result_df['us_hours'] = ((result_df['hour'] >= 16) & (result_df['hour'] < 24)).astype(int)
    
    print(f"ç‰¹å¾´é‡ä½œæˆå®Œäº†: {len(result_df.columns)}å€‹ã®ç‰¹å¾´é‡")
    return result_df

def analyze_feature_importance(df: pd.DataFrame, target_periods: list = [1, 4, 12, 24]):
    """
    ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’åˆ†æ
    
    Args:
        df: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
        target_periods: äºˆæ¸¬å¯¾è±¡æœŸé–“ï¼ˆæ™‚é–“ï¼‰
    """
    print("\n=== ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ ===")
    
    results = {}
    
    for period in target_periods:
        print(f"\nğŸ“ˆ {period}æ™‚é–“å¾Œã®ä¾¡æ ¼å¤‰å‹•äºˆæ¸¬:")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ä½œæˆ
        target = df['Close'].pct_change(period).shift(-period)
        
        # ç‰¹å¾´é‡é¸æŠï¼ˆæ•°å€¤ã®ã¿ï¼‰
        feature_cols = df.select_dtypes(include=[np.number]).columns
        feature_cols = [col for col in feature_cols if col not in ['Open', 'High', 'Low', 'Close', 'Volume']]
        
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿
        valid_mask = target.notna() & df[feature_cols].notna().all(axis=1)
        if valid_mask.sum() < 50:
            print(f"  æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {valid_mask.sum()}ä»¶")
            continue
        
        X = df.loc[valid_mask, feature_cols]
        y = target.loc[valid_mask]
        
        # ç›¸é–¢åˆ†æ
        correlations = []
        for col in feature_cols:
            corr = X[col].corr(y)
            if not pd.isna(corr):
                correlations.append({
                    'feature': col,
                    'correlation': abs(corr),
                    'correlation_raw': corr,
                })
        
        # ç›¸é–¢é †ã«ã‚½ãƒ¼ãƒˆ
        correlations = sorted(correlations, key=lambda x: x['correlation'], reverse=True)
        
        print(f"  æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(X)}ä»¶")
        print(f"  ä¸Šä½10ç‰¹å¾´é‡:")
        for i, item in enumerate(correlations[:10]):
            print(f"    {i+1:2d}. {item['feature']:<30} ç›¸é–¢: {item['correlation_raw']:+.4f}")
        
        results[f'{period}h'] = correlations
    
    return results

def create_optimized_feature_set(df: pd.DataFrame, importance_results: dict):
    """
    æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    
    Args:
        df: å…ƒãƒ‡ãƒ¼ã‚¿
        importance_results: é‡è¦åº¦åˆ†æçµæœ
        
    Returns:
        æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡DataFrame
    """
    print("\n=== æœ€é©åŒ–ç‰¹å¾´é‡ã‚»ãƒƒãƒˆä½œæˆ ===")
    
    # å…¨æœŸé–“ã§é‡è¦ãªç‰¹å¾´é‡ã‚’æŠ½å‡º
    all_important_features = set()
    
    for period, correlations in importance_results.items():
        # ä¸Šä½20ç‰¹å¾´é‡ã‚’é¸æŠ
        top_features = [item['feature'] for item in correlations[:20] if item['correlation'] > 0.01]
        all_important_features.update(top_features)
        print(f"{period}: {len(top_features)}å€‹ã®é‡è¦ç‰¹å¾´é‡")
    
    print(f"çµ±åˆé‡è¦ç‰¹å¾´é‡: {len(all_important_features)}å€‹")
    
    # åŸºæœ¬ã‚«ãƒ©ãƒ  + é‡è¦ç‰¹å¾´é‡
    base_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'open_interest', 'funding_rate', 'fear_greed_value']
    optimized_cols = base_cols + list(all_important_features)
    
    # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿é¸æŠ
    available_cols = [col for col in optimized_cols if col in df.columns]
    
    optimized_df = df[available_cols].copy()
    
    print(f"æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {optimized_df.shape}")
    print(f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡: {len(available_cols)}å€‹")
    
    return optimized_df

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("åŠ¹æœçš„ãªç‰¹å¾´é‡ã®å®Ÿè£…ã¨æ¤œè¨¼")
    print("=" * 50)
    
    try:
        # 1. ãƒªã‚¢ãƒ«ãªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        df = generate_realistic_crypto_data(720)  # 30æ—¥åˆ†
        
        # 2. é«˜åº¦ãªç‰¹å¾´é‡ä½œæˆ
        df_with_features = create_advanced_features(df)
        
        # 3. ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        importance_results = analyze_feature_importance(df_with_features)
        
        # 4. æœ€é©åŒ–ç‰¹å¾´é‡ã‚»ãƒƒãƒˆä½œæˆ
        optimized_df = create_optimized_feature_set(df_with_features, importance_results)
        
        print("\n" + "=" * 50)
        print("ğŸ¯ æ¨å¥¨æ”¹å–„ç­–:")
        print("1. é«˜ç›¸é–¢ç‰¹å¾´é‡ã‚’å„ªå…ˆçš„ã«å®Ÿè£…")
        print("2. è¤‡åˆç‰¹å¾´é‡ï¼ˆç›¸äº’ä½œç”¨ï¼‰ã®æ´»ç”¨")
        print("3. æ™‚é–“å¸¯åˆ¥ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
        print("4. ãƒ‡ãƒ¼ã‚¿é »åº¦ã®é•ã„ã‚’è€ƒæ…®ã—ãŸè£œé–“")
        print("5. ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡è¨­è¨ˆ")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        output_path = Path(__file__).parent / "sample_optimized_features.csv"
        optimized_df.to_csv(output_path)
        print(f"\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {output_path}")
        
    except Exception as e:
        print(f"å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
