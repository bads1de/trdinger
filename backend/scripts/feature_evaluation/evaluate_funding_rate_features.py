"""
ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€æ–°ã—ãå®Ÿè£…ã—ãŸTier 1ç‰¹å¾´é‡ï¼ˆ15å€‹ï¼‰ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    cd backend
    python -m scripts.feature_evaluation.evaluate_funding_rate_features
    python -m scripts.feature_evaluation.evaluate_funding_rate_features --days 90
"""

import argparse
import json
import logging
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
from sklearn.feature_selection import mutual_info_regression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from app.services.ml.feature_engineering.funding_rate_features import (
    FundingRateFeatureCalculator,
)
from database.connection import SessionLocal
from database.repositories.funding_rate_repository import FundingRateRepository
from database.repositories.ohlcv_repository import OHLCVRepository

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class FundingRateFeatureEvaluator:
    """
    ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡è©•ä¾¡ã‚¯ãƒ©ã‚¹
    
    Tier 1ç‰¹å¾´é‡ï¼ˆ15å€‹ï¼‰ã®æœ‰åŠ¹æ€§ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ã¾ã™ã€‚
    """

    # Tier 1ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆ15å€‹ï¼‰
    TIER1_FEATURES = [
        # åŸºæœ¬é‡‘åˆ©æŒ‡æ¨™ï¼ˆ4å€‹ï¼‰
        "funding_rate_raw",
        "fr_lag_1p",
        "fr_lag_2p",
        "fr_lag_3p",
        # æ™‚é–“ã‚µã‚¤ã‚¯ãƒ«ï¼ˆ3å€‹ï¼‰
        "fr_hours_since_settlement",
        "fr_cycle_sin",
        "fr_cycle_cos",
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆ3å€‹ï¼‰
        "fr_velocity",
        "fr_ema_3periods",
        "fr_ema_7periods",
        # ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆ2å€‹ï¼‰
        "fr_regime_encoded",
        "regime_duration",
        # ä¾¡æ ¼ç›¸äº’ä½œç”¨ï¼ˆ2å€‹ï¼‰
        "fr_price_corr_24h",
        "fr_volatility_adjusted",
    ]

    def __init__(self, symbol: str = "BTC/USDT:USDT", timeframe: str = "1h"):
        """
        åˆæœŸåŒ–
        
        Args:
            symbol: å–å¼•ãƒšã‚¢
            timeframe: æ™‚é–“è¶³
        """
        self.symbol = symbol
        self.timeframe = timeframe
        self.db = SessionLocal()
        self.ohlcv_repo = OHLCVRepository(self.db)
        self.fr_repo = FundingRateRepository(self.db)
        self.calculator = FundingRateFeatureCalculator()
        self.evaluation_results = {}

    def __enter__(self):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼: å…¥å ´"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼: é€€å ´"""
        self.db.close()

    def load_data(
        self, start_date: str, end_date: str
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰OHLCVã¨ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Args:
            start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
            end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰
        
        Returns:
            (ohlcv_df, funding_df)ã®ã‚¿ãƒ—ãƒ«
        """
        logger.info(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {start_date} ã€œ {end_date}")

        try:
            # æ—¥ä»˜ã‚’datetimeã«å¤‰æ›
            start_dt = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)

            # OHLCVãƒ‡ãƒ¼ã‚¿å–å¾—
            ohlcv_df = self.ohlcv_repo.get_ohlcv_dataframe(
                symbol=self.symbol,
                timeframe=self.timeframe,
                start_time=start_dt,
                end_time=end_dt,
            )

            if ohlcv_df.empty:
                raise ValueError(f"OHLCVãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.symbol}")

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒtimestampã®å ´åˆã€ã‚«ãƒ©ãƒ ã¨ã—ã¦ã‚‚ãƒªã‚»ãƒƒãƒˆ
            if ohlcv_df.index.name == "timestamp":
                ohlcv_df = ohlcv_df.reset_index()

            logger.info(f"OHLCV: {len(ohlcv_df)}è¡Œå–å¾—")

            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
            fr_records = self.fr_repo.get_funding_rate_data(
                symbol=self.symbol,
                start_time=start_dt,
                end_time=end_dt,
            )

            if not fr_records:
                raise ValueError(
                    f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.symbol}"
                )

            # DataFrameã«å¤‰æ›ï¼ˆfunding_timestampã‚’timestampã«åå‰å¤‰æ›´ï¼‰
            funding_df = pd.DataFrame(
                [
                    {
                        "timestamp": r.funding_timestamp,
                        "funding_rate": r.funding_rate,
                    }
                    for r in fr_records
                ]
            )

            logger.info(f"FR: {len(funding_df)}è¡Œå–å¾—")

            return ohlcv_df, funding_df

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def evaluate_data_quality(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’è©•ä¾¡
        
        Returns:
            {
                'missing_values': æ¬ æå€¤ã®æ•°ã¨å‰²åˆ,
                'imputed_ratio': è£œé–“ã•ã‚ŒãŸè¡Œã®å‰²åˆ,
                'outliers': ç•°å¸¸å€¤ã®æ•°,
                'date_range': ãƒ‡ãƒ¼ã‚¿æœŸé–“,
                'total_rows': ç·è¡Œæ•°
            }
        """
        logger.info("ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡é–‹å§‹")

        quality_metrics = {
            "total_rows": len(df),
            "date_range": {
                "start": df["timestamp"].min().isoformat() if not df.empty and "timestamp" in df.columns else None,
                "end": df["timestamp"].max().isoformat() if not df.empty and "timestamp" in df.columns else None,
            },
            "missing_values": {},
            "imputed_ratio": 0.0,
            "outliers": {},
        }

        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        for col in self.TIER1_FEATURES:
            if col in df.columns:
                missing_count = df[col].isna().sum()
                missing_ratio = missing_count / len(df) if len(df) > 0 else 0
                quality_metrics["missing_values"][col] = {
                    "count": int(missing_count),
                    "ratio": float(missing_ratio),
                }

        # è£œé–“ãƒ•ãƒ©ã‚°ãŒã‚ã‚‹å ´åˆã€è£œé–“ç‡ã‚’è¨ˆç®—
        if "fr_imputed_flag" in df.columns:
            imputed_count = (df["fr_imputed_flag"] == 1).sum()
            quality_metrics["imputed_ratio"] = float(imputed_count / len(df))

        # ç•°å¸¸å€¤æ¤œå‡ºï¼ˆZ-scoreæ³•ã€é–¾å€¤=3ï¼‰
        for col in self.TIER1_FEATURES:
            if col in df.columns and df[col].notna().sum() > 0:
                values = df[col].dropna()
                if len(values) > 0:
                    z_scores = np.abs(stats.zscore(values))
                    outlier_count = (z_scores > 3).sum()
                    quality_metrics["outliers"][col] = int(outlier_count)

        logger.info("ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡å®Œäº†")
        return quality_metrics

    def calculate_feature_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å„ç‰¹å¾´é‡ã®åŸºæœ¬çµ±è¨ˆé‡ã‚’è¨ˆç®—
        
        Returns:
            çµ±è¨ˆé‡ã®DataFrameï¼ˆmean, std, min, max, skew, kurtç­‰ï¼‰
        """
        logger.info("åŸºæœ¬çµ±è¨ˆé‡è¨ˆç®—é–‹å§‹")

        stats_list = []
        for col in self.TIER1_FEATURES:
            if col not in df.columns:
                continue

            values = df[col].dropna()
            if len(values) == 0:
                continue

            stats_list.append(
                {
                    "feature": col,
                    "count": len(values),
                    "mean": float(values.mean()),
                    "std": float(values.std()),
                    "min": float(values.min()),
                    "25%": float(values.quantile(0.25)),
                    "50%": float(values.median()),
                    "75%": float(values.quantile(0.75)),
                    "max": float(values.max()),
                    "skewness": float(values.skew()),
                    "kurtosis": float(values.kurtosis()),
                }
            )

        stats_df = pd.DataFrame(stats_list)
        logger.info("åŸºæœ¬çµ±è¨ˆé‡è¨ˆç®—å®Œäº†")
        return stats_df

    def analyze_feature_correlations(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç‰¹å¾´é‡é–“ã®ç›¸é–¢è¡Œåˆ—ã‚’è¨ˆç®—
        
        Returns:
            ç›¸é–¢è¡Œåˆ—ï¼ˆ15x15ï¼‰
        """
        logger.info("ç‰¹å¾´é‡é–“ç›¸é–¢åˆ†æé–‹å§‹")

        available_features = [f for f in self.TIER1_FEATURES if f in df.columns]
        corr_matrix = df[available_features].corr()

        logger.info("ç‰¹å¾´é‡é–“ç›¸é–¢åˆ†æå®Œäº†")
        return corr_matrix

    def calculate_target_correlations(
        self, df: pd.DataFrame, target_col: str = "returns_1h"
    ) -> pd.Series:
        """
        å„ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®ç›¸é–¢ã‚’è¨ˆç®—
        
        Args:
            target_col: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®ã‚«ãƒ©ãƒ å
        
        Returns:
            å„ç‰¹å¾´é‡ã®ç›¸é–¢ä¿‚æ•°ï¼ˆé™é †ï¼‰
        """
        logger.info("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢åˆ†æé–‹å§‹")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’ä½œæˆï¼ˆ1æ™‚é–“å…ˆã®ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
        if "close" not in df.columns:
            raise ValueError("closeã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        df[target_col] = df["close"].pct_change().shift(-1)

        available_features = [f for f in self.TIER1_FEATURES if f in df.columns]

        # ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
        correlations = df[available_features].corrwith(df[target_col])
        correlations = correlations.abs().sort_values(ascending=False)

        logger.info("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢åˆ†æå®Œäº†")
        return correlations

    def calculate_mutual_information(
        self, df: pd.DataFrame, target_col: str = "returns_1h"
    ) -> pd.Series:
        """
        ç›¸äº’æƒ…å ±é‡ã‚’è¨ˆç®—
        
        Returns:
            å„ç‰¹å¾´é‡ã®MIã‚¹ã‚³ã‚¢ï¼ˆé™é †ï¼‰
        """
        logger.info("ç›¸äº’æƒ…å ±é‡è¨ˆç®—é–‹å§‹")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’ä½œæˆ
        if target_col not in df.columns:
            if "close" not in df.columns:
                raise ValueError("closeã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            df[target_col] = df["close"].pct_change().shift(-1)

        available_features = [f for f in self.TIER1_FEATURES if f in df.columns]

        # NaNã€infã€-infã‚’é™¤å»
        valid_idx = ~(
            df[available_features].isna().any(axis=1)
            | df[target_col].isna()
            | np.isinf(df[available_features]).any(axis=1)
            | np.isinf(df[target_col])
        )
        X = df.loc[valid_idx, available_features]
        y = df.loc[valid_idx, target_col]

        if len(X) < 100:
            logger.warning("ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ã€ç›¸äº’æƒ…å ±é‡è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return pd.Series()

        # ç›¸äº’æƒ…å ±é‡ã‚’è¨ˆç®—
        mi_scores = mutual_info_regression(X, y, random_state=42)
        mi_series = pd.Series(mi_scores, index=available_features).sort_values(
            ascending=False
        )

        logger.info("ç›¸äº’æƒ…å ±é‡è¨ˆç®—å®Œäº†")
        return mi_series

    def evaluate_prediction_contribution(
        self, df: pd.DataFrame, target_col: str = "returns_1h"
    ) -> Dict[str, Any]:
        """
        LightGBMã‚’ä½¿ç”¨ã—ã¦ç‰¹å¾´é‡ã®äºˆæ¸¬ã¸ã®å¯„ä¸åº¦ã‚’è©•ä¾¡
        
        Returns:
            {
                'feature_importance': {ç‰¹å¾´é‡å: é‡è¦åº¦ã‚¹ã‚³ã‚¢},
                'baseline_rmse': ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆFRç‰¹å¾´é‡ãªã—ï¼‰ã®RMSE,
                'with_fr_rmse': FRç‰¹å¾´é‡ã‚ã‚Šã®RMSE,
                'improvement': æ”¹å–„ç‡ï¼ˆ%ï¼‰
            }
        """
        logger.info("äºˆæ¸¬æ€§èƒ½è©•ä¾¡é–‹å§‹")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’ä½œæˆ
        if target_col not in df.columns:
            if "close" not in df.columns:
                raise ValueError("closeã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            df[target_col] = df["close"].pct_change().shift(-1)

        # åŸºæœ¬çš„ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’ä½œæˆï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”¨ï¼‰
        baseline_features = []
        if "close" in df.columns:
            df["returns"] = df["close"].pct_change()
            df["sma_20"] = df["close"].rolling(20).mean()
            df["volatility_20"] = df["close"].pct_change().rolling(20).std()
            baseline_features = ["returns", "sma_20", "volatility_20"]

        available_fr_features = [f for f in self.TIER1_FEATURES if f in df.columns]

        # NaNã€infã€-infã‚’é™¤å»
        all_features = baseline_features + available_fr_features
        valid_idx = ~(
            df[all_features].isna().any(axis=1)
            | df[target_col].isna()
            | np.isinf(df[all_features]).any(axis=1)
            | np.isinf(df[target_col])
        )
        df_clean = df.loc[valid_idx].copy()

        if len(df_clean) < 100:
            logger.warning("ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³ã€äºˆæ¸¬æ€§èƒ½è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return {}

        # æ™‚ç³»åˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=5)

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆFRç‰¹å¾´é‡ãªã—ï¼‰
        baseline_rmse_scores = []
        for train_idx, test_idx in tscv.split(df_clean):
            X_train = df_clean.iloc[train_idx][baseline_features]
            y_train = df_clean.iloc[train_idx][target_col]
            X_test = df_clean.iloc[test_idx][baseline_features]
            y_test = df_clean.iloc[test_idx][target_col]

            model = lgb.LGBMRegressor(
                objective="regression",
                n_estimators=100,
                learning_rate=0.05,
                random_state=42,
                verbosity=-1,
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            baseline_rmse_scores.append(rmse)

        baseline_rmse = np.mean(baseline_rmse_scores)

        # FRç‰¹å¾´é‡ã‚ã‚Šè©•ä¾¡
        fr_rmse_scores = []
        feature_importance_sum = np.zeros(len(available_fr_features))

        for train_idx, test_idx in tscv.split(df_clean):
            X_train = df_clean.iloc[train_idx][all_features]
            y_train = df_clean.iloc[train_idx][target_col]
            X_test = df_clean.iloc[test_idx][all_features]
            y_test = df_clean.iloc[test_idx][target_col]

            model = lgb.LGBMRegressor(
                objective="regression",
                n_estimators=100,
                learning_rate=0.05,
                random_state=42,
                verbosity=-1,
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            fr_rmse_scores.append(rmse)

            # FRç‰¹å¾´é‡ã®é‡è¦åº¦ã®ã¿é›†è¨ˆ
            importance = model.feature_importances_
            fr_importance = importance[len(baseline_features) :]
            feature_importance_sum += fr_importance

        fr_rmse = np.mean(fr_rmse_scores)

        # é‡è¦åº¦ã‚’æ­£è¦åŒ–
        feature_importance_avg = feature_importance_sum / tscv.n_splits
        if feature_importance_avg.sum() > 0:
            feature_importance_avg = (
                feature_importance_avg / feature_importance_avg.sum()
            )

        feature_importance = dict(
            zip(available_fr_features, feature_importance_avg.tolist())
        )

        # æ”¹å–„ç‡ã‚’è¨ˆç®—
        improvement = ((baseline_rmse - fr_rmse) / baseline_rmse) * 100

        result = {
            "baseline_rmse": float(baseline_rmse),
            "baseline_rmse_std": float(np.std(baseline_rmse_scores)),
            "with_fr_rmse": float(fr_rmse),
            "with_fr_rmse_std": float(np.std(fr_rmse_scores)),
            "improvement_pct": float(improvement),
            "feature_importance": {
                k: float(v) for k, v in feature_importance.items()
            },
        }

        logger.info(f"äºˆæ¸¬æ€§èƒ½è©•ä¾¡å®Œäº† - æ”¹å–„ç‡: {improvement:.2f}%")
        return result

    def plot_visualizations(
        self, df: pd.DataFrame, output_dir: str = "feature_evaluation_plots"
    ):
        """
        è©•ä¾¡çµæœã®å¯è¦–åŒ–
        
        Args:
            df: ç‰¹å¾´é‡DataFrame
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        logger.info("å¯è¦–åŒ–é–‹å§‹")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        plot_dir = Path(output_dir)
        plot_dir.mkdir(parents=True, exist_ok=True)

        # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        sns.set_style("whitegrid")
        plt.rcParams["figure.figsize"] = (12, 8)

        available_features = [f for f in self.TIER1_FEATURES if f in df.columns]

        # 1. ç‰¹å¾´é‡ã®åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
        n_features = len(available_features)
        n_cols = 3
        n_rows = (n_features + n_cols - 1) // n_cols

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))
        axes = axes.flatten() if n_features > 1 else [axes]

        for idx, feature in enumerate(available_features):
            if idx < len(axes):
                # infã€-infã€NaNã‚’é™¤å¤–
                values = df[feature].replace([np.inf, -np.inf], np.nan).dropna()
                if len(values) > 0:
                    values.hist(bins=50, ax=axes[idx], edgecolor="black")
                    axes[idx].set_title(feature, fontsize=10)
                    axes[idx].set_xlabel("Value")
                    axes[idx].set_ylabel("Frequency")
                else:
                    axes[idx].text(0.5, 0.5, 'No valid data', ha='center', va='center')
                    axes[idx].set_title(feature, fontsize=10)

        # æœªä½¿ç”¨ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º
        for idx in range(n_features, len(axes)):
            axes[idx].axis("off")

        plt.tight_layout()
        plt.savefig(plot_dir / "feature_distributions.png", dpi=300, bbox_inches="tight")
        plt.close()

        # 2. ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        corr_matrix = self.analyze_feature_correlations(df)
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            corr_matrix,
            annot=True,
            fmt=".2f",
            cmap="coolwarm",
            center=0,
            square=True,
            linewidths=0.5,
        )
        plt.title("Feature Correlation Matrix", fontsize=14, fontweight="bold")
        plt.tight_layout()
        plt.savefig(plot_dir / "correlation_heatmap.png", dpi=300, bbox_inches="tight")
        plt.close()

        # 3. ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆäºˆæ¸¬æ€§èƒ½è©•ä¾¡ã‹ã‚‰ï¼‰
        if "prediction_contribution" in self.evaluation_results:
            importance = self.evaluation_results["prediction_contribution"].get(
                "feature_importance", {}
            )
            if importance:
                importance_sorted = dict(
                    sorted(importance.items(), key=lambda x: x[1], reverse=True)
                )
                plt.figure(figsize=(10, 8))
                plt.barh(list(importance_sorted.keys()), list(importance_sorted.values()))
                plt.xlabel("Importance Score")
                plt.ylabel("Feature")
                plt.title(
                    "Feature Importance (LightGBM)", fontsize=14, fontweight="bold"
                )
                plt.tight_layout()
                plt.savefig(
                    plot_dir / "feature_importance.png", dpi=300, bbox_inches="tight"
                )
                plt.close()

        # 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢ï¼ˆæ•£å¸ƒå›³ - TOP 6ç‰¹å¾´é‡ï¼‰
        target_corr = self.calculate_target_correlations(df)
        top_features = target_corr.head(6).index.tolist()

        if "returns_1h" in df.columns and len(top_features) > 0:
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            axes = axes.flatten()

            for idx, feature in enumerate(top_features[:6]):
                valid_idx = df[[feature, "returns_1h"]].notna().all(axis=1)
                x = df.loc[valid_idx, feature]
                y = df.loc[valid_idx, "returns_1h"]

                axes[idx].scatter(x, y, alpha=0.3, s=10)
                axes[idx].set_xlabel(feature)
                axes[idx].set_ylabel("Returns (1h)")
                axes[idx].set_title(
                    f"{feature}\n(corr={target_corr[feature]:.4f})", fontsize=10
                )

            plt.tight_layout()
            plt.savefig(
                plot_dir / "target_correlation_scatter.png", dpi=300, bbox_inches="tight"
            )
            plt.close()

        logger.info(f"å¯è¦–åŒ–å®Œäº†: {plot_dir}")

    def generate_report(self, output_path: str = "funding_rate_evaluation_report.md"):
        """
        è©•ä¾¡çµæœã‚’Markdownãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦å‡ºåŠ›
        
        Args:
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logger.info("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")

        report_lines = [
            "# ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ\n",
            f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
            f"**è©•ä¾¡å¯¾è±¡**: {self.symbol} ({self.timeframe})\n",
            "\n---\n",
            "\n## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼\n",
        ]

        # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚µãƒãƒªãƒ¼
        if "data_quality" in self.evaluation_results:
            quality = self.evaluation_results["data_quality"]
            report_lines.extend(
                [
                    "\n### ãƒ‡ãƒ¼ã‚¿å“è³ª\n",
                    f"- **ç·è¡Œæ•°**: {quality['total_rows']:,}è¡Œ\n",
                    f"- **ãƒ‡ãƒ¼ã‚¿æœŸé–“**: {quality['date_range']['start']} ã€œ {quality['date_range']['end']}\n",
                    f"- **è£œé–“ç‡**: {quality['imputed_ratio']*100:.2f}%\n",
                ]
            )

        # äºˆæ¸¬æ€§èƒ½ã‚µãƒãƒªãƒ¼
        if "prediction_contribution" in self.evaluation_results:
            pred = self.evaluation_results["prediction_contribution"]
            report_lines.extend(
                [
                    "\n### äºˆæ¸¬æ€§èƒ½ã¸ã®å¯„ä¸\n",
                    f"- **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³RMSE**: {pred['baseline_rmse']:.6f} (Â±{pred['baseline_rmse_std']:.6f})\n",
                    f"- **FRç‰¹å¾´é‡ã‚ã‚ŠRMSE**: {pred['with_fr_rmse']:.6f} (Â±{pred['with_fr_rmse_std']:.6f})\n",
                    f"- **æ”¹å–„ç‡**: {pred['improvement_pct']:.2f}%\n",
                ]
            )

        report_lines.append("\n---\n")

        # 2. ãƒ‡ãƒ¼ã‚¿å“è³ªè©³ç´°
        if "data_quality" in self.evaluation_results:
            quality = self.evaluation_results["data_quality"]
            report_lines.extend(["\n## 2. ãƒ‡ãƒ¼ã‚¿å“è³ªè©³ç´°\n", "\n### æ¬ æå€¤\n"])

            missing_data = []
            for feature, info in quality["missing_values"].items():
                missing_data.append(
                    f"- **{feature}**: {info['count']}å€‹ ({info['ratio']*100:.2f}%)\n"
                )
            report_lines.extend(sorted(missing_data))

            report_lines.append("\n### ç•°å¸¸å€¤ï¼ˆZ-score > 3ï¼‰\n")
            outlier_data = []
            for feature, count in quality["outliers"].items():
                outlier_data.append(f"- **{feature}**: {count}å€‹\n")
            report_lines.extend(sorted(outlier_data))

        # 3. åŸºæœ¬çµ±è¨ˆé‡
        if "feature_statistics" in self.evaluation_results:
            report_lines.append("\n---\n\n## 3. åŸºæœ¬çµ±è¨ˆé‡\n")
            stats_df = self.evaluation_results["feature_statistics"]
            report_lines.append("\n```\n")
            report_lines.append(stats_df.to_string(index=False))
            report_lines.append("\n```\n")

        # 4. ç›¸é–¢åˆ†æ
        if "target_correlations" in self.evaluation_results:
            report_lines.append("\n---\n\n## 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢ï¼ˆTOP 10ï¼‰\n")
            corr = self.evaluation_results["target_correlations"]
            for idx, (feature, value) in enumerate(corr.head(10).items(), 1):
                report_lines.append(f"{idx}. **{feature}**: {value:.6f}\n")

        # 5. ç›¸äº’æƒ…å ±é‡
        if "mutual_information" in self.evaluation_results:
            report_lines.append("\n---\n\n## 5. ç›¸äº’æƒ…å ±é‡ï¼ˆTOP 10ï¼‰\n")
            mi = self.evaluation_results["mutual_information"]
            if not mi.empty:
                for idx, (feature, value) in enumerate(mi.head(10).items(), 1):
                    report_lines.append(f"{idx}. **{feature}**: {value:.6f}\n")

        # 6. ç‰¹å¾´é‡é‡è¦åº¦
        if "prediction_contribution" in self.evaluation_results:
            pred = self.evaluation_results["prediction_contribution"]
            importance = pred.get("feature_importance", {})
            if importance:
                report_lines.append("\n---\n\n## 6. ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆLightGBMï¼‰\n")
                importance_sorted = sorted(
                    importance.items(), key=lambda x: x[1], reverse=True
                )
                for idx, (feature, value) in enumerate(importance_sorted, 1):
                    report_lines.append(f"{idx}. **{feature}**: {value:.6f}\n")

        # 7. æ¨å¥¨äº‹é …
        report_lines.extend(
            [
                "\n---\n",
                "\n## 7. æ¨å¥¨äº‹é …ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
                "\n### ä¸»è¦ãªç™ºè¦‹\n",
            ]
        )

        # äºˆæ¸¬æ€§èƒ½ã®æ”¹å–„ãŒã‚ã‚‹ã‹
        if "prediction_contribution" in self.evaluation_results:
            pred = self.evaluation_results["prediction_contribution"]
            if pred["improvement_pct"] > 0:
                report_lines.append(
                    f"âœ… ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã«ã‚ˆã‚Šäºˆæ¸¬æ€§èƒ½ãŒ**{pred['improvement_pct']:.2f}%æ”¹å–„**ã—ã¾ã—ãŸã€‚\n"
                )
            else:
                report_lines.append(
                    f"âš ï¸ ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã«ã‚ˆã‚‹æ˜ç¢ºãªæ”¹å–„ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆ{pred['improvement_pct']:.2f}%ï¼‰ã€‚\n"
                )

        # æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡
        if "prediction_contribution" in self.evaluation_results:
            importance = self.evaluation_results["prediction_contribution"].get(
                "feature_importance", {}
            )
            if importance:
                top_feature = max(importance.items(), key=lambda x: x[1])
                report_lines.append(
                    f"âœ… æœ€ã‚‚é‡è¦ãªç‰¹å¾´é‡: **{top_feature[0]}** (é‡è¦åº¦: {top_feature[1]:.4f})\n"
                )

        report_lines.extend(
            [
                "\n### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
                "1. ğŸ”„ **Tier 2ç‰¹å¾´é‡ã®å®Ÿè£…**: ã‚ˆã‚Šé«˜åº¦ãªæ´¾ç”Ÿç‰¹å¾´é‡ã®è¿½åŠ \n",
                "2. ğŸ¯ **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´\n",
                "3. ğŸ“Š **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«**: XGBoostã€TabNetã¨ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ\n",
                "4. â±ï¸ **æ™‚é–“çª“ã®æœ€é©åŒ–**: 24æ™‚é–“çª“ä»¥å¤–ã®æ¤œè¨¼\n",
                "5. ğŸ” **ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†æã®å¼·åŒ–**: ã‚ˆã‚Šè©³ç´°ãªãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡ã®æ¤œè¨\n",
                "\n---\n",
                "\n*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*\n",
            ]
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(output_path, "w", encoding="utf-8") as f:
            f.writelines(report_lines)

        logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_path}")

    def evaluate_all(self, df: pd.DataFrame):
        """
        å…¨è©•ä¾¡ã‚’å®Ÿè¡Œ
        
        Args:
            df: ç‰¹å¾´é‡ã‚’å«ã‚€DataFrame
        """
        logger.info("=== ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡è©•ä¾¡é–‹å§‹ ===")

        # 1. ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
        self.evaluation_results["data_quality"] = self.evaluate_data_quality(df)

        # 2. åŸºæœ¬çµ±è¨ˆé‡
        self.evaluation_results["feature_statistics"] = (
            self.calculate_feature_statistics(df)
        )

        # 3. ç›¸é–¢åˆ†æ
        self.evaluation_results["feature_correlations"] = (
            self.analyze_feature_correlations(df)
        )

        # 4. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢
        self.evaluation_results["target_correlations"] = (
            self.calculate_target_correlations(df)
        )

        # 5. ç›¸äº’æƒ…å ±é‡
        self.evaluation_results["mutual_information"] = (
            self.calculate_mutual_information(df)
        )

        # 6. äºˆæ¸¬æ€§èƒ½è©•ä¾¡
        self.evaluation_results["prediction_contribution"] = (
            self.evaluate_prediction_contribution(df)
        )

        logger.info("=== å…¨è©•ä¾¡å®Œäº† ===")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
    )
    parser.add_argument(
        "--symbol",
        type=str,
        default="BTC/USDT:USDT",
        help="å–å¼•ãƒšã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: BTC/USDT:USDTï¼‰",
    )
    parser.add_argument(
        "--days", type=int, default=90, help="è©•ä¾¡æœŸé–“ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90ï¼‰"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="feature_evaluation_results",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: feature_evaluation_resultsï¼‰",
    )

    args = parser.parse_args()

    try:
        # æœŸé–“è¨­å®š
        end_date = datetime.now()
        start_date = end_date - timedelta(days=args.days)

        logger.info(f"è©•ä¾¡æœŸé–“: {start_date.date()} ã€œ {end_date.date()}")

        # è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–
        with FundingRateFeatureEvaluator(symbol=args.symbol) as evaluator:
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            ohlcv_df, funding_df = evaluator.load_data(
                start_date.strftime("%Y-%m-%d"),
                end_date.strftime("%Y-%m-%d"),
            )

            # ç‰¹å¾´é‡è¨ˆç®—
            df = evaluator.calculator.calculate_features(ohlcv_df, funding_df)

            logger.info(f"ç‰¹å¾´é‡è¨ˆç®—å®Œäº†: {len(df)}è¡Œ, {len(df.columns)}ã‚«ãƒ©ãƒ ")

            # è©•ä¾¡å®Ÿè¡Œ
            evaluator.evaluate_all(df)

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_dir = Path(args.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report_path = output_dir / "funding_rate_evaluation_report.md"
            evaluator.generate_report(str(report_path))

            # å¯è¦–åŒ–
            plot_dir = output_dir / "plots"
            evaluator.plot_visualizations(df, str(plot_dir))

            # çµ±è¨ˆCSVã‚’ä¿å­˜
            if "feature_statistics" in evaluator.evaluation_results:
                stats_df = evaluator.evaluation_results["feature_statistics"]
                stats_path = output_dir / "feature_statistics.csv"
                stats_df.to_csv(stats_path, index=False)
                logger.info(f"çµ±è¨ˆCSVä¿å­˜: {stats_path}")

            # çµæœJSONã‚’ä¿å­˜
            result_json = {
                "evaluation_date": datetime.now().isoformat(),
                "symbol": args.symbol,
                "period_days": args.days,
                "results": {
                    k: v.to_dict() if isinstance(v, pd.DataFrame) else v
                    if not isinstance(v, pd.Series)
                    else v.to_dict()
                    for k, v in evaluator.evaluation_results.items()
                },
            }

            json_path = output_dir / "evaluation_results.json"
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(result_json, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"çµæœJSONä¿å­˜: {json_path}")

            # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
            print("\n" + "=" * 80)
            print("ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡è©•ä¾¡ - ã‚µãƒãƒªãƒ¼")
            print("=" * 80)

            if "data_quality" in evaluator.evaluation_results:
                quality = evaluator.evaluation_results["data_quality"]
                print(f"\nãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢:")
                print(f"  ç·è¡Œæ•°: {quality['total_rows']:,}è¡Œ")
                print(f"  è£œé–“ç‡: {quality['imputed_ratio']*100:.2f}%")

            if "prediction_contribution" in evaluator.evaluation_results:
                pred = evaluator.evaluation_results["prediction_contribution"]
                print(f"\näºˆæ¸¬æ€§èƒ½:")
                print(
                    f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³RMSE: {pred['baseline_rmse']:.6f} (Â±{pred['baseline_rmse_std']:.6f})"
                )
                print(
                    f"  FRç‰¹å¾´é‡ã‚ã‚ŠRMSE: {pred['with_fr_rmse']:.6f} (Â±{pred['with_fr_rmse_std']:.6f})"
                )
                print(f"  æ”¹å–„ç‡: {pred['improvement_pct']:+.2f}%")

                importance = pred.get("feature_importance", {})
                if importance:
                    top5 = sorted(importance.items(), key=lambda x: x[1], reverse=True)[
                        :5
                    ]
                    print(f"\nTOP 5 é‡è¦ç‰¹å¾´é‡:")
                    for idx, (feat, imp) in enumerate(top5, 1):
                        print(f"  {idx}. {feat}: {imp:.6f}")

            if "target_correlations" in evaluator.evaluation_results:
                corr = evaluator.evaluation_results["target_correlations"]
                top5 = corr.head(5)
                print(f"\nTOP 5 ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç›¸é–¢:")
                for idx, (feat, corr_val) in enumerate(top5.items(), 1):
                    print(f"  {idx}. {feat}: {corr_val:.6f}")

            print("\n" + "=" * 80)
            print(f"\nâœ… è©•ä¾¡å®Œäº†ï¼çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
            print("=" * 80 + "\n")

    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()