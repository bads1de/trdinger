"""
æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒŠãƒ¼

Optuna ã‚’ä½¿ç”¨ã—ã¦æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚
"""

import logging
from typing import Any, Dict, Optional

from app.services.ml.optimization.optuna_optimizer import OptunaOptimizer

from ..config.ga import GAConfig
from ..core.individual_evaluator import IndividualEvaluator
from ..genes.strategy import StrategyGene
from .strategy_parameter_space import StrategyParameterSpace

logger = logging.getLogger(__name__)


class StrategyParameterTuner:
    """
    Optuna ã«ã‚ˆã‚‹æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

    GAã§ç™ºè¦‹ã•ã‚ŒãŸæˆ¦ç•¥æ§‹é€ ã«å¯¾ã—ã¦ã€Optunaã‚’ä½¿ç”¨ã—ã¦
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿æœŸé–“ã€TPSLè¨­å®šãªã©ï¼‰ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        evaluator: IndividualEvaluator,
        config: GAConfig,
        n_trials: int = 30,
        use_wfa: bool = True,
        include_indicators: bool = True,
        include_tpsl: bool = True,
        include_thresholds: bool = False,
    ):
        """
        åˆæœŸåŒ–

        Args:
            evaluator: è©•ä¾¡å™¨ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼‰
            config: GAè¨­å®š
            n_trials: Optunaè©¦è¡Œå›æ•°
            use_wfa: WFAè©•ä¾¡ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
            include_indicators: ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã™ã‚‹ã‹
            include_tpsl: TPSLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã™ã‚‹ã‹
            include_thresholds: æ¡ä»¶é–¾å€¤ã‚’æœ€é©åŒ–ã™ã‚‹ã‹
        """
        self.evaluator = evaluator
        self.config = config
        self.n_trials = n_trials
        self.use_wfa = use_wfa
        self.include_indicators = include_indicators
        self.include_tpsl = include_tpsl
        self.include_thresholds = include_thresholds

        self.parameter_space_builder = StrategyParameterSpace()
        self.optimizer = OptunaOptimizer()

    def tune(self, gene: StrategyGene) -> StrategyGene:
        """
        å˜ä¸€ã®æˆ¦ç•¥éºä¼å­ã«å¯¾ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ

        Optunaã‚’ä½¿ç”¨ã—ã¦ã€æŒ‡æ¨™ã®æœŸé–“ã€TP/SLã€ã‚ã‚‹ã„ã¯å–å¼•æ¡ä»¶ã®é–¾å€¤ãªã©ã®
        é€£ç¶šå¤‰æ•°/é›¢æ•£å¤‰æ•°ã‚’æœ€é©åŒ–ã—ã€ã‚ˆã‚Šé«˜ã„ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚’æŒã¤éºä¼å­ã‚’è¿”ã—ã¾ã™ã€‚

        Args:
            gene: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã®æˆ¦ç•¥éºä¼å­

        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é©ç”¨ã—ãŸæ–°ã—ã„StrategyGene
        """
        logger.info("ğŸ”§ æˆ¦ç•¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹")

        parameter_space = self.parameter_space_builder.build_parameter_space(
            gene, self.include_indicators, self.include_tpsl, self.include_thresholds
        )

        if not parameter_space:
            logger.warning("æœ€é©åŒ–å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return gene

        # ç›®çš„é–¢æ•°
        def objective(params: Dict[str, Any]) -> float:
            tuned = self.parameter_space_builder.apply_params_to_gene(gene, params)
            return self._evaluate_gene(tuned)

        try:
            res = self.optimizer.optimize(objective, parameter_space, self.n_trials)

            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é©ç”¨ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            best_gene = self.parameter_space_builder.apply_params_to_gene(
                gene, res.best_params
            )
            best_gene.metadata.update(
                {
                    "optuna_tuned": True,
                    "optuna_best_score": res.best_score,
                    "optuna_trials": res.total_evaluations,
                    "optuna_time": res.optimization_time,
                }
            )
            return best_gene

        except Exception as e:
            logger.error(f"ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return gene
        finally:
            self.optimizer.cleanup()

    def _evaluate_gene(self, gene: StrategyGene) -> float:
        """
        éºä¼å­ã®ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚’è©•ä¾¡

        Args:
            gene: è©•ä¾¡å¯¾è±¡ã®éºä¼å­

        Returns:
            ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å€¤ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰
        """
        try:
            # WFAè©•ä¾¡ãŒæœ‰åŠ¹ãªå ´åˆ
            if self.use_wfa and self.config.enable_walk_forward:
                # WFAè¨­å®šã‚’ä¸€æ™‚çš„ã«æœ‰åŠ¹åŒ–ã—ãŸconfigã‚’ä½¿ç”¨
                wfa_config = self._create_wfa_config()
                fitness_tuple = self.evaluator.evaluate_individual(gene, wfa_config)
            else:
                fitness_tuple = self.evaluator.evaluate_individual(gene, self.config)

            # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¿ãƒ—ãƒ«ã‹ã‚‰ä¸»è¦ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
            if isinstance(fitness_tuple, tuple) and len(fitness_tuple) > 0:
                return float(fitness_tuple[0])
            else:
                return 0.0

        except Exception as e:
            logger.warning(f"éºä¼å­è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def _create_wfa_config(self) -> GAConfig:
        """WFAç”¨ã®è¨­å®šã‚’ä½œæˆ"""
        # å…ƒã®configã‚’ã‚³ãƒ”ãƒ¼ã—ã¦WFAã‚’æœ‰åŠ¹åŒ–
        import copy

        wfa_config = copy.deepcopy(self.config)
        wfa_config.enable_walk_forward = True

        # WFAãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰æ•°ã‚’æ¸›ã‚‰ã—ã¦é«˜é€ŸåŒ–ï¼ˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰
        if wfa_config.wfa_n_folds > 3:
            wfa_config.wfa_n_folds = 3

        return wfa_config

    def tune_multiple(
        self, genes: list[StrategyGene], top_n: Optional[int] = None
    ) -> list[StrategyGene]:
        """
        è¤‡æ•°ã®éºä¼å­ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

        Args:
            genes: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã®éºä¼å­ãƒªã‚¹ãƒˆ
            top_n: ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ä¸Šä½Nå€‹ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰

        Returns:
            ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸéºä¼å­ã®ãƒªã‚¹ãƒˆ
        """
        if top_n is not None:
            genes = genes[:top_n]

        tuned_genes = []
        for idx, gene in enumerate(genes):
            logger.info(f"éºä¼å­ {idx + 1}/{len(genes)} ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
            tuned_gene = self.tune(gene)
            tuned_genes.append(tuned_gene)

        return tuned_genes
