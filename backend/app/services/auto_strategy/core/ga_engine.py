"""
éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¨ãƒ³ã‚¸ãƒ³

DEAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸGAå®Ÿè£…ã€‚
"""

import logging
import time
from dataclasses import fields
from typing import Any, Dict, Optional

import numpy as np
from deap import tools

from app.services.backtest.backtest_service import BacktestService

from ..config.ga_runtime import GAConfig
from ..generators.random_gene_generator import RandomGeneGenerator
from ..generators.strategy_factory import StrategyFactory
from .deap_setup import DEAPSetup
from .evolution_runner import EvolutionRunner
from .fitness_sharing import FitnessSharing
from .genetic_operators import (
    create_deap_mutate_wrapper,
    crossover_strategy_genes,
    mutate_strategy_gene,
)
from .individual_evaluator import IndividualEvaluator
from .parallel_evaluator import ParallelEvaluator

logger = logging.getLogger(__name__)


class EvaluatorWrapper:
    """è©•ä¾¡é–¢æ•°ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆPickleåŒ–å¯¾å¿œï¼‰"""

    def __init__(self, evaluator, config):
        self.evaluator = evaluator
        self.config = config

    def __call__(self, individual):
        return self.evaluator.evaluate_individual(individual, self.config)


class GeneticAlgorithmEngine:
    """éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã€‚

    DEAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦æˆ¦ç•¥ã®è‡ªå‹•ç”Ÿæˆãƒ»æœ€é©åŒ–ã‚’è¡Œã„ã¾ã™ã€‚
    è¤‡é›‘ãªåˆ†é›¢æ§‹é€ ã‚’å‰Šé™¤ã—ã€ç›´æ¥çš„ã§ç†è§£ã—ã‚„ã™ã„å®Ÿè£…ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚
    """

    def __init__(
        self,
        backtest_service: BacktestService,
        strategy_factory: StrategyFactory,
        gene_generator: RandomGeneGenerator,
        hybrid_mode: bool = False,
        hybrid_predictor: Optional[Any] = None,
        hybrid_feature_adapter: Optional[Any] = None,
    ):
        """åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            backtest_service (BacktestService): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã€‚
            strategy_factory (StrategyFactory): æˆ¦ç•¥ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã€‚
            gene_generator (RandomGeneGenerator): éºä¼å­ç”Ÿæˆå™¨ã€‚
            hybrid_mode (bool): ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GA+MLãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Falseã€‚
            hybrid_predictor (Optional[Any]): ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬å™¨ï¼ˆhybrid_mode=Trueã®å ´åˆï¼‰ã€‚
            hybrid_feature_adapter (Optional[Any]): ç‰¹å¾´é‡ã‚¢ãƒ€ãƒ—ã‚¿ï¼ˆhybrid_mode=Trueã®å ´åˆï¼‰ã€‚
        """
        self.backtest_service = backtest_service
        self.strategy_factory = strategy_factory
        self.gene_generator = gene_generator
        self.hybrid_mode = hybrid_mode

        # å®Ÿè¡ŒçŠ¶æ…‹
        self.is_running = False

        # åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.deap_setup = DEAPSetup()

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦Evaluatorã‚’é¸æŠ
        if hybrid_mode:
            logger.info("ğŸ”¬ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GA+MLãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
            from .hybrid_individual_evaluator import HybridIndividualEvaluator

            self.individual_evaluator = HybridIndividualEvaluator(
                backtest_service=backtest_service,
                predictor=hybrid_predictor,
                feature_adapter=hybrid_feature_adapter,
            )
        else:
            logger.info("ğŸ§¬ æ¨™æº–GAãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
            self.individual_evaluator = IndividualEvaluator(backtest_service)

        self.individual_class = None  # setup_deapæ™‚ã«è¨­å®š
        self.fitness_sharing = None  # setup_deapæ™‚ã«åˆæœŸåŒ–

    def setup_deap(self, config: GAConfig):
        """DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆçµ±åˆç‰ˆï¼‰ã‚’è¡Œã„ã¾ã™ã€‚

        Args:
            config (GAConfig): GAè¨­å®šã€‚
        """
        # DEAPç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæˆ¦ç•¥å€‹ä½“ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã§çµ±åˆï¼‰
        self.deap_setup.setup_deap(
            config,
            self._create_strategy_individual,
            self.individual_evaluator.evaluate_individual,
            crossover_strategy_genes,
            mutate_strategy_gene,
        )

        # å€‹ä½“ã‚¯ãƒ©ã‚¹ã‚’å–å¾—ï¼ˆå€‹ä½“ç”Ÿæˆæ™‚ã«ä½¿ç”¨ï¼‰
        self.individual_class = self.deap_setup.get_individual_class()

        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã®åˆæœŸåŒ–
        if config.enable_fitness_sharing:
            self.fitness_sharing = FitnessSharing(
                sharing_radius=config.sharing_radius,
                alpha=config.sharing_alpha,
                sampling_threshold=config.sampling_threshold,
                sampling_ratio=config.sampling_ratio,
            )
        else:
            self.fitness_sharing = None

        logger.info("DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def run_evolution(
        self, config: GAConfig, backtest_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚’ä½¿ã£ã¦è¨­å®šã«å¿œã˜ã¦é©åˆ‡ãªæœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

        Args:
            config (GAConfig): GAè¨­å®šã€‚
            backtest_config (Dict[str, Any]): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã€‚

        Returns:
            Dict[str, Any]: é€²åŒ–çµæœã€‚
        """
        try:
            self.is_running = True
            start_time = time.time()

            logger.info(
                "GA Engine - Starting evolution with backtest_config: %s",
                backtest_config,
            )

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ—¥ä»˜ã‚’è¨­å®šï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
            if "start_date" not in backtest_config:
                backtest_config["start_date"] = config.fallback_start_date
                logger.info(
                    "GA Engine - Using fallback start_date: %s",
                    config.fallback_start_date,
                )
            if "end_date" not in backtest_config:
                backtest_config["end_date"] = config.fallback_end_date
                logger.info(
                    f"GA Engine - Using fallback end_date: {config.fallback_end_date}"
                )

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã‚’ä¿å­˜
            self.individual_evaluator.set_backtest_config(backtest_config)

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šï¼ˆçœç•¥å¯èƒ½ï¼‰
            self._set_generator_context(backtest_config)

            # DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self.setup_deap(config)

            # ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã¨çµ±è¨ˆæƒ…å ±ã®å–å¾—
            toolbox = self.deap_setup.get_toolbox()
            assert toolbox is not None, "Toolbox must be initialized before use."

            stats = self._create_statistics()

            # åˆæœŸå€‹ä½“ç¾¤ã®ç”Ÿæˆï¼ˆè©•ä¾¡ãªã—ï¼‰
            population = toolbox.population(n=config.population_size)

            # é©å¿œçš„çªç„¶å¤‰ç•°ç”¨mutate_wrapperã®è¨­å®š
            individual_class = self.deap_setup.get_individual_class()
            mutate_wrapper = create_deap_mutate_wrapper(
                individual_class, population, config
            )
            toolbox.register("mutate", mutate_wrapper)

            # ç‹¬ç«‹ã—ãŸEvolutionRunnerã®ä½œæˆï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰
            runner = self._create_evolution_runner(toolbox, stats, population, config)

            # åˆæœŸå€‹ä½“ç¾¤ã®è©•ä¾¡ï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰
            runner._evaluate_population(population)

            # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œ
            population, logbook, halloffame = self._run_optimization(
                runner, population, config
            )

            # æœ€è‰¯å€‹ä½“ã®å‡¦ç†ã¨çµæœç”Ÿæˆ
            result = self._process_results(
                population, config, logbook, start_time, halloffame
            )

            logger.info(f"é€²åŒ–å®Œäº† - å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"é€²åŒ–å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            self.is_running = False

    def _set_generator_context(self, backtest_config: Dict[str, Any]):
        """ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            backtest_config (Dict[str, Any]): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã€‚
        """
        try:
            tf = backtest_config.get("timeframe")
            sym = backtest_config.get("symbol")
            if hasattr(self.gene_generator, "smart_condition_generator"):
                smart_gen = getattr(self.gene_generator, "smart_condition_generator")
                if smart_gen and hasattr(smart_gen, "set_context"):
                    smart_gen.set_context(timeframe=tf, symbol=sym)
        except Exception:
            pass

    def _create_statistics(self):
        """çµ±è¨ˆæƒ…å ±åé›†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

        Returns:
            DEAP Statistics: çµ±è¨ˆæƒ…å ±åé›†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        stats = tools.Statistics(lambda ind: ind.fitness.values)
        stats.register("avg", np.mean)
        stats.register("std", np.std)
        stats.register("min", np.min)
        stats.register("max", np.max)
        return stats

    def _create_evolution_runner(self, toolbox, stats, population=None, config=None):
        """ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

        Args:
            toolbox: DEAPãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã€‚
            stats: çµ±è¨ˆæƒ…å ±ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
            population: åˆæœŸå€‹ä½“ç¾¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚
            config: GAè¨­å®šï¼ˆä¸¦åˆ—è©•ä¾¡ç”¨ï¼‰ã€‚

        Returns:
            EvolutionRunner: EvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
        """
        fitness_sharing = (
            self.fitness_sharing
            if hasattr(self, "fitness_sharing") and self.fitness_sharing
            else None
        )

        # ä¸¦åˆ—è©•ä¾¡å™¨ã®ä½œæˆï¼ˆè¨­å®šã§æœ‰åŠ¹ãªå ´åˆï¼‰
        parallel_evaluator = None
        if config and getattr(config, "enable_parallel_evaluation", False):
            # ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
            worker_initializer = None
            worker_initargs = ()

            try:
                # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                if (
                    hasattr(self.individual_evaluator, "_fixed_backtest_config")
                    and self.individual_evaluator._fixed_backtest_config
                ):
                    bc = self.individual_evaluator._fixed_backtest_config

                    # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã‘ã‚Œã°ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ï¼‰
                    main_data = self.individual_evaluator._get_cached_data(bc)

                    # 1åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
                    minute_data = self.individual_evaluator._get_cached_minute_data(bc)

                    data_context = {"main_data": main_data}
                    if minute_data is not None:
                        data_context["minute_data"] = minute_data

                    from .worker_initializer import initialize_worker

                    worker_initializer = initialize_worker
                    worker_initargs = (data_context,)

                    logger.info("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(
                    f"ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿å…±æœ‰ãªã—ã§ç¶šè¡Œï¼‰: {e}"
                )

            parallel_evaluator = ParallelEvaluator(
                evaluate_func=EvaluatorWrapper(self.individual_evaluator, config),
                max_workers=getattr(config, "max_evaluation_workers", None),
                timeout_per_individual=getattr(config, "evaluation_timeout", 300.0),
                worker_initializer=worker_initializer,
                worker_initargs=worker_initargs,
            )
            logger.info(
                f"âš¡ ä¸¦åˆ—è©•ä¾¡æœ‰åŠ¹: max_workers={parallel_evaluator.max_workers}"
            )

        return EvolutionRunner(
            toolbox, stats, fitness_sharing, population, parallel_evaluator
        )

    def _run_optimization(self, runner: EvolutionRunner, population, config: GAConfig):
        """ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            runner (EvolutionRunner): EvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
            population: åˆæœŸå€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚

        Returns:
            tuple: æœ€é©åŒ–å¾Œã®å€‹ä½“ç¾¤ã€ãƒ­ã‚°ãƒ–ãƒƒã‚¯ã€æ®¿å ‚å…¥ã‚Šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        # ç›®çš„æ•°ã«å¿œã˜ã¦é©åˆ‡ãªHallOfFameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        if config.enable_multi_objective:
            halloffame = tools.ParetoFront()
        else:
            halloffame = tools.HallOfFame(maxsize=1)

        # çµ±ä¸€ã•ã‚ŒãŸé€²åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œ
        population, logbook = runner.run_evolution(population, config, halloffame)

        return population, logbook, halloffame

    def _process_results(
        self,
        population,
        config: GAConfig,
        logbook,
        start_time: float,
        halloffame=None,
    ):
        """æœ€é©åŒ–çµæœã‚’å‡¦ç†ã—ã¾ã™ã€‚

        Args:
            population: æœ€çµ‚å€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚
            logbook: é€²åŒ–ãƒ­ã‚°ã€‚
            start_time (float): é–‹å§‹æ™‚åˆ»ï¼ˆç§’ï¼‰ã€‚

        Returns:
            Dict[str, Any]: å‡¦ç†ã•ã‚ŒãŸé€²åŒ–çµæœã®è¾æ›¸ã€‚
        """
        # æœ€è‰¯å€‹ä½“ã®å–å¾—ã¨ãƒ‡ã‚³ãƒ¼ãƒ‰
        best_individual, best_gene, best_strategies = self._extract_best_individuals(
            population, config, halloffame
        )

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
        if config.enable_parameter_tuning:
            best_gene = self._tune_elite_parameters(best_gene, config)

        execution_time = time.time() - start_time

        result = {
            "best_strategy": best_gene,
            "best_fitness": (
                best_individual.fitness.values[0]
                if not config.enable_multi_objective
                else best_individual.fitness.values
            ),
            "population": population,
            "logbook": logbook,
            "execution_time": execution_time,
            "generations_completed": config.generations,
            "final_population_size": len(population),
        }

        # å¤šç›®çš„æœ€é©åŒ–ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’è¿½åŠ 
        if config.enable_multi_objective:
            result["pareto_front"] = best_strategies
            result["objectives"] = config.objectives

        return result

    def _extract_best_individuals(self, population, config: GAConfig, halloffame=None):
        """æœ€è‰¯å€‹ä½“ã‚’æŠ½å‡ºã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

        Args:
            population: æœ€çµ‚å€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚
            halloffame: æ®¿å ‚å…¥ã‚Šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆHallOfFame ã¾ãŸã¯ ParetoFrontï¼‰ã€‚

        Returns:
            tuple: æœ€è‰¯å€‹ä½“ã€æœ€è‰¯éºä¼å­ã€ãŠã‚ˆã³æœ€è‰¯æˆ¦ç•¥ã®ã‚¿ãƒ—ãƒ«ã€‚
        """
        from ..models import StrategyGene
        from ..serializers.gene_serialization import GeneSerializer

        gene_serializer = GeneSerializer()

        best_strategies = None
        best_individual = None

        if config.enable_multi_objective:
            # å¤šç›®çš„æœ€é©åŒ–ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’å–å¾—
            # halloffameãŒParetoFrontã§ãªã„å ´åˆï¼ˆfallbackï¼‰ã¯populationã‹ã‚‰å†æ§‹ç¯‰
            if halloffame is None or not isinstance(halloffame, tools.ParetoFront):
                pareto_front = tools.ParetoFront()
                pareto_front.update(population)
                best_individuals = list(pareto_front)
            else:
                best_individuals = list(halloffame)

            # ç©ºã®å ´åˆã®ã‚¬ãƒ¼ãƒ‰
            if not best_individuals:
                best_individuals = [tools.selBest(population, 1)[0]]

            best_individual = best_individuals[0]

            best_strategies = []
            for ind in best_individuals[:10]:  # ä¸Šä½10å€‹ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£
                if isinstance(ind, StrategyGene):
                    gene = ind
                else:
                    gene = gene_serializer.from_list(ind, StrategyGene)

                best_strategies.append(
                    {"strategy": gene, "fitness_values": list(ind.fitness.values)}
                )
        else:
            # å˜ä¸€ç›®çš„æœ€é©åŒ–ã®å ´åˆ
            if halloffame is not None and len(halloffame) > 0:
                best_individual = halloffame[0]
            else:
                best_individual = tools.selBest(population, 1)[0]

        if isinstance(best_individual, StrategyGene):
            best_gene = best_individual
        else:
            best_gene = gene_serializer.from_list(best_individual, StrategyGene)

        return best_individual, best_gene, best_strategies

    def stop_evolution(self):
        """é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"""
        self.is_running = False

    def _create_strategy_individual(self):
        """æˆ¦ç•¥å€‹ä½“ç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚

        Returns:
            Individual: Individualã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        try:
            # RandomGeneGeneratorã‚’ä½¿ç”¨ã—ã¦éºä¼å­ã‚’ç”Ÿæˆ
            gene = self.gene_generator.generate_random_gene()

            if not self.individual_class:
                raise TypeError("å€‹ä½“ã‚¯ãƒ©ã‚¹ 'Individual' ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

            # StrategyGeneã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ã£ã¦Individualã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            # Individualã¯StrategyGeneã‚’ç¶™æ‰¿ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã§åˆæœŸåŒ–å¯èƒ½
            # asdictã¯å†å¸°çš„ã«è¾æ›¸åŒ–ã—ã¦ã—ã¾ã†ãŸã‚ä½¿ç”¨ã—ãªã„
            gene_dict = {f.name: getattr(gene, f.name) for f in fields(gene)}
            return self.individual_class(**gene_dict)

        except Exception as e:
            logger.error(f"å€‹ä½“ç”Ÿæˆä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            # éºä¼å­ç”Ÿæˆã¯GAã®æ ¹å¹¹éƒ¨åˆ†ã§ã‚ã‚Šã€å¤±æ•—ã—ãŸå ´åˆã¯ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã—ã¦å‡¦ç†ã‚’åœæ­¢ã™ã‚‹ã®ãŒå®‰å…¨
            raise

    def _tune_elite_parameters(self, best_gene, config: GAConfig):
        """ã‚¨ãƒªãƒ¼ãƒˆå€‹ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Optunaã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚

        Args:
            best_gene: æœ€è‰¯æˆ¦ç•¥éºä¼å­
            config (GAConfig): GAè¨­å®š

        Returns:
            ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸæˆ¦ç•¥éºä¼å­
        """
        try:
            from ..optimization import StrategyParameterTuner

            logger.info("ğŸ”§ ã‚¨ãƒªãƒ¼ãƒˆå€‹ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹")

            tuner = StrategyParameterTuner(
                evaluator=self.individual_evaluator,
                config=config,
                n_trials=config.tuning_n_trials,
                use_wfa=config.tuning_use_wfa,
                include_indicators=config.tuning_include_indicators,
                include_tpsl=config.tuning_include_tpsl,
                include_thresholds=config.tuning_include_thresholds,
            )

            tuned_gene = tuner.tune(best_gene)

            logger.info("âœ… ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
            return tuned_gene

        except Exception as e:
            logger.warning(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®éºä¼å­ã‚’è¿”ã™
            return best_gene


