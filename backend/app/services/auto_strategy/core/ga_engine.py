"""
éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¨ãƒ³ã‚¸ãƒ³

DEAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸGAå®Ÿè£…ã€‚
"""

import logging
import random
import time
from dataclasses import fields
from typing import Any, Dict, List, Optional

import numpy as np
from deap import base, creator, tools

from app.services.backtest.backtest_service import BacktestService

from ..config.ga import GAConfig
from ..generators.random_gene_generator import RandomGeneGenerator
from .fitness_sharing import FitnessSharing
from .genetic_operators import (
    create_deap_mutate_wrapper,
    crossover_strategy_genes,
    mutate_strategy_gene,
)
from .individual_evaluator import IndividualEvaluator
from .parallel_evaluator import ParallelEvaluator

logger = logging.getLogger(__name__)


class EvolutionRunner:
    """
    é€²åŒ–è¨ˆç®—ã®å®Ÿè¡Œã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹

    å˜ä¸€ç›®çš„ã¨å¤šç›®çš„æœ€é©åŒ–ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚«ãƒ—ã‚»ãƒ«åŒ–ã—ãŸç‹¬ç«‹ã‚¯ãƒ©ã‚¹ã€‚
    GAã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰åˆ†å‰²ã•ã‚ŒãŸãŒã€ç¾åœ¨ã¯åŒä¸€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã§å®šç¾©ã€‚
    ä¸¦åˆ—è©•ä¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã€‚
    """

    def __init__(
        self,
        toolbox,
        stats,
        fitness_sharing: Optional[FitnessSharing] = None,
        population: Optional[List[Any]] = None,
        parallel_evaluator: Optional[ParallelEvaluator] = None,
    ):
        """
        åˆæœŸåŒ–

        Args:
            toolbox: DEAPãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹
            stats: çµ±è¨ˆæƒ…å ±åé›†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            fitness_sharing: é©å¿œåº¦å…±æœ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            population: å€‹ä½“é›†å›£ï¼ˆé©å¿œçš„çªç„¶å¤‰ç•°ç”¨ï¼‰
            parallel_evaluator: ä¸¦åˆ—è©•ä¾¡å™¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.toolbox = toolbox
        self.stats = stats
        self.fitness_sharing = fitness_sharing
        self.population = population  # é©å¿œçš„çªç„¶å¤‰ç•°ç”¨
        self.parallel_evaluator = parallel_evaluator

    def run_evolution(
        self, population: List[Any], config: Any, halloffame: Optional[Any] = None
    ) -> tuple[List[Any], Any]:
        """
        é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œï¼ˆå˜ä¸€ãƒ»å¤šç›®çš„ çµ±ä¸€ç‰ˆï¼‰

        å˜ä¸€ç›®çš„ãƒ»å¤šç›®çš„ã‚’å•ã‚ãšã€toolboxã«ç™»éŒ²ã•ã‚ŒãŸæ¼”ç®—å­ã¨
        æ¸¡ã•ã‚ŒãŸhalloffameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆHallOfFame ã¾ãŸã¯ ParetoFrontï¼‰ã‚’ä½¿ç”¨ã—ã¦
        é€²åŒ–è¨ˆç®—ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            population: åˆæœŸå€‹ä½“ç¾¤
            config: GAè¨­å®š
            halloffame: æ®¿å ‚å…¥ã‚Šå€‹ä½“ãƒªã‚¹ãƒˆï¼ˆHallOfFame ã¾ãŸã¯ ParetoFrontï¼‰

        Returns:
            (æœ€çµ‚å€‹ä½“ç¾¤, é€²åŒ–ãƒ­ã‚°)
        """
        logger.info(
            f"é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é–‹å§‹ï¼ˆä¸–ä»£æ•°: {config.generations}, ç›®çš„æ•°: {len(config.objectives)}ï¼‰"
        )

        # åˆæœŸé©å¿œåº¦è©•ä¾¡
        population = self._evaluate_population(population)
        self._update_dynamic_objective_scalars(population, config)

        # Hall of Fame / Pareto Front åˆå›æ›´æ–°
        if halloffame is not None:
            halloffame.update(population)

        logbook = tools.Logbook()

        # ä¸–ä»£ãƒ«ãƒ¼ãƒ—
        for gen in range(config.generations):
            logger.debug(f"ä¸–ä»£ {gen + 1}/{config.generations} ã‚’é–‹å§‹")

            # é©å¿œåº¦å…±æœ‰ã®é©ç”¨ï¼ˆæœ‰åŠ¹ãªå ´åˆã€ä¸–ä»£æ¯ï¼‰
            if (
                getattr(config, "enable_fitness_sharing", False)
                and self.fitness_sharing
            ):
                population = self.fitness_sharing.apply_fitness_sharing(population)

            # é¸æŠï¼ˆè¦ªå€‹ä½“ã®é¸æŠï¼‰
            # cloneã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€äº¤å‰ãƒ»å¤‰ç•°ãŒå…ƒã®å€‹ä½“ã«å½±éŸ¿ã—ãªã„ã‚ˆã†ã«ã™ã‚‹
            offspring = list(self.toolbox.map(self.toolbox.clone, population))

            # äº¤å‰
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < config.crossover_rate:
                    self.toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values

            # çªç„¶å¤‰ç•°
            for mutant in offspring:
                if random.random() < config.mutation_rate:
                    self.toolbox.mutate(mutant)
                    del mutant.fitness.values

            # æœªè©•ä¾¡å€‹ä½“ã®è©•ä¾¡ï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰
            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            self._evaluate_invalid_individuals(invalid_ind)

            # æ¬¡ä¸–ä»£ã®é¸æŠ (mu+lambda)
            # toolbox.select ã¯ DEAPSetup ã§ NSGA-II ãªã©ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹
            population[:] = self.toolbox.select(offspring + population, len(population))

            self._update_dynamic_objective_scalars(population, config)

            # çµ±è¨ˆã®è¨˜éŒ²
            record = self.stats.compile(population) if self.stats else {}
            logbook.record(gen=gen, **record)

            # Hall of Fame / Pareto Front ã®æ›´æ–°
            if halloffame is not None:
                halloffame.update(population)

        logger.info("é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å®Œäº†")
        return population, logbook

    def _evaluate_population(self, population: List[Any]) -> List[Any]:
        """
        å€‹ä½“ç¾¤ã®é©å¿œåº¦è©•ä¾¡ï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰

        Args:
            population: è©•ä¾¡å¯¾è±¡ã®å€‹ä½“ç¾¤

        Returns:
            è©•ä¾¡ã•ã‚ŒãŸå€‹ä½“ç¾¤
        """
        if self.parallel_evaluator:
            # ä¸¦åˆ—è©•ä¾¡
            fitnesses = self.parallel_evaluator.evaluate_population(population)
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit
        else:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«è©•ä¾¡ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            fitnesses = list(self.toolbox.map(self.toolbox.evaluate, population))
            for ind, fit in zip(population, fitnesses):
                ind.fitness.values = fit

        return population

    def _evaluate_invalid_individuals(self, invalid_ind: List[Any]) -> None:
        """
        é©å¿œåº¦ãŒç„¡åŠ¹ãªå€‹ä½“ã®ã¿ã‚’è©•ä¾¡ï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰

        Args:
            invalid_ind: è©•ä¾¡å¯¾è±¡ã®ç„¡åŠ¹ãªå€‹ä½“ãƒªã‚¹ãƒˆ
        """
        if not invalid_ind:
            return

        if self.parallel_evaluator:
            # ä¸¦åˆ—è©•ä¾¡
            fitnesses = self.parallel_evaluator.evaluate_population(invalid_ind)
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit
        else:
            # ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«è©•ä¾¡ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            fitnesses = self.toolbox.map(self.toolbox.evaluate, invalid_ind)
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit

    def _update_dynamic_objective_scalars(
        self, population: List[Any], config: Any
    ) -> None:
        """Update dynamic objective scaling factors for risk-aware weighting."""

        if not getattr(config, "dynamic_objective_reweighting", False):
            config.objective_dynamic_scalars = {}
            return

        if not population:
            config.objective_dynamic_scalars = {}
            return

        scalars: Dict[str, float] = {}
        for index, objective in enumerate(getattr(config, "objectives", [])):
            values: List[float] = []
            for individual in population:
                fitness = getattr(individual, "fitness", None)
                if not fitness or not getattr(fitness, "valid", False):
                    continue
                fitness_values = getattr(fitness, "values", ())
                if len(fitness_values) <= index:
                    continue
                try:
                    values.append(float(fitness_values[index]))
                except (TypeError, ValueError):
                    continue

            if not values:
                continue

            average_value = float(np.mean(values))
            if objective in {"max_drawdown", "ulcer_index", "trade_frequency_penalty"}:
                scalars[objective] = min(2.0, 1.0 + max(average_value, 0.0))
            else:
                scalars[objective] = 1.0

        config.objective_dynamic_scalars = scalars


class DEAPSetup:
    """
    DEAPè¨­å®šã‚¯ãƒ©ã‚¹

    DEAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¨­å®šã¨ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã®åˆæœŸåŒ–ã‚’æ‹…å½“ã—ã¾ã™ã€‚
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.toolbox: Optional[base.Toolbox] = None
        self.Individual = None

    def setup_deap(
        self,
        config: GAConfig,
        create_individual_func,
        evaluate_func,
        crossover_func,
        mutate_func,
    ):
        """
        DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå¤šç›®çš„æœ€é©åŒ–å°‚ç”¨ï¼‰

        Args:
            config: GAè¨­å®š
            create_individual_func: å€‹ä½“ç”Ÿæˆé–¢æ•°
            evaluate_func: è©•ä¾¡é–¢æ•°
            crossover_func: äº¤å‰é–¢æ•°
            mutate_func: çªç„¶å¤‰ç•°é–¢æ•°
        """
        # å¤šç›®çš„æœ€é©åŒ–ç”¨ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¯ãƒ©ã‚¹ã®å®šç¾©
        fitness_class_name = "FitnessMulti"
        weights = tuple(config.objective_weights)
        logger.info(f"å¤šç›®çš„æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: ç›®çš„={config.objectives}, é‡ã¿={weights}")

        # æ—¢å­˜ã®ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¯ãƒ©ã‚¹ã‚’å‰Šé™¤ï¼ˆå†å®šç¾©ã®ãŸã‚ï¼‰
        if hasattr(creator, fitness_class_name):
            delattr(creator, fitness_class_name)

        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
        creator.create(fitness_class_name, base.Fitness, weights=weights)
        fitness_class = getattr(creator, fitness_class_name)

        # å€‹ä½“ã‚¯ãƒ©ã‚¹ã®å®šç¾©
        if hasattr(creator, "Individual"):
            delattr(creator, "Individual")

        from ..genes import StrategyGene

        # StrategyGeneã‚’ç¶™æ‰¿ã—ã€fitnesså±æ€§ã‚’æŒã¤ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
        creator.create("Individual", StrategyGene, fitness=fitness_class)  # type: ignore
        self.Individual = creator.Individual  # type: ignore # ç”Ÿæˆã—ãŸã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«æ ¼ç´

        # ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã®åˆæœŸåŒ–
        self.toolbox = base.Toolbox()

        # å€‹ä½“ç”Ÿæˆé–¢æ•°ã®ç™»éŒ²
        self.toolbox.register("individual", create_individual_func)
        self.toolbox.register(
            "population",
            tools.initRepeat,
            list,
            self.toolbox.individual,  # type: ignore
        )

        # è©•ä¾¡é–¢æ•°ã®ç™»éŒ²
        self.toolbox.register("evaluate", evaluate_func, config=config)

        # é€²åŒ–æ¼”ç®—å­ã®ç™»éŒ²ï¼ˆæˆ¦ç•¥éºä¼å­ãƒ¬ãƒ™ãƒ«ï¼‰
        self.toolbox.register("mate", crossover_func, config=config)

        # çªç„¶å¤‰ç•°ã®ç™»éŒ²ï¼ˆDEAPäº’æ›ã®è¿”ã‚Šå€¤ (ind,) ã‚’ä¿è¨¼ã™ã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰
        def _mutate_wrapper(individual):
            res = mutate_func(individual, mutation_rate=config.mutation_rate)
            if isinstance(res, tuple):
                return res
            return (res,)

        self.toolbox.register("mutate", _mutate_wrapper)

        # é¸æŠã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç™»éŒ²ï¼ˆç›®çš„æ•°ã«å¿œã˜ã¦åˆ‡ã‚Šæ›¿ãˆï¼‰
        if config.enable_multi_objective:
            self.toolbox.register("select", tools.selNSGA2)
            logger.info("å¤šç›®çš„æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: NSGA-IIé¸æŠã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç™»éŒ²")
        else:
            # å˜ä¸€ç›®çš„ã®å ´åˆã¯ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚º3ï¼‰
            tourn_size = getattr(config, "tournament_size", 3)
            self.toolbox.register("select", tools.selTournament, tournsize=tourn_size)
            logger.info(
                f"å˜ä¸€ç›®çš„æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰: ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ (size={tourn_size})ã‚’ç™»éŒ²"
            )

        logger.info("DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def get_toolbox(self) -> Optional[base.Toolbox]:
        """ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—"""
        return self.toolbox

    def get_individual_class(self):
        """å€‹ä½“ã‚¯ãƒ©ã‚¹ã‚’å–å¾—"""
        return self.Individual


class EvaluatorWrapper:
    """è©•ä¾¡é–¢æ•°ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆPickleåŒ–å¯¾å¿œï¼‰"""

    def __init__(self, evaluator, config):
        self.evaluator = evaluator
        self.config = config

    def __call__(self, individual):
        return self.evaluator.evaluate_individual(individual, self.config)


class GeneticAlgorithmEngine:
    """éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã€‚

    DEAPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦æˆ¦ç•¥ã®è‡ªå‹•ç”Ÿæˆãƒ»æœ€é©åŒ–ã‚’è¡Œã„ã¾ã™ã€‚
    è¤‡é›‘ãªåˆ†é›¢æ§‹é€ ã‚’å‰Šé™¤ã—ã€ç›´æ¥çš„ã§ç†è§£ã—ã‚„ã™ã„å®Ÿè£…ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚
    """

    def __init__(
        self,
        backtest_service: BacktestService,
        gene_generator: RandomGeneGenerator,
        hybrid_mode: bool = False,
        hybrid_predictor: Optional[Any] = None,
        hybrid_feature_adapter: Optional[Any] = None,
    ):
        """åˆæœŸåŒ–ã—ã¾ã™ã€‚

        Args:
            backtest_service (BacktestService): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã€‚
            gene_generator (RandomGeneGenerator): éºä¼å­ç”Ÿæˆå™¨ã€‚
            hybrid_mode (bool): ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GA+MLãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Falseã€‚
            hybrid_predictor (Optional[Any]): ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬å™¨ï¼ˆhybrid_mode=Trueã®å ´åˆï¼‰ã€‚
            hybrid_feature_adapter (Optional[Any]): ç‰¹å¾´é‡ã‚¢ãƒ€ãƒ—ã‚¿ï¼ˆhybrid_mode=Trueã®å ´åˆï¼‰ã€‚
        """
        self.backtest_service = backtest_service
        self.gene_generator = gene_generator
        self.hybrid_mode = hybrid_mode

        # å®Ÿè¡ŒçŠ¶æ…‹
        self.is_running = False

        # åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.deap_setup = DEAPSetup()

        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦Evaluatorã‚’é¸æŠ
        if hybrid_mode:
            logger.info("ğŸ”¬ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GA+MLãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
            from .hybrid_individual_evaluator import HybridIndividualEvaluator

            self.individual_evaluator = HybridIndividualEvaluator(
                backtest_service=backtest_service,
                predictor=hybrid_predictor,
                feature_adapter=hybrid_feature_adapter,
            )
        else:
            logger.info("ğŸ§¬ æ¨™æº–GAãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•")
            self.individual_evaluator = IndividualEvaluator(backtest_service)

        self.individual_class = None  # setup_deapæ™‚ã«è¨­å®š
        self.fitness_sharing = None  # setup_deapæ™‚ã«åˆæœŸåŒ–

    def setup_deap(self, config: GAConfig):
        """DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆçµ±åˆç‰ˆï¼‰ã‚’è¡Œã„ã¾ã™ã€‚

        Args:
            config (GAConfig): GAè¨­å®šã€‚
        """
        # DEAPç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæˆ¦ç•¥å€‹ä½“ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ã§çµ±åˆï¼‰
        self.deap_setup.setup_deap(
            config,
            self._create_strategy_individual,
            self.individual_evaluator.evaluate_individual,
            crossover_strategy_genes,
            mutate_strategy_gene,
        )

        # å€‹ä½“ã‚¯ãƒ©ã‚¹ã‚’å–å¾—ï¼ˆå€‹ä½“ç”Ÿæˆæ™‚ã«ä½¿ç”¨ï¼‰
        self.individual_class = self.deap_setup.get_individual_class()

        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã®åˆæœŸåŒ–
        if config.enable_fitness_sharing:
            self.fitness_sharing = FitnessSharing(
                sharing_radius=config.sharing_radius,
                alpha=config.sharing_alpha,
                sampling_threshold=config.sampling_threshold,
                sampling_ratio=config.sampling_ratio,
            )
        else:
            self.fitness_sharing = None

        logger.info("DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def run_evolution(
        self, config: GAConfig, backtest_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚’ä½¿ã£ã¦è¨­å®šã«å¿œã˜ã¦é©åˆ‡ãªæœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

        Args:
            config (GAConfig): GAè¨­å®šã€‚
            backtest_config (Dict[str, Any]): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã€‚

        Returns:
            Dict[str, Any]: é€²åŒ–çµæœã€‚
        """
        try:
            self.is_running = True
            start_time = time.time()

            logger.info(
                "GA Engine - Starting evolution with backtest_config: %s",
                backtest_config,
            )

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ—¥ä»˜ã‚’è¨­å®šï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
            if "start_date" not in backtest_config:
                backtest_config["start_date"] = config.fallback_start_date
                logger.info(
                    "GA Engine - Using fallback start_date: %s",
                    config.fallback_start_date,
                )
            if "end_date" not in backtest_config:
                backtest_config["end_date"] = config.fallback_end_date
                logger.info(
                    f"GA Engine - Using fallback end_date: {config.fallback_end_date}"
                )

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã‚’ä¿å­˜
            self.individual_evaluator.set_backtest_config(backtest_config)

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šï¼ˆçœç•¥å¯èƒ½ï¼‰
            self._set_generator_context(backtest_config)

            # DEAPç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self.setup_deap(config)

            # ãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã¨çµ±è¨ˆæƒ…å ±ã®å–å¾—
            toolbox = self.deap_setup.get_toolbox()
            assert toolbox is not None, "Toolbox must be initialized before use."

            stats = self._create_statistics()

            # åˆæœŸå€‹ä½“ç¾¤ã®ç”Ÿæˆï¼ˆè©•ä¾¡ãªã—ï¼‰
            population = toolbox.population(n=config.population_size)

            # é©å¿œçš„çªç„¶å¤‰ç•°ç”¨mutate_wrapperã®è¨­å®š
            individual_class = self.deap_setup.get_individual_class()
            mutate_wrapper = create_deap_mutate_wrapper(
                individual_class, population, config
            )
            toolbox.register("mutate", mutate_wrapper)

            # ç‹¬ç«‹ã—ãŸEvolutionRunnerã®ä½œæˆï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰
            runner = self._create_evolution_runner(toolbox, stats, population, config)

            # åˆæœŸå€‹ä½“ç¾¤ã®è©•ä¾¡ï¼ˆä¸¦åˆ—è©•ä¾¡å¯¾å¿œï¼‰
            runner._evaluate_population(population)

            # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œ
            population, logbook, halloffame = self._run_optimization(
                runner, population, config
            )

            # æœ€è‰¯å€‹ä½“ã®å‡¦ç†ã¨çµæœç”Ÿæˆ
            result = self._process_results(
                population, config, logbook, start_time, halloffame
            )

            logger.info(f"é€²åŒ–å®Œäº† - å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"é€²åŒ–å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            self.is_running = False

    def _set_generator_context(self, backtest_config: Dict[str, Any]):
        """ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚

        Args:
            backtest_config (Dict[str, Any]): ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šã€‚
        """
        try:
            tf = backtest_config.get("timeframe")
            sym = backtest_config.get("symbol")
            if hasattr(self.gene_generator, "smart_condition_generator"):
                smart_gen = getattr(self.gene_generator, "smart_condition_generator")
                if smart_gen and hasattr(smart_gen, "set_context"):
                    smart_gen.set_context(timeframe=tf, symbol=sym)
        except Exception:
            pass

    def _create_statistics(self):
        """çµ±è¨ˆæƒ…å ±åé›†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

        Returns:
            DEAP Statistics: çµ±è¨ˆæƒ…å ±åé›†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        stats = tools.Statistics(lambda ind: ind.fitness.values)
        stats.register("avg", np.mean)
        stats.register("std", np.std)
        stats.register("min", np.min)
        stats.register("max", np.max)
        return stats

    def _create_evolution_runner(self, toolbox, stats, population=None, config=None):
        """ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

        Args:
            toolbox: DEAPãƒ„ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã€‚
            stats: çµ±è¨ˆæƒ…å ±ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
            population: åˆæœŸå€‹ä½“ç¾¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚
            config: GAè¨­å®šï¼ˆä¸¦åˆ—è©•ä¾¡ç”¨ï¼‰ã€‚

        Returns:
            EvolutionRunner: EvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
        """
        fitness_sharing = (
            self.fitness_sharing
            if hasattr(self, "fitness_sharing") and self.fitness_sharing
            else None
        )

        # ä¸¦åˆ—è©•ä¾¡å™¨ã®ä½œæˆï¼ˆè¨­å®šã§æœ‰åŠ¹ãªå ´åˆï¼‰
        parallel_evaluator = None
        if config and getattr(config, "enable_parallel_evaluation", False):
            # ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
            worker_initializer = None
            worker_initargs = ()

            try:
                # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆè¨­å®šãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                if (
                    hasattr(self.individual_evaluator, "_fixed_backtest_config")
                    and self.individual_evaluator._fixed_backtest_config
                ):
                    bc = self.individual_evaluator._fixed_backtest_config

                    # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã‘ã‚Œã°ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ï¼‰
                    main_data = self.individual_evaluator._get_cached_data(bc)

                    # 1åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
                    minute_data = self.individual_evaluator._get_cached_minute_data(bc)

                    data_context = {"main_data": main_data}
                    if minute_data is not None:
                        data_context["minute_data"] = minute_data

                    from .parallel_evaluator import initialize_worker

                    worker_initializer = initialize_worker
                    worker_initargs = (data_context,)

                    logger.info("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ã®å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã—ãŸ")
            except Exception as e:
                logger.warning(
                    f"ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿å…±æœ‰ãªã—ã§ç¶šè¡Œï¼‰: {e}"
                )

            parallel_evaluator = ParallelEvaluator(
                evaluate_func=EvaluatorWrapper(self.individual_evaluator, config),
                max_workers=getattr(config, "max_evaluation_workers", None),
                timeout_per_individual=getattr(config, "evaluation_timeout", 300.0),
                worker_initializer=worker_initializer,
                worker_initargs=worker_initargs,
            )
            logger.info(
                f"âš¡ ä¸¦åˆ—è©•ä¾¡æœ‰åŠ¹: max_workers={parallel_evaluator.max_workers}"
            )

        return EvolutionRunner(
            toolbox, stats, fitness_sharing, population, parallel_evaluator
        )

    def _run_optimization(self, runner: EvolutionRunner, population, config: GAConfig):
        """ç‹¬ç«‹ã—ãŸEvolutionRunnerã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

        Args:
            runner (EvolutionRunner): EvolutionRunnerã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚
            population: åˆæœŸå€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚

        Returns:
            tuple: æœ€é©åŒ–å¾Œã®å€‹ä½“ç¾¤ã€ãƒ­ã‚°ãƒ–ãƒƒã‚¯ã€æ®¿å ‚å…¥ã‚Šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        # ç›®çš„æ•°ã«å¿œã˜ã¦é©åˆ‡ãªHallOfFameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        if config.enable_multi_objective:
            halloffame = tools.ParetoFront()
        else:
            halloffame = tools.HallOfFame(maxsize=1)

        # çµ±ä¸€ã•ã‚ŒãŸé€²åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè¡Œ
        population, logbook = runner.run_evolution(population, config, halloffame)

        return population, logbook, halloffame

    def _process_results(
        self,
        population,
        config: GAConfig,
        logbook,
        start_time: float,
        halloffame=None,
    ):
        """æœ€é©åŒ–çµæœã‚’å‡¦ç†ã—ã¾ã™ã€‚

        Args:
            population: æœ€çµ‚å€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚
            logbook: é€²åŒ–ãƒ­ã‚°ã€‚
            start_time (float): é–‹å§‹æ™‚åˆ»ï¼ˆç§’ï¼‰ã€‚

        Returns:
            Dict[str, Any]: å‡¦ç†ã•ã‚ŒãŸé€²åŒ–çµæœã®è¾æ›¸ã€‚
        """
        # æœ€è‰¯å€‹ä½“ã®å–å¾—ã¨ãƒ‡ã‚³ãƒ¼ãƒ‰
        best_individual, best_gene, best_strategies = self._extract_best_individuals(
            population, config, halloffame
        )

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
        if config.enable_parameter_tuning:
            best_gene = self._tune_elite_parameters(best_gene, config)

        execution_time = time.time() - start_time

        result = {
            "best_strategy": best_gene,
            "best_fitness": (
                best_individual.fitness.values[0]
                if not config.enable_multi_objective
                else best_individual.fitness.values
            ),
            "population": population,
            "logbook": logbook,
            "execution_time": execution_time,
            "generations_completed": config.generations,
            "final_population_size": len(population),
        }

        # å¤šç›®çš„æœ€é©åŒ–ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’è¿½åŠ 
        if config.enable_multi_objective:
            result["pareto_front"] = best_strategies
            result["objectives"] = config.objectives

        return result

    def _extract_best_individuals(self, population, config: GAConfig, halloffame=None):
        """æœ€è‰¯å€‹ä½“ã‚’æŠ½å‡ºã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

        Args:
            population: æœ€çµ‚å€‹ä½“ç¾¤ã€‚
            config (GAConfig): GAè¨­å®šã€‚
            halloffame: æ®¿å ‚å…¥ã‚Šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆHallOfFame ã¾ãŸã¯ ParetoFrontï¼‰ã€‚

        Returns:
            tuple: æœ€è‰¯å€‹ä½“ã€æœ€è‰¯éºä¼å­ã€ãŠã‚ˆã³æœ€è‰¯æˆ¦ç•¥ã®ã‚¿ãƒ—ãƒ«ã€‚
        """
        from ..genes import StrategyGene
        from ..serializers.serialization import GeneSerializer

        gene_serializer = GeneSerializer()

        best_strategies = None
        best_individual = None

        if config.enable_multi_objective:
            # å¤šç›®çš„æœ€é©åŒ–ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’å–å¾—
            # halloffameãŒParetoFrontã§ãªã„å ´åˆï¼ˆfallbackï¼‰ã¯populationã‹ã‚‰å†æ§‹ç¯‰
            if halloffame is None or not isinstance(halloffame, tools.ParetoFront):
                pareto_front = tools.ParetoFront()
                pareto_front.update(population)
                best_individuals = list(pareto_front)
            else:
                best_individuals = list(halloffame)

            # ç©ºã®å ´åˆã®ã‚¬ãƒ¼ãƒ‰
            if not best_individuals:
                best_individuals = [tools.selBest(population, 1)[0]]

            best_individual = best_individuals[0]

            best_strategies = []
            for ind in best_individuals[:10]:  # ä¸Šä½10å€‹ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£
                if isinstance(ind, StrategyGene):
                    gene = ind
                else:
                    gene = gene_serializer.from_list(ind, StrategyGene)

                best_strategies.append(
                    {"strategy": gene, "fitness_values": list(ind.fitness.values)}
                )
        else:
            # å˜ä¸€ç›®çš„æœ€é©åŒ–ã®å ´åˆ
            if halloffame is not None and len(halloffame) > 0:
                best_individual = halloffame[0]
            else:
                best_individual = tools.selBest(population, 1)[0]

        if isinstance(best_individual, StrategyGene):
            best_gene = best_individual
        else:
            best_gene = gene_serializer.from_list(best_individual, StrategyGene)

        return best_individual, best_gene, best_strategies

    def stop_evolution(self):
        """é€²åŒ–ã‚’åœæ­¢ã—ã¾ã™ã€‚"""
        self.is_running = False

    def _create_strategy_individual(self):
        """æˆ¦ç•¥å€‹ä½“ç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚

        Returns:
            Individual: Individualã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        """
        try:
            # RandomGeneGeneratorã‚’ä½¿ç”¨ã—ã¦éºä¼å­ã‚’ç”Ÿæˆ
            gene = self.gene_generator.generate_random_gene()

            if not self.individual_class:
                raise TypeError("å€‹ä½“ã‚¯ãƒ©ã‚¹ 'Individual' ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

            # StrategyGeneã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ã£ã¦Individualã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            # Individualã¯StrategyGeneã‚’ç¶™æ‰¿ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã§åˆæœŸåŒ–å¯èƒ½
            # asdictã¯å†å¸°çš„ã«è¾æ›¸åŒ–ã—ã¦ã—ã¾ã†ãŸã‚ä½¿ç”¨ã—ãªã„
            gene_dict = {f.name: getattr(gene, f.name) for f in fields(gene)}
            return self.individual_class(**gene_dict)

        except Exception as e:
            logger.error(f"å€‹ä½“ç”Ÿæˆä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            # éºä¼å­ç”Ÿæˆã¯GAã®æ ¹å¹¹éƒ¨åˆ†ã§ã‚ã‚Šã€å¤±æ•—ã—ãŸå ´åˆã¯ä¾‹å¤–ã‚’ã‚¹ãƒ­ãƒ¼ã—ã¦å‡¦ç†ã‚’åœæ­¢ã™ã‚‹ã®ãŒå®‰å…¨
            raise

    def _tune_elite_parameters(self, best_gene, config: GAConfig):
        """ã‚¨ãƒªãƒ¼ãƒˆå€‹ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Optunaã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚

        Args:
            best_gene: æœ€è‰¯æˆ¦ç•¥éºä¼å­
            config (GAConfig): GAè¨­å®š

        Returns:
            ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸæˆ¦ç•¥éºä¼å­
        """
        try:
            from ..optimization import StrategyParameterTuner

            logger.info("ğŸ”§ ã‚¨ãƒªãƒ¼ãƒˆå€‹ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹")

            tuner = StrategyParameterTuner(
                evaluator=self.individual_evaluator,
                config=config,
                n_trials=config.tuning_n_trials,
                use_wfa=config.tuning_use_wfa,
                include_indicators=config.tuning_include_indicators,
                include_tpsl=config.tuning_include_tpsl,
                include_thresholds=config.tuning_include_thresholds,
            )

            tuned_gene = tuner.tune(best_gene)

            logger.info("âœ… ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
            return tuned_gene

        except Exception as e:
            logger.warning(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®éºä¼å­ã‚’è¿”ã™
            return best_gene
