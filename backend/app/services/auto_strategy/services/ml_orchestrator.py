"""
ML ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼

è²¬ä»»ã‚’åˆ†é›¢ã—ãŸè»½é‡ãªMLã‚µãƒ¼ãƒ“ã‚¹çµ±åˆã‚¯ãƒ©ã‚¹ã€‚
ç‰¹å¾´é‡è¨ˆç®—ã€ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã€çµæœã®çµ±åˆã‚’è¡Œã„ã¾ã™ã€‚

MLPredictionInterfaceã‚’å®Ÿè£…ã—ã€çµ±ä¸€ã•ã‚ŒãŸMLäºˆæ¸¬APIã‚’æä¾›ã—ã¾ã™ã€‚
å­¦ç¿’æ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚Œã€äºˆæ¸¬æ©Ÿèƒ½ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚
"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional

from app.services.ml.config import ml_config
from app.utils.unified_error_handler import (
    UnifiedErrorHandler,
    MLDataError,
    MLValidationError,
    unified_timeout_decorator,
    unified_operation_context,
)
from app.utils.data_preprocessing import data_preprocessor
from app.services.ml.feature_engineering.feature_engineering_service import (
    FeatureEngineeringService,
)
from app.services.ml.feature_engineering.enhanced_feature_engineering_service import (
    EnhancedFeatureEngineeringService,
)
from app.services.ml.feature_engineering.automl_features.automl_config import (
    AutoMLConfig,
)
from app.services.ml.ml_training_service import MLTrainingService
from app.services.ml.model_manager import model_manager

from app.services.ml.interfaces import MLPredictionInterface
from app.services.backtest.backtest_data_service import BacktestDataService
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.funding_rate_repository import FundingRateRepository
from database.repositories.open_interest_repository import OpenInterestRepository
from database.connection import get_db
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class MLOrchestrator(MLPredictionInterface):
    """
    ML ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼

    è²¬ä»»ã‚’åˆ†é›¢ã—ãŸè»½é‡ãªMLã‚µãƒ¼ãƒ“ã‚¹çµ±åˆã‚¯ãƒ©ã‚¹ã€‚
    ç‰¹å¾´é‡è¨ˆç®—ã€ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã€çµæœã®çµ±åˆã‚’è¡Œã„ã¾ã™ã€‚

    MLPredictionInterfaceã‚’å®Ÿè£…ã—ã€çµ±ä¸€ã•ã‚ŒãŸMLäºˆæ¸¬APIã‚’æä¾›ã—ã¾ã™ã€‚
    å­¦ç¿’æ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚Œã€äºˆæ¸¬æ©Ÿèƒ½ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚
    """

    def __init__(
        self,
        ml_training_service: Optional[MLTrainingService] = None,
        enable_automl: bool = True,
        automl_config: Optional[Dict[str, Any]] = None,
    ):
        """
        åˆæœŸåŒ–

        Args:
            ml_training_service: MLTrainingServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            enable_automl: AutoMLæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
            automl_config: AutoMLè¨­å®šï¼ˆè¾æ›¸å½¢å¼ï¼‰
        """
        self.config = ml_config
        self.enable_automl = enable_automl
        self.automl_config = automl_config

        # AutoMLæ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹ã«å¿œã˜ã¦ç‰¹å¾´é‡ã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ
        if enable_automl:
            # AutoMLè¨­å®šã‚’ä½œæˆ
            if automl_config:
                automl_config_obj = self._create_automl_config_from_dict(automl_config)
            else:
                automl_config_obj = AutoMLConfig.get_financial_optimized_config()

            self.feature_service = EnhancedFeatureEngineeringService(automl_config_obj)
            logger.info("ğŸ¤– AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
        else:
            self.feature_service = FeatureEngineeringService()
            logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")

        self.ml_training_service = (
            ml_training_service
            if ml_training_service
            else MLTrainingService(trainer_type="ensemble")
        )

        # BacktestDataServiceã‚’åˆæœŸåŒ–ï¼ˆå®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå–å¾—ç”¨ï¼‰
        self._backtest_data_service = None
        # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã®çµ±åˆç®¡ç†ï¼ˆml_training_serviceã®trainerã‚’ä½¿ç”¨ï¼‰
        self.is_model_loaded = getattr(
            self.ml_training_service.trainer, "is_trained", False
        )
        self._last_predictions = self.config.prediction.get_default_predictions()

        # æ—¢å­˜ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
        self._try_load_latest_model()

    def _create_automl_config_from_dict(
        self, config_dict: Dict[str, Any]
    ) -> AutoMLConfig:
        """è¾æ›¸ã‹ã‚‰AutoMLConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
        from app.services.ml.feature_engineering.automl_features.automl_config import (
            TSFreshConfig,
            AutoFeatConfig,
        )

        # TSFreshè¨­å®š
        tsfresh_dict = config_dict.get("tsfresh", {})
        tsfresh_config = TSFreshConfig(
            enabled=tsfresh_dict.get("enabled", True),
            feature_selection=tsfresh_dict.get("feature_selection", True),
            fdr_level=tsfresh_dict.get("fdr_level", 0.05),
            feature_count_limit=tsfresh_dict.get("feature_count_limit", 100),
            parallel_jobs=tsfresh_dict.get("parallel_jobs", 2),
            performance_mode=tsfresh_dict.get("performance_mode", "balanced"),
        )

        # AutoFeatè¨­å®š
        autofeat_dict = config_dict.get("autofeat", {})
        autofeat_config = AutoFeatConfig(
            enabled=autofeat_dict.get("enabled", True),
            max_features=autofeat_dict.get("max_features", 50),
            feateng_steps=autofeat_dict.get("feateng_steps", 2),
            max_gb=autofeat_dict.get("max_gb", 1.0),
            generations=autofeat_dict.get("generations", 20),
            population_size=autofeat_dict.get("population_size", 50),
            tournament_size=autofeat_dict.get("tournament_size", 3),
        )

        return AutoMLConfig(
            tsfresh_config=tsfresh_config,
            autofeat_config=autofeat_config,
        )

    def get_backtest_data_service(self, db: Session) -> BacktestDataService:
        """BacktestDataServiceã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆä¾å­˜æ€§æ³¨å…¥å¯¾å¿œï¼‰"""
        if self._backtest_data_service is None:
            ohlcv_repo = OHLCVRepository(db)
            fr_repo = FundingRateRepository(db)
            oi_repo = OpenInterestRepository(db)
            self._backtest_data_service = BacktestDataService(
                ohlcv_repo=ohlcv_repo, oi_repo=oi_repo, fr_repo=fr_repo
            )
        return self._backtest_data_service

    @unified_timeout_decorator(
        timeout_seconds=ml_config.data_processing.FEATURE_CALCULATION_TIMEOUT
    )
    def calculate_ml_indicators(
        self,
        df: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> Dict[str, np.ndarray]:
        """
        MLäºˆæ¸¬ç¢ºç‡æŒ‡æ¨™ã‚’è¨ˆç®—

        Args:
            df: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            MLæŒ‡æ¨™ã®è¾æ›¸ {"ML_UP_PROB": array, "ML_DOWN_PROB": array, "ML_RANGE_PROB": array}
        """
        with unified_operation_context("MLæŒ‡æ¨™è¨ˆç®—"):
            try:
                # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¶é™
                df = self._limit_data_size(df)

                # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ï¼ˆæ¤œè¨¼å‰ã«å®Ÿè¡Œï¼‰
                df = self._normalize_column_names(df)

                # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ï¼ˆæ­£è¦åŒ–å¾Œã«å®Ÿè¡Œï¼‰
                self._validate_input_data(df)

                # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•å–å¾—
                if funding_rate_data is None or open_interest_data is None:
                    logger.info("ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å–å¾—ã—ã¾ã™")
                    enhanced_df = self._get_enhanced_data_with_fr_oi(df)
                    if enhanced_df is not None:
                        df = enhanced_df
                        # æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
                        funding_rate_data, open_interest_data = (
                            self._extract_fr_oi_data(df)
                        )

                # ç‰¹å¾´é‡è¨ˆç®—
                features_df = self._calculate_features(
                    df, funding_rate_data, open_interest_data
                )

                # ç‰¹å¾´é‡è¨ˆç®—ãŒå¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
                if features_df is None or features_df.empty:
                    error_msg = (
                        "ç‰¹å¾´é‡è¨ˆç®—ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚MLãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚"
                    )
                    logger.error(error_msg)
                    raise MLDataError(error_msg)

                # MLäºˆæ¸¬ã®å®Ÿè¡Œ
                predictions = self._safe_ml_prediction(features_df)

                # äºˆæ¸¬ç¢ºç‡ã‚’å…¨ãƒ‡ãƒ¼ã‚¿é•·ã«æ‹¡å¼µ
                ml_indicators = self._expand_predictions_to_data_length(
                    predictions, len(df)
                )

                # çµæœã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                self._validate_ml_indicators(ml_indicators)

                return ml_indicators

            except (MLDataError, MLValidationError) as e:
                logger.error(f"MLæŒ‡æ¨™è¨ˆç®—ã§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                raise  # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã¦å‡¦ç†ã‚’åœæ­¢
            except Exception as e:
                logger.error(f"MLæŒ‡æ¨™è¨ˆç®—ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                raise MLDataError(
                    f"MLæŒ‡æ¨™è¨ˆç®—ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                ) from e

    def calculate_single_ml_indicator(
        self,
        indicator_type: str,
        df: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> np.ndarray:
        """
        å˜ä¸€ã®MLæŒ‡æ¨™ã‚’è¨ˆç®—

        Args:
            indicator_type: æŒ‡æ¨™ã‚¿ã‚¤ãƒ—ï¼ˆML_UP_PROB, ML_DOWN_PROB, ML_RANGE_PROBï¼‰
            df: OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            æŒ‡æ¨™å€¤ã®é…åˆ—
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åŸºæœ¬æ¤œè¨¼
        if df is None or df.empty:
            error_msg = f"ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæä¾›ã•ã‚Œã¾ã—ãŸ: {indicator_type}"
            logger.error(error_msg)
            raise MLDataError(error_msg)

        # MLæŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¾‹å¤–ãŒç™ºç”Ÿï¼‰
        ml_indicators = self.calculate_ml_indicators(
            df, funding_rate_data, open_interest_data
        )

        if indicator_type in ml_indicators:
            return ml_indicators[indicator_type]
        else:
            error_msg = f"æœªçŸ¥ã®MLæŒ‡æ¨™ã‚¿ã‚¤ãƒ—: {indicator_type}"
            logger.error(error_msg)
            raise MLValidationError(error_msg)

    def load_model(self, model_path: str) -> bool:
        """
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã¿æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            success = self.ml_training_service.load_model(model_path)
            if success:
                self.is_model_loaded = True
                logger.info(f"MLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {model_path}")
            else:
                logger.warning(f"MLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {model_path}")
            return success

        except Exception as e:
            logger.error(f"MLãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def get_model_status(self) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‚’å–å¾—

        Returns:
            ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã®è¾æ›¸
        """

        status = {
            "is_model_loaded": self.is_model_loaded,
            "is_trained": getattr(
                self.ml_training_service.trainer, "is_trained", False
            ),
            "last_predictions": self._last_predictions,
            "feature_count": (
                len(self.ml_training_service.trainer.feature_columns)
                if self.ml_training_service.trainer.feature_columns
                else 0
            ),
        }

        # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ€§èƒ½æŒ‡æ¨™ã‚’å–å¾—
        try:
            latest_model = model_manager.get_latest_model("*")
            if latest_model:
                # ModelManagerã‹ã‚‰ç›´æ¥ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                model_data = model_manager.load_model(latest_model)
                if model_data and "metadata" in model_data:
                    metadata = model_data["metadata"]
                    # æ–°ã—ã„å½¢å¼ã®æ€§èƒ½æŒ‡æ¨™ã‚’æŠ½å‡ºï¼ˆå…¨ã¦ã®è©•ä¾¡æŒ‡æ¨™ã‚’å«ã‚€ï¼‰
                    performance_metrics = {
                        # åŸºæœ¬æŒ‡æ¨™
                        "accuracy": metadata.get("accuracy", 0.0),
                        "precision": metadata.get("precision", 0.0),
                        "recall": metadata.get("recall", 0.0),
                        "f1_score": metadata.get("f1_score", 0.0),
                        # AUCæŒ‡æ¨™
                        "auc_roc": metadata.get("auc_roc", 0.0),
                        "auc_pr": metadata.get("auc_pr", 0.0),
                        # é«˜åº¦ãªæŒ‡æ¨™
                        "balanced_accuracy": metadata.get("balanced_accuracy", 0.0),
                        "matthews_corrcoef": metadata.get("matthews_corrcoef", 0.0),
                        "cohen_kappa": metadata.get("cohen_kappa", 0.0),
                        # å°‚é–€æŒ‡æ¨™
                        "specificity": metadata.get("specificity", 0.0),
                        "sensitivity": metadata.get("sensitivity", 0.0),
                        "npv": metadata.get("npv", 0.0),
                        "ppv": metadata.get("ppv", 0.0),
                        # ç¢ºç‡æŒ‡æ¨™
                        "log_loss": metadata.get("log_loss", 0.0),
                        "brier_score": metadata.get("brier_score", 0.0),
                        # ãã®ä»–
                        "loss": metadata.get("loss", 0.0),
                        "val_accuracy": metadata.get("val_accuracy", 0.0),
                        "val_loss": metadata.get("val_loss", 0.0),
                        "training_time": metadata.get("training_time", 0.0),
                    }
                    status["performance_metrics"] = performance_metrics
                else:
                    pass
            else:
                pass
        except Exception as e:
            logger.error(f"æ€§èƒ½æŒ‡æ¨™å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        return status

    def update_predictions(self, predictions: Dict[str, float]):
        """
        äºˆæ¸¬å€¤ã‚’æ›´æ–°ï¼ˆå¤–éƒ¨ã‹ã‚‰è¨­å®šã™ã‚‹å ´åˆï¼‰

        Args:
            predictions: äºˆæ¸¬ç¢ºç‡ã®è¾æ›¸
        """
        try:
            UnifiedErrorHandler.validate_predictions(predictions)
            self._last_predictions = predictions
        except MLValidationError as e:
            logger.warning(f"ç„¡åŠ¹ãªäºˆæ¸¬å€¤å½¢å¼: {e}")

    def get_feature_importance(self, top_n: int = 10) -> Dict[str, float]:
        """
        ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—

        Args:
            top_n: ä¸Šä½Nå€‹ã®ç‰¹å¾´é‡

        Returns:
            ç‰¹å¾´é‡é‡è¦åº¦ã®è¾æ›¸
        """
        try:
            logger.info(f"ç‰¹å¾´é‡é‡è¦åº¦å–å¾—é–‹å§‹: top_n={top_n}")

            # 1. ç¾åœ¨èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            if self.is_model_loaded and getattr(
                self.ml_training_service.trainer, "is_trained", False
            ):
                logger.info(
                    f"ç¾åœ¨èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—: trainer_type={type(self.ml_training_service.trainer).__name__}"
                )
                feature_importance = self.ml_training_service.get_feature_importance()
                if feature_importance:
                    logger.info(
                        f"ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—: {len(feature_importance)}å€‹"
                    )
                    # ä¸Šä½Nå€‹ã‚’å–å¾—
                    sorted_importance = sorted(
                        feature_importance.items(), key=lambda x: x[1], reverse=True
                    )[:top_n]
                    return dict(sorted_importance)
                else:
                    logger.warning("ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            # 2. æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
            from ...ml.model_manager import model_manager

            logger.info("æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã‚’è©¦è¡Œ")
            latest_model = model_manager.get_latest_model("*")
            if latest_model:
                logger.info(f"æœ€æ–°ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {latest_model}")
                model_data = model_manager.load_model(latest_model)
                if model_data and "metadata" in model_data:
                    metadata = model_data["metadata"]
                    feature_importance = metadata.get("feature_importance", {})
                    logger.info(
                        f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª: {len(feature_importance)}å€‹"
                    )

                    if feature_importance:
                        # ä¸Šä½Nå€‹ã‚’å–å¾—
                        sorted_importance = sorted(
                            feature_importance.items(), key=lambda x: x[1], reverse=True
                        )[:top_n]
                        logger.info(
                            f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—: {len(sorted_importance)}å€‹"
                        )
                        return dict(sorted_importance)
                    else:
                        logger.warning("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ç‰¹å¾´é‡é‡è¦åº¦ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                else:
                    logger.warning("ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                logger.warning("æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            logger.warning("ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}

        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡é‡è¦åº¦å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def predict_probabilities(self, features: pd.DataFrame) -> Dict[str, float]:
        """
        ç‰¹å¾´é‡ã‹ã‚‰äºˆæ¸¬ç¢ºç‡ã‚’è¨ˆç®—ï¼ˆMLServiceInterfaceå®Ÿè£…ï¼‰

        Args:
            features: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿

        Returns:
            äºˆæ¸¬ç¢ºç‡ã®è¾æ›¸ {"up": float, "down": float, "range": float}
        """
        return self._safe_ml_prediction(features)

    def _validate_input_data(self, df: pd.DataFrame):
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        required_columns = ["open", "high", "low", "close", "volume"]
        UnifiedErrorHandler.validate_dataframe(
            df, required_columns=required_columns, min_rows=1
        )

    def _limit_data_size(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¶é™ã‚’ç„¡åŠ¹åŒ–ï¼ˆåˆ¶é™ãªã—ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾è¿”ã™ï¼‰"""
        # åˆ¶é™ã‚’å¤–ã—ãŸãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾è¿”ã™
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(df)}è¡Œï¼ˆåˆ¶é™ãªã—ï¼‰")
        return df

    def _normalize_column_names(self, df: pd.DataFrame) -> pd.DataFrame:
        """ã‚«ãƒ©ãƒ åã‚’æ­£è¦åŒ–"""
        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèªï¼ˆå¤§æ–‡å­—ãƒ»å°æ–‡å­—ä¸¡æ–¹ã«å¯¾å¿œï¼‰
        required_columns_lower = ["open", "high", "low", "close", "volume"]
        required_columns_upper = ["Open", "High", "Low", "Close", "Volume"]

        # å°æ–‡å­—ã®ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        missing_lower = [col for col in required_columns_lower if col not in df.columns]
        # å¤§æ–‡å­—ã®ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        missing_upper = [col for col in required_columns_upper if col not in df.columns]

        # ã©ã¡ã‚‰ã‹ã®ã‚»ãƒƒãƒˆãŒå®Œå…¨ã«å­˜åœ¨ã™ã‚Œã°OK
        if len(missing_lower) == 0:
            # å°æ–‡å­—ã®ã‚«ãƒ©ãƒ ãŒæƒã£ã¦ã„ã‚‹
            return df.copy()
        elif len(missing_upper) == 0:
            # å¤§æ–‡å­—ã®ã‚«ãƒ©ãƒ ãŒæƒã£ã¦ã„ã‚‹å ´åˆã€å°æ–‡å­—ã«å¤‰æ›
            df_normalized = df.copy()
            df_normalized.columns = [
                col.lower() if col in required_columns_upper else col
                for col in df_normalized.columns
            ]
            return df_normalized
        else:
            raise MLDataError(
                f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³: {missing_lower} (å°æ–‡å­—) ã¾ãŸã¯ {missing_upper} (å¤§æ–‡å­—)"
            )

    def _calculate_features(
        self,
        df: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> Optional[pd.DataFrame]:
        """ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆAutoMLçµ±åˆç‰ˆï¼‰"""
        try:

            # ç‰¹å¾´é‡è¨ˆç®—ç”¨ã«ã‚«ãƒ©ãƒ åã‚’å¤§æ–‡å­—ã«å¤‰æ›
            df_for_features = df.copy()
            column_mapping = {
                "open": "Open",
                "high": "High",
                "low": "Low",
                "close": "Close",
                "volume": "Volume",
            }

            # ã‚«ãƒ©ãƒ åã‚’å¤§æ–‡å­—ã«å¤‰æ›
            df_for_features.columns = [
                column_mapping.get(col, col) for col in df_for_features.columns
            ]

            # AutoMLæ©Ÿèƒ½ãŒæœ‰åŠ¹ãªå ´åˆã¯æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œ
            if self.enable_automl and isinstance(
                self.feature_service, EnhancedFeatureEngineeringService
            ):
                logger.info("ğŸ¤– AutoMLæ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")

                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’è¨ˆç®—ï¼ˆAutoMLç‰¹å¾´é‡ç”Ÿæˆç”¨ï¼‰
                target = self._calculate_target_for_automl(df_for_features)

                features_df = self.feature_service.calculate_enhanced_features(
                    ohlcv_data=df_for_features,
                    funding_rate_data=funding_rate_data,
                    open_interest_data=open_interest_data,
                    automl_config=self.automl_config,
                    target=target,
                )
            else:
                logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")
                features_df = self.feature_service.calculate_advanced_features(
                    df_for_features, funding_rate_data, open_interest_data
                )
            if features_df is not None:
                logger.info(f"ç‰¹å¾´é‡è¨ˆç®—çµæœ: {len(features_df)}è¡Œ")
            else:
                logger.warning("ç‰¹å¾´é‡è¨ˆç®—çµæœãŒNone")

            return features_df
        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _calculate_target_for_automl(self, df: pd.DataFrame) -> Optional[pd.Series]:
        """AutoMLç‰¹å¾´é‡ç”Ÿæˆç”¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’è¨ˆç®—"""
        try:
            if df is None or df.empty or "Close" not in df.columns:
                logger.warning("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°è¨ˆç®—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return None

            # ä¾¡æ ¼å¤‰åŒ–ç‡ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã¨ã—ã¦ä½¿ç”¨
            close_prices = df["Close"]
            price_change = close_prices.pct_change()

            # å°†æ¥ã®ä¾¡æ ¼å¤‰åŒ–ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€1æœŸé–“å…ˆã«ã‚·ãƒ•ãƒˆ
            target = price_change.shift(-1)

            # çµ±è¨ˆçš„æ‰‹æ³•ã§æ¬ æå€¤ã‚’è£œå®Œ
            target_df = pd.DataFrame({"target": target})
            target_df = data_preprocessor.transform_missing_values(
                target_df, strategy="median"
            )
            target = target_df["target"]

            return target

        except Exception as e:
            logger.error(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def set_automl_enabled(
        self, enabled: bool, automl_config: Optional[Dict[str, Any]] = None
    ):
        """AutoMLæ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’è¨­å®š"""
        try:
            self.enable_automl = enabled
            self.automl_config = automl_config

            if enabled:
                # AutoMLè¨­å®šã‚’ä½œæˆ
                if automl_config:
                    automl_config_obj = self._create_automl_config_from_dict(
                        automl_config
                    )
                else:
                    automl_config_obj = AutoMLConfig.get_financial_optimized_config()

                # æ—¢å­˜ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if hasattr(self.feature_service, "cleanup_resources"):
                    self.feature_service.cleanup_resources()

                self.feature_service = EnhancedFeatureEngineeringService(
                    automl_config_obj
                )
                logger.info("ğŸ¤– AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
            else:
                # æ—¢å­˜ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if hasattr(self.feature_service, "cleanup_resources"):
                    self.feature_service.cleanup_resources()

                self.feature_service = FeatureEngineeringService()
                logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"AutoMLè¨­å®šå¤‰æ›´ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_automl_status(self) -> Dict[str, Any]:
        """AutoMLæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "enabled": self.enable_automl,
            "service_type": type(self.feature_service).__name__,
            "config": self.automl_config,
            "available_features": (
                self.feature_service.get_available_automl_features()
                if hasattr(self.feature_service, "get_available_automl_features")
                else {}
            ),
        }

    def _safe_ml_prediction(self, features_df: pd.DataFrame) -> Dict[str, float]:
        """å³æ ¼ãªMLäºˆæ¸¬å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã•ãªã„ï¼‰"""
        try:
            # äºˆæ¸¬ã‚’å®Ÿè¡Œ
            predictions = self.ml_training_service.generate_signals(features_df)

            # äºˆæ¸¬å€¤ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            UnifiedErrorHandler.validate_predictions(predictions)
            self._last_predictions = predictions
            return predictions
        except Exception as e:
            error_msg = f"MLäºˆæ¸¬ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            logger.error(error_msg)
            raise MLDataError(error_msg) from e

    def _expand_predictions_to_data_length(
        self, predictions: Dict[str, float], data_length: int
    ) -> Dict[str, np.ndarray]:
        """äºˆæ¸¬å€¤ã‚’ãƒ‡ãƒ¼ã‚¿é•·ã«æ‹¡å¼µ"""
        try:
            result = {
                "ML_UP_PROB": np.full(data_length, predictions["up"]),
                "ML_DOWN_PROB": np.full(data_length, predictions["down"]),
                "ML_RANGE_PROB": np.full(data_length, predictions["range"]),
            }
            return result
        except Exception as e:
            logger.error(f"äºˆæ¸¬å€¤æ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")
            default_result = self._get_default_indicators(data_length)
            return default_result

    def _validate_ml_indicators(self, ml_indicators: Dict[str, np.ndarray]):
        """MLæŒ‡æ¨™ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        required_indicators = ["ML_UP_PROB", "ML_DOWN_PROB", "ML_RANGE_PROB"]

        # å¿…è¦ãªæŒ‡æ¨™ãŒå­˜åœ¨ã™ã‚‹ã‹
        missing_indicators = [
            ind for ind in required_indicators if ind not in ml_indicators
        ]
        if missing_indicators:
            raise MLValidationError(f"å¿…è¦ãªMLæŒ‡æ¨™ãŒä¸è¶³: {missing_indicators}")

        # å„æŒ‡æ¨™ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        for indicator, values in ml_indicators.items():
            if not isinstance(values, np.ndarray):
                raise MLValidationError(f"MLæŒ‡æ¨™ãŒé…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {indicator}")
            if len(values) == 0:
                raise MLValidationError(f"MLæŒ‡æ¨™ãŒç©ºã§ã™: {indicator}")
            if not np.all((values >= 0) & (values <= 1)):
                raise MLValidationError(f"MLæŒ‡æ¨™ã®å€¤ãŒç¯„å›²å¤–ã§ã™: {indicator}")
            if np.any(np.isnan(values)) or np.any(np.isinf(values)):
                raise MLValidationError(
                    f"MLæŒ‡æ¨™ã«ç„¡åŠ¹ãªå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {indicator}"
                )

    def _get_default_indicators(self, data_length: int) -> Dict[str, np.ndarray]:
        """
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®MLæŒ‡æ¨™ã‚’å–å¾—ï¼ˆéæ¨å¥¨ï¼‰

        æ³¨æ„: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å³æ ¼åŒ–ã«ã‚ˆã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ä½¿ç”¨ã•ã‚Œãªããªã‚Šã¾ã—ãŸã€‚
        ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™ã®ã§ã¯ãªãã€ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹ã¹ãã§ã™ã€‚
        """
        logger.warning(
            "_get_default_indicators ã¯éæ¨å¥¨ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã¦ãã ã•ã„ã€‚"
        )
        config = self.config.prediction
        return {
            "ML_UP_PROB": np.full(data_length, config.DEFAULT_UP_PROB),
            "ML_DOWN_PROB": np.full(data_length, config.DEFAULT_DOWN_PROB),
            "ML_RANGE_PROB": np.full(data_length, config.DEFAULT_RANGE_PROB),
        }

    def _try_load_latest_model(self) -> bool:
        """æœ€æ–°ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿"""
        try:
            latest_model = model_manager.get_latest_model("*")
            if latest_model:
                success = self.ml_training_service.load_model(latest_model)
                if success:
                    self.is_model_loaded = True
                    logger.info(f"æœ€æ–°ã®MLãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿: {latest_model}")
                    return True
                else:
                    logger.warning(f"MLãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {latest_model}")
            else:
                logger.info(
                    "å­¦ç¿’æ¸ˆã¿MLãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚MLæ©Ÿèƒ½ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§å‹•ä½œã—ã¾ã™ã€‚"
                )
            return False

        except Exception as e:
            logger.warning(f"MLãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _get_enhanced_data_with_fr_oi(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            df: å…ƒã®OHLCVãƒ‡ãƒ¼ã‚¿

        Returns:
            æ‹¡å¼µã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆFR/OIãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰æ™‚é–“ç¯„å›²ã‚’å–å¾—
            if df.empty or not isinstance(df.index, pd.DatetimeIndex):
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã‹ã€DatetimeIndexã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                return None

            start_date = df.index.min()
            end_date = df.index.max()

            # ã‚·ãƒ³ãƒœãƒ«ã¨ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‹•çš„ã«æ¨å®š
            symbol = self._infer_symbol_from_data(df)
            timeframe = self._infer_timeframe_from_data(df)

            logger.info(f"æ¨å®šã•ã‚ŒãŸã‚·ãƒ³ãƒœãƒ«: {symbol}, ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ : {timeframe}")

            # BacktestDataServiceã‚’ä½¿ç”¨ã—ã¦æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            # æ³¨æ„: ã“ã®éƒ¨åˆ†ã¯ä¾å­˜æ€§æ³¨å…¥ãŒå¿…è¦ã§ã™ãŒã€ç¾åœ¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã¯
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç›´æ¥å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
            db = next(get_db())
            try:
                backtest_service = self.get_backtest_data_service(db)
                enhanced_df = backtest_service.get_data_for_backtest(
                    symbol=symbol,
                    timeframe=timeframe,
                    start_date=start_date,
                    end_date=end_date,
                )
            finally:
                db.close()

            if enhanced_df is not None and not enhanced_df.empty:
                logger.info(
                    f"æ‹¡å¼µãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(enhanced_df)}è¡Œ, ã‚«ãƒ©ãƒ : {list(enhanced_df.columns)}"
                )
                return enhanced_df
            else:
                logger.warning("æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return None

        except Exception as e:
            logger.error(f"æ‹¡å¼µãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _extract_fr_oi_data(
        self, enhanced_df: pd.DataFrame
    ) -> tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

        Args:
            enhanced_df: æ‹¡å¼µã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

        Returns:
            (funding_rate_data, open_interest_data)ã®ã‚¿ãƒ—ãƒ«
        """
        try:
            funding_rate_data = None
            open_interest_data = None

            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if "funding_rate" in enhanced_df.columns:
                funding_rate_data = enhanced_df[["funding_rate"]].copy()

            # å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if "open_interest" in enhanced_df.columns:
                open_interest_data = enhanced_df[["open_interest"]].copy()

            return funding_rate_data, open_interest_data

        except Exception as e:
            logger.error(f"FR/OIãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None, None

    def _infer_symbol_from_data(self, df: pd.DataFrame) -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’æ¨å®š

        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

        Returns:
            æ¨å®šã•ã‚ŒãŸã‚·ãƒ³ãƒœãƒ«
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’å–å¾—ã‚’è©¦è¡Œ
            if hasattr(df, "attrs") and "symbol" in df.attrs:
                return df.attrs["symbol"]

            # ã‚«ãƒ©ãƒ åã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’æ¨å®š
            if hasattr(df, "columns"):
                for col in df.columns:
                    if isinstance(col, str) and (
                        "BTC" in col.upper() or "ETH" in col.upper()
                    ):
                        if "BTC" in col.upper():
                            return "BTC/USDT:USDT"
                        elif "ETH" in col.upper():
                            return "ETH/USDT:USDT"

            # ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ã‹ã‚‰ã‚·ãƒ³ãƒœãƒ«ã‚’æ¨å®šï¼ˆBTCã¯é€šå¸¸é«˜ä¾¡æ ¼ï¼‰
            if "Close" in df.columns and not df["Close"].empty:
                avg_price = df["Close"].mean()
                if avg_price > 10000:  # BTCã®ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸
                    return "BTC/USDT:USDT"
                elif avg_price > 1000:  # ETHã®ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸
                    return "ETH/USDT:USDT"

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯BTC
            logger.info(
                "ã‚·ãƒ³ãƒœãƒ«ã‚’æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®BTC/USDT:USDTã‚’ä½¿ç”¨ã—ã¾ã™"
            )
            return "BTC/USDT:USDT"

        except Exception as e:
            logger.warning(f"ã‚·ãƒ³ãƒœãƒ«æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return "BTC/USDT:USDT"

    def _infer_timeframe_from_data(self, df: pd.DataFrame) -> str:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¨å®š

        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 

        Returns:
            æ¨å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã‚’è©¦è¡Œ
            if hasattr(df, "attrs") and "timeframe" in df.attrs:
                return df.attrs["timeframe"]

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ™‚é–“é–“éš”ã‹ã‚‰æ¨å®š
            if isinstance(df.index, pd.DatetimeIndex) and len(df.index) > 1:
                # æœ€åˆã®æ•°å€‹ã®æ™‚é–“å·®ã‚’è¨ˆç®—
                time_diffs = []
                for i in range(1, min(6, len(df.index))):
                    diff = df.index[i] - df.index[i - 1]
                    time_diffs.append(diff.total_seconds() / 60)  # åˆ†å˜ä½

                if time_diffs:
                    avg_diff_minutes = sum(time_diffs) / len(time_diffs)

                    # æ™‚é–“é–“éš”ã«åŸºã¥ã„ã¦ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆ¤å®š
                    if abs(avg_diff_minutes - 1) < 0.5:
                        return "1m"
                    elif abs(avg_diff_minutes - 5) < 2:
                        return "5m"
                    elif abs(avg_diff_minutes - 15) < 5:
                        return "15m"
                    elif abs(avg_diff_minutes - 30) < 10:
                        return "30m"
                    elif abs(avg_diff_minutes - 60) < 15:
                        return "1h"
                    elif abs(avg_diff_minutes - 240) < 30:
                        return "4h"
                    elif abs(avg_diff_minutes - 1440) < 60:
                        return "1d"

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1æ™‚é–“
            logger.info(
                "ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®1hã‚’ä½¿ç”¨ã—ã¾ã™"
            )
            return "1h"

        except Exception as e:
            logger.warning(f"ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return "1h"


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§AutoMLæœ‰åŠ¹ï¼‰
ml_orchestrator = MLOrchestrator(enable_automl=True)
