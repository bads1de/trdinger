"""
GradientBoostingãƒ¢ãƒ‡ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼

ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã§ä½¿ç”¨ã™ã‚‹GradientBoostingãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚
scikit-learnã®GradientBoostingClassifierã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å°‚ç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
"""

import logging
from typing import Any, Dict, List, Optional, cast

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier

from ....utils.error_handler import ModelError

logger = logging.getLogger(__name__)


class GradientBoostingModel:
    """
    ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å†…ã§ä½¿ç”¨ã™ã‚‹GradientBoostingãƒ¢ãƒ‡ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼

    scikit-learnã®GradientBoostingClassifierã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å°‚ç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
    """

    # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åï¼ˆAlgorithmRegistryã‹ã‚‰å–å¾—ï¼‰
    ALGORITHM_NAME = "gradientboosting"

    def __init__(self, automl_config: Optional[Dict[str, Any]] = None):
        """
        åˆæœŸåŒ–

        Args:
            automl_config: AutoMLè¨­å®šï¼ˆç¾åœ¨ã¯æœªä½¿ç”¨ï¼‰
        """
        self.model: Optional[GradientBoostingClassifier] = None
        self.is_trained = False
        self._feature_columns: Optional[List[str]] = None
        self.scaler = None
        self.automl_config = automl_config

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.default_params = {
            "n_estimators": 100,
            "max_depth": 6,
            "learning_rate": 0.1,
            "subsample": 0.8,
            "min_samples_split": 5,
            "min_samples_leaf": 2,
            "random_state": 42,
        }

    def _train_model_impl(
        self,
        X_train: pd.DataFrame,
        X_test: pd.DataFrame,
        y_train: pd.Series,
        y_test: pd.Series,
        **training_params,
    ) -> Dict[str, Any]:
        """
        GradientBoostingãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’

        Args:
            X_train: å­¦ç¿’ç”¨ç‰¹å¾´é‡
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_train: å­¦ç¿’ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            y_test: ãƒ†ã‚¹ãƒˆç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ

        Returns:
            å­¦ç¿’çµæœã®è¾æ›¸
        """
        try:
            logger.info("ğŸ“ˆ GradientBoostingãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹")

            # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’ä¿å­˜
            self.feature_columns = list(X_train.columns)

            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            self.model = GradientBoostingClassifier(**self.default_params)

            # å­¦ç¿’å®Ÿè¡Œ
            self.model.fit(X_train, y_train)

            # ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert self.model is not None, "Model should be initialized after fit"
            model: GradientBoostingClassifier = self.model

            # äºˆæ¸¬
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)

            # ç¢ºç‡äºˆæ¸¬ï¼ˆGradientBoostingã¯ç¢ºç‡äºˆæ¸¬ã‚’ã‚µãƒãƒ¼ãƒˆï¼‰
            y_pred_proba_train = model.predict_proba(X_train)
            y_pred_proba_test = model.predict_proba(X_test)

            # å…±é€šã®è©•ä¾¡é–¢æ•°ã‚’ä½¿ç”¨
            from ..common.evaluation_utils import evaluate_model_predictions

            # åŒ…æ‹¬çš„ãªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰
            test_metrics = evaluate_model_predictions(
                y_test,
                cast(np.ndarray, y_pred_test),
                cast(np.ndarray, y_pred_proba_test),
            )

            # åŒ…æ‹¬çš„ãªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰
            train_metrics = evaluate_model_predictions(
                y_train,
                cast(np.ndarray, y_pred_train),
                cast(np.ndarray, y_pred_proba_train),
            )

            # ã‚¯ãƒ©ã‚¹æ•°ã‚’å–å¾—
            n_classes = len(np.unique(y_train))

            # ç‰¹å¾´é‡é‡è¦åº¦
            feature_importance = dict(
                zip(self.feature_columns, model.feature_importances_)
            )

            self.is_trained = True

            results = {
                "algorithm": self.ALGORITHM_NAME,
                "train_metrics": train_metrics,
                "test_metrics": test_metrics,
                "feature_importance": feature_importance,
                "n_estimators": self.model.n_estimators,
                "max_depth": self.model.max_depth,
                "learning_rate": self.model.learning_rate,
                "best_iteration": getattr(
                    self.model, "n_estimators_", self.model.n_estimators
                ),
                "feature_count": len(self.feature_columns),
                "train_samples": len(X_train),
                "test_samples": len(X_test),
                "num_classes": n_classes,
                # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®çµ±ä¸€ã‚­ãƒ¼
                "accuracy": test_metrics.get("accuracy", 0.0),
                "balanced_accuracy": test_metrics.get("balanced_accuracy", 0.0),
                "f1_score": test_metrics.get("f1_score", 0.0),
                "matthews_corrcoef": test_metrics.get("matthews_corrcoef", 0.0),
                "auc_roc": test_metrics.get("roc_auc", 0.0),
                "auc_pr": test_metrics.get("pr_auc", 0.0),
            }

            logger.info(
                f"âœ… GradientBoostingå­¦ç¿’å®Œäº† - ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_metrics.get('accuracy', 0.0):.4f}"
            )
            return results

        except Exception as e:
            logger.error(f"âŒ GradientBoostingå­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            raise ModelError(f"GradientBoostingå­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬çµæœ
        """
        if not self.is_trained or self.model is None:
            raise ModelError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        try:
            # ç‰¹å¾´é‡ã®é †åºã‚’ç¢ºèª
            if self.feature_columns:
                X = pd.DataFrame(X[self.feature_columns])

            predictions = self.model.predict(X)
            return predictions  # type: ignore

        except Exception as e:
            logger.error(f"GradientBoostingäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise ModelError(f"äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """
        äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—

        Args:
            X: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬ç¢ºç‡ã®é…åˆ—
        """
        if not self.is_trained or self.model is None:
            raise ModelError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        try:
            # ç‰¹å¾´é‡ã®é †åºã‚’ç¢ºèª
            if self.feature_columns:
                X = pd.DataFrame(X[self.feature_columns])

            probabilities = self.model.predict_proba(X)
            return probabilities  # type: ignore

        except Exception as e:
            logger.error(f"GradientBoostingç¢ºç‡äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise ModelError(f"ç¢ºç‡äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    @property
    def feature_columns(self) -> Optional[List[str]]:
        """ç‰¹å¾´é‡ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self._feature_columns

    @feature_columns.setter
    def feature_columns(self, columns: Optional[List[str]]):
        """ç‰¹å¾´é‡ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆã‚’è¨­å®š"""
        self._feature_columns = columns

    def get_feature_importance(self) -> Dict[str, float]:
        """
        ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—

        Returns:
            ç‰¹å¾´é‡é‡è¦åº¦ã®è¾æ›¸
        """
        if not self.is_trained or self.model is None:
            raise ModelError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        if not self.feature_columns:
            raise ModelError("ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        model: GradientBoostingClassifier = self.model
        return dict(zip(self.feature_columns, model.feature_importances_))

    def get_model_info(self) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—

        Returns:
            ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¾æ›¸
        """
        if not self.is_trained or self.model is None:
            return {"status": "not_trained"}

        model: GradientBoostingClassifier = self.model
        return {
            "algorithm": self.ALGORITHM_NAME,
            "n_estimators": model.n_estimators,
            "max_depth": model.max_depth,
            "learning_rate": model.learning_rate,
            "subsample": model.subsample,
            "min_samples_split": model.min_samples_split,
            "min_samples_leaf": model.min_samples_leaf,
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
            "status": "trained",
        }
