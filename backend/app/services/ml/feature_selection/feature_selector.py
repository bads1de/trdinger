"""
ç‰¹å¾´é‡é¸æŠã‚·ã‚¹ãƒ†ãƒ 

åˆ†æå ±å‘Šæ›¸ã§ææ¡ˆã•ã‚ŒãŸçµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠã¨ML-basedç‰¹å¾´é‡é¸æŠã‚’å®Ÿè£…ã€‚
é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é‡è¦ãªç‰¹å¾´é‡ã‚’åŠ¹ç‡çš„ã«é¸æŠã—ã¾ã™ã€‚
"""

import logging
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import (
    RFE,
    RFECV,
    SelectFromModel,
    SelectKBest,
    chi2,
    f_classif,
    mutual_info_classif,
)
from sklearn.inspection import permutation_importance
from sklearn.linear_model import LassoCV

logger = logging.getLogger(__name__)


class SelectionMethod(Enum):
    """ç‰¹å¾´é‡é¸æŠæ‰‹æ³•"""

    # çµ±è¨ˆçš„æ‰‹æ³•
    UNIVARIATE_F = "univariate_f"
    UNIVARIATE_CHI2 = "univariate_chi2"
    MUTUAL_INFO = "mutual_info"

    # ML-basedæ‰‹æ³•
    LASSO = "lasso"
    RANDOM_FOREST = "random_forest"
    RFE = "rfe"
    RFECV = "rfecv"
    PERMUTATION = "permutation"

    # çµ„ã¿åˆã‚ã›æ‰‹æ³•
    ENSEMBLE = "ensemble"


@dataclass
class FeatureSelectionConfig:
    """ç‰¹å¾´é‡é¸æŠè¨­å®š"""

    method: SelectionMethod = SelectionMethod.ENSEMBLE
    k_features: Optional[int] = None  # é¸æŠã™ã‚‹ç‰¹å¾´é‡æ•°
    percentile: float = 50  # ä¸Šä½ä½•%ã‚’é¸æŠã™ã‚‹ã‹
    cv_folds: int = 5  # RFECVã§ã®åˆ†å‰²æ•°
    random_state: int = 42
    n_jobs: int = -1

    # é–¾å€¤è¨­å®š
    importance_threshold: float = 0.01
    correlation_threshold: float = 0.95

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
    ensemble_methods: Optional[List[SelectionMethod]] = None
    ensemble_voting: str = "majority"  # "majority" or "unanimous"


class FeatureSelector:
    """
    ç‰¹å¾´é‡é¸æŠå™¨

    è¤‡æ•°ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦æœ€é©ãªç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¾ã™ã€‚
    """

    def __init__(self, config: Optional[FeatureSelectionConfig] = None):
        """
        åˆæœŸåŒ–

        Args:
            config: ç‰¹å¾´é‡é¸æŠè¨­å®š
        """
        self.config = config or FeatureSelectionConfig()
        if self.config.ensemble_methods is None:
            self.config.ensemble_methods = [
                SelectionMethod.MUTUAL_INFO,
                SelectionMethod.RANDOM_FOREST,
                SelectionMethod.LASSO,
            ]

        self.selected_features_ = None
        self.selection_results_ = {}

    def fit_transform(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡DataFrame
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆSeries

        Returns:
            é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®DataFrameã¨é¸æŠçµæœã®è¾æ›¸
        """
        logger.info(f"ğŸ¯ ç‰¹å¾´é‡é¸æŠé–‹å§‹: {self.config.method.value}")
        logger.info(f"å…¥åŠ›ç‰¹å¾´é‡æ•°: {X.shape[1]}, ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}")

        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        X_processed, feature_names = self._preprocess_data(X)

        # ç‰¹å¾´é‡é¸æŠå®Ÿè¡Œ
        if self.config.method == SelectionMethod.ENSEMBLE:
            selected_features, results = self._ensemble_selection(
                X_processed, y, feature_names
            )
        else:
            selected_features, results = self._single_method_selection(
                X_processed, y, feature_names, self.config.method
            )

        # çµæœã®ä¿å­˜
        self.selected_features_ = selected_features
        self.selection_results_ = results

        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã§DataFrameã‚’ä½œæˆ (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œã‚’é¿ã‘ã‚‹)
        if selected_features:
            data_dict = {c: X[c].values for c in selected_features if c in X.columns}
            X_selected = pd.DataFrame(data_dict, index=X.index)
        else:
            # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ãŒãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
            X_selected = pd.DataFrame(index=X.index)

        # çµæœãŒDataFrameã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
        if not isinstance(X_selected, pd.DataFrame):
            X_selected = pd.DataFrame(X_selected)

        logger.info(f"âœ… ç‰¹å¾´é‡é¸æŠå®Œäº†: {len(selected_features)}å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ")
        logger.info(f"é¸æŠç‡: {len(selected_features) / X.shape[1] * 100:.1f}%")

        return X_selected, results

    def _preprocess_data(self, X: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
        # æ¬ æå€¤ãƒ»ç„¡é™å€¤ã®å‡¦ç† (ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ãªå‡¦ç†ã«é™å®š)
        X_filled = X.replace([np.inf, -np.inf], np.nan)
        X_filled = X_filled.fillna(X_filled.median())

        # å®šæ•°ç‰¹å¾´é‡ã®é™¤å» (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œã‚’é¿ã‘ã‚‹)
        cols = X_filled.columns.tolist()
        nunique = [X_filled[c].nunique() for c in cols]
        keep_cols = [cols[i] for i, n in enumerate(nunique) if n > 1]

        if len(keep_cols) < len(cols):
            logger.info(f"å®šæ•°ç‰¹å¾´é‡ã‚’é™¤å»: {len(cols) - len(keep_cols)}å€‹")
            # è¾æ›¸ã‹ã‚‰å†æ§‹ç¯‰
            data_dict = {c: X_filled[c].values for c in keep_cols}
            X_filled = pd.DataFrame(data_dict, index=X_filled.index)

        # é«˜ç›¸é–¢ç‰¹å¾´é‡ã®é™¤å»
        X_filled = self._remove_highly_correlated_features(X_filled)

        return X_filled.values, X_filled.columns.tolist()

    def _remove_highly_correlated_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """é«˜ç›¸é–¢ç‰¹å¾´é‡ã‚’é™¤å»"""
        try:
            # ç›¸é–¢è¡Œåˆ—ã®å–å¾—
            corr_matrix = X.corr().abs()
            cols = corr_matrix.columns.tolist()
            drop_cols = []

            # 2é‡ãƒ«ãƒ¼ãƒ—ã§ã®ç›¸é–¢ãƒã‚§ãƒƒã‚¯ (ilocã‚’ä½¿ã‚ãšvaluesã§é«˜é€ŸåŒ–)
            corr_values = corr_matrix.values
            for i in range(len(cols)):
                for j in range(i + 1, len(cols)):
                    if corr_values[i, j] > self.config.correlation_threshold:
                        col_to_drop = cols[j]
                        if col_to_drop not in drop_cols:
                            drop_cols.append(col_to_drop)

            if drop_cols:
                logger.info(f"é«˜ç›¸é–¢ç‰¹å¾´é‡ã‚’é™¤å»: {len(drop_cols)}å€‹")
                # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿ã§å†æ§‹ç¯‰
                keep_cols = [c for c in cols if c not in drop_cols]
                data_dict = {c: X[c].values for c in keep_cols}
                X = pd.DataFrame(data_dict, index=X.index)

        except Exception as e:
            logger.warning(f"ç›¸é–¢é™¤å»ã‚¨ãƒ©ãƒ¼: {e}")

        return X

    def _ensemble_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç‰¹å¾´é‡é¸æŠ"""
        logger.info("ğŸ”„ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ")

        method_results = {}
        feature_votes = {name: 0 for name in feature_names}

        # ensemble_methods ãŒ None ã®å ´åˆã®å‡¦ç†
        ensemble_methods = self.config.ensemble_methods or [
            SelectionMethod.MUTUAL_INFO,
            SelectionMethod.RANDOM_FOREST,
            SelectionMethod.LASSO,
        ]

        # å„æ‰‹æ³•ã§ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ
        for method in ensemble_methods:
            try:
                selected_features, result = self._single_method_selection(
                    X, y, feature_names, method
                )
                method_results[method.value] = result

                # æŠ•ç¥¨
                for feature in selected_features:
                    feature_votes[feature] += 1

                logger.info(f"{method.value}: {len(selected_features)}å€‹é¸æŠ")

            except Exception as e:
                logger.warning(f"{method.value}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue

        # æŠ•ç¥¨çµæœã«åŸºã¥ã„ã¦æœ€çµ‚é¸æŠ
        n_methods = len(ensemble_methods)

        if self.config.ensemble_voting == "unanimous":
            # å…¨æ‰‹æ³•ã§é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿
            threshold = n_methods
        else:
            # éåŠæ•°ã§é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡
            threshold = max(1, n_methods // 2)

        selected_features = [
            feature for feature, votes in feature_votes.items() if votes >= threshold
        ]

        # æœ€å°ç‰¹å¾´é‡æ•°ã®ä¿è¨¼
        if len(selected_features) < 5:
            # æŠ•ç¥¨æ•°é †ã§ãƒˆãƒƒãƒ—5ã‚’é¸æŠ
            sorted_features = sorted(
                feature_votes.items(), key=lambda x: x[1], reverse=True
            )
            selected_features = [f[0] for f in sorted_features[:5]]

        results = {
            "method": "ensemble",
            "ensemble_methods": [m.value for m in ensemble_methods],
            "method_results": method_results,
            "feature_votes": feature_votes,
            "voting_threshold": threshold,
            "selected_features": selected_features,
        }

        return selected_features, results

    def _mask_to_features(
        self,
        mask: Optional[np.ndarray],
        scores: np.ndarray,
        feature_names: List[str],
        k: int = 5,
    ) -> List[str]:
        """ãƒã‚¹ã‚¯ã¾ãŸã¯ã‚¹ã‚³ã‚¢ã‹ã‚‰ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆå…±é€šå‡¦ç†ï¼‰"""
        if mask is not None and mask.any():
            selected = [feature_names[i] for i, m in enumerate(mask) if m]
            if len(selected) >= k:
                return selected

        # ãƒã‚¹ã‚¯ãŒç„¡åŠ¹ã¾ãŸã¯æ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯ã‚¹ã‚³ã‚¢ä¸Šä½ã‚’é¸æŠ
        top_idx = np.argsort(np.abs(scores))[-min(k, len(scores)) :]
        return [feature_names[i] for i in top_idx]

    def _single_method_selection(
        self,
        X: np.ndarray,
        y: pd.Series,
        feature_names: List[str],
        method: SelectionMethod,
    ) -> Tuple[List[str], Dict[str, Any]]:
        """å˜ä¸€æ‰‹æ³•ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸æŠ"""
        try:
            k_def = self.config.k_features or max(5, int(len(feature_names) * 0.3))

            if method == SelectionMethod.UNIVARIATE_F:
                sel = SelectKBest(f_classif, k=k_def).fit(X, y)
                feats = self._mask_to_features(
                    sel.get_support(), sel.scores_, feature_names, k=k_def
                )
                return feats, {
                    "method": "f_classif",
                    "scores": sel.scores_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.UNIVARIATE_CHI2:
                X_pos = X - X.min(axis=0) + 1e-8
                sel = SelectKBest(chi2, k=k_def).fit(X_pos, y)
                feats = self._mask_to_features(
                    sel.get_support(), sel.scores_, feature_names, k=k_def
                )
                return feats, {
                    "method": "chi2",
                    "scores": sel.scores_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.MUTUAL_INFO:
                sel = SelectKBest(mutual_info_classif, k=k_def).fit(X, y)
                feats = self._mask_to_features(
                    sel.get_support(), sel.scores_, feature_names, k=k_def
                )
                return feats, {
                    "method": "mutual_info",
                    "scores": sel.scores_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.LASSO:
                model = LassoCV(
                    cv=self.config.cv_folds, random_state=self.config.random_state
                ).fit(X, y)
                sel = SelectFromModel(
                    model, threshold=self.config.importance_threshold, prefit=True
                )
                feats = self._mask_to_features(
                    sel.get_support(), model.coef_, feature_names, k=k_def
                )
                return feats, {
                    "method": "lasso",
                    "coefficients": model.coef_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.RANDOM_FOREST:
                model = RandomForestClassifier(
                    n_estimators=100,
                    random_state=self.config.random_state,
                    n_jobs=self.config.n_jobs,
                ).fit(X, y)
                sel = SelectFromModel(
                    model, threshold=self.config.importance_threshold, prefit=True
                )
                feats = self._mask_to_features(
                    sel.get_support(),
                    model.feature_importances_,
                    feature_names,
                    k=k_def,
                )
                return feats, {
                    "method": "random_forest",
                    "importances": model.feature_importances_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.RFE:
                est = RandomForestClassifier(
                    n_estimators=50, random_state=self.config.random_state
                )
                sel = RFE(est, n_features_to_select=k_def).fit(X, y)
                feats = self._mask_to_features(
                    sel.get_support(), -sel.ranking_, feature_names, k=k_def
                )
                return feats, {
                    "method": "rfe",
                    "ranking": sel.ranking_.tolist(),
                    "selected_features": feats,
                }

            if method == SelectionMethod.RFECV:
                est = RandomForestClassifier(
                    n_estimators=50, random_state=self.config.random_state
                )
                sel = RFECV(est, cv=self.config.cv_folds).fit(X, y)
                feats = self._mask_to_features(
                    sel.get_support(),
                    sel.support_.astype(float),
                    feature_names,
                    k=k_def,
                )
                return feats, {
                    "method": "rfecv",
                    "n_features": int(sel.n_features_),
                    "selected_features": feats,
                }

            if method == SelectionMethod.PERMUTATION:
                est = RandomForestClassifier(
                    n_estimators=50, random_state=self.config.random_state
                ).fit(X, y)
                imp = permutation_importance(
                    est, X, y, n_repeats=5, random_state=self.config.random_state
                )
                feats = self._mask_to_features(
                    imp.importances_mean > self.config.importance_threshold,
                    imp.importances_mean,
                    feature_names,
                    k=k_def,
                )
                return feats, {
                    "method": "permutation",
                    "importances": imp.importances_mean.tolist(),
                    "selected_features": feats,
                }

            raise ValueError(f"æœªå¯¾å¿œã®æ‰‹æ³•: {method}")

        except Exception as e:
            method_name = method.value if hasattr(method, "value") else str(method)
            logger.error(f"{method_name}é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}
