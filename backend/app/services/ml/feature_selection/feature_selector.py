"""
ç‰¹å¾´é‡é¸æŠã‚·ã‚¹ãƒ†ãƒ 

åˆ†æå ±å‘Šæ›¸ã§ææ¡ˆã•ã‚ŒãŸçµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠã¨ML-basedç‰¹å¾´é‡é¸æŠã‚’å®Ÿè£…ã€‚
é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é‡è¦ãªç‰¹å¾´é‡ã‚’åŠ¹ç‡çš„ã«é¸æŠã—ã¾ã™ã€‚
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, Any, List, Optional, Tuple
from sklearn.feature_selection import (
    SelectKBest,
    f_classif,
    chi2,
    mutual_info_classif,
    RFE,
    RFECV,
    SelectFromModel,
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LassoCV
from sklearn.inspection import permutation_importance
from dataclasses import dataclass
from enum import Enum


logger = logging.getLogger(__name__)


class SelectionMethod(Enum):
    """ç‰¹å¾´é‡é¸æŠæ‰‹æ³•"""

    # çµ±è¨ˆçš„æ‰‹æ³•
    UNIVARIATE_F = "univariate_f"
    UNIVARIATE_CHI2 = "univariate_chi2"
    MUTUAL_INFO = "mutual_info"

    # ML-basedæ‰‹æ³•
    LASSO = "lasso"
    RANDOM_FOREST = "random_forest"
    RFE = "rfe"
    RFECV = "rfecv"
    PERMUTATION = "permutation"

    # çµ„ã¿åˆã‚ã›æ‰‹æ³•
    ENSEMBLE = "ensemble"


@dataclass
class FeatureSelectionConfig:
    """ç‰¹å¾´é‡é¸æŠè¨­å®š"""

    method: SelectionMethod = SelectionMethod.ENSEMBLE
    k_features: Optional[int] = None  # é¸æŠã™ã‚‹ç‰¹å¾´é‡æ•°
    percentile: float = 50  # ä¸Šä½ä½•%ã‚’é¸æŠã™ã‚‹ã‹
    cv_folds: int = 5  # RFECVã§ã®åˆ†å‰²æ•°
    random_state: int = 42
    n_jobs: int = -1

    # é–¾å€¤è¨­å®š
    importance_threshold: float = 0.01
    correlation_threshold: float = 0.95

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
    ensemble_methods: List[SelectionMethod] = None
    ensemble_voting: str = "majority"  # "majority" or "unanimous"


class FeatureSelector:
    """
    ç‰¹å¾´é‡é¸æŠå™¨

    è¤‡æ•°ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦æœ€é©ãªç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¾ã™ã€‚
    """

    def __init__(self, config: FeatureSelectionConfig = None):
        """
        åˆæœŸåŒ–

        Args:
            config: ç‰¹å¾´é‡é¸æŠè¨­å®š
        """
        self.config = config or FeatureSelectionConfig()
        if self.config.ensemble_methods is None:
            self.config.ensemble_methods = [
                SelectionMethod.MUTUAL_INFO,
                SelectionMethod.RANDOM_FOREST,
                SelectionMethod.LASSO,
            ]

        self.selected_features_ = None
        self.feature_scores_ = None
        self.selection_results_ = {}

    def fit_transform(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡DataFrame
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆSeries

        Returns:
            é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®DataFrameã¨é¸æŠçµæœã®è¾æ›¸
        """
        logger.info(f"ğŸ¯ ç‰¹å¾´é‡é¸æŠé–‹å§‹: {self.config.method.value}")
        logger.info(f"å…¥åŠ›ç‰¹å¾´é‡æ•°: {X.shape[1]}, ã‚µãƒ³ãƒ—ãƒ«æ•°: {X.shape[0]}")

        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        X_processed, feature_names = self._preprocess_data(X)

        # ç‰¹å¾´é‡é¸æŠå®Ÿè¡Œ
        if self.config.method == SelectionMethod.ENSEMBLE:
            selected_features, results = self._ensemble_selection(
                X_processed, y, feature_names
            )
        else:
            selected_features, results = self._single_method_selection(
                X_processed, y, feature_names, self.config.method
            )

        # çµæœã®ä¿å­˜
        self.selected_features_ = selected_features
        self.selection_results_ = results

        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã§DataFrameã‚’ä½œæˆ
        X_selected = X[selected_features]

        logger.info(f"âœ… ç‰¹å¾´é‡é¸æŠå®Œäº†: {len(selected_features)}å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ")
        logger.info(f"é¸æŠç‡: {len(selected_features)/X.shape[1]*100:.1f}%")

        return X_selected, results

    def _preprocess_data(self, X: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
        # æ¬ æå€¤ã®å‡¦ç†
        X_filled = X.fillna(X.median())

        # ç„¡é™å€¤ã®å‡¦ç†
        X_filled = X_filled.replace([np.inf, -np.inf], np.nan)
        X_filled = X_filled.fillna(X_filled.median())

        # å®šæ•°ç‰¹å¾´é‡ã®é™¤å»
        constant_features = X_filled.columns[X_filled.nunique() <= 1].tolist()
        if constant_features:
            logger.info(f"å®šæ•°ç‰¹å¾´é‡ã‚’é™¤å»: {len(constant_features)}å€‹")
            X_filled = X_filled.drop(columns=constant_features)

        # é«˜ç›¸é–¢ç‰¹å¾´é‡ã®é™¤å»
        X_filled = self._remove_highly_correlated_features(X_filled)

        return X_filled.values, X_filled.columns.tolist()

    def _remove_highly_correlated_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """é«˜ç›¸é–¢ç‰¹å¾´é‡ã‚’é™¤å»"""
        try:
            corr_matrix = X.corr().abs()
            upper_triangle = corr_matrix.where(
                np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
            )

            to_drop = [
                column
                for column in upper_triangle.columns
                if any(upper_triangle[column] > self.config.correlation_threshold)
            ]

            if to_drop:
                logger.info(f"é«˜ç›¸é–¢ç‰¹å¾´é‡ã‚’é™¤å»: {len(to_drop)}å€‹")
                X = X.drop(columns=to_drop)

        except Exception as e:
            logger.warning(f"ç›¸é–¢é™¤å»ã‚¨ãƒ©ãƒ¼: {e}")

        return X

    def _ensemble_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç‰¹å¾´é‡é¸æŠ"""
        logger.info("ğŸ”„ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ")

        method_results = {}
        feature_votes = {name: 0 for name in feature_names}

        # å„æ‰‹æ³•ã§ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ
        for method in self.config.ensemble_methods:
            try:
                selected_features, result = self._single_method_selection(
                    X, y, feature_names, method
                )
                method_results[method.value] = result

                # æŠ•ç¥¨
                for feature in selected_features:
                    feature_votes[feature] += 1

                logger.info(f"{method.value}: {len(selected_features)}å€‹é¸æŠ")

            except Exception as e:
                logger.warning(f"{method.value}ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue

        # æŠ•ç¥¨çµæœã«åŸºã¥ã„ã¦æœ€çµ‚é¸æŠ
        n_methods = len(self.config.ensemble_methods)

        if self.config.ensemble_voting == "unanimous":
            # å…¨æ‰‹æ³•ã§é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã¿
            threshold = n_methods
        else:
            # éåŠæ•°ã§é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡
            threshold = max(1, n_methods // 2)

        selected_features = [
            feature for feature, votes in feature_votes.items() if votes >= threshold
        ]

        # æœ€å°ç‰¹å¾´é‡æ•°ã®ä¿è¨¼
        if len(selected_features) < 5:
            # æŠ•ç¥¨æ•°é †ã§ãƒˆãƒƒãƒ—5ã‚’é¸æŠ
            sorted_features = sorted(
                feature_votes.items(), key=lambda x: x[1], reverse=True
            )
            selected_features = [f[0] for f in sorted_features[:5]]

        results = {
            "method": "ensemble",
            "ensemble_methods": [m.value for m in self.config.ensemble_methods],
            "method_results": method_results,
            "feature_votes": feature_votes,
            "voting_threshold": threshold,
            "selected_features": selected_features,
        }

        return selected_features, results

    def _single_method_selection(
        self,
        X: np.ndarray,
        y: pd.Series,
        feature_names: List[str],
        method: SelectionMethod,
    ) -> Tuple[List[str], Dict[str, Any]]:
        """å˜ä¸€æ‰‹æ³•ã«ã‚ˆã‚‹ç‰¹å¾´é‡é¸æŠ"""

        if method == SelectionMethod.UNIVARIATE_F:
            return self._univariate_selection(X, y, feature_names, f_classif)
        elif method == SelectionMethod.UNIVARIATE_CHI2:
            return self._univariate_selection(X, y, feature_names, chi2)
        elif method == SelectionMethod.MUTUAL_INFO:
            return self._mutual_info_selection(X, y, feature_names)
        elif method == SelectionMethod.LASSO:
            return self._lasso_selection(X, y, feature_names)
        elif method == SelectionMethod.RANDOM_FOREST:
            return self._random_forest_selection(X, y, feature_names)
        elif method == SelectionMethod.RFE:
            return self._rfe_selection(X, y, feature_names)
        elif method == SelectionMethod.RFECV:
            return self._rfecv_selection(X, y, feature_names)
        elif method == SelectionMethod.PERMUTATION:
            return self._permutation_selection(X, y, feature_names)
        else:
            raise ValueError(f"æœªå¯¾å¿œã®æ‰‹æ³•: {method}")

    def _univariate_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str], score_func
    ) -> Tuple[List[str], Dict[str, Any]]:
        """å˜å¤‰é‡çµ±è¨ˆçš„é¸æŠ"""
        try:
            # Chi2ã®å ´åˆã¯éè² å€¤ã«å¤‰æ›
            if score_func == chi2:
                X_transformed = X - X.min(axis=0) + 1e-8
            else:
                X_transformed = X

            k = self.config.k_features or max(5, int(len(feature_names) * 0.3))
            selector = SelectKBest(score_func=score_func, k=k)
            selector.fit(X_transformed, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            results = {
                "method": score_func.__name__,
                "scores": selector.scores_.tolist(),
                "selected_features": selected_features,
                "k": k,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"å˜å¤‰é‡é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _mutual_info_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """ç›¸äº’æƒ…å ±é‡ã«ã‚ˆã‚‹é¸æŠ"""
        try:
            k = self.config.k_features or max(5, int(len(feature_names) * 0.3))
            selector = SelectKBest(score_func=mutual_info_classif, k=k)
            selector.fit(X, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            results = {
                "method": "mutual_info",
                "scores": selector.scores_.tolist(),
                "selected_features": selected_features,
                "k": k,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"ç›¸äº’æƒ…å ±é‡é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _lasso_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """Lassoå›å¸°ã«ã‚ˆã‚‹é¸æŠ"""
        try:
            lasso = LassoCV(
                cv=self.config.cv_folds, random_state=self.config.random_state
            )
            lasso.fit(X, y)  # æ˜ç¤ºçš„ã«fitã‚’å®Ÿè¡Œ

            selector = SelectFromModel(
                lasso, threshold=self.config.importance_threshold
            )
            selector.fit(X, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            # æœ€å°ç‰¹å¾´é‡æ•°ã®ä¿è¨¼
            if len(selected_features) < 5:
                importances = np.abs(lasso.coef_)
                top_indices = np.argsort(importances)[-5:]
                selected_features = [feature_names[i] for i in top_indices]

            results = {
                "method": "lasso",
                "coefficients": lasso.coef_.tolist(),
                "alpha": lasso.alpha_,
                "selected_features": selected_features,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"Lassoé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _random_forest_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã«ã‚ˆã‚‹é¸æŠ"""
        try:
            rf = RandomForestClassifier(
                n_estimators=100,
                random_state=self.config.random_state,
                n_jobs=self.config.n_jobs,
            )
            rf.fit(X, y)  # æ˜ç¤ºçš„ã«fitã‚’å®Ÿè¡Œ

            selector = SelectFromModel(rf, threshold=self.config.importance_threshold)
            selector.fit(X, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            # æœ€å°ç‰¹å¾´é‡æ•°ã®ä¿è¨¼
            if len(selected_features) < 5:
                importances = rf.feature_importances_
                top_indices = np.argsort(importances)[-5:]
                selected_features = [feature_names[i] for i in top_indices]

            results = {
                "method": "random_forest",
                "feature_importances": rf.feature_importances_.tolist(),
                "selected_features": selected_features,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _rfe_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """å†å¸°çš„ç‰¹å¾´é‡é™¤å»"""
        try:
            estimator = RandomForestClassifier(
                n_estimators=50, random_state=self.config.random_state
            )
            n_features = self.config.k_features or max(5, int(len(feature_names) * 0.3))
            selector = RFE(estimator, n_features_to_select=n_features)
            selector.fit(X, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            results = {
                "method": "rfe",
                "ranking": selector.ranking_.tolist(),
                "selected_features": selected_features,
                "n_features": n_features,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"RFEé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _rfecv_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãå†å¸°çš„ç‰¹å¾´é‡é™¤å»"""
        try:
            estimator = RandomForestClassifier(
                n_estimators=50, random_state=self.config.random_state
            )
            selector = RFECV(estimator, cv=self.config.cv_folds)
            selector.fit(X, y)

            selected_mask = selector.get_support()
            selected_features = [
                feature_names[i] for i in range(len(feature_names)) if selected_mask[i]
            ]

            results = {
                "method": "rfecv",
                "ranking": selector.ranking_.tolist(),
                "cv_scores": selector.cv_results_["mean_test_score"].tolist(),
                "optimal_features": selector.n_features_,
                "selected_features": selected_features,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"RFECVé¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def _permutation_selection(
        self, X: np.ndarray, y: pd.Series, feature_names: List[str]
    ) -> Tuple[List[str], Dict[str, Any]]:
        """é †åˆ—é‡è¦åº¦ã«ã‚ˆã‚‹é¸æŠ"""
        try:
            estimator = RandomForestClassifier(
                n_estimators=50, random_state=self.config.random_state
            )
            estimator.fit(X, y)

            perm_importance = permutation_importance(
                estimator, X, y, n_repeats=5, random_state=self.config.random_state
            )

            # é‡è¦åº¦ã®é–¾å€¤ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’é¸æŠ
            important_features = (
                perm_importance.importances_mean > self.config.importance_threshold
            )
            selected_features = [
                feature_names[i]
                for i in range(len(feature_names))
                if important_features[i]
            ]

            # æœ€å°ç‰¹å¾´é‡æ•°ã®ä¿è¨¼
            if len(selected_features) < 5:
                top_indices = np.argsort(perm_importance.importances_mean)[-5:]
                selected_features = [feature_names[i] for i in top_indices]

            results = {
                "method": "permutation",
                "importances_mean": perm_importance.importances_mean.tolist(),
                "importances_std": perm_importance.importances_std.tolist(),
                "selected_features": selected_features,
            }

            return selected_features, results

        except Exception as e:
            logger.error(f"é †åˆ—é‡è¦åº¦é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            return feature_names[:5], {"error": str(e)}

    def get_feature_importance_ranking(self) -> Optional[pd.DataFrame]:
        """ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—"""
        if not self.selection_results_:
            return None

        # å®Ÿè£…ã¯çœç•¥ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ ï¼‰
        return None


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
feature_selector = FeatureSelector()
