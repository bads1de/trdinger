"""
å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼

BaseMLTrainerã‚’ç¶™æ‰¿ã—ã€å˜ä¸€ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æä¾›ã—ã¾ã™ã€‚
LightGBMã€XGBoostã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
"""

import logging
from typing import Any, Dict, cast

import numpy as np
import pandas as pd

from ..base_ml_trainer import BaseMLTrainer
from ..exceptions import MLModelError

logger = logging.getLogger(__name__)


class SingleModelTrainer(BaseMLTrainer):
    """
    å˜ä¸€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼

    BaseMLTrainerã‚’ç¶™æ‰¿ã—ã€å˜ä¸€ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨ã›ãšã€æŒ‡å®šã•ã‚ŒãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚
    """

    def __init__(
        self,
        model_type: str = "lightgbm",
    ):
        """
        åˆæœŸåŒ–

        Args:
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆlightgbm, xgboostï¼‰
        """
        super().__init__()

        self.model_type = model_type.lower()
        self.single_model = None
        self.last_training_results = None  # æœ€å¾Œã®å­¦ç¿’çµæœã‚’ä¿æŒ

        # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
        supported_models = ["lightgbm", "xgboost"]
        if self.model_type not in supported_models:
            raise MLModelError(
                f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}. "
                f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«: {supported_models}"
            )

        logger.info(f"SingleModelTraineråˆæœŸåŒ–: model_type={self.model_type}")

    def _train_model_impl(
        self,
        X_train: pd.DataFrame,
        X_test: pd.DataFrame,
        y_train: pd.Series,
        y_test: pd.Series,
        **training_params,
    ) -> Dict[str, Any]:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ

        Args:
            X_train: å­¦ç¿’ç”¨ç‰¹å¾´é‡
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_train: å­¦ç¿’ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            y_test: ãƒ†ã‚¹ãƒˆç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            **training_params: è¿½åŠ ã®å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            å­¦ç¿’çµæœã®è¾æ›¸
        """
        try:
            logger.info(f"ğŸ¤– {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã§ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™")

            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            self.single_model = self._create_model_instance()

            # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
            training_result = self.single_model.fit(
                X_train, y_train, eval_set=[(X_test, y_test)], **training_params
            )

            # å­¦ç¿’å®Œäº†ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
            self.is_trained = True
            self.feature_columns = list(X_train.columns)

            # BaseMLTrainerç”¨ã®ãƒ¢ãƒ‡ãƒ«å‚ç…§ã‚’è¨­å®š
            self._model = self.single_model.model

            # çµæœã‚’æ•´å½¢
            # training_resultã¯ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®fitãƒ¡ã‚½ãƒƒãƒ‰ã‹ã‚‰ã¯è¿”ã•ã‚Œãªã„ï¼ˆselfã‚’è¿”ã™ï¼‰
            # ãã®ãŸã‚ã€è©•ä¾¡çµæœã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
            # evaluate_model_predictionsã¯BaseGradientBoostingModel.fitå†…éƒ¨ã§ãƒ­ã‚°å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ãŒ
            # ã“ã“ã§ã‚‚å–å¾—ã—ã¦è¿”ã™ã®ãŒæœ›ã¾ã—ã„
            
            y_pred_proba = self.predict_proba(X_test)
            y_pred = self.predict(X_test)
            
            from ..common.evaluation_utils import evaluate_model_predictions
            
            detailed_metrics = evaluate_model_predictions(
                y_test, y_pred, y_pred_proba
            )

            # ç‰¹å¾´é‡é‡è¦åº¦
            feature_importance = self.single_model.get_feature_importance()

            result = {
                "model_type": self.model_type,
                "training_samples": len(X_train),
                "test_samples": len(X_test),
                "feature_count": len(X_train.columns),
                "feature_importance": feature_importance,
                **detailed_metrics,
            }

            # å­¦ç¿’çµæœã‚’ä¿å­˜ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
            self.last_training_results = result

            logger.info(f"âœ… {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return result

        except Exception as e:
            logger.error(f"âŒ {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            )

    def _create_model_instance(self):
        """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
        try:
            if self.model_type == "lightgbm":
                from ..models.lightgbm import LightGBMModel

                return LightGBMModel()

            elif self.model_type == "xgboost":
                from ..models.xgboost import XGBoostModel

                return XGBoostModel()

            else:
                raise MLModelError(f"æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}")

        except ImportError as e:
            logger.error(f"{self.model_type.upper()}ã®ä¾å­˜é–¢ä¿‚ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ã®ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"
            )

    def predict(self, features_df: pd.DataFrame) -> np.ndarray:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆã‚¯ãƒ©ã‚¹äºˆæ¸¬ï¼‰

        Args:
            features_df: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®é…åˆ—
        """
        if self.single_model is None or not self.single_model.is_trained:
            raise MLModelError("å­¦ç¿’æ¸ˆã¿å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        try:
            # ç‰¹å¾´é‡ã®é †åºã‚’å­¦ç¿’æ™‚ã¨åˆã‚ã›ã‚‹
            if self.feature_columns:
                features_df = cast(
                    pd.DataFrame, features_df.loc[:, self.feature_columns]
                )

            return self.single_model.predict(features_df)

        except Exception as e:
            logger.error(f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            )

    def predict_proba(self, features_df: pd.DataFrame) -> np.ndarray:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—

        Args:
            features_df: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬ç¢ºç‡ã®é…åˆ—
        """
        if self.single_model is None or not self.single_model.is_trained:
            raise MLModelError("å­¦ç¿’æ¸ˆã¿å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        try:
            # ç‰¹å¾´é‡ã®é †åºã‚’å­¦ç¿’æ™‚ã¨åˆã‚ã›ã‚‹
            if self.feature_columns:
                features_df = cast(
                    pd.DataFrame, features_df.loc[:, self.feature_columns]
                )

            return self.single_model.predict_proba(features_df)

        except Exception as e:
            logger.error(f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            )

    @staticmethod
    def get_available_models() -> list:
        """
        åˆ©ç”¨å¯èƒ½ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆEssential Modelsã®ã¿ï¼‰

        Returns:
            åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
        """
        available = []
        import importlib.util

        # Essential 2 Modelsï¼ˆä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼‰
        essential_models = ["lightgbm", "xgboost"]
        for model in essential_models:
            if importlib.util.find_spec(model):
                available.append(model)

        return available

    def _get_model_to_save(self) -> Any:
        """ä¿å­˜å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—"""
        if self.single_model is None:
            return None
        return self.single_model.model

    def _get_model_specific_metadata(self, model_name: str) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        metadata = {
            "model_type": self.model_type,
            "trainer_type": "single_model",
            "feature_count": (len(self.feature_columns) if self.feature_columns else 0),
        }

        # å­¦ç¿’çµæœã®è©•ä¾¡æŒ‡æ¨™ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        if self.last_training_results:
            # ä¸»è¦ãªè©•ä¾¡æŒ‡æ¨™ã‚’æŠ½å‡º
            performance_metrics = {}
            for key in [
                "accuracy",
                "balanced_accuracy",
                "f1_score",
                "matthews_corrcoef",
                "auc_roc",
                "auc_pr",
                "test_accuracy",
                "test_balanced_accuracy",
                "test_f1_score",
                "test_mcc",
                "test_roc_auc",
                "test_pr_auc",
            ]:
                if key in self.last_training_results:
                    performance_metrics[key] = self.last_training_results[key]

            metadata["performance_metrics"] = performance_metrics

        return metadata

    def load_model(self, model_path: str) -> bool:
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼‰"""
        # è¦ªã‚¯ãƒ©ã‚¹ã®load_modelã‚’å‘¼ã³å‡ºã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        if not super().load_model(model_path):
            return False

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’å¾©å…ƒ
        if hasattr(self, "metadata"):
            self.model_type = self.metadata.get("model_type", self.model_type)

        # single_modelã‚’å†æ§‹ç¯‰
        try:
            self.single_model = self._create_model_instance()
            # ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒãƒˆ
            self.single_model.model = self._model
            self.single_model.is_trained = True
            # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚‚ã‚»ãƒƒãƒˆ
            self.single_model.feature_columns = self.feature_columns

            return True

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¾Œã®å†æ§‹ç¯‰ã«å¤±æ•—: {e}")
            return False