"""
å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼

BaseMLTrainerã‚’ç¶™æ‰¿ã—ã€å˜ä¸€ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æä¾›ã—ã¾ã™ã€‚
LightGBMã€XGBoostã€CatBoostã€TabNetã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
"""

import logging
from typing import Any, Dict, Optional, cast

import numpy as np
import pandas as pd

from ..exceptions import MLModelError
from ..base_ml_trainer import BaseMLTrainer

logger = logging.getLogger(__name__)


class SingleModelTrainer(BaseMLTrainer):
    """
    å˜ä¸€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼

    BaseMLTrainerã‚’ç¶™æ‰¿ã—ã€å˜ä¸€ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨ã›ãšã€æŒ‡å®šã•ã‚ŒãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚
    """

    def __init__(
        self,
        model_type: str = "lightgbm",
        automl_config: Optional[Dict[str, Any]] = None,
    ):
        """
        åˆæœŸåŒ–

        Args:
            model_type: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆlightgbm, xgboost, catboost, tabnetï¼‰
            automl_config: AutoMLè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        super().__init__(automl_config=automl_config)

        self.model_type = model_type.lower()
        self.single_model = None
        self.last_training_results = None  # æœ€å¾Œã®å­¦ç¿’çµæœã‚’ä¿æŒ

        # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
        supported_models = [
            "lightgbm",
            "xgboost",
            "catboost",
            "tabnet",
            "randomforest",
            "extratrees",
            "gradientboosting",
            "adaboost",
            "ridge",
            "naivebayes",
            "knn",
        ]
        if self.model_type not in supported_models:
            raise MLModelError(
                f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}. "
                f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«: {supported_models}"
            )

        logger.info(f"SingleModelTraineråˆæœŸåŒ–: model_type={self.model_type}")

    def _train_model_impl(
        self,
        X_train: pd.DataFrame,
        X_test: pd.DataFrame,
        y_train: pd.Series,
        y_test: pd.Series,
        **training_params,
    ) -> Dict[str, Any]:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ

        Args:
            X_train: å­¦ç¿’ç”¨ç‰¹å¾´é‡
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_train: å­¦ç¿’ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            y_test: ãƒ†ã‚¹ãƒˆç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            **training_params: è¿½åŠ ã®å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            å­¦ç¿’çµæœã®è¾æ›¸
        """
        try:
            logger.info(f"ğŸ¤– {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã§ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™")

            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            self.single_model = self._create_model_instance()

            # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
            training_result = self.single_model._train_model_impl(
                X_train, X_test, y_train, y_test, **training_params
            )

            # å­¦ç¿’å®Œäº†ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
            self.is_trained = True
            self.feature_columns = list(X_train.columns)

            # çµæœã‚’æ•´å½¢
            result = {
                "model_type": self.model_type,
                "training_samples": len(X_train),
                "test_samples": len(X_test),
                "feature_count": len(X_train.columns),
                **training_result,
            }

            # å­¦ç¿’çµæœã‚’ä¿å­˜ï¼ˆsave_modelã§ä½¿ç”¨ï¼‰
            self.last_training_results = result

            logger.info(f"âœ… {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return result

        except Exception as e:
            logger.error(f"âŒ {self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            )

    def _create_model_instance(self):
        """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
        try:
            if self.model_type == "lightgbm":
                from ..models.lightgbm import LightGBMModel

                return LightGBMModel(automl_config=self.automl_config)

            elif self.model_type == "xgboost":
                from ..models.xgboost import XGBoostModel

                return XGBoostModel(automl_config=self.automl_config)

            elif self.model_type == "catboost":
                from ..models.catboost import CatBoostModel

                return CatBoostModel(automl_config=self.automl_config)

            elif self.model_type == "tabnet":
                from ..models.tabnet import TabNetModel

                return TabNetModel(automl_config=self.automl_config)

            elif self.model_type == "randomforest":
                from ..models.randomforest import RandomForestModel

                return RandomForestModel(automl_config=self.automl_config)

            elif self.model_type == "extratrees":
                from ..models.extratrees import ExtraTreesModel

                return ExtraTreesModel(automl_config=self.automl_config)

            elif self.model_type == "gradientboosting":
                from ..models.gradientboosting import GradientBoostingModel

                return GradientBoostingModel(automl_config=self.automl_config)

            elif self.model_type == "adaboost":
                from ..models.adaboost import AdaBoostModel

                return AdaBoostModel(automl_config=self.automl_config)

            elif self.model_type == "ridge":
                from ..models.ridge import RidgeModel

                return RidgeModel(automl_config=self.automl_config)

            elif self.model_type == "naivebayes":
                from ..models.naivebayes import NaiveBayesModel

                return NaiveBayesModel(automl_config=self.automl_config)

            elif self.model_type == "knn":
                from ..models.knn import KNNModel

                return KNNModel(automl_config=self.automl_config)

            else:
                raise MLModelError(f"æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {self.model_type}")

        except ImportError as e:
            logger.error(f"{self.model_type.upper()}ã®ä¾å­˜é–¢ä¿‚ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ã®ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚"
            )

    def predict(self, features_df: pd.DataFrame) -> np.ndarray:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            features_df: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬ç¢ºç‡ã®é…åˆ— [ä¸‹è½ç¢ºç‡, ãƒ¬ãƒ³ã‚¸ç¢ºç‡, ä¸Šæ˜‡ç¢ºç‡]
        """
        if self.single_model is None or not self.single_model.is_trained:
            raise MLModelError("å­¦ç¿’æ¸ˆã¿å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        try:
            # ç‰¹å¾´é‡ã®é †åºã‚’å­¦ç¿’æ™‚ã¨åˆã‚ã›ã‚‹
            if self.feature_columns:
                features_df = cast(
                    pd.DataFrame, features_df.loc[:, self.feature_columns]
                )

            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ç¢ºç‡ã‚’å–å¾—
            predictions = self.single_model.predict_proba(features_df)

            # äºˆæ¸¬ç¢ºç‡ãŒ3ã‚¯ãƒ©ã‚¹åˆ†é¡ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if predictions.ndim == 2 and predictions.shape[1] == 3:
                return predictions
            else:
                raise MLModelError(
                    f"äºˆæœŸã—ãªã„äºˆæ¸¬ç¢ºç‡ã®å½¢çŠ¶: {predictions.shape}. "
                    f"3ã‚¯ãƒ©ã‚¹åˆ†é¡ (down, range, up) ã®ç¢ºç‡ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚"
                )

        except Exception as e:
            logger.error(f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise MLModelError(
                f"{self.model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
            )

    def save_model(
        self, model_name: str, metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜

        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
        """
        if self.single_model is None or not self.single_model.is_trained:
            raise MLModelError("ä¿å­˜ã™ã‚‹å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        try:
            from ..model_manager import model_manager

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å˜ä¸€ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿½åŠ 
            final_metadata = metadata or {}
            final_metadata.update(
                {
                    "model_type": self.model_type,
                    "trainer_type": "single_model",
                    "feature_count": (
                        len(self.feature_columns) if self.feature_columns else 0
                    ),
                }
            )

            # å­¦ç¿’çµæœã®è©•ä¾¡æŒ‡æ¨™ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            if self.last_training_results:
                # ä¸»è¦ãªè©•ä¾¡æŒ‡æ¨™ã‚’æŠ½å‡º
                performance_metrics = {}
                for key in [
                    "accuracy",
                    "balanced_accuracy",
                    "f1_score",
                    "matthews_corrcoef",
                    "auc_roc",
                    "auc_pr",
                    "test_accuracy",
                    "test_balanced_accuracy",
                    "test_f1_score",
                    "test_mcc",
                    "test_roc_auc",
                    "test_pr_auc",
                ]:
                    if key in self.last_training_results:
                        performance_metrics[key] = self.last_training_results[key]

                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
                final_metadata.update(performance_metrics)
                final_metadata["training_samples"] = self.last_training_results.get(
                    "training_samples", 0
                )
                final_metadata["test_samples"] = self.last_training_results.get(
                    "test_samples", 0
                )

                logger.info(
                    f"è©•ä¾¡æŒ‡æ¨™ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ : {len(performance_metrics)}å€‹ã®æŒ‡æ¨™"
                )

            # ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            try:
                feature_importance = self.get_feature_importance(top_n=100)
                if feature_importance:
                    final_metadata["feature_importance"] = feature_importance
                    logger.info(
                        f"ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ : {len(feature_importance)}å€‹"
                    )
            except Exception as e:
                logger.warning(f"ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—ã«å¤±æ•—: {e}")

            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            model_path = model_manager.save_model(
                model=self.single_model.model,
                model_name=model_name,
                metadata=final_metadata,
                scaler=getattr(self.single_model, "scaler", None),
                feature_columns=self.feature_columns,
            )

            if model_path is None:
                raise MLModelError("ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")

            logger.info(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
            return cast(str, model_path)

        except Exception as e:
            logger.error(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise MLModelError(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def load_model(self, model_path: str) -> bool:
        """
        å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã¿æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
            self.single_model = self._create_model_instance()

            # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            from ..model_manager import model_manager

            model_data = model_manager.load_model(model_path)

            if model_data is not None:
                # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’single_modelã«è¨­å®š
                self.single_model.model = model_data.get("model")
                self.single_model.scaler = model_data.get("scaler")
                self.feature_columns = model_data.get("feature_columns")

                self.is_trained = True
                logger.info(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: model_type={self.model_type}")
                return True
            else:
                logger.error("å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—")
                return False

        except Exception as e:
            logger.error(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    @property
    def model(self):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return self.single_model.model if self.single_model else None

    @model.setter
    def model(self, value):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰"""
        # BaseMLTrainerã¨ã®äº’æ›æ€§ã®ãŸã‚ã€setterã‚’æä¾›
        # å®Ÿéš›ã®è¨­å®šã¯_train_model_implã§è¡Œã‚ã‚Œã‚‹

    def get_model_info(self) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—

        Returns:
            ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¾æ›¸
        """
        if self.single_model is None:
            return {
                "model_type": self.model_type,
                "is_trained": False,
                "trainer_type": "single_model",
            }

        return {
            "model_type": self.model_type,
            "is_trained": self.single_model.is_trained,
            "trainer_type": "single_model",
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
        }

    @staticmethod
    def get_available_models() -> list:
        """
        åˆ©ç”¨å¯èƒ½ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—

        Returns:
            åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ
        """
        available = []
        import importlib.util

        # ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«
        libs = ["lightgbm", "xgboost", "catboost", "tabnet"]
        for lib in libs:
            if importlib.util.find_spec(lib):
                available.append(lib)

        # scikit-learnãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«
        sklearn_models = [
            "randomforest",
            "extratrees",
            "gradientboosting",
            "adaboost",
            "ridge",
            "naivebayes",
            "knn",
        ]

        # scikit-learnè‡ªä½“ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if importlib.util.find_spec("sklearn"):
            available.extend(sklearn_models)

        return available

    def get_feature_importance(self, top_n: int = 10) -> Dict[str, float]:
        """
        ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—

        Args:
            top_n: ä¸Šä½Nå€‹ã®ç‰¹å¾´é‡

        Returns:
            ç‰¹å¾´é‡é‡è¦åº¦ã®è¾æ›¸
        """
        if not self.is_trained or self.single_model is None:
            logger.warning("å­¦ç¿’æ¸ˆã¿å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return {}

        try:
            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
            if hasattr(self.single_model, "get_feature_importance"):
                try:
                    return self.single_model.get_feature_importance()
                except TypeError:
                    return self.single_model.get_feature_importance()
            else:
                logger.warning(
                    f"{self.model_type}ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å¾´é‡é‡è¦åº¦ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“"
                )
                return {}

        except Exception as e:
            logger.error(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡é‡è¦åº¦å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
