"""
Optunaãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³

æ—¢å­˜ã®è¤‡é›‘ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’ç½®ãæ›ãˆã‚‹ã€ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹ç‡çš„ãªå®Ÿè£…ã€‚
"""

import logging
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Callable, Dict, Optional

import optuna

from app.utils.error_handler import safe_operation

logger = logging.getLogger(__name__)


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""

    best_params: Dict[str, Any]
    best_score: float
    total_evaluations: int
    optimization_time: float
    study: optuna.Study


@dataclass
class ParameterSpace:
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®å®šç¾©"""

    type: str  # "real", "integer", "categorical"
    low: Optional[float] = None
    high: Optional[float] = None
    categories: Optional[list] = None


class OptunaOptimizer:
    """
    Optuna ã‚’æ´»ç”¨ã—ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³

    TPE (Tree-structured Parzen Estimator) ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’ç”¨ã„ãŸãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’æä¾›ã—ã¾ã™ã€‚
    è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’åŠ¹ç‡çš„ã«æ¢ç´¢ã—ã€
    æŒ‡å®šã•ã‚ŒãŸç›®çš„é–¢æ•°ï¼ˆObjective Functionï¼‰ã®æœ€å¤§åŒ–ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
    å¤§é‡ã®è©•ä¾¡ã‚’è¡Œã† GA ã‚„ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã¨çµ±åˆã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã€
    Study ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†ã¨ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.study: Optional[optuna.Study] = None

    @safe_operation(context="Optunaæœ€é©åŒ–", is_api_call=False)
    def optimize(
        self,
        objective_function: Callable[[Dict[str, Any]], float],
        parameter_space: Dict[str, ParameterSpace],
        n_calls: int = 50,
    ) -> OptimizationResult:
        """
        Optuna ã‚’ä½¿ç”¨ã—ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè¡Œ

        æœ€å¤§åŒ–ï¼ˆmaximizeï¼‰ã‚’ç›®çš„ã¨ã—ã¦ TPE ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚’ç”¨ã„ã€
        æŒ‡å®šã•ã‚ŒãŸè©¦è¡Œå›æ•°åˆ†ã€ç›®çš„é–¢æ•°ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

        Args:
            objective_function: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ã‚’å—ã‘å–ã‚Šã‚¹ã‚³ã‚¢ã‚’è¿”ã™é–¢æ•°
            parameter_space: æ¢ç´¢å¯¾è±¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã¨ãã®ç¯„å›²å®šç¾©
            n_calls: æœ€é©åŒ–ã®æœ€å¤§è©¦è¡Œå›æ•°

        Returns:
            ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã€ã‚¹ã‚¿ãƒ‡ã‚£ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç­‰ã‚’å«ã‚€ OptimizationResult

        Raises:
            RuntimeError: æœ€é©åŒ–ãŒå®Ÿè¡Œã•ã‚Œãªã‹ã£ãŸå ´åˆã‚„çµæœãŒå¾—ã‚‰ã‚Œãªã‹ã£ãŸå ´åˆ
        """
        logger.info(f"ğŸš€ Optunaæœ€é©åŒ–ã‚’é–‹å§‹: è©¦è¡Œå›æ•°={n_calls}")
        start_time = datetime.now()

        # Optunaã‚¹ã‚¿ãƒ‡ã‚£ã‚’ä½œæˆ
        self.study = optuna.create_study(
            direction="maximize",
            sampler=optuna.samplers.TPESampler(seed=42),
            pruner=optuna.pruners.MedianPruner(),
        )

        # ç›®çš„é–¢æ•°ã‚’Optunaã«é©å¿œ
        def optuna_objective(trial: optuna.Trial) -> float:
            params = self._suggest_parameters(trial, parameter_space)
            try:
                score = objective_function(params)
                return score
            except Exception as e:
                logger.warning(f"ç›®çš„é–¢æ•°è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                raise optuna.TrialPruned()

        # æœ€é©åŒ–å®Ÿè¡Œ
        self.study.optimize(optuna_objective, n_trials=n_calls)

        end_time = datetime.now()
        optimization_time = (end_time - start_time).total_seconds()

        # çµæœã‚’ä½œæˆ
        if self.study is None or len(self.study.trials) == 0:
            raise RuntimeError("æœ€é©åŒ–ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„ã‹ã€è©¦è¡ŒãŒã‚ã‚Šã¾ã›ã‚“")

        best_trial = self.study.best_trial
        if best_trial is None:
            raise RuntimeError("æœ€é©ãªè©¦è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        best_score = best_trial.value if best_trial.value is not None else 0.0
        if best_trial.value is None:
            logger.warning("ãƒ™ã‚¹ãƒˆè©¦è¡Œã®å€¤ãŒNoneã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤0.0ã‚’ä½¿ç”¨ã—ã¾ã™")

        result = OptimizationResult(
            best_params=best_trial.params,
            best_score=best_score,
            total_evaluations=len(self.study.trials),
            optimization_time=optimization_time,
            study=self.study,
        )

        logger.info(
            f"âœ… Optunaæœ€é©åŒ–å®Œäº†: ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢={result.best_score:.4f}, æ™‚é–“={optimization_time:.2f}ç§’"
        )
        return result

    @safe_operation(context="Optunaãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—", is_api_call=False)
    def cleanup(self):
        """
        Optuna ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä¿æŒã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

        å¤§è¦æ¨¡ãªæœ€é©åŒ–ã‚„ GA ä¸­ã®ç¹°ã‚Šè¿”ã—å‘¼ã³å‡ºã—ã«ãŠã„ã¦ã€
        Study ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã«è“„ç©ã•ã‚Œã‚‹ Trial ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾ã—ã€
        ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢ã—ã¾ã™ã€‚
        """
        if self.study is not None:
            # Studyã®å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
            if hasattr(self.study, "trials"):
                self.study.trials.clear()

            # Studyã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè‡ªä½“ã‚’ã‚¯ãƒªã‚¢
            self.study = None

            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc

            gc.collect()

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ç¢ºå®Ÿã«å®Ÿè¡Œ"""
        try:
            self.cleanup()
        except Exception:
            pass  # ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§ã¯ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ãªã„

    def _suggest_parameters(
        self, trial: optuna.Trial, parameter_space: Dict[str, ParameterSpace]
    ) -> Dict[str, Any]:
        """
        ParameterSpace ã®å®šç¾©ã«åŸºã¥ãã€ç¾åœ¨ã®è©¦è¡Œã«ä½¿ç”¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ææ¡ˆ

        Args:
            trial: Optuna ã® Trial ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            parameter_space: æ¢ç´¢ç©ºé–“ã®å®šç¾©è¾æ›¸

        Returns:
            ã‚µã‚¸ã‚§ã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆåå‰ã¨å€¤ã®ãƒšã‚¢ï¼‰

        Raises:
            AssertionError: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã«ä¸è¶³ãŒã‚ã‚‹å ´åˆ
        """
        params = {}
        for name, cfg in parameter_space.items():
            if cfg.type in ["real", "integer"]:
                if cfg.low is None or cfg.high is None:
                    raise AssertionError(
                        f"Bounds (low, high) required for {cfg.type} parameter: {name}"
                    )
                if cfg.type == "real":
                    params[name] = trial.suggest_float(name, cfg.low, cfg.high)
                else:
                    params[name] = trial.suggest_int(name, int(cfg.low), int(cfg.high))
            elif cfg.type == "categorical":
                if not cfg.categories:
                    raise AssertionError(
                        f"Categories required for categorical parameter: {name}"
                    )
                params[name] = trial.suggest_categorical(name, cfg.categories)
        return params

    @staticmethod
    def get_default_parameter_space() -> Dict[str, ParameterSpace]:
        """LightGBMã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return {
            "num_leaves": ParameterSpace(type="integer", low=10, high=100),
            "learning_rate": ParameterSpace(type="real", low=0.01, high=0.3),
            "feature_fraction": ParameterSpace(type="real", low=0.5, high=1.0),
            "bagging_fraction": ParameterSpace(type="real", low=0.5, high=1.0),
            "min_data_in_leaf": ParameterSpace(type="integer", low=5, high=50),
            "max_depth": ParameterSpace(type="integer", low=3, high=15),
        }

    @staticmethod
    @safe_operation(context="ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“å–å¾—", is_api_call=False)
    def get_ensemble_parameter_space(
        ensemble_method: str, enabled_models: list
    ) -> Dict[str, ParameterSpace]:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ç”¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’å–å¾—

        Args:
            ensemble_method: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³• ("stacking")
            enabled_models: æœ‰åŠ¹ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ

        Returns:
            ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“
        """
        from .ensemble_parameter_space import EnsembleParameterSpace

        return EnsembleParameterSpace.get_ensemble_parameter_space(
            ensemble_method, enabled_models
        )
