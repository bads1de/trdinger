"""
ML ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹ã«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼‰ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®
é«˜ãƒ¬ãƒ™ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚Optuna ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã—ã€ç›®çš„é–¢æ•°ã®å®šç¾©ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®æ¢ç´¢ã€
å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œã‚’ç®¡ç†ã—ã¾ã™ã€‚

ä¸»ãªã‚¯ãƒ©ã‚¹:
    - OptimizationSettings: æœ€é©åŒ–ã®å®Ÿè¡Œè¨­å®šï¼ˆè©¦è¡Œå›æ•°ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ãªã©ï¼‰ã‚’å®šç¾©ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚
    - OptimizationService: æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã‚’çµ±æ‹¬ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ã€‚ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã¨é€£æºã—ã¦æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢ã—ã¾ã™ã€‚
"""

import logging
from typing import Any, Callable, Dict, Optional

import pandas as pd

from app.services.ml.ensemble.ensemble_trainer import EnsembleTrainer
from app.utils.error_handler import safe_operation

from .optuna_optimizer import OptunaOptimizer, ParameterSpace

logger = logging.getLogger(__name__)


class OptimizationSettings:
    """æœ€é©åŒ–è¨­å®šã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        enabled: bool = False,
        n_calls: int = 50,
        parameter_space: Optional[Dict[str, Dict[str, Any]]] = None,
    ):
        self.enabled = enabled
        self.n_calls = n_calls
        self.parameter_space = parameter_space or {}


class OptimizationService:
    """
    ML ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’çµ±æ‹¬ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹

    `OptunaOptimizer` ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã—ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹æˆã™ã‚‹
    å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•æ¢ç´¢ã—ã¾ã™ã€‚
    ç›®çš„é–¢æ•°ï¼ˆObjective Functionï¼‰ã®ç”Ÿæˆã€æ¢ç´¢ç©ºé–“ã®è¨­å®šã€
    CVï¼ˆäº¤å·®æ¤œè¨¼ï¼‰å›æ•°ã®èª¿æ•´ç­‰ã‚’è¡Œã„ã€æŒ‡å®šã•ã‚ŒãŸè©¦è¡Œå›æ•°å†…ã§
    ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ï¼ˆä¸»ã«ãƒã‚¯ãƒ­ F1 ã‚¹ã‚³ã‚¢ï¼‰ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚
    """

    def __init__(self):
        self.optimizer = OptunaOptimizer()

    @safe_operation(context="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–", is_api_call=False)
    def optimize_parameters(
        self,
        trainer: Any,
        training_data: pd.DataFrame,
        optimization_settings: OptimizationSettings,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        model_name: Optional[str] = None,
        **training_params,
    ) -> Dict[str, Any]:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Optuna ã‚’ç”¨ã„ã¦ã€æŒ‡å®šã•ã‚ŒãŸè©¦è¡Œå›æ•°ï¼ˆn_callsï¼‰ã®ä¸­ã§
        æœ€ã‚‚é«˜ã„ F1 ã‚¹ã‚³ã‚¢ï¼ˆãƒã‚¯ãƒ­å¹³å‡ï¼‰ã‚’å‡ºã™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’æ¢ç´¢ã—ã¾ã™ã€‚
        å†…éƒ¨ã§ä¸€æ™‚çš„ãªãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ç”Ÿæˆã—ã€è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

        Args:
            trainer: ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            training_data: å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿
            optimization_settings: æœ€é©åŒ–ã®è¨­å®šï¼ˆæœ‰åŠ¹åŒ–ã€è©¦è¡Œå›æ•°ã€æ¢ç´¢ç©ºé–“ï¼‰
            funding_rate_data: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã® FR ãƒ‡ãƒ¼ã‚¿
            open_interest_data: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã® OI ãƒ‡ãƒ¼ã‚¿
            model_name: ä¿å­˜æ™‚ã®ãƒ¢ãƒ‡ãƒ«åï¼ˆæœ€é©åŒ–ä¸­ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ï¼‰
            **training_params: è¿½åŠ ã®å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã€è©•ä¾¡æ™‚é–“ç­‰ã‚’å«ã‚€çµæœè¾æ›¸
        """
        try:
            logger.info("ğŸš€ æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹")

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’æº–å‚™
            parameter_space = self._prepare_parameter_space(
                trainer, optimization_settings
            )

            # ç›®çš„é–¢æ•°ã‚’ä½œæˆ
            objective_function = self._create_objective_function(
                trainer=trainer,
                training_data=training_data,
                optimization_settings=optimization_settings,
                funding_rate_data=funding_rate_data,
                open_interest_data=open_interest_data,
                **training_params,
            )

            # æœ€é©åŒ–ã‚’å®Ÿè¡Œ
            result = self.optimizer.optimize(
                objective_function=objective_function,
                parameter_space=parameter_space,
                n_calls=optimization_settings.n_calls,
            )

            return {
                "method": "optuna",
                "best_params": result.best_params,
                "best_score": result.best_score,
                "total_evaluations": result.total_evaluations,
                "optimization_time": result.optimization_time,
            }

        finally:
            # ç¢ºå®Ÿã«ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
            self.optimizer.cleanup()

    def _prepare_parameter_space(
        self, trainer: Any, optimization_settings: OptimizationSettings
    ) -> Dict[str, ParameterSpace]:
        """
        æ¢ç´¢å¯¾è±¡ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’å®šç¾©

        è¨­å®šã§æ¢ç´¢ç©ºé–“ãŒæ˜ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã—ã€
        ãã†ã§ãªã„å ´åˆã¯ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šã«åŸºã¥ã„ãŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç©ºé–“ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

        Args:
            trainer: å¯¾è±¡ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
            optimization_settings: æœ€é©åŒ–è¨­å®š

        Returns:
            ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’ã‚­ãƒ¼ã€æ¢ç´¢ç¯„å›²ï¼ˆParameterSpaceï¼‰ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
        """
        if optimization_settings.parameter_space:
            return self._convert_parameter_space_config(
                optimization_settings.parameter_space
            )

        # EnsembleTrainerã®å ´åˆï¼ˆå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚‚å«ã‚€ï¼‰
        if hasattr(trainer, "ensemble_config"):
            c = trainer.ensemble_config
            return self.optimizer.get_ensemble_parameter_space(
                c.get("method", "stacking"), c.get("models", ["lightgbm", "xgboost"])
            )

        return self.optimizer.get_default_parameter_space()

    def _convert_parameter_space_config(
        self, parameter_space_config: Dict[str, Dict[str, Any]]
    ) -> Dict[str, ParameterSpace]:
        """è¨­å®šè¾æ›¸ã‚’ParameterSpaceã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
        return {
            name: ParameterSpace(
                type=cfg["type"],
                low=int(cfg["low"]) if cfg["type"] == "integer" else cfg.get("low"),
                high=int(cfg["high"]) if cfg["type"] == "integer" else cfg.get("high"),
                categories=cfg.get("categories"),
            )
            for name, cfg in parameter_space_config.items()
        }

    def _create_objective_function(
        self,
        trainer: Any,
        training_data: pd.DataFrame,
        optimization_settings: OptimizationSettings,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        **base_training_params,
    ) -> Callable[[Dict[str, Any]], float]:
        """
        Optuna ã«æ¸¡ã™ç›®çš„é–¢æ•°ï¼ˆObjective Functionï¼‰ã‚’ä½œæˆ

        å„è©¦è¡Œã§æ¸¡ã•ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡ã‚’è¡Œã„ã€
        æœ€å¤§åŒ–ã™ã¹ãã‚¹ã‚³ã‚¢ï¼ˆF1 ã‚¹ã‚³ã‚¢ï¼‰ã‚’è¿”ã—ã¾ã™ã€‚

        Args:
            trainer: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
            training_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            optimization_settings: æœ€é©åŒ–è¨­å®š
            **base_training_params: å›ºå®šã®å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ã‚’å—ã‘å–ã‚Šã‚¹ã‚³ã‚¢ï¼ˆfloatï¼‰ã‚’è¿”ã™é–¢æ•°
        """
        evaluation_count = 0

        def objective_function(params: Dict[str, Any]) -> float:
            nonlocal evaluation_count
            evaluation_count += 1

            try:
                logger.info(
                    f"ğŸ” è©¦è¡Œ {evaluation_count}/{optimization_settings.n_calls}: {params}"
                )

                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
                training_params = {**base_training_params, **params}

                # ä¸€æ™‚çš„ãªãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ
                temp_trainer = self._create_temp_trainer(trainer, params)

                # å­¦ç¿’å®Ÿè¡Œï¼ˆä¿å­˜ãªã—ï¼‰
                result = temp_trainer.train_model(
                    training_data=training_data,
                    funding_rate_data=funding_rate_data,
                    open_interest_data=open_interest_data,
                    save_model=False,
                    model_name=None,
                    **training_params,
                )

                # ã‚¹ã‚³ã‚¢å–å¾—
                f1_score = result.get("f1_score", 0.0)
                if "classification_report" in result:
                    f1_score = (
                        result["classification_report"]
                        .get("macro avg", {})
                        .get("f1-score", f1_score)
                    )

                return f1_score

            except Exception as e:
                logger.warning(f"ç›®çš„é–¢æ•°è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                return 0.0

        return objective_function

    def _create_temp_trainer(
        self, original_trainer: Any, params: Dict[str, Any]
    ) -> Any:
        """ä¸€æ™‚çš„ãªãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆï¼ˆå…¨ã¦EnsembleTrainerã§çµ±ä¸€ï¼‰"""
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãŒEnsembleTrainerã§ã‚ã‚‹ã“ã¨ã‚’å‰æ
        if hasattr(original_trainer, "ensemble_config"):
            temp_config = original_trainer.ensemble_config.copy()

            # æœ€é©åŒ–ç”¨ã«CV foldsã‚’æ¸›ã‚‰ã™ï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰
            if "stacking_params" in temp_config:
                stacking_params = temp_config["stacking_params"].copy()
                stacking_params["cv_folds"] = 3
                temp_config["stacking_params"] = stacking_params

            return EnsembleTrainer(ensemble_config=temp_config)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§EnsembleTrainerä½œæˆ
            return EnsembleTrainer(ensemble_config={"method": "stacking"})
