"""
ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

OHLCVã€ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆFRï¼‰ã€å»ºç‰æ®‹é«˜ï¼ˆOIï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€
å¸‚å ´ã®æ­ªã¿ã‚„åã‚Šã‚’æ‰ãˆã‚‹é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼šè²¬ä»»ã‚’åˆ†å‰²ã—ã€å„ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’çµ±åˆã—ã¾ã™ã€‚
AutoMLæ©Ÿèƒ½ã‚‚çµ±åˆã•ã‚Œã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ãŒå¯èƒ½ã§ã™ã€‚
"""

# cSpell:ignore automl tsfresh

import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from ....utils.data_processing import data_processor as data_preprocessor

from ....utils.error_handler import safe_ml_operation
from .data_frequency_manager import DataFrequencyManager
from .interaction_features import InteractionFeatureCalculator
from .market_data_features import MarketDataFeatureCalculator
from .price_features import PriceFeatureCalculator
from .technical_features import TechnicalFeatureCalculator
from .temporal_features import TemporalFeatureCalculator
from .crypto_features import CryptoFeatures
from .advanced_features import AdvancedFeatureEngineer

# AutoMLé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
AutoFeatCalculator = None
TSFreshFeatureCalculator = None

try:
    from .automl_features.autofeat_calculator import AutoFeatCalculator
    from .automl_features.automl_config import AutoMLConfig
    from .automl_features.performance_optimizer import PerformanceOptimizer
    from .automl_features.tsfresh_calculator import TSFreshFeatureCalculator

    AUTOML_AVAILABLE = True
except ImportError:
    AUTOML_AVAILABLE = False

logger = logging.getLogger(__name__)


class FeatureEngineeringService:
    """
    ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

    å„ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’çµ±åˆã—ã€é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    å˜ä¸€è²¬ä»»åŸå‰‡ã«å¾“ã„ã€å„ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ã®è¨ˆç®—ã¯å°‚ç”¨ã‚¯ãƒ©ã‚¹ã«å§”è­²ã—ã¾ã™ã€‚
    AutoMLæ©Ÿèƒ½ã‚‚ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚
    """

    def __init__(self, automl_config: Optional[Any] = None):
        """
        åˆæœŸåŒ–

        Args:
            automl_config: AutoMLè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.feature_cache = {}
        self.max_cache_size = 10  # æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
        self.cache_ttl = 3600  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰

        # ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
        self.price_calculator = PriceFeatureCalculator()
        self.market_data_calculator = MarketDataFeatureCalculator()
        self.technical_calculator = TechnicalFeatureCalculator()
        self.temporal_calculator = TemporalFeatureCalculator()
        self.interaction_calculator = InteractionFeatureCalculator()

        # ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.frequency_manager = DataFrequencyManager()

        # AutoMLæ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        self.automl_enabled = automl_config is not None and AUTOML_AVAILABLE
        if self.automl_enabled:
            # AutoMLConfigãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ä½¿ç”¨
            if AUTOML_AVAILABLE and AutoMLConfig is not None:
                self.automl_config = (
                    automl_config or AutoMLConfig.get_financial_optimized_config()
                )
            else:
                self.automl_config = None

            # AutoMLç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹
            if (
                self.automl_config is not None
                and hasattr(self.automl_config, "tsfresh")
                and self.automl_config.tsfresh is not None
                and TSFreshFeatureCalculator is not None
            ):
                self.tsfresh_calculator = TSFreshFeatureCalculator(
                    self.automl_config.tsfresh
                )
            else:
                self.tsfresh_calculator = None

            if (
                self.automl_config is not None
                and hasattr(self.automl_config, "autofeat")
                and self.automl_config.autofeat is not None
                and AutoFeatCalculator is not None
            ):
                self.autofeat_calculator = AutoFeatCalculator(
                    self.automl_config.autofeat
                )
            else:
                self.autofeat_calculator = None

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹
            if self.automl_config is not None and PerformanceOptimizer is not None:
                self.performance_optimizer = PerformanceOptimizer()
            else:
                self.performance_optimizer = None

            # æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ï¼‰
            self.crypto_features = CryptoFeatures()
            logger.debug("æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")

            # é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ï¼‰
            self.advanced_features = AdvancedFeatureEngineer()
            logger.debug("é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")

            # çµ±è¨ˆæƒ…å ±
            self.last_enhancement_stats = {}

        else:
            self.automl_config = None
            if automl_config is not None and not AUTOML_AVAILABLE:
                logger.warning(
                    "AutoMLè¨­å®šãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸãŒã€AutoMLãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                )

            # æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆAutoMLãŒNoneã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ï¼‰
            self.crypto_features = CryptoFeatures()
            logger.debug("æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")

            # é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆAutoMLãŒNoneã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ï¼‰
            self.advanced_features = AdvancedFeatureEngineer()
            logger.debug("é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")

            # çµ±è¨ˆæƒ…å ±
            self.last_enhancement_stats = {}

    def calculate_advanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
    ) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            lookback_periods: å„ç‰¹å¾´é‡ã®è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        try:
            if ohlcv_data.empty:
                raise ValueError("OHLCVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            # DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’DatetimeIndexã«å¤‰æ›ï¼ˆè„†å¼±æ€§ä¿®æ­£ï¼‰
            if not isinstance(ohlcv_data.index, pd.DatetimeIndex):
                if "timestamp" in ohlcv_data.columns:
                    ohlcv_data = ohlcv_data.set_index("timestamp")
                    logger.info("timestampã‚«ãƒ©ãƒ ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®šã—ã¾ã—ãŸ")
                else:
                    # timestampã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯ã€ç¾åœ¨ã®æ™‚åˆ»ã‹ã‚‰ç”Ÿæˆ
                    logger.warning(
                        "timestampã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ä»®ã®DatetimeIndexã‚’ç”Ÿæˆã—ã¾ã™"
                    )
                    ohlcv_data.index = pd.date_range(
                        start="2024-01-01", periods=len(ohlcv_data), freq="1H"
                    )

            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒDatetimeIndexã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if not isinstance(ohlcv_data.index, pd.DatetimeIndex):
                raise ValueError(
                    "DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯DatetimeIndexã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                )

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶é™
            if len(ohlcv_data) > 50000:
                logger.warning(
                    f"å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{len(ohlcv_data)}è¡Œï¼‰ã€æœ€æ–°50,000è¡Œã«åˆ¶é™"
                )
                ohlcv_data = ohlcv_data.tail(50000)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
            cache_key = self._generate_cache_key(
                ohlcv_data,
                funding_rate_data,
                open_interest_data,
                lookback_periods,
            )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰çµæœã‚’å–å¾—
            cached_result = self._get_from_cache(cache_key)
            if cached_result is not None:
                return cached_result

            # ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€å‡¦ç†ï¼ˆæœ€å„ªå…ˆå•é¡Œã®è§£æ±ºï¼‰
            logger.info("ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€å‡¦ç†ã‚’é–‹å§‹")
            ohlcv_timeframe = self.frequency_manager.detect_ohlcv_timeframe(ohlcv_data)

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
            validation_result = self.frequency_manager.validate_data_alignment(
                ohlcv_data, funding_rate_data, open_interest_data
            )

            if not validation_result["is_valid"]:
                logger.warning("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
                for error in validation_result["errors"]:
                    logger.warning(f"  ã‚¨ãƒ©ãƒ¼: {error}")

            # ãƒ‡ãƒ¼ã‚¿é »åº¦ã‚’çµ±ä¸€
            funding_rate_data, open_interest_data = (
                self.frequency_manager.align_data_frequencies(
                    ohlcv_data, funding_rate_data, open_interest_data, ohlcv_timeframe
                )
            )

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨ˆç®—æœŸé–“
            if lookback_periods is None:
                lookback_periods = {
                    "short_ma": 10,
                    "long_ma": 50,
                    "volatility": 20,
                    "momentum": 14,
                    "volume": 20,
                }

            # çµæœDataFrameã‚’åˆæœŸåŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
            result_df = ohlcv_data.copy()

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–
            result_df = self._optimize_dtypes(result_df)

            # åŸºæœ¬çš„ãªä¾¡æ ¼ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_price_features(
                result_df, lookback_periods
            )

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_volatility_features(
                result_df, lookback_periods
            )

            # å‡ºæ¥é«˜ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_volume_features(
                result_df, lookback_periods
            )

            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            if funding_rate_data is not None and not funding_rate_data.empty:
                result_df = self.market_data_calculator.calculate_funding_rate_features(
                    result_df, funding_rate_data, lookback_periods
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                fr_columns = [
                    "FR_MA_24",
                    "FR_MA_168",
                    "FR_Change",
                    "FR_Change_Rate",
                    "Price_FR_Divergence",
                    "FR_Normalized",
                    "FR_Trend",
                    "FR_Volatility",
                ]
                existing_fr_columns = [
                    col for col in fr_columns if col in result_df.columns
                ]
                if existing_fr_columns:
                    try:
                        # median ã§æ¬ æã‚’è£œå®Œ
                        medians = result_df[existing_fr_columns].median()
                        result_df[existing_fr_columns] = result_df[
                            existing_fr_columns
                        ].fillna(medians)
                    except Exception as e:
                        logger.warning(f"FRä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã€ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                logger.warning(
                    "ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
                )
                result_df = self._generate_pseudo_funding_rate_features(
                    result_df, lookback_periods
                )

            # å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            if open_interest_data is not None and not open_interest_data.empty:
                result_df = (
                    self.market_data_calculator.calculate_open_interest_features(
                        result_df, open_interest_data, lookback_periods
                    )
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                oi_columns = [
                    "OI_Change_Rate",
                    "OI_Change_Rate_24h",
                    "OI_Surge",
                    "Volatility_Adjusted_OI",
                    "OI_MA_24",
                    "OI_MA_168",
                    "OI_Trend",
                    "OI_Price_Correlation",
                    "OI_Normalized",
                ]
                existing_oi_columns = [
                    col for col in oi_columns if col in result_df.columns
                ]
                if existing_oi_columns:
                    try:
                        medians = result_df[existing_oi_columns].median()
                        result_df[existing_oi_columns] = result_df[
                            existing_oi_columns
                        ].fillna(medians)
                    except Exception as e:
                        logger.warning(f"OIä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                # å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã€ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                logger.warning(
                    "å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
                )
                result_df = self._generate_pseudo_open_interest_features(
                    result_df, lookback_periods
                )

            # è¤‡åˆç‰¹å¾´é‡ï¼ˆFR + OIï¼‰
            if (
                funding_rate_data is not None
                and not funding_rate_data.empty
                and open_interest_data is not None
                and not open_interest_data.empty
            ):
                result_df = self.market_data_calculator.calculate_composite_features(
                    result_df, funding_rate_data, open_interest_data, lookback_periods
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                composite_columns = [
                    "FR_OI_Ratio",
                    "Market_Heat_Index",
                    "Market_Stress",
                    "Market_Balance",
                ]
                existing_composite_columns = [
                    col for col in composite_columns if col in result_df.columns
                ]
                if existing_composite_columns:
                    try:
                        medians = result_df[existing_composite_columns].median()
                        result_df[existing_composite_columns] = result_df[
                            existing_composite_columns
                        ].fillna(medians)
                    except Exception as e:
                        logger.warning(f"Compositeä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼: {e}")

            # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_market_regime_features(
                result_df, lookback_periods
            )

            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_momentum_features(
                result_df, lookback_periods
            )

            # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_pattern_features(
                result_df, lookback_periods
            )

            # æ™‚é–“çš„ç‰¹å¾´é‡
            result_df = self.temporal_calculator.calculate_temporal_features(result_df)

            # æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¿½åŠ ï¼‰
            if self.crypto_features is not None:
                logger.debug("æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
                result_df = self.crypto_features.create_crypto_features(
                    result_df, funding_rate_data, open_interest_data
                )

            # é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¿½åŠ ï¼‰
            if self.advanced_features is not None:
                logger.debug("é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
                result_df = self.advanced_features.create_advanced_features(
                    result_df, funding_rate_data, open_interest_data
                )

            # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆå…¨ã¦ã®åŸºæœ¬ç‰¹å¾´é‡ãŒè¨ˆç®—ã•ã‚ŒãŸå¾Œã«å®Ÿè¡Œï¼‰
            result_df = self.interaction_calculator.calculate_interaction_features(
                result_df
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            # ä¸»è¦ãªä¾¡æ ¼åˆ—ã‚’é™¤å¤–ã—ãŸç‰¹å¾´é‡åˆ—ã®ä¸€è¦§ãŒå¿…è¦ãªå ´åˆã®ã¿ã€ãã®å ´ã§è¨ˆç®—ã™ã‚‹ã“ã¨
            # ï¼ˆæœªä½¿ç”¨å¤‰æ•°ã‚’é¿ã‘ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä¿æŒã—ã¾ã›ã‚“ï¼‰

            # é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æœ‰åŠ¹åŒ–ã€IQRãƒ™ãƒ¼ã‚¹å¤–ã‚Œå€¤æ¤œå‡ºï¼‰
            logger.info("çµ±è¨ˆçš„æ‰‹æ³•ã«ã‚ˆã‚‹ç‰¹å¾´é‡å‰å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
            try:
                # ã‚·ãƒ³ãƒ—ãƒ«ãªNaNè£œå®Œå‡¦ç†ã§ç½®æ›
                numeric_columns = result_df.select_dtypes(include=[np.number]).columns
                for col in numeric_columns:
                    if result_df[col].isna().any():
                        result_df[col] = result_df[col].fillna(result_df[col].median())
                logger.info("ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº†")
            except Exception as e:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

            # NaNå€¤ã®è¿½åŠ çš„ãªå‡¦ç†ï¼ˆé…åˆ—å½¢çŠ¶ã‚¨ãƒ©ãƒ¼ã‚’é˜²ãï¼‰
            try:
                # æ•°å€¤åˆ—ã®NaNå€¤ã‚’å®‰å…¨ã«å¤‰æ›
                numeric_columns = result_df.select_dtypes(include=[np.number]).columns
                for col in numeric_columns:
                    if result_df[col].isnull().any():
                        # NaNã‚„ç„¡é™å¤§ã‚’medianã§ç½®æ›
                        median_val = result_df[col].median()
                        if pd.isna(median_val):
                            median_val = 0.0
                        result_df[col] = result_df[col].fillna(median_val)

                        # ç„¡é™å¤§å€¤ã‚’æœ‰é™å€¤ã«ç½®æ›
                        result_df[col] = result_df[col].replace(
                            [np.inf, -np.inf], median_val
                        )

                # é…åˆ—å½¢çŠ¶ã®æ¤œè¨¼ã¨ä¿®æ­£
                if result_df.empty:
                    raise ValueError("å‰å‡¦ç†å¾Œã«ç©ºã®DataFrameã«ãªã‚Šã¾ã—ãŸ")

                # å…¨ã¦ã®åˆ—ãŒ2Dé…åˆ—ã¨ã—ã¦æ‰±ãˆã‚‹ã“ã¨ã‚’ç¢ºèª
                for col in result_df.columns:
                    if not isinstance(result_df[col].iloc[0], (int, float)):
                        logger.warning(
                            f"éæ•°å€¤åˆ—ã‚’æ¤œå‡º: {col}, å‹: {type(result_df[col].iloc[0])}"
                        )
                        # éæ•°å€¤åˆ—ã‚’æ•°å€¤ã«å¤‰æ›ã¾ãŸã¯å‰Šé™¤
                        try:
                            result_df[col] = pd.to_numeric(
                                result_df[col], errors="coerce"
                            )
                            result_df[col] = result_df[col].fillna(0.0)
                        except Exception:
                            logger.warning(f"åˆ— {col} ã‚’å‰Šé™¤ï¼ˆéæ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰")
                            result_df = result_df.drop(columns=[col])

            except Exception as nan_error:
                logger.warning(f"NaNå€¤å‡¦ç†ã‚¨ãƒ©ãƒ¼ã€åŸºæœ¬æƒ…å ±ã®ã¿ä½¿ç”¨: {nan_error}")
                # åŸºæœ¬çš„ãªNaNå‡¦ç†ã®ã¿å®Ÿè¡Œ
                result_df = result_df.fillna(0.0)

            logger.info(f"ç‰¹å¾´é‡è¨ˆç®—å®Œäº†: {len(result_df.columns)}å€‹ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ")

            # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._save_to_cache(cache_key, result_df)

            return result_df

        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    @safe_ml_operation(
        default_return=None, context="æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )
    def calculate_enhanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
        automl_config: Optional[Dict] = None,
        target: Optional[pd.Series] = None,
        max_features_per_step: int = 50,  # ç‰¹å¾´é‡æ•°å‰Šæ¸›: 100 â†’ 50
    ) -> pd.DataFrame:
        """
        æ‹¡å¼µç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆæ‰‹å‹• + AutoMLï¼‰- ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—æ–¹å¼

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿
            lookback_periods: è¨ˆç®—æœŸé–“è¨­å®š
            automl_config: AutoMLè¨­å®šï¼ˆè¾æ›¸å½¢å¼ï¼‰
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆç‰¹å¾´é‡é¸æŠç”¨ï¼‰
            max_features_per_step: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®æœ€å¤§ç‰¹å¾´é‡æ•°

        Returns:
            æ‹¡å¼µç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        if not self.automl_enabled:
            logger.warning("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™ã€‚åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œã—ã¾ã™")
            return self.calculate_advanced_features(
                ohlcv_data=ohlcv_data,
                funding_rate_data=funding_rate_data,
                open_interest_data=open_interest_data,
                lookback_periods=lookback_periods,
            )

        if ohlcv_data is None or ohlcv_data.empty:
            logger.warning("ç©ºã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¾ã—ãŸ")
            return ohlcv_data

        start_time = time.time()

        try:
            # AutoMLè¨­å®šã®æ›´æ–°
            if automl_config:
                self._update_automl_config(automl_config)

            logger.info("ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆã‚’é–‹å§‹")

            # ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—
            result_df = self._step1_manual_features(
                ohlcv_data,
                funding_rate_data,
                open_interest_data,
                lookback_periods,
                include_crypto_features=True,  # CryptoFeaturesã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹
                include_advanced_features=True,  # AdvancedFeatureEngineerã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹
            )

            # ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if (
                self.automl_config is not None
                and hasattr(self.automl_config, "tsfresh")
                and self.automl_config.tsfresh is not None
                and hasattr(self.automl_config.tsfresh, "enabled")
                and self.automl_config.tsfresh.enabled
            ):
                result_df = self._step2_tsfresh_features(
                    result_df, target, max_features_per_step
                )

            # ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if (
                self.automl_config is not None
                and hasattr(self.automl_config, "autofeat")
                and self.automl_config.autofeat is not None
                and hasattr(self.automl_config.autofeat, "enabled")
                and self.automl_config.autofeat.enabled
            ):
                result_df = self._step3_autofeat_features(
                    result_df, target, max_features_per_step
                )

            # æœ€çµ‚çš„ãªç‰¹å¾´é‡çµ±è¨ˆã‚’è¨˜éŒ²
            final_feature_count = len(result_df.columns)
            logger.info(
                f"ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: æœ€çµ‚ç‰¹å¾´é‡æ•° {final_feature_count}å€‹"
            )

            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            total_time = time.time() - start_time
            stats_update = {
                "total_features": final_feature_count,
                "total_time": total_time,
                "data_rows": len(result_df),
                "processing_method": "step_by_step",
            }
            if self.automl_config is not None and hasattr(
                self.automl_config, "to_dict"
            ):
                stats_update["automl_config_used"] = self.automl_config.to_dict()
            self.last_enhancement_stats.update(stats_update)

            return result_df

        except Exception as e:
            logger.error(f"æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_feature_names(self) -> List[str]:
        """
        ç”Ÿæˆã•ã‚Œã‚‹ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆã‚’å–å¾—

        Returns:
            ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
        """
        feature_names = []

        # å„è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‹ã‚‰ç‰¹å¾´é‡åã‚’å–å¾—
        feature_names.extend(self.price_calculator.get_feature_names())
        feature_names.extend(self.market_data_calculator.get_feature_names())
        feature_names.extend(self.technical_calculator.get_feature_names())
        feature_names.extend(self.temporal_calculator.get_feature_names())
        feature_names.extend(self.interaction_calculator.get_feature_names())

        return feature_names

    def _step1_manual_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
        include_crypto_features: bool = True,
        include_advanced_features: bool = True,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—"""
        logger.info("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()

        result_df = self.calculate_advanced_features(
            ohlcv_data=ohlcv_data,
            funding_rate_data=funding_rate_data,
            open_interest_data=open_interest_data,
            lookback_periods=lookback_periods,
        )

        manual_time = time.time() - start_time
        manual_feature_count = len(result_df.columns)

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "manual_features": manual_feature_count,
                    "manual_time": manual_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: {manual_feature_count}å€‹ã®æ‰‹å‹•ç‰¹å¾´é‡ ({manual_time:.2f}ç§’)"
        )
        return result_df

    def _step2_tsfresh_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 50,  # ç‰¹å¾´é‡æ•°å‰Šæ¸›: 100 â†’ 50
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        logger.info("ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—
        if self.tsfresh_calculator is None:
            logger.warning("TSFresh calculator is not available")
            return df

        tsfresh_config = None
        if (
            self.automl_config is not None
            and hasattr(self.automl_config, "tsfresh")
            and self.automl_config.tsfresh is not None
        ):
            tsfresh_config = self.automl_config.tsfresh.feature_selection

        result_df = self.tsfresh_calculator.calculate_tsfresh_features(
            df=df,
            target=target,
            feature_selection=tsfresh_config,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        tsfresh_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "tsfresh_features": added_features,
                    "tsfresh_time": tsfresh_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {added_features}å€‹ã®TSFreshç‰¹å¾´é‡è¿½åŠ  ({tsfresh_time:.2f}ç§’)"
        )
        return result_df

    def _step3_autofeat_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 50,  # ç‰¹å¾´é‡æ•°å‰Šæ¸›: 100 â†’ 50
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        if target is None:
            logger.warning(
                "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ãŒãªã„ãŸã‚ã€AutoFeatç‰¹å¾´é‡ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
            )
            return df

        logger.info("ğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—
        if self.autofeat_calculator is None:
            logger.warning("AutoFeat calculator is not available")
            return df

        autofeat_max_features = None
        if (
            self.automl_config is not None
            and hasattr(self.automl_config, "autofeat")
            and self.automl_config.autofeat is not None
            and hasattr(self.automl_config.autofeat, "max_features")
        ):
            autofeat_max_features = self.automl_config.autofeat.max_features

        result_df, generation_info = self.autofeat_calculator.generate_features(
            df=df,
            target=target,
            task_type="regression",
            max_features=autofeat_max_features,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        autofeat_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "autofeat_features": added_features,
                    "autofeat_time": autofeat_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: {added_features}å€‹ã®AutoFeatç‰¹å¾´é‡è¿½åŠ  ({autofeat_time:.2f}ç§’)"
        )
        return result_df

    def _generate_cache_key(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame],
        open_interest_data: Optional[pd.DataFrame],
        lookback_periods: Optional[Dict[str, int]],
    ) -> str:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            lookback_periods: å„ç‰¹å¾´é‡ã®è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼æ–‡å­—åˆ—
        """
        import hashlib

        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        ohlcv_hash = hashlib.md5(str(ohlcv_data.shape).encode()).hexdigest()[:8]
        fr_hash = hashlib.md5(
            str(
                funding_rate_data.shape if funding_rate_data is not None else "None"
            ).encode()
        ).hexdigest()[:8]
        oi_hash = hashlib.md5(
            str(
                open_interest_data.shape if open_interest_data is not None else "None"
            ).encode()
        ).hexdigest()[:8]
        periods_hash = hashlib.md5(
            str(
                sorted(lookback_periods.items())
                if lookback_periods is not None
                else "None"
            ).encode()
        ).hexdigest()[:8]

        return f"features_{ohlcv_hash}_{fr_hash}_{oi_hash}_{periods_hash}"

    def _get_from_cache(self, cache_key: str) -> Optional[pd.DataFrame]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰çµæœã‚’å–å¾—

        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼

        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸDataFrameã€ã¾ãŸã¯None
        """
        try:
            if cache_key in self.feature_cache:
                cached_data, timestamp = self.feature_cache[cache_key]

                # TTLãƒã‚§ãƒƒã‚¯
                if datetime.now().timestamp() - timestamp < self.cache_ttl:
                    return cached_data.copy()
                else:
                    # æœŸé™åˆ‡ã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                    del self.feature_cache[cache_key]

            return None

        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _save_to_cache(self, cache_key: str, data: pd.DataFrame):
        """
        çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜

        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            data: ä¿å­˜ã™ã‚‹DataFrame
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
            if len(self.feature_cache) >= self.max_cache_size:
                # æœ€ã‚‚å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                oldest_key = min(
                    self.feature_cache.keys(), key=lambda k: self.feature_cache[k][1]
                )
                del self.feature_cache[oldest_key]

            # æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜
            self.feature_cache[cache_key] = (data.copy(), datetime.now().timestamp())

        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›

        Args:
            df: æœ€é©åŒ–ã™ã‚‹DataFrame

        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸDataFrame
        """
        try:
            optimized_df = df.copy()

            for col in optimized_df.columns:
                if col == "timestamp":
                    continue

                if optimized_df[col].dtype == "float64":
                    # float64ã‚’float32ã«å¤‰æ›ï¼ˆç²¾åº¦ã¯ååˆ†ï¼‰
                    optimized_df[col] = optimized_df[col].astype("float32")
                elif optimized_df[col].dtype == "int64":
                    # int64ã‚’int32ã«å¤‰æ›ï¼ˆç¯„å›²ãŒååˆ†ãªå ´åˆï¼‰
                    if (
                        optimized_df[col].min() >= -2147483648
                        and optimized_df[col].max() <= 2147483647
                    ):
                        optimized_df[col] = optimized_df[col].astype("int32")

            return optimized_df

        except Exception as e:
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def clear_cache(self):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        """
        self.feature_cache.clear()
        logger.info("ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    def _generate_pseudo_funding_rate_features(
        self, df: pd.DataFrame, lookback_periods: Dict[str, int]
    ) -> pd.DataFrame:
        """
        ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆ

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            lookback_periods: è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç–‘ä¼¼ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        try:
            result_df = df.copy()

            # ä¾¡æ ¼å¤‰å‹•ç‡ãƒ™ãƒ¼ã‚¹ã®ç–‘ä¼¼ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
            returns = result_df["close"].pct_change()

            # ç–‘ä¼¼ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆä¾¡æ ¼å‹¢ã„ãƒ™ãƒ¼ã‚¹ï¼‰
            pseudo_fr = returns.rolling(8).mean() * 0.1
            # æ˜ç¤ºçš„ã«pandas Seriesã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
            pseudo_fr = pd.Series(pseudo_fr, index=result_df.index)

            # FRç‰¹å¾´é‡ã‚’ç”Ÿæˆ
            result_df["FR_MA_24"] = pseudo_fr.rolling(24).mean()
            result_df["FR_MA_168"] = pseudo_fr.rolling(168).mean()
            result_df["FR_Change"] = pseudo_fr.diff()
            result_df["FR_Change_Rate"] = pseudo_fr.pct_change()
            result_df["Price_FR_Divergence"] = returns - pseudo_fr
            result_df["FR_Normalized"] = (
                pseudo_fr - pseudo_fr.rolling(168).mean()
            ) / pseudo_fr.rolling(168).std()
            result_df["FR_Trend"] = result_df["FR_MA_24"] / result_df["FR_MA_168"] - 1
            result_df["FR_Volatility"] = pseudo_fr.rolling(24).std()

            # NaNå€¤ã‚’0ã§è£œå®Œ
            fr_columns = [
                "FR_MA_24",
                "FR_MA_168",
                "FR_Change",
                "FR_Change_Rate",
                "Price_FR_Divergence",
                "FR_Normalized",
                "FR_Trend",
                "FR_Volatility",
            ]
            for col in fr_columns:
                if col in result_df.columns:
                    result_df[col] = result_df[col].fillna(0)

            logger.info("ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            return result_df

        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç–‘ä¼¼ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def _generate_pseudo_open_interest_features(
        self, df: pd.DataFrame, lookback_periods: Dict[str, int]
    ) -> pd.DataFrame:
        """
        å»ºç‰æ®‹é«˜ç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆ

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            lookback_periods: è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç–‘ä¼¼ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        try:
            result_df = df.copy()

            # ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ™ãƒ¼ã‚¹ã®ç–‘ä¼¼å»ºç‰æ®‹é«˜
            pseudo_oi = result_df["volume"].rolling(24).mean() * 10
            # æ˜ç¤ºçš„ã«pandas Seriesã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼
            pseudo_oi = pd.Series(pseudo_oi, index=result_df.index)

            # OIç‰¹å¾´é‡ã‚’ç”Ÿæˆ
            result_df["OI_Change_Rate"] = pseudo_oi.pct_change()
            result_df["OI_Change_Rate_24h"] = pseudo_oi.pct_change(24)

            # OIæ€¥å¢—ï¼ˆãƒœãƒªãƒ¥ãƒ¼ãƒ æ€¥å¢—ãƒ™ãƒ¼ã‚¹ï¼‰
            oi_threshold = pseudo_oi.rolling(168).quantile(0.9)
            result_df["OI_Surge"] = (pseudo_oi > oi_threshold).astype(int)

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´å»ºç‰æ®‹é«˜
            volatility = result_df["close"].pct_change().rolling(24).std()
            result_df["Volatility_Adjusted_OI"] = pseudo_oi / (volatility + 1e-8)

            # OIç§»å‹•å¹³å‡
            result_df["OI_MA_24"] = pseudo_oi.rolling(24).mean()
            result_df["OI_MA_168"] = pseudo_oi.rolling(168).mean()

            # OIãƒˆãƒ¬ãƒ³ãƒ‰
            result_df["OI_Trend"] = result_df["OI_MA_24"] / result_df["OI_MA_168"] - 1

            # OIä¾¡æ ¼ç›¸é–¢ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            price_change = result_df["close"].pct_change()
            oi_change = result_df["OI_Change_Rate"]
            result_df["OI_Price_Correlation"] = price_change * oi_change

            # OIæ­£è¦åŒ–
            result_df["OI_Normalized"] = (
                pseudo_oi - pseudo_oi.rolling(168).mean()
            ) / pseudo_oi.rolling(168).std()

            # NaNå€¤ã‚’0ã§è£œå®Œ
            oi_columns = [
                "OI_Change_Rate",
                "OI_Change_Rate_24h",
                "OI_Surge",
                "Volatility_Adjusted_OI",
                "OI_MA_24",
                "OI_MA_168",
                "OI_Trend",
                "OI_Price_Correlation",
                "OI_Normalized",
            ]
            for col in oi_columns:
                if col in result_df.columns:
                    result_df[col] = result_df[col].fillna(0)

            logger.info("å»ºç‰æ®‹é«˜ç–‘ä¼¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            return result_df

        except Exception as e:
            logger.error(f"å»ºç‰æ®‹é«˜ç–‘ä¼¼ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def _select_top_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int,
    ) -> pd.DataFrame:
        """ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œã—ã¦ä¸Šä½ç‰¹å¾´é‡ã‚’é¸æŠ"""
        if target is None or len(df.columns) <= max_features:
            return df

        try:
            from sklearn.feature_selection import SelectKBest, f_regression
            from sklearn.impute import SimpleImputer

            logger.info(f"ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­: {len(df.columns)} â†’ {max_features}å€‹")

            # æ¬ æå€¤ã‚’è£œå®Œ
            imputer = SimpleImputer(strategy="median")
            X_imputed = imputer.fit_transform(df)

            # ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ
            selector = SelectKBest(score_func=f_regression, k=max_features)
            X_selected = selector.fit_transform(X_imputed, target)

            # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ åã‚’å–å¾—
            selected_features = df.columns[selector.get_support()]
            result_df = pd.DataFrame(
                X_selected, columns=selected_features, index=df.index
            )

            logger.info(f"ç‰¹å¾´é‡é¸æŠå®Œäº†: {len(selected_features)}å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ")
            return result_df

        except Exception as e:
            logger.warning(f"ç‰¹å¾´é‡é¸æŠã§ã‚¨ãƒ©ãƒ¼: {e}. å…ƒã®DataFrameã‚’è¿”ã—ã¾ã™")
            return df

    def _update_automl_config(self, config_dict: Dict[str, Any]):
        """AutoMLè¨­å®šã‚’æ›´æ–°"""
        if not self.automl_enabled:
            logger.warning("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã®ãŸã‚ã€è¨­å®šæ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return

        try:
            # TSFreshè¨­å®šã®æ›´æ–°
            if "tsfresh" in config_dict and self.automl_config is not None:
                tsfresh_config = config_dict["tsfresh"]
                if (
                    isinstance(tsfresh_config, dict)
                    and hasattr(self.automl_config, "tsfresh")
                    and self.automl_config.tsfresh is not None
                ):
                    for key, value in tsfresh_config.items():
                        if hasattr(self.automl_config.tsfresh, key):
                            setattr(self.automl_config.tsfresh, key, value)

                    # TSFreshCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    if self.tsfresh_calculator is not None and hasattr(
                        self.tsfresh_calculator, "config"
                    ):
                        self.tsfresh_calculator.config = self.automl_config.tsfresh

            # AutoFeatè¨­å®šã®æ›´æ–°
            if "autofeat" in config_dict and self.automl_config is not None:
                autofeat_config = config_dict["autofeat"]
                if (
                    isinstance(autofeat_config, dict)
                    and hasattr(self.automl_config, "autofeat")
                    and self.automl_config.autofeat is not None
                ):
                    for key, value in autofeat_config.items():
                        if hasattr(self.automl_config.autofeat, key):
                            setattr(self.automl_config.autofeat, key, value)

                    # AutoFeatCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    if self.autofeat_calculator is not None and hasattr(
                        self.autofeat_calculator, "config"
                    ):
                        self.autofeat_calculator.config = self.automl_config.autofeat

            logger.info("AutoMLè¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"AutoMLè¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def get_enhancement_stats(self) -> Dict[str, Any]:
        """æœ€å¾Œã®æ‹¡å¼µå‡¦ç†ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.automl_enabled or not hasattr(self, "last_enhancement_stats"):
            return {}
        return self.last_enhancement_stats.copy()

    def get_available_automl_features(self) -> Dict[str, List[str]]:
        """åˆ©ç”¨å¯èƒ½ãªAutoMLç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        if not self.automl_enabled:
            return {}

        return {
            "tsfresh": (
                self.tsfresh_calculator.get_feature_names()
                if self.tsfresh_calculator
                else []
            ),
            "autofeat": (
                self.autofeat_calculator.get_feature_names()
                if self.autofeat_calculator
                else []
            ),
        }

    def clear_automl_cache(self):
        """AutoMLç‰¹å¾´é‡ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        if not self.automl_enabled:
            return

        try:
            if self.tsfresh_calculator:
                self.tsfresh_calculator.clear_cache()
            if self.autofeat_calculator:
                self.autofeat_calculator.clear_model()

            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc

            collected = gc.collect()

            logger.info(
                f"AutoMLç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ˆ{collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›åï¼‰"
            )
        except Exception as e:
            logger.error(f"AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def validate_automl_config(self, config_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        AutoMLè¨­å®šã‚’æ¤œè¨¼

        Args:
            config_dict: AutoMLè¨­å®šè¾æ›¸

        Returns:
            Dict[str, Any]: æ¤œè¨¼çµæœ
                - valid: bool - è¨­å®šãŒæœ‰åŠ¹ã‹ã©ã†ã‹
                - errors: List[str] - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
                - warnings: List[str] - è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
        """
        try:
            errors = []
            warnings = []

            # å¿…é ˆã‚­ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
            if not isinstance(config_dict, dict):
                errors.append("è¨­å®šã¯è¾æ›¸å½¢å¼ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                return {"valid": False, "errors": errors, "warnings": warnings}

            # AutoMLConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆã‚’è©¦è¡Œ
            if AutoMLConfig is not None:
                try:
                    config = AutoMLConfig.from_dict(config_dict)
                except Exception as e:
                    errors.append(f"AutoMLè¨­å®šã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                    return {"valid": False, "errors": errors, "warnings": warnings}
            else:
                errors.append("AutoMLæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return {"valid": False, "errors": errors, "warnings": warnings}

            # TSFreshè¨­å®šã®æ¤œè¨¼
            if hasattr(config, "tsfresh"):
                tsfresh_config = config.tsfresh

                # TSFreshãŒæœ‰åŠ¹ãªå ´åˆã®ãƒã‚§ãƒƒã‚¯
                if tsfresh_config.enabled:
                    if not (0.001 <= tsfresh_config.fdr_level <= 1.0):
                        errors.append(
                            "TSFreshã®FDRãƒ¬ãƒ™ãƒ«ã¯0.001ã‹ã‚‰1.0ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    if not (10 <= tsfresh_config.feature_count_limit <= 500):
                        errors.append(
                            "TSFreshã®ç‰¹å¾´é‡æ•°åˆ¶é™ã¯10ã‹ã‚‰500ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    if not (1 <= tsfresh_config.parallel_jobs <= 8):
                        errors.append(
                            "TSFreshã®ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•°ã¯1ã‹ã‚‰8ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    valid_modes = [
                        "fast",
                        "balanced",
                        "financial_optimized",
                        "comprehensive",
                    ]
                    if tsfresh_config.performance_mode not in valid_modes:
                        errors.append(
                            f"TSFreshã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ã¯{valid_modes}ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

            # AutoFeatè¨­å®šã®æ¤œè¨¼
            if hasattr(config, "autofeat"):
                autofeat_config = config.autofeat

                # AutoFeatãŒæœ‰åŠ¹ãªå ´åˆã®ãƒã‚§ãƒƒã‚¯
                if autofeat_config.enabled:
                    if not (10 <= autofeat_config.max_features <= 200):
                        errors.append(
                            "AutoFeatã®æœ€å¤§ç‰¹å¾´é‡æ•°ã¯10ã‹ã‚‰200ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    if not (5 <= autofeat_config.generations <= 50):
                        errors.append(
                            "AutoFeatã®ä¸–ä»£æ•°ã¯5ã‹ã‚‰50ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    if not (20 <= autofeat_config.population_size <= 200):
                        errors.append(
                            "AutoFeatã®é›†å›£ã‚µã‚¤ã‚ºã¯20ã‹ã‚‰200ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    if not (2 <= autofeat_config.tournament_size <= 10):
                        errors.append(
                            "AutoFeatã®ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚µã‚¤ã‚ºã¯2ã‹ã‚‰10ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è­¦å‘Š
                    if autofeat_config.max_gb > 4.0:
                        warnings.append(
                            "AutoFeatã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ4GBã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                        )

            # AutoMLæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
            if not AUTOML_AVAILABLE and (
                config.tsfresh.enabled or config.autofeat.enabled
            ):
                warnings.append(
                    "AutoMLæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )

            # è¨­å®šã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if config.tsfresh.enabled and config.autofeat.enabled:
                total_features = (
                    config.tsfresh.feature_count_limit + config.autofeat.max_features
                )
                if total_features > 300:
                    warnings.append(
                        f"TSFreshã¨AutoFeatã®åˆè¨ˆç‰¹å¾´é‡æ•°({total_features}å€‹)ãŒ300å€‹ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«æ³¨æ„ã—ã¦ãã ã•ã„"
                    )

            return {"valid": len(errors) == 0, "errors": errors, "warnings": warnings}

        except Exception as e:
            logger.error(f"AutoMLè¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "valid": False,
                "errors": [f"è¨­å®šæ¤œè¨¼ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"],
                "warnings": [],
            }

    def analyze_features(
        self, features_df: pd.DataFrame, target: pd.Series
    ) -> Optional[Dict[str, Any]]:
        """
        ç‰¹å¾´é‡ã‚’åˆ†æï¼ˆAutoMLç‰¹å¾´é‡åˆ†æï¼‰

        Args:
            features_df: ç‰¹å¾´é‡DataFrame
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°

        Returns:
            ç‰¹å¾´é‡åˆ†æçµæœã®è¾æ›¸ï¼ˆAutoMLãŒç„¡åŠ¹ã®å ´åˆã¯Noneï¼‰
        """
        if not self.automl_enabled:
            logger.info("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã®ãŸã‚ã€ç‰¹å¾´é‡åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return None

        try:
            logger.info("ç‰¹å¾´é‡åˆ†æã‚’é–‹å§‹")

            # AutoMLFeatureAnalyzerã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆæœŸåŒ–
            from .automl_feature_analyzer import AutoMLFeatureAnalyzer

            analyzer = AutoMLFeatureAnalyzer()

            # ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            from sklearn.ensemble import RandomForestClassifier

            # æ¬ æå€¤å‡¦ç†
            # å…ˆã«NaNå€¤ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if features_df.isnull().values.any():
                # NaNå€¤ã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆscalerç”¨ã«å®‰å…¨ãªå€¤ï¼‰
                features_clean = features_df.fillna(0.0)
            else:
                features_clean = features_df.copy()

            # ç‰¹å¾´é‡é‡è¦åº¦ã®æ¨å®š
            model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
            model.fit(features_clean, target)

            # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
            feature_importance = dict(
                zip(features_df.columns, model.feature_importances_)
            )

            # AutoMLFeatureAnalyzerã§åˆ†æ
            analysis_result = analyzer.analyze_feature_importance(feature_importance)

            logger.info("ç‰¹å¾´é‡åˆ†æãŒå®Œäº†")
            return analysis_result

        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def cleanup_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            logger.info("FeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹")

            # åŸºæœ¬ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            self.clear_cache()

            if self.automl_enabled:
                # AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                self.clear_automl_cache()

                # çµ±è¨ˆæƒ…å ±ã‚’ã‚¯ãƒªã‚¢
                if hasattr(self, "last_enhancement_stats"):
                    self.last_enhancement_stats.clear()

                # å„è¨ˆç®—æ©Ÿã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å€‹åˆ¥ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if self.tsfresh_calculator and hasattr(
                    self.tsfresh_calculator, "cleanup"
                ):
                    self.tsfresh_calculator.cleanup()

                if self.autofeat_calculator and hasattr(
                    self.autofeat_calculator, "cleanup"
                ):
                    self.autofeat_calculator.cleanup()

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if self.performance_optimizer and hasattr(
                    self.performance_optimizer, "cleanup"
                ):
                    self.performance_optimizer.cleanup()

            logger.info("FeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

        except Exception as e:
            logger.error(f"FeatureEngineeringServiceã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
