"""
ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

OHLCVã€ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆFRï¼‰ã€å»ºç‰æ®‹é«˜ï¼ˆOIï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€
å¸‚å ´ã®æ­ªã¿ã‚„åã‚Šã‚’æ‰ãˆã‚‹é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼šè²¬ä»»ã‚’åˆ†å‰²ã—ã€å„ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’çµ±åˆã—ã¾ã™ã€‚
AutoMLæ©Ÿèƒ½ã‚‚çµ±åˆã•ã‚Œã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ãŒå¯èƒ½ã§ã™ã€‚
"""

import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import pandas as pd

from ....utils.data_preprocessing import data_preprocessor
from ....utils.data_validation import DataValidator
from ....utils.unified_error_handler import safe_ml_operation
from .data_frequency_manager import DataFrequencyManager
from .fear_greed_features import FearGreedFeatureCalculator
from .interaction_features import InteractionFeatureCalculator
from .market_data_features import MarketDataFeatureCalculator
from .price_features import PriceFeatureCalculator
from .technical_features import TechnicalFeatureCalculator
from .temporal_features import TemporalFeatureCalculator

# AutoMLé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from .automl_features.autofeat_calculator import AutoFeatCalculator
    from .automl_features.automl_config import AutoMLConfig
    from .automl_features.performance_optimizer import PerformanceOptimizer
    from .automl_features.tsfresh_calculator import TSFreshFeatureCalculator
    from .enhanced_crypto_features import EnhancedCryptoFeatures
    from .optimized_crypto_features import OptimizedCryptoFeatures

    AUTOML_AVAILABLE = True
except ImportError:
    AUTOML_AVAILABLE = False

logger = logging.getLogger(__name__)


class FeatureEngineeringService:
    """
    ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

    å„ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’çµ±åˆã—ã€é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    å˜ä¸€è²¬ä»»åŸå‰‡ã«å¾“ã„ã€å„ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—ã®è¨ˆç®—ã¯å°‚ç”¨ã‚¯ãƒ©ã‚¹ã«å§”è­²ã—ã¾ã™ã€‚
    AutoMLæ©Ÿèƒ½ã‚‚ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚
    """

    def __init__(self, automl_config: Optional["AutoMLConfig"] = None):
        """
        åˆæœŸåŒ–

        Args:
            automl_config: AutoMLè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.feature_cache = {}
        self.max_cache_size = 10  # æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º
        self.cache_ttl = 3600  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰

        # ç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
        self.price_calculator = PriceFeatureCalculator()
        self.market_data_calculator = MarketDataFeatureCalculator()
        self.technical_calculator = TechnicalFeatureCalculator()
        self.temporal_calculator = TemporalFeatureCalculator()
        self.interaction_calculator = InteractionFeatureCalculator()
        self.fear_greed_calculator = FearGreedFeatureCalculator()

        # ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        self.frequency_manager = DataFrequencyManager()

        # AutoMLæ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        self.automl_enabled = automl_config is not None and AUTOML_AVAILABLE
        if self.automl_enabled:
            self.automl_config = (
                automl_config or AutoMLConfig.get_financial_optimized_config()
            )

            # AutoMLç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹
            self.tsfresh_calculator = TSFreshFeatureCalculator(
                self.automl_config.tsfresh
            )
            self.autofeat_calculator = AutoFeatCalculator(self.automl_config.autofeat)

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹
            self.performance_optimizer = PerformanceOptimizer()

            # æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            self.crypto_features = EnhancedCryptoFeatures()

            # æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            self.optimized_features = OptimizedCryptoFeatures()

            # çµ±è¨ˆæƒ…å ±
            self.last_enhancement_stats = {}

            logger.info("ğŸ¤– AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
        else:
            self.automl_config = None
            if automl_config is not None and not AUTOML_AVAILABLE:
                logger.warning(
                    "AutoMLè¨­å®šãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸãŒã€AutoMLãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
                )
            logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")

    def calculate_advanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        fear_greed_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
    ) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’è¨ˆç®—

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            fear_greed_data: Fear & Greed Index ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            lookback_periods: å„ç‰¹å¾´é‡ã®è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        try:
            if ohlcv_data.empty:
                raise ValueError("OHLCVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶é™
            if len(ohlcv_data) > 50000:
                logger.warning(
                    f"å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ{len(ohlcv_data)}è¡Œï¼‰ã€æœ€æ–°50,000è¡Œã«åˆ¶é™"
                )
                ohlcv_data = ohlcv_data.tail(50000)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ
            cache_key = self._generate_cache_key(
                ohlcv_data,
                funding_rate_data,
                open_interest_data,
                fear_greed_data,
                lookback_periods,
            )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰çµæœã‚’å–å¾—
            cached_result = self._get_from_cache(cache_key)
            if cached_result is not None:
                return cached_result

            # ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€å‡¦ç†ï¼ˆæœ€å„ªå…ˆå•é¡Œã®è§£æ±ºï¼‰
            logger.info("ãƒ‡ãƒ¼ã‚¿é »åº¦çµ±ä¸€å‡¦ç†ã‚’é–‹å§‹")
            ohlcv_timeframe = self.frequency_manager.detect_ohlcv_timeframe(ohlcv_data)

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
            validation_result = self.frequency_manager.validate_data_alignment(
                ohlcv_data, funding_rate_data, open_interest_data
            )

            if not validation_result["is_valid"]:
                logger.warning("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
                for error in validation_result["errors"]:
                    logger.warning(f"  ã‚¨ãƒ©ãƒ¼: {error}")

            # ãƒ‡ãƒ¼ã‚¿é »åº¦ã‚’çµ±ä¸€
            funding_rate_data, open_interest_data = (
                self.frequency_manager.align_data_frequencies(
                    ohlcv_data, funding_rate_data, open_interest_data, ohlcv_timeframe
                )
            )

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨ˆç®—æœŸé–“
            if lookback_periods is None:
                lookback_periods = {
                    "short_ma": 10,
                    "long_ma": 50,
                    "volatility": 20,
                    "momentum": 14,
                    "volume": 20,
                }

            # çµæœDataFrameã‚’åˆæœŸåŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
            result_df = ohlcv_data.copy()

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–
            result_df = self._optimize_dtypes(result_df)

            # åŸºæœ¬çš„ãªä¾¡æ ¼ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_price_features(
                result_df, lookback_periods
            )

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_volatility_features(
                result_df, lookback_periods
            )

            # å‡ºæ¥é«˜ç‰¹å¾´é‡
            result_df = self.price_calculator.calculate_volume_features(
                result_df, lookback_periods
            )

            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            if funding_rate_data is not None and not funding_rate_data.empty:
                result_df = self.market_data_calculator.calculate_funding_rate_features(
                    result_df, funding_rate_data, lookback_periods
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                fr_columns = [
                    "FR_MA_24",
                    "FR_MA_168",
                    "FR_Change",
                    "FR_Change_Rate",
                    "Price_FR_Divergence",
                    "FR_Normalized",
                    "FR_Trend",
                    "FR_Volatility",
                ]
                existing_fr_columns = [
                    col for col in fr_columns if col in result_df.columns
                ]
                if existing_fr_columns:
                    result_df = DataValidator.clean_dataframe(
                        result_df,
                        column_names=existing_fr_columns,
                        fill_method="median",
                    )

            # å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            if open_interest_data is not None and not open_interest_data.empty:
                result_df = (
                    self.market_data_calculator.calculate_open_interest_features(
                        result_df, open_interest_data, lookback_periods
                    )
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                oi_columns = [
                    "OI_Change_Rate",
                    "OI_Change_Rate_24h",
                    "OI_Surge",
                    "Volatility_Adjusted_OI",
                    "OI_MA_24",
                    "OI_MA_168",
                    "OI_Trend",
                    "OI_Price_Correlation",
                    "OI_Normalized",
                ]
                existing_oi_columns = [
                    col for col in oi_columns if col in result_df.columns
                ]
                if existing_oi_columns:
                    result_df = DataValidator.clean_dataframe(
                        result_df,
                        column_names=existing_oi_columns,
                        fill_method="median",
                    )

            # è¤‡åˆç‰¹å¾´é‡ï¼ˆFR + OIï¼‰
            if (
                funding_rate_data is not None
                and not funding_rate_data.empty
                and open_interest_data is not None
                and not open_interest_data.empty
            ):
                result_df = self.market_data_calculator.calculate_composite_features(
                    result_df, funding_rate_data, open_interest_data, lookback_periods
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                composite_columns = [
                    "FR_OI_Ratio",
                    "Market_Heat_Index",
                    "Market_Stress",
                    "Market_Balance",
                ]
                existing_composite_columns = [
                    col for col in composite_columns if col in result_df.columns
                ]
                if existing_composite_columns:
                    result_df = DataValidator.clean_dataframe(
                        result_df,
                        column_names=existing_composite_columns,
                        fill_method="median",
                    )

            # Fear & Greed Index ç‰¹å¾´é‡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
            if fear_greed_data is not None and not fear_greed_data.empty:
                result_df = self.fear_greed_calculator.calculate_fear_greed_features(
                    result_df, fear_greed_data, lookback_periods
                )
                # ä¸­é–“ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                fear_greed_columns = self.fear_greed_calculator.get_feature_names()
                existing_fg_columns = [
                    col for col in fear_greed_columns if col in result_df.columns
                ]
                if existing_fg_columns:
                    result_df = DataValidator.clean_dataframe(
                        result_df,
                        column_names=existing_fg_columns,
                        fill_method="median",
                    )

            # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_market_regime_features(
                result_df, lookback_periods
            )

            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_momentum_features(
                result_df, lookback_periods
            )

            # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç‰¹å¾´é‡
            result_df = self.technical_calculator.calculate_pattern_features(
                result_df, lookback_periods
            )

            # æ™‚é–“çš„ç‰¹å¾´é‡
            result_df = self.temporal_calculator.calculate_temporal_features(result_df)

            # ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆå…¨ã¦ã®åŸºæœ¬ç‰¹å¾´é‡ãŒè¨ˆç®—ã•ã‚ŒãŸå¾Œã«å®Ÿè¡Œï¼‰
            result_df = self.interaction_calculator.calculate_interaction_features(
                result_df
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            # ä¸»è¦ãªä¾¡æ ¼åˆ—ã‚’é™¤å¤–ã—ãŸç‰¹å¾´é‡åˆ—ã®ä¸€è¦§ãŒå¿…è¦ãªå ´åˆã®ã¿ã€ãã®å ´ã§è¨ˆç®—ã™ã‚‹ã“ã¨
            # ï¼ˆæœªä½¿ç”¨å¤‰æ•°ã‚’é¿ã‘ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä¿æŒã—ã¾ã›ã‚“ï¼‰

            # é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æœ‰åŠ¹åŒ–ã€IQRãƒ™ãƒ¼ã‚¹å¤–ã‚Œå€¤æ¤œå‡ºï¼‰
            logger.info("çµ±è¨ˆçš„æ‰‹æ³•ã«ã‚ˆã‚‹ç‰¹å¾´é‡å‰å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
            result_df = data_preprocessor.preprocess_features(
                result_df,
                imputation_strategy="median",
                scale_features=True,  # ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
                remove_outliers=True,
                outlier_threshold=3.0,
                scaling_method="robust",  # ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
                outlier_method="iqr",  # IQRãƒ™ãƒ¼ã‚¹ã®å¤–ã‚Œå€¤æ¤œå‡ºã‚’ä½¿ç”¨
            )

            logger.info(f"ç‰¹å¾´é‡è¨ˆç®—å®Œäº†: {len(result_df.columns)}å€‹ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ")

            # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._save_to_cache(cache_key, result_df)

            return result_df

        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    @safe_ml_operation(
        default_return=None, context="æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )
    def calculate_enhanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        fear_greed_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
        automl_config: Optional[Dict] = None,
        target: Optional[pd.Series] = None,
        max_features_per_step: int = 100,
    ) -> pd.DataFrame:
        """
        æ‹¡å¼µç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆæ‰‹å‹• + AutoMLï¼‰- ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—æ–¹å¼

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿
            fear_greed_data: Fear & Greed Index ãƒ‡ãƒ¼ã‚¿
            lookback_periods: è¨ˆç®—æœŸé–“è¨­å®š
            automl_config: AutoMLè¨­å®šï¼ˆè¾æ›¸å½¢å¼ï¼‰
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆç‰¹å¾´é‡é¸æŠç”¨ï¼‰
            max_features_per_step: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®æœ€å¤§ç‰¹å¾´é‡æ•°

        Returns:
            æ‹¡å¼µç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        if not self.automl_enabled:
            logger.warning("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™ã€‚åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œã—ã¾ã™")
            return self.calculate_advanced_features(
                ohlcv_data=ohlcv_data,
                funding_rate_data=funding_rate_data,
                open_interest_data=open_interest_data,
                fear_greed_data=fear_greed_data,
                lookback_periods=lookback_periods,
            )

        if ohlcv_data is None or ohlcv_data.empty:
            logger.warning("ç©ºã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¾ã—ãŸ")
            return ohlcv_data

        start_time = time.time()

        try:
            # AutoMLè¨­å®šã®æ›´æ–°
            if automl_config:
                self._update_automl_config(automl_config)

            logger.info("ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆã‚’é–‹å§‹")

            # ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—
            result_df = self._step1_manual_features(
                ohlcv_data,
                funding_rate_data,
                open_interest_data,
                fear_greed_data,
                lookback_periods,
            )

            # ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if self.automl_config.tsfresh.enabled:
                result_df = self._step2_tsfresh_features(
                    result_df, target, max_features_per_step
                )

            # ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if self.automl_config.autofeat.enabled:
                result_df = self._step3_autofeat_features(
                    result_df, target, max_features_per_step
                )

            # æœ€çµ‚çš„ãªç‰¹å¾´é‡çµ±è¨ˆã‚’è¨˜éŒ²
            final_feature_count = len(result_df.columns)
            logger.info(
                f"ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: æœ€çµ‚ç‰¹å¾´é‡æ•° {final_feature_count}å€‹"
            )

            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            total_time = time.time() - start_time
            self.last_enhancement_stats.update(
                {
                    "total_features": final_feature_count,
                    "total_time": total_time,
                    "data_rows": len(result_df),
                    "automl_config_used": self.automl_config.to_dict(),
                    "processing_method": "step_by_step",
                }
            )

            return result_df

        except Exception as e:
            logger.error(f"æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def get_feature_names(self) -> List[str]:
        """
        ç”Ÿæˆã•ã‚Œã‚‹ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆã‚’å–å¾—

        Returns:
            ç‰¹å¾´é‡åã®ãƒªã‚¹ãƒˆ
        """
        feature_names = []

        # å„è¨ˆç®—ã‚¯ãƒ©ã‚¹ã‹ã‚‰ç‰¹å¾´é‡åã‚’å–å¾—
        feature_names.extend(self.price_calculator.get_feature_names())
        feature_names.extend(self.market_data_calculator.get_feature_names())
        feature_names.extend(self.technical_calculator.get_feature_names())
        feature_names.extend(self.temporal_calculator.get_feature_names())
        feature_names.extend(self.interaction_calculator.get_feature_names())
        feature_names.extend(self.fear_greed_calculator.get_feature_names())

        return feature_names

    def _step1_manual_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        fear_greed_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—"""
        logger.info("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()

        result_df = self.calculate_advanced_features(
            ohlcv_data=ohlcv_data,
            funding_rate_data=funding_rate_data,
            open_interest_data=open_interest_data,
            fear_greed_data=fear_greed_data,
            lookback_periods=lookback_periods,
        )

        manual_time = time.time() - start_time
        manual_feature_count = len(result_df.columns)

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "manual_features": manual_feature_count,
                    "manual_time": manual_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: {manual_feature_count}å€‹ã®æ‰‹å‹•ç‰¹å¾´é‡ ({manual_time:.2f}ç§’)"
        )
        return result_df

    def _step2_tsfresh_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 100,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        logger.info("ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—
        result_df = self.tsfresh_calculator.calculate_tsfresh_features(
            df=df,
            target=target,
            feature_selection=self.automl_config.tsfresh.feature_selection,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        tsfresh_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "tsfresh_features": added_features,
                    "tsfresh_time": tsfresh_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {added_features}å€‹ã®TSFreshç‰¹å¾´é‡è¿½åŠ  ({tsfresh_time:.2f}ç§’)"
        )
        return result_df

    def _step3_autofeat_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 100,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        if target is None:
            logger.warning(
                "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ãŒãªã„ãŸã‚ã€AutoFeatç‰¹å¾´é‡ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
            )
            return df

        logger.info("ğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—
        result_df, generation_info = self.autofeat_calculator.generate_features(
            df=df,
            target=target,
            task_type="regression",
            max_features=self.automl_config.autofeat.max_features,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        autofeat_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        if hasattr(self, "last_enhancement_stats"):
            self.last_enhancement_stats.update(
                {
                    "autofeat_features": added_features,
                    "autofeat_time": autofeat_time,
                }
            )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: {added_features}å€‹ã®AutoFeatç‰¹å¾´é‡è¿½åŠ  ({autofeat_time:.2f}ç§’)"
        )
        return result_df

    def _generate_cache_key(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame],
        open_interest_data: Optional[pd.DataFrame],
        fear_greed_data: Optional[pd.DataFrame],
        lookback_periods: Optional[Dict[str, int]],
    ) -> str:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            fear_greed_data: Fear & Greed Index ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            lookback_periods: å„ç‰¹å¾´é‡ã®è¨ˆç®—æœŸé–“è¨­å®š

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼æ–‡å­—åˆ—
        """
        import hashlib

        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        ohlcv_hash = hashlib.md5(str(ohlcv_data.shape).encode()).hexdigest()[:8]
        fr_hash = hashlib.md5(
            str(
                funding_rate_data.shape if funding_rate_data is not None else "None"
            ).encode()
        ).hexdigest()[:8]
        oi_hash = hashlib.md5(
            str(
                open_interest_data.shape if open_interest_data is not None else "None"
            ).encode()
        ).hexdigest()[:8]
        fg_hash = hashlib.md5(
            str(
                fear_greed_data.shape if fear_greed_data is not None else "None"
            ).encode()
        ).hexdigest()[:8]
        periods_hash = hashlib.md5(
            str(
                sorted(lookback_periods.items())
                if lookback_periods is not None
                else "None"
            ).encode()
        ).hexdigest()[:8]

        return f"features_{ohlcv_hash}_{fr_hash}_{oi_hash}_{fg_hash}_{periods_hash}"

    def _get_from_cache(self, cache_key: str) -> Optional[pd.DataFrame]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰çµæœã‚’å–å¾—

        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼

        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸDataFrameã€ã¾ãŸã¯None
        """
        try:
            if cache_key in self.feature_cache:
                cached_data, timestamp = self.feature_cache[cache_key]

                # TTLãƒã‚§ãƒƒã‚¯
                if datetime.now().timestamp() - timestamp < self.cache_ttl:
                    return cached_data.copy()
                else:
                    # æœŸé™åˆ‡ã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                    del self.feature_cache[cache_key]

            return None

        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _save_to_cache(self, cache_key: str, data: pd.DataFrame):
        """
        çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜

        Args:
            cache_key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            data: ä¿å­˜ã™ã‚‹DataFrame
        """
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
            if len(self.feature_cache) >= self.max_cache_size:
                # æœ€ã‚‚å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                oldest_key = min(
                    self.feature_cache.keys(), key=lambda k: self.feature_cache[k][1]
                )
                del self.feature_cache[oldest_key]

            # æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜
            self.feature_cache[cache_key] = (data.copy(), datetime.now().timestamp())

        except Exception as e:
            logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›

        Args:
            df: æœ€é©åŒ–ã™ã‚‹DataFrame

        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸDataFrame
        """
        try:
            optimized_df = df.copy()

            for col in optimized_df.columns:
                if col == "timestamp":
                    continue

                if optimized_df[col].dtype == "float64":
                    # float64ã‚’float32ã«å¤‰æ›ï¼ˆç²¾åº¦ã¯ååˆ†ï¼‰
                    optimized_df[col] = optimized_df[col].astype("float32")
                elif optimized_df[col].dtype == "int64":
                    # int64ã‚’int32ã«å¤‰æ›ï¼ˆç¯„å›²ãŒååˆ†ãªå ´åˆï¼‰
                    if (
                        optimized_df[col].min() >= -2147483648
                        and optimized_df[col].max() <= 2147483647
                    ):
                        optimized_df[col] = optimized_df[col].astype("int32")

            return optimized_df

        except Exception as e:
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return df

    def clear_cache(self):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        """
        self.feature_cache.clear()
        logger.info("ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    def get_cache_info(self) -> Dict[str, Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±ã‚’å–å¾—
        """
        return {
            "cache_size": len(self.feature_cache),
            "max_cache_size": self.max_cache_size,
            "cache_ttl": self.cache_ttl,
            "cache_keys": list(self.feature_cache.keys()),
        }

    def _select_top_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int,
    ) -> pd.DataFrame:
        """ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œã—ã¦ä¸Šä½ç‰¹å¾´é‡ã‚’é¸æŠ"""
        if target is None or len(df.columns) <= max_features:
            return df

        try:
            from sklearn.feature_selection import SelectKBest, f_regression
            from sklearn.impute import SimpleImputer

            logger.info(f"ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­: {len(df.columns)} â†’ {max_features}å€‹")

            # æ¬ æå€¤ã‚’è£œå®Œ
            imputer = SimpleImputer(strategy="median")
            X_imputed = imputer.fit_transform(df)

            # ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ
            selector = SelectKBest(score_func=f_regression, k=max_features)
            X_selected = selector.fit_transform(X_imputed, target)

            # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ åã‚’å–å¾—
            selected_features = df.columns[selector.get_support()]
            result_df = pd.DataFrame(
                X_selected, columns=selected_features, index=df.index
            )

            logger.info(f"ç‰¹å¾´é‡é¸æŠå®Œäº†: {len(selected_features)}å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ")
            return result_df

        except Exception as e:
            logger.warning(f"ç‰¹å¾´é‡é¸æŠã§ã‚¨ãƒ©ãƒ¼: {e}. å…ƒã®DataFrameã‚’è¿”ã—ã¾ã™")
            return df

    def _update_automl_config(self, config_dict: Dict[str, Any]):
        """AutoMLè¨­å®šã‚’æ›´æ–°"""
        if not self.automl_enabled:
            logger.warning("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã®ãŸã‚ã€è¨­å®šæ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return

        try:
            # TSFreshè¨­å®šã®æ›´æ–°
            if "tsfresh" in config_dict:
                tsfresh_config = config_dict["tsfresh"]
                if isinstance(tsfresh_config, dict):
                    for key, value in tsfresh_config.items():
                        if hasattr(self.automl_config.tsfresh, key):
                            setattr(self.automl_config.tsfresh, key, value)

                    # TSFreshCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    self.tsfresh_calculator.config = self.automl_config.tsfresh

            # AutoFeatè¨­å®šã®æ›´æ–°
            if "autofeat" in config_dict:
                autofeat_config = config_dict["autofeat"]
                if isinstance(autofeat_config, dict):
                    for key, value in autofeat_config.items():
                        if hasattr(self.automl_config.autofeat, key):
                            setattr(self.automl_config.autofeat, key, value)

                    # AutoFeatCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    self.autofeat_calculator.config = self.automl_config.autofeat

            logger.info("AutoMLè¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"AutoMLè¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def get_enhancement_stats(self) -> Dict[str, Any]:
        """æœ€å¾Œã®æ‹¡å¼µå‡¦ç†ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.automl_enabled or not hasattr(self, "last_enhancement_stats"):
            return {}
        return self.last_enhancement_stats.copy()

    def get_automl_config(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®AutoMLè¨­å®šã‚’å–å¾—"""
        if not self.automl_enabled:
            return {}
        return self.automl_config.to_dict()

    def set_automl_config(self, config: "AutoMLConfig"):
        """AutoMLè¨­å®šã‚’è¨­å®š"""
        if not self.automl_enabled:
            logger.warning("AutoMLæ©Ÿèƒ½ãŒç„¡åŠ¹ã®ãŸã‚ã€è¨­å®šå¤‰æ›´ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return

        self.automl_config = config
        self.tsfresh_calculator.config = config.tsfresh

    def get_available_automl_features(self) -> Dict[str, List[str]]:
        """åˆ©ç”¨å¯èƒ½ãªAutoMLç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        if not self.automl_enabled:
            return {}

        return {
            "tsfresh": self.tsfresh_calculator.get_feature_names(),
            "autofeat": self.autofeat_calculator.get_feature_names(),
        }

    def clear_automl_cache(self):
        """AutoMLç‰¹å¾´é‡ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        if not self.automl_enabled:
            return

        try:
            self.tsfresh_calculator.clear_cache()
            self.autofeat_calculator.clear_model()

            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc

            collected = gc.collect()

            logger.info(
                f"AutoMLç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ˆ{collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›åï¼‰"
            )
        except Exception as e:
            logger.error(f"AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def cleanup_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            logger.info("FeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹")

            # åŸºæœ¬ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            self.clear_cache()

            if self.automl_enabled:
                # AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                self.clear_automl_cache()

                # çµ±è¨ˆæƒ…å ±ã‚’ã‚¯ãƒªã‚¢
                if hasattr(self, "last_enhancement_stats"):
                    self.last_enhancement_stats.clear()

                # å„è¨ˆç®—æ©Ÿã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å€‹åˆ¥ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if hasattr(self.tsfresh_calculator, "cleanup"):
                    self.tsfresh_calculator.cleanup()

                if hasattr(self.autofeat_calculator, "cleanup"):
                    self.autofeat_calculator.cleanup()

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if hasattr(self.performance_optimizer, "cleanup"):
                    self.performance_optimizer.cleanup()

            logger.info("FeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

        except Exception as e:
            logger.error(f"FeatureEngineeringServiceã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
