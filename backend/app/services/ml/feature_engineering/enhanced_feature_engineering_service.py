"""
æ‹¡å¼µç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

æ—¢å­˜ã®æ‰‹å‹•ç‰¹å¾´é‡ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã«AutoMLç‰¹å¾´é‡ã‚’çµ±åˆã—ã¾ã™ã€‚
"""

import logging
import time
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd

from ....utils.unified_error_handler import safe_ml_operation
from .automl_features.autofeat_calculator import AutoFeatCalculator
from .automl_features.automl_config import AutoMLConfig
from .automl_features.performance_optimizer import PerformanceOptimizer
from .automl_features.tsfresh_calculator import TSFreshFeatureCalculator
from .enhanced_crypto_features import EnhancedCryptoFeatures
from .feature_engineering_service import FeatureEngineeringService
from .optimized_crypto_features import OptimizedCryptoFeatures

logger = logging.getLogger(__name__)


class EnhancedFeatureEngineeringService(FeatureEngineeringService):
    """
    æ‹¡å¼µç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹

    æ—¢å­˜ã®æ‰‹å‹•ç‰¹å¾´é‡ã«AutoMLç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¾ã™ã€‚
    """

    def __init__(self, automl_config: Optional[AutoMLConfig] = None):
        """
        åˆæœŸåŒ–

        Args:
            automl_config: AutoMLè¨­å®š
        """
        super().__init__()

        # AutoMLè¨­å®š
        self.automl_config = (
            automl_config or AutoMLConfig.get_financial_optimized_config()
        )

        # AutoMLç‰¹å¾´é‡è¨ˆç®—ã‚¯ãƒ©ã‚¹
        self.tsfresh_calculator = TSFreshFeatureCalculator(self.automl_config.tsfresh)
        self.autofeat_calculator = AutoFeatCalculator(self.automl_config.autofeat)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹
        self.performance_optimizer = PerformanceOptimizer()

        # æš—å·é€šè²¨ç‰¹åŒ–ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        self.crypto_features = EnhancedCryptoFeatures()

        # æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        self.optimized_features = OptimizedCryptoFeatures()

        # çµ±è¨ˆæƒ…å ±
        self.last_enhancement_stats = {}

    @safe_ml_operation(
        default_return=None, context="æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )
    def calculate_enhanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        fear_greed_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
        automl_config: Optional[Dict] = None,
        target: Optional[pd.Series] = None,
        max_features_per_step: int = 100,
    ) -> pd.DataFrame:
        """
        æ‹¡å¼µç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆæ‰‹å‹• + AutoMLï¼‰- ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—æ–¹å¼

        Args:
            ohlcv_data: OHLCVä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿
            fear_greed_data: Fear & Greed Index ãƒ‡ãƒ¼ã‚¿
            lookback_periods: è¨ˆç®—æœŸé–“è¨­å®š
            automl_config: AutoMLè¨­å®šï¼ˆè¾æ›¸å½¢å¼ï¼‰
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆç‰¹å¾´é‡é¸æŠç”¨ï¼‰
            max_features_per_step: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®æœ€å¤§ç‰¹å¾´é‡æ•°

        Returns:
            æ‹¡å¼µç‰¹å¾´é‡ãŒè¿½åŠ ã•ã‚ŒãŸDataFrame
        """
        if ohlcv_data is None or ohlcv_data.empty:
            logger.warning("ç©ºã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¾ã—ãŸ")
            return ohlcv_data

        start_time = time.time()

        try:
            # AutoMLè¨­å®šã®æ›´æ–°
            if automl_config:
                self._update_automl_config(automl_config)

            logger.info("ğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆã‚’é–‹å§‹")

            # ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—
            result_df = self._step1_manual_features(
                ohlcv_data,
                funding_rate_data,
                open_interest_data,
                fear_greed_data,
                lookback_periods,
            )

            # ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if self.automl_config.tsfresh.enabled:
                result_df = self._step2_tsfresh_features(
                    result_df, target, max_features_per_step
                )

            # ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ
            if self.automl_config.autofeat.enabled:
                result_df = self._step3_autofeat_features(
                    result_df, target, max_features_per_step
                )

            # æœ€çµ‚çš„ãªç‰¹å¾´é‡çµ±è¨ˆã‚’è¨˜éŒ²
            final_feature_count = len(result_df.columns)
            logger.info(
                f"ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: æœ€çµ‚ç‰¹å¾´é‡æ•° {final_feature_count}å€‹"
            )

            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            total_time = time.time() - start_time
            self.last_enhancement_stats.update(
                {
                    "total_features": final_feature_count,
                    "total_time": total_time,
                    "data_rows": len(result_df),
                    "automl_config_used": self.automl_config.to_dict(),
                    "processing_method": "step_by_step",
                }
            )

            return result_df

        except Exception as e:
            logger.error(f"æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _step1_manual_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        fear_greed_data: Optional[pd.DataFrame] = None,
        lookback_periods: Optional[Dict[str, int]] = None,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—"""
        logger.info("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: æ‰‹å‹•ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()

        result_df = self.calculate_advanced_features(
            ohlcv_data=ohlcv_data,
            funding_rate_data=funding_rate_data,
            open_interest_data=open_interest_data,
            fear_greed_data=fear_greed_data,
            lookback_periods=lookback_periods,
        )

        manual_time = time.time() - start_time
        manual_feature_count = len(result_df.columns)

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        self.last_enhancement_stats.update(
            {
                "manual_features": manual_feature_count,
                "manual_time": manual_time,
            }
        )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: {manual_feature_count}å€‹ã®æ‰‹å‹•ç‰¹å¾´é‡ ({manual_time:.2f}ç§’)"
        )
        return result_df

    def _step2_tsfresh_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 100,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        logger.info("ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # TSFreshç‰¹å¾´é‡ã‚’è¨ˆç®—
        result_df = self.tsfresh_calculator.calculate_tsfresh_features(
            df=df,
            target=target,
            feature_selection=self.automl_config.tsfresh.feature_selection,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        tsfresh_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        self.last_enhancement_stats.update(
            {
                "tsfresh_features": added_features,
                "tsfresh_time": tsfresh_time,
            }
        )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: {added_features}å€‹ã®TSFreshç‰¹å¾´é‡è¿½åŠ  ({tsfresh_time:.2f}ç§’)"
        )
        return result_df

    def _step3_autofeat_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int = 100,
    ) -> pd.DataFrame:
        """ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¿½åŠ  + ç‰¹å¾´é‡é¸æŠ"""
        if target is None:
            logger.warning(
                "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ãŒãªã„ãŸã‚ã€AutoFeatç‰¹å¾´é‡ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
            )
            return df

        logger.info("ğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—3: AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...")
        start_time = time.time()
        initial_feature_count = len(df.columns)

        # AutoFeatç‰¹å¾´é‡ã‚’è¨ˆç®—
        result_df, generation_info = self.autofeat_calculator.generate_features(
            df=df,
            target=target,
            task_type="regression",
            max_features=self.automl_config.autofeat.max_features,
        )

        # ç‰¹å¾´é‡æ•°ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯é¸æŠã‚’å®Ÿè¡Œ
        if len(result_df.columns) > max_features:
            logger.info(f"ç‰¹å¾´é‡æ•°ãŒåˆ¶é™({max_features})ã‚’è¶…éã€‚ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­...")
            result_df = self._select_top_features(result_df, target, max_features)

        autofeat_time = time.time() - start_time
        added_features = len(result_df.columns) - initial_feature_count

        # çµ±è¨ˆæƒ…å ±ã‚’è¨˜éŒ²
        self.last_enhancement_stats.update(
            {
                "autofeat_features": added_features,
                "autofeat_time": autofeat_time,
            }
        )

        logger.info(
            f"âœ… ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: {added_features}å€‹ã®AutoFeatç‰¹å¾´é‡è¿½åŠ  ({autofeat_time:.2f}ç§’)"
        )
        return result_df

    def _select_top_features(
        self,
        df: pd.DataFrame,
        target: Optional[pd.Series],
        max_features: int,
    ) -> pd.DataFrame:
        """ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œã—ã¦ä¸Šä½ç‰¹å¾´é‡ã‚’é¸æŠ"""
        if target is None or len(df.columns) <= max_features:
            return df

        try:
            from sklearn.feature_selection import SelectKBest, f_regression
            from sklearn.impute import SimpleImputer

            logger.info(f"ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œä¸­: {len(df.columns)} â†’ {max_features}å€‹")

            # æ¬ æå€¤ã‚’è£œå®Œ
            imputer = SimpleImputer(strategy="median")
            X_imputed = imputer.fit_transform(df)

            # ç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ
            selector = SelectKBest(score_func=f_regression, k=max_features)
            X_selected = selector.fit_transform(X_imputed, target)

            # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚«ãƒ©ãƒ åã‚’å–å¾—
            selected_features = df.columns[selector.get_support()]
            result_df = pd.DataFrame(
                X_selected, columns=selected_features, index=df.index
            )

            logger.info(f"ç‰¹å¾´é‡é¸æŠå®Œäº†: {len(selected_features)}å€‹ã®ç‰¹å¾´é‡ã‚’é¸æŠ")
            return result_df

        except Exception as e:
            logger.warning(f"ç‰¹å¾´é‡é¸æŠã§ã‚¨ãƒ©ãƒ¼: {e}. å…ƒã®DataFrameã‚’è¿”ã—ã¾ã™")
            return df

    def _perform_integrated_feature_selection(
        self,
        features_df: pd.DataFrame,
        target: pd.Series,
        manual_feature_count: int,
        max_features: int = 150,
    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        çµ±åˆç‰¹å¾´é‡é¸æŠã‚’å®Ÿè¡Œ

        æ‰‹å‹•ç”Ÿæˆç‰¹å¾´é‡ã¨AutoMLç‰¹å¾´é‡ã‚’çµ±åˆã—ã¦å†—é•·æ€§ã‚’é™¤å»ã—ã€
        æœ€ã‚‚æœ‰ç”¨ãªç‰¹å¾´é‡ã‚’é¸æŠã—ã¾ã™ã€‚

        Args:
            features_df: å…¨ç‰¹å¾´é‡DataFrame
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            manual_feature_count: æ‰‹å‹•ç‰¹å¾´é‡ã®æ•°
            max_features: æœ€å¤§ç‰¹å¾´é‡æ•°

        Returns:
            é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        try:
            from .automl_features.feature_selector import AdvancedFeatureSelector

            # çµ±åˆç‰¹å¾´é‡é¸æŠå™¨ã‚’åˆæœŸåŒ–
            integrated_selector = AdvancedFeatureSelector()

            # ç‰¹å¾´é‡ã‚’åˆ†é¡
            feature_categories = self._categorize_features(
                features_df, manual_feature_count
            )

            # å†—é•·æ€§åˆ†æã‚’å®Ÿè¡Œ
            redundancy_info = self._analyze_feature_redundancy(
                features_df, target, feature_categories
            )

            # çµ±åˆé¸æŠã‚’å®Ÿè¡Œ
            selected_features, selection_info = (
                integrated_selector.select_features_comprehensive(
                    features_df,
                    target,
                    max_features=max_features,
                    selection_methods=[
                        "statistical_test",
                        "correlation_filter",  # æ‰‹å‹•+AutoMLé–“ã®å†—é•·æ€§é™¤å»
                        "mutual_information",
                        "importance_based",
                    ],
                )
            )

            # é¸æŠçµæœã«å†—é•·æ€§æƒ…å ±ã‚’è¿½åŠ 
            selection_info.update(
                {
                    "feature_categories": feature_categories,
                    "redundancy_analysis": redundancy_info,
                    "integrated_selection": True,
                }
            )

            logger.info(
                f"çµ±åˆç‰¹å¾´é‡é¸æŠçµæœ: "
                f"æ‰‹å‹•:{feature_categories['manual_count']}å€‹, "
                f"AutoML:{feature_categories['automl_count']}å€‹ â†’ "
                f"é¸æŠ:{len(selected_features.columns)}å€‹"
            )

            return selected_features, selection_info

        except Exception as e:
            logger.error(f"çµ±åˆç‰¹å¾´é‡é¸æŠã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ç‰¹å¾´é‡ã‚’è¿”ã™
            return features_df, {"error": str(e), "integrated_selection": False}

    def _categorize_features(
        self, features_df: pd.DataFrame, manual_feature_count: int
    ) -> Dict[str, Any]:
        """
        ç‰¹å¾´é‡ã‚’æ‰‹å‹•ç”Ÿæˆã¨AutoMLç”Ÿæˆã«åˆ†é¡

        Args:
            features_df: ç‰¹å¾´é‡DataFrame
            manual_feature_count: æ‰‹å‹•ç‰¹å¾´é‡ã®æ•°

        Returns:
            ç‰¹å¾´é‡åˆ†é¡æƒ…å ±
        """
        all_columns = features_df.columns.tolist()

        # æ‰‹å‹•ç‰¹å¾´é‡ï¼ˆæœ€åˆã®Nå€‹ï¼‰
        manual_features = all_columns[:manual_feature_count]

        # AutoMLç‰¹å¾´é‡ï¼ˆæ®‹ã‚Šï¼‰
        automl_features = all_columns[manual_feature_count:]

        # AutoMLç‰¹å¾´é‡ã‚’ãƒ„ãƒ¼ãƒ«åˆ¥ã«åˆ†é¡
        tsfresh_features = [
            col
            for col in automl_features
            if col.startswith("TSF_") or col.startswith("TS_")
        ]
        autofeat_features = [col for col in automl_features if col.startswith("AF_")]
        other_automl_features = [
            col
            for col in automl_features
            if not any(col.startswith(prefix) for prefix in ["TSF_", "AF_"])
        ]

        return {
            "manual_features": manual_features,
            "manual_count": len(manual_features),
            "automl_features": automl_features,
            "automl_count": len(automl_features),
            "tsfresh_features": tsfresh_features,
            "tsfresh_count": len(tsfresh_features),
            "autofeat_features": autofeat_features,
            "autofeat_count": len(autofeat_features),
            "other_automl_features": other_automl_features,
            "other_automl_count": len(other_automl_features),
            "total_count": len(all_columns),
        }

    def _analyze_feature_redundancy(
        self,
        features_df: pd.DataFrame,
        target: pd.Series,
        feature_categories: Dict[str, Any],
        correlation_threshold: float = 0.85,
    ) -> Dict[str, Any]:
        """
        ç‰¹å¾´é‡é–“ã®å†—é•·æ€§ã‚’åˆ†æ

        ç‰¹ã«æ‰‹å‹•ç‰¹å¾´é‡ã¨AutoMLç‰¹å¾´é‡é–“ã®å†—é•·æ€§ã‚’é‡ç‚¹çš„ã«åˆ†æã—ã¾ã™ã€‚
        ä¾‹: manual_RSI ã¨ TSF_rsi_* ã®å†—é•·æ€§

        Args:
            features_df: ç‰¹å¾´é‡DataFrame
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            feature_categories: ç‰¹å¾´é‡åˆ†é¡æƒ…å ±
            correlation_threshold: å†—é•·æ€§åˆ¤å®šã®ç›¸é–¢é–¾å€¤

        Returns:
            å†—é•·æ€§åˆ†æçµæœ
        """
        try:
            # ç›¸é–¢è¡Œåˆ—ã‚’è¨ˆç®—
            correlation_matrix = features_df.corr().abs()

            # æ‰‹å‹•ç‰¹å¾´é‡ã¨AutoMLç‰¹å¾´é‡é–“ã®é«˜ç›¸é–¢ãƒšã‚¢ã‚’ç‰¹å®š
            manual_automl_redundancy = []
            manual_features = feature_categories["manual_features"]
            automl_features = feature_categories["automl_features"]

            for manual_feat in manual_features:
                for automl_feat in automl_features:
                    if (
                        manual_feat in correlation_matrix.index
                        and automl_feat in correlation_matrix.columns
                    ):
                        corr_value = correlation_matrix.loc[manual_feat, automl_feat]
                        if corr_value > correlation_threshold:
                            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ã‚‚è¨ˆç®—
                            manual_target_corr = abs(
                                features_df[manual_feat].corr(target)
                            )
                            automl_target_corr = abs(
                                features_df[automl_feat].corr(target)
                            )

                            manual_automl_redundancy.append(
                                {
                                    "manual_feature": manual_feat,
                                    "automl_feature": automl_feat,
                                    "correlation": corr_value,
                                    "manual_target_corr": manual_target_corr,
                                    "automl_target_corr": automl_target_corr,
                                    "recommended_removal": (
                                        manual_feat
                                        if manual_target_corr < automl_target_corr
                                        else automl_feat
                                    ),
                                }
                            )

            # AutoMLç‰¹å¾´é‡é–“ã®å†—é•·æ€§ã‚‚åˆ†æ
            automl_automl_redundancy = []
            for i, feat1 in enumerate(automl_features):
                for feat2 in automl_features[i + 1 :]:
                    if (
                        feat1 in correlation_matrix.index
                        and feat2 in correlation_matrix.columns
                    ):
                        corr_value = correlation_matrix.loc[feat1, feat2]
                        if corr_value > correlation_threshold:
                            automl_automl_redundancy.append(
                                {
                                    "feature1": feat1,
                                    "feature2": feat2,
                                    "correlation": corr_value,
                                }
                            )

            redundancy_info = {
                "correlation_threshold": correlation_threshold,
                "manual_automl_redundancy": manual_automl_redundancy,
                "manual_automl_redundant_pairs": len(manual_automl_redundancy),
                "automl_automl_redundancy": automl_automl_redundancy,
                "automl_automl_redundant_pairs": len(automl_automl_redundancy),
                "total_redundant_pairs": len(manual_automl_redundancy)
                + len(automl_automl_redundancy),
            }

            logger.info(
                f"å†—é•·æ€§åˆ†æå®Œäº†: "
                f"æ‰‹å‹•-AutoMLå†—é•·ãƒšã‚¢:{len(manual_automl_redundancy)}å€‹, "
                f"AutoML-AutoMLå†—é•·ãƒšã‚¢:{len(automl_automl_redundancy)}å€‹"
            )

            return redundancy_info

        except Exception as e:
            logger.error(f"å†—é•·æ€§åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "analysis_completed": False}

    def _update_automl_config(self, config_dict: Dict[str, Any]):
        """AutoMLè¨­å®šã‚’æ›´æ–°"""
        try:
            # TSFreshè¨­å®šã®æ›´æ–°
            if "tsfresh" in config_dict:
                tsfresh_config = config_dict["tsfresh"]
                if isinstance(tsfresh_config, dict):
                    for key, value in tsfresh_config.items():
                        if hasattr(self.automl_config.tsfresh, key):
                            setattr(self.automl_config.tsfresh, key, value)

                    # TSFreshCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    self.tsfresh_calculator.config = self.automl_config.tsfresh

            # AutoFeatè¨­å®šã®æ›´æ–°
            if "autofeat" in config_dict:
                autofeat_config = config_dict["autofeat"]
                if isinstance(autofeat_config, dict):
                    for key, value in autofeat_config.items():
                        if hasattr(self.automl_config.autofeat, key):
                            setattr(self.automl_config.autofeat, key, value)

                    # AutoFeatCalculatorã®è¨­å®šã‚‚æ›´æ–°
                    self.autofeat_calculator.config = self.automl_config.autofeat

            logger.info("AutoMLè¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"AutoMLè¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def get_enhancement_stats(self) -> Dict[str, Any]:
        """æœ€å¾Œã®æ‹¡å¼µå‡¦ç†ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return self.last_enhancement_stats.copy()

    def get_automl_config(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®AutoMLè¨­å®šã‚’å–å¾—"""
        return self.automl_config.to_dict()

    def set_automl_config(self, config: AutoMLConfig):
        """AutoMLè¨­å®šã‚’è¨­å®š"""
        self.automl_config = config
        self.tsfresh_calculator.config = config.tsfresh

    def get_available_automl_features(self) -> Dict[str, List[str]]:
        """åˆ©ç”¨å¯èƒ½ãªAutoMLç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return {
            "tsfresh": self.tsfresh_calculator.get_feature_names(),
            "autofeat": self.autofeat_calculator.get_feature_names(),
        }

    def clear_automl_cache(self):
        """AutoMLç‰¹å¾´é‡ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        try:
            self.tsfresh_calculator.clear_cache()
            self.autofeat_calculator.clear_model()

            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc

            collected = gc.collect()

            logger.info(
                f"AutoMLç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸï¼ˆ{collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›åï¼‰"
            )
        except Exception as e:
            logger.error(f"AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

    def cleanup_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            logger.info(
                "EnhancedFeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹"
            )

            # AutoMLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            self.clear_automl_cache()

            # çµ±è¨ˆæƒ…å ±ã‚’ã‚¯ãƒªã‚¢
            self.last_enhancement_stats.clear()

            # å„è¨ˆç®—æ©Ÿã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å€‹åˆ¥ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if hasattr(self.tsfresh_calculator, "cleanup"):
                self.tsfresh_calculator.cleanup()

            if hasattr(self.autofeat_calculator, "cleanup"):
                self.autofeat_calculator.cleanup()

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¯ãƒ©ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if hasattr(self.performance_optimizer, "cleanup"):
                self.performance_optimizer.cleanup()

            logger.info("EnhancedFeatureEngineeringServiceã®ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")

        except Exception as e:
            logger.error(f"EnhancedFeatureEngineeringServiceã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def validate_automl_config(self, config_dict: Dict[str, Any]) -> Dict[str, Any]:
        """AutoMLè¨­å®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        validation_result = {"valid": True, "errors": [], "warnings": []}

        try:
            # TSFreshè¨­å®šã®æ¤œè¨¼
            if "tsfresh" in config_dict:
                tsfresh_config = config_dict["tsfresh"]

                if "feature_count_limit" in tsfresh_config:
                    limit = tsfresh_config["feature_count_limit"]
                    if not isinstance(limit, int) or limit <= 0:
                        validation_result["errors"].append(
                            "feature_count_limitã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )
                    elif limit > 500:
                        validation_result["warnings"].append(
                            "feature_count_limitãŒå¤§ãã™ãã¾ã™ã€‚å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                        )

                if "fdr_level" in tsfresh_config:
                    fdr = tsfresh_config["fdr_level"]
                    if not isinstance(fdr, (int, float)) or not 0 < fdr < 1:
                        validation_result["errors"].append(
                            "fdr_levelã¯0ã¨1ã®é–“ã®æ•°å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

                if "parallel_jobs" in tsfresh_config:
                    jobs = tsfresh_config["parallel_jobs"]
                    if not isinstance(jobs, int) or jobs <= 0:
                        validation_result["errors"].append(
                            "parallel_jobsã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )
                    elif jobs > 8:
                        validation_result["warnings"].append(
                            "parallel_jobsãŒå¤§ãã™ãã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                        )

                if "performance_mode" in tsfresh_config:
                    mode = tsfresh_config["performance_mode"]
                    valid_modes = [
                        "fast",
                        "balanced",
                        "financial_optimized",
                        "comprehensive",
                    ]
                    if not isinstance(mode, str) or mode not in valid_modes:
                        validation_result["errors"].append(
                            f"performance_modeã¯{valid_modes}ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
                        )

            # Featuretoolsè¨­å®šã‚­ãƒ¼ã¯ã‚µãƒãƒ¼ãƒˆå¤–ï¼ˆå®Œå…¨å‰Šé™¤æ¸ˆã¿ï¼‰ã ãŒã€äº’æ›æ€§ã®ãŸã‚è­¦å‘Šã¯å‡ºã•ãªã„ã§ç„¡è¦–
            if "featuretools" in config_dict:
                pass

            validation_result["valid"] = len(validation_result["errors"]) == 0

        except Exception as e:
            validation_result["valid"] = False
            validation_result["errors"].append(f"è¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

        return validation_result
