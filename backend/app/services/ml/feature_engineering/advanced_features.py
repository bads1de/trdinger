"""
é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã¨ãƒ©ã‚°ç‰¹å¾´é‡ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ç¾åœ¨ã®40.55%ã‹ã‚‰60%ä»¥ä¸Šã¸ã®ç²¾åº¦å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
"""

import logging
from typing import Optional

import numpy as np
import pandas as pd
import pandas_ta as ta
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)


class AdvancedFeatureEngineer:
    """é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.scaler = StandardScaler()

    # æ—§APIäº’æ›ï¼ˆcreate_features -> create_advanced_featuresï¼‰
    def create_features(self, ohlcv_data: pd.DataFrame) -> pd.DataFrame:
        return self.create_advanced_features(ohlcv_data)

    def create_advanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ

        Args:
            ohlcv_data: OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿

        Returns:
            é«˜åº¦ãªç‰¹å¾´é‡ã‚’å«ã‚€DataFrame
        """
        logger.info("ğŸš€ é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")

        features = ohlcv_data.copy()

        # 1. ãƒ©ã‚°ç‰¹å¾´é‡
        features = self._add_lag_features(features)

        # 2. é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™
        features = self._add_advanced_technical_indicators(features)

        # 3. çµ±è¨ˆçš„ç‰¹å¾´é‡
        features = self._add_statistical_features(features)

        # 4. æ™‚ç³»åˆ—ç‰¹å¾´é‡
        features = self._add_time_series_features(features)

        # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
        features = self._add_volatility_features(features)

        # 6. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡
        if funding_rate_data is not None:
            features = self._add_funding_rate_features(features, funding_rate_data)

        if open_interest_data is not None:
            features = self._add_open_interest_features(features, open_interest_data)

        # 7. ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
        features = self._add_interaction_features(features)

        # 8. å­£ç¯€æ€§ç‰¹å¾´é‡
        features = self._add_seasonal_features(features)

        # 9. ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ (MTF)ç‰¹å¾´é‡ (2025-11-23è¿½åŠ : 4h, 24h)
        features = self._add_mtf_features(features, ohlcv_data, timeframe_hours=4)
        features = self._add_mtf_features(features, ohlcv_data, timeframe_hours=24)

        # 10. å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ (OI/FR/Priceã®ç›¸äº’ä½œç”¨) (2025-11-23è¿½åŠ )
        if funding_rate_data is not None and open_interest_data is not None:
            features = self._add_market_dynamics_features(
                features, ohlcv_data, funding_rate_data, open_interest_data
            )

        logger.info(f"âœ… é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features.shape[1]}å€‹ã®ç‰¹å¾´é‡")

        return features

    def _add_lag_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªæœŸé–“ã®ã¿ï¼‰"""
        logger.info("ğŸ“Š ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã®ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆæœ€é‡è¦æœŸé–“ã®ã¿: 1h, 24hï¼‰
        lag_periods = [1, 24]

        for period in lag_periods:
            new_features[f"close_lag_{period}"] = data["close"].shift(period)

        # ä¾¡æ ¼å¤‰åŒ–ç‡ã®ãƒ©ã‚°ï¼ˆ24hã®ã¿ï¼‰
        # NOTE: "returns" è‡ªä½“ã¯ç‰¹å¾´é‡é‡è¦åº¦åˆ†æã§å®Œå…¨æœªä½¿ç”¨ã¨åˆ¤å®šã•ã‚ŒãŸãŸã‚å‰Šé™¤
        # ä»£ã‚ã‚Šã« returns_lag_24 ã¨ cumulative_returns_24 ã®ã¿è¨ˆç®—
        returns_temp = data["close"].pct_change()
        new_features["returns_lag_24"] = returns_temp.shift(24)

        # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ24hã®ã¿ï¼‰
        new_features["cumulative_returns_24"] = returns_temp.rolling(24).sum()

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_advanced_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ """
        logger.info("ğŸ“ˆ é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        data["high"].values
        data["low"].values
        data["close"].values
        data["volume"].values

        try:
            import pandas_ta as ta

            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            # Removed: stochastic_k, stochastic_d (ä½å¯„ä¸åº¦ç‰¹å¾´é‡å‰Šé™¤: 2025-11-13)

            williams_r_result = ta.willr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            if williams_r_result is not None:
                new_features["williams_r"] = williams_r_result

            cci_result = ta.cci(high=data["high"], low=data["low"], close=data["close"])
            if cci_result is not None:
                new_features["cci"] = cci_result

            mfi_result = ta.mfi(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            if mfi_result is not None:
                new_features["mfi"] = mfi_result

            uo_result = ta.uo(high=data["high"], low=data["low"], close=data["close"])
            if uo_result is not None:
                new_features["ultimate_oscillator"] = uo_result

            # === ãƒ¬ãƒ³ã‚¸/ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šå¼·åŒ– (2025-11-23è¿½åŠ ) ===
            # 1. Choppiness Index (CHOP)
            # å€¤ãŒé«˜ã„(>61.8)ã¨ãƒ¬ãƒ³ã‚¸ã€ä½ã„(<38.2)ã¨ãƒˆãƒ¬ãƒ³ãƒ‰
            chop_result = ta.chop(high=data["high"], low=data["low"], close=data["close"])
            if chop_result is not None:
                new_features["CHOP"] = chop_result

            # 2. Vortex Indicator (VI)
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘ã¨å¼·ã•ã€‚ADXã®è£œå®Œ
            vortex_result = ta.vortex(high=data["high"], low=data["low"], close=data["close"])
            if vortex_result is not None and not vortex_result.empty:
                new_features["VI_Plus"] = vortex_result["VTXP_14"]
                new_features["VI_Minus"] = vortex_result["VTXM_14"]

            # 3. Bollinger Bandwidth (BBW)
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®åç¸®ï¼ˆã‚¹ã‚¯ã‚¤ãƒ¼ã‚ºï¼‰ã‚’æ¤œçŸ¥
            bbands = ta.bbands(close=data["close"])
            if bbands is not None and not bbands.empty:
                # ãƒãƒ³ãƒ‰å¹… = (Upper - Lower) / Middle
                new_features["BBW"] = bbands["BBP_5_2.0"] # pandas-taã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã«æ³¨æ„ãŒå¿…è¦ã ãŒã€ã“ã“ã§ã¯Bandwidthã‚’è¨ˆç®—
                # pandas-taã®bbandsã¯ BBB_5_2.0 (Bandwidth), BBP_5_2.0 (%B) ãªã©ã‚’è¿”ã™
                if "BBB_5_2.0" in bbands.columns:
                    new_features["BBW"] = bbands["BBB_5_2.0"]
                if "BBP_5_2.0" in bbands.columns:
                    new_features["BB_Percent"] = bbands["BBP_5_2.0"]

            # ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            adx_result = ta.adx(high=data["high"], low=data["low"], close=data["close"])
            if adx_result is not None and not adx_result.empty:
                new_features["ADX"] = adx_result["ADX_14"]
                new_features["DI_Plus"] = adx_result["DMP_14"]
                new_features["DI_Minus"] = adx_result["DMN_14"]

            aroon_result = ta.aroon(high=data["high"], low=data["low"])
            if aroon_result is not None and not aroon_result.empty:
                new_features["Aroon_Up"] = aroon_result["AROONU_14"]
                new_features["Aroon_Down"] = aroon_result["AROOND_14"]

            aroon_osc_result = ta.aroon(high=data["high"], low=data["low"], scalar=100)
            if aroon_osc_result is not None and not aroon_osc_result.empty:
                new_features["AROONOSC"] = aroon_osc_result["AROONOSC_14"]

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            new_features["ATR"] = ta.atr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["NATR"] = ta.natr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["TRANGE"] = ta.true_range(
                high=data["high"], low=data["low"], close=data["close"]
            )

            # å‡ºæ¥é«˜æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            new_features["OBV"] = ta.obv(close=data["close"], volume=data["volume"])
            new_features["AD"] = ta.ad(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            new_features["ADOSC"] = ta.adosc(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )

        except Exception as e:
            logger.warning(f"pandas-taæŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_statistical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆä¸»è¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã¿ï¼‰"""
        logger.info("ğŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}
        windows = [20, 50]  # æ¨™æº–æœŸé–“ã¨ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“ã®ã¿

        for window in windows:
            # Removed: Close_mean_20, Close_mean_50 (ä½å¯„ä¸åº¦ç‰¹å¾´é‡å‰Šé™¤: 2025-11-13)
            # ç§»å‹•çµ±è¨ˆï¼ˆæ¨™æº–åå·®ã®ã¿æ®‹ã™ï¼‰
            new_features[f"Close_std_{window}"] = data["close"].rolling(window).std()

            # ç¯„å›²çµ±è¨ˆï¼ˆé‡è¦ãªæŒ‡æ¨™ã®ã¿ï¼‰
            high_max = data["high"].rolling(window).max()
            low_min = data["low"].rolling(window).min()
            new_features[f"Close_range_{window}"] = high_max - low_min

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_time_series_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªæœŸé–“ã®ã¿ï¼‰"""
        logger.info("â° æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # Removed: Close_pct_change_1, Close_pct_change_24 (ä½å¯„ä¸åº¦ç‰¹å¾´é‡å‰Šé™¤: 2025-11-13)
        # å¤‰åŒ–ç‡ç‰¹å¾´é‡ã¯å‰Šé™¤

        # ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        ma_20 = data["close"].rolling(20).mean()
        new_features["Close_deviation_from_ma_20"] = (data["close"] - ma_20) / ma_20

        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        new_features["Trend_strength_20"] = ta.linreg(
            data["close"], length=20, slope=True
        )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_volatility_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé«˜å¯„ä¸åº¦ã®ã¿ï¼‰"""
        logger.info("ğŸ“Š ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # å®Ÿç¾ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ20æœŸé–“ã®ã¿ï¼‰- é«˜å¯„ä¸åº¦
        # Removed: Returns (ä½å¯„ä¸åº¦ç‰¹å¾´é‡å‰Šé™¤: 2025-11-13)
        returns_temp = data["close"].pct_change()
        new_features["Realized_Vol_20"] = returns_temp.rolling(20).std() * np.sqrt(24)

        # Parkinsonæ¨å®šé‡ï¼ˆ20æœŸé–“ã®ã¿ï¼‰- é«˜å¯„ä¸åº¦
        hl_ratio = np.log(data["high"] / data["low"])
        new_features["Parkinson_Vol_20"] = hl_ratio.rolling(20).var() * (
            1 / (4 * np.log(2))
        )

        # å‰Šé™¤ã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆä½å¯„ä¸åº¦ï¼‰:
        # - Vol_Regime (ã‚¹ã‚³ã‚¢: 5.38e-05)
        # - high_vol_regime (ã‚¹ã‚³ã‚¢: 1.50e-04)

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_funding_rate_features(
        self, data: pd.DataFrame, fr_data: pd.DataFrame
    ) -> pd.DataFrame:
        """
        ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ï¼ˆæ–°è¨­è¨ˆ: Tier 1ç‰¹å¾´é‡ï¼‰

        æ–°ã—ã„FundingRateFeatureCalculatorã‚’ä½¿ç”¨ã—ã¦Tier 1ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        """
        logger.info("ğŸ’° ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        from .funding_rate_features import FundingRateFeatureCalculator

        try:
            # FundingRateFeatureCalculatorã‚’ä½¿ç”¨
            fr_calculator = FundingRateFeatureCalculator()
            result_df = fr_calculator.calculate_features(data, fr_data)

            fr_features = [col for col in result_df.columns if col.startswith("fr_")]
            logger.info(f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ : {len(fr_features)}å€‹")

            return result_df
        except Exception as e:
            logger.warning(f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return data

    def _add_open_interest_features(
        self, data: pd.DataFrame, oi_data: pd.DataFrame
    ) -> pd.DataFrame:
        """å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆä¸»è¦æŒ‡æ¨™ã®ã¿ï¼‰"""
        logger.info("ğŸ“Š å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        if "open_interest" in oi_data.columns:
            # å»ºç‰æ®‹é«˜ã®å¤‰åŒ–ç‡ï¼ˆ24hã®ã¿ï¼‰
            new_features["OI_pct_change_24"] = oi_data["open_interest"].pct_change(24)

            # å»ºç‰æ®‹é«˜ã®ç§»å‹•å¹³å‡ï¼ˆ24hã®ã¿ï¼‰
            new_features["OI_ma_24"] = oi_data["open_interest"].rolling(24).mean()
            new_features["OI_deviation_24"] = (
                oi_data["open_interest"] - new_features["OI_ma_24"]
            ) / new_features["OI_ma_24"]

            # å»ºç‰æ®‹é«˜ã¨ä¾¡æ ¼ã®é–¢ä¿‚
            new_features["OI_Price_Correlation"] = (
                oi_data["open_interest"].rolling(24).corr(data["close"])
            )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_interaction_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªçµ„ã¿åˆã‚ã›ã®ã¿ï¼‰"""
        logger.info("ğŸ”— ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã¨å‡ºæ¥é«˜ã®ç›¸äº’ä½œç”¨ï¼ˆæœ€ã‚‚é‡è¦ï¼‰
        new_features["Price_Volume_Ratio"] = data["close"] / (data["volume"] + 1e-8)

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å‡ºæ¥é«˜
        if "Realized_Vol_20" in data.columns:
            new_features["Vol_Volume_Product"] = (
                data["Realized_Vol_20"] * data["volume"]
            )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_seasonal_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å­£ç¯€æ€§ç‰¹å¾´é‡ï¼ˆå‰Šé™¤: æš—å·é€šè²¨å¸‚å ´ã§ã¯24æ™‚é–“å–å¼•ã§æ™‚é–“åŠ¹æœãŒå¼±ã„ï¼‰"""
        logger.info("ğŸ“… å­£ç¯€æ€§ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        # åˆ†æçµæœ: æ™‚é–“ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³é–¢é€£ç‰¹å¾´é‡ã¯å…¨ã¦æ¥µã‚ã¦ä½ã„å¯„ä¸åº¦ã®ãŸã‚å‰Šé™¤
        # å‰Šé™¤ã•ã‚ŒãŸç‰¹å¾´é‡: Hour, DayOfWeek, Hour_sin, Hour_cos, DayOfWeek_sin, DayOfWeek_cos,
        #                 Is_Weekend, Is_Asian_Hours, Is_American_Hours
        # ç†ç”±: æš—å·é€šè²¨ã¯24æ™‚é–“å–å¼•ã§æ™‚é–“å¸¯åŠ¹æœãŒå¼±ã„ï¼ˆå…¨ã¦ã‚¹ã‚³ã‚¢ < 0.0003ï¼‰

        return data

    def _add_mtf_features(
        self, features: pd.DataFrame, ohlcv: pd.DataFrame, timeframe_hours: int = 4
    ) -> pd.DataFrame:
        """
        ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹å¾´é‡ã‚’è¿½åŠ 
        ä¸Šä½è¶³ï¼ˆ4hãªã©ï¼‰ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹
        """
        logger.info(f"ğŸŒ MTFç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­ ({timeframe_hours}h)...")

        try:
            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (1h -> 4h)
            agg_dict = {
                "open": "first",
                "high": "max",
                "low": "min",
                "close": "last",
                "volume": "sum",
            }
            resampled = ohlcv.resample(f"{timeframe_hours}h").agg(agg_dict).dropna()

            if resampled.empty:
                return features

            mtf_features = pd.DataFrame(index=resampled.index)
            
            # ä¸Šä½è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰ (RSI, EMAä¹–é›¢)
            mtf_features[f"MTF_{timeframe_hours}h_RSI"] = ta.rsi(resampled["close"], length=14)
            
            ema_50 = ta.ema(resampled["close"], length=50)
            if ema_50 is not None:
                mtf_features[f"MTF_{timeframe_hours}h_EMA50_Diff"] = (resampled["close"] - ema_50) / ema_50

            # ä¸Šä½è¶³ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (BBW)
            bbands = ta.bbands(resampled["close"], length=20, std=2)
            if bbands is not None and "BBB_20_2.0" in bbands.columns:
                mtf_features[f"MTF_{timeframe_hours}h_BBW"] = bbands["BBB_20_2.0"]

            # ä¸Šä½è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ (ADX)
            adx = ta.adx(resampled["high"], resampled["low"], resampled["close"], length=14)
            if adx is not None and "ADX_14" in adx.columns:
                mtf_features[f"MTF_{timeframe_hours}h_ADX"] = adx["ADX_14"]

            # å…ƒã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (ffillã§ç›´å‰ã®å€¤ã‚’æ¡ç”¨ = æœªæ¥ã®æƒ…å ±ã‚’ãƒªãƒ¼ã‚¯ã•ã›ãªã„)
            # reindexã—ã¦ã‹ã‚‰ffillã™ã‚‹ã“ã¨ã§ã€13:00ã®è¡Œã«ã¯12:00æ™‚ç‚¹(09:00-12:59)ã®4hè¶³ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã‚‹
            mtf_features_aligned = mtf_features.reindex(features.index).ffill()

            # çµåˆ
            new_df = pd.concat([features, mtf_features_aligned], axis=1)
            
            # è¿½åŠ ã•ã‚ŒãŸåˆ—æ•°
            added_cols = len(new_df.columns) - len(features.columns)
            logger.info(f"MTFç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return new_df

        except Exception as e:
            logger.warning(f"MTFç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return features

    def _add_market_dynamics_features(
        self,
        features: pd.DataFrame,
        ohlcv: pd.DataFrame,
        fr_data: pd.DataFrame,
        oi_data: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ  (OI/FR/Priceã®é«˜åº¦ãªç›¸äº’ä½œç”¨)
        ãƒˆãƒ¬ãƒ³ãƒ‰ã®é§†å‹•åŠ›ã‚„è»¢æ›ã®äºˆå…†ã‚’æ‰ãˆã‚‹
        """
        logger.info("ğŸŒªï¸ å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        try:
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ (ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã—ã¦çµåˆ)
            combined = features[["close"]].copy()
            
            # Funding Rateã®çµåˆ
            if "funding_rate" in fr_data.columns:
                fr_aligned = fr_data["funding_rate"].reindex(features.index).ffill()
                combined["fr"] = fr_aligned
            
            # Open Interestã®çµåˆ
            if "open_interest" in oi_data.columns:
                oi_aligned = oi_data["open_interest"].reindex(features.index).ffill()
                combined["oi"] = oi_aligned

            # å¿…é ˆã‚«ãƒ©ãƒ ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
            if "fr" not in combined.columns or "oi" not in combined.columns:
                logger.warning("FRã¾ãŸã¯OIãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return features

            new_features = pd.DataFrame(index=features.index)

            # 1. OI Weighted FR (å»ºç‰åŠ é‡FR)
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã®åã‚Šã®ç·é‡ã€‚å€¤ãŒå¤§ãã„ã»ã©ã€Œåã‚ŠãŒé™ç•Œã«è¿‘ã„ã€å¯èƒ½æ€§
            new_features["OI_Weighted_FR"] = combined["fr"] * combined["oi"]
            
            # 2. Cumulative OI Weighted FR (è“„ç©ã•ã‚ŒãŸæ­ªã¿ã‚¨ãƒãƒ«ã‚®ãƒ¼)
            # éå»24æ™‚é–“ã®åã‚Šã®è“„ç©ã€‚ç™ºæ•£ã™ã‚‹ã¨ãƒˆãƒ¬ãƒ³ãƒ‰è»¢æ›ã®ã‚µã‚¤ãƒ³
            new_features["Cumulative_OI_Weighted_FR_24h"] = new_features["OI_Weighted_FR"].rolling(24).sum()

            # 3. OI/Price Divergence (å»ºç‰ã¨ä¾¡æ ¼ã®ä¹–é›¢)
            # ä¾¡æ ¼ã®å¤‰åŒ–ç‡
            price_pct = combined["close"].pct_change()
            # OIã®å¤‰åŒ–ç‡
            oi_pct = combined["oi"].pct_change()
            
            # Divergence: OIãŒå¢—ãˆã¦ã„ã‚‹ã®ã«ä¾¡æ ¼ãŒå‹•ã‹ãªã„ã€ãªã©ã®çŠ¶æ…‹ã‚’æ¤œçŸ¥
            # ã‚¼ãƒ­é™¤ç®—å›é¿ã®ãŸã‚ã«epsilonã‚’åŠ ç®—
            epsilon = 1e-6
            new_features["OI_Price_Divergence"] = oi_pct / (price_pct.abs() + epsilon)

            # 4. FR/Price Divergence (FRã¨ä¾¡æ ¼ã®ä¹–é›¢)
            # ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰ã¨FRã®æ–¹å‘æ€§ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹
            # 24æ™‚é–“ã®ç›¸é–¢ä¿‚æ•°
            new_features["FR_Price_Correlation_24h"] = combined["fr"].rolling(24).corr(combined["close"])

            # çµåˆ
            new_df = pd.concat([features, new_features], axis=1)
            
            added_cols = len(new_df.columns) - len(features.columns)
            logger.info(f"å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return new_df

        except Exception as e:
            logger.warning(f"å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return features
    
    def _add_range_detection_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        RANGEæ¤œå‡ºã«ç‰¹åŒ–ã—ãŸç‰¹å¾´é‡ï¼ˆRANGE vs TRENDåˆ¤åˆ¥ã®æ±ºå®šç‰ˆï¼‰
        
        RANGEç›¸å ´ã®ç‰¹å¾´:
        1. ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        2. ç‹­ã„ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸
        3. ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ¬ å¦‚
        4. ä¾¡æ ¼ãŒå¾€å¾©é‹å‹•
        5. é«˜ã„Choppiness Index
        
        Args:
            data: å…¥åŠ›DataFrame
            
        Returns:
            RANGEæ¤œå‡ºç‰¹å¾´é‡ã‚’è¿½åŠ ã—ãŸDataFrame
        """
        logger.info("ğŸ¯ RANGEæ¤œå‡ºç‰¹åŒ–ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")
        
        try:
            new_features = pd.DataFrame(index=data.index)
            
            # 1. ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ã®ç‹­ã•ï¼ˆæ­£è¦åŒ–ï¼‰
            # éå»Nãƒãƒ¼ã®é«˜å€¤-å®‰å€¤ã‚’ç¾åœ¨ä¾¡æ ¼ã§æ­£è¦åŒ–
            for window in [24, 72, 168]:  # 1æ—¥ã€3æ—¥ã€1é€±é–“
                high_max = data["high"].rolling(window=window).max()
                low_min = data["low"].rolling(window=window).min()
                price_range = high_max - low_min
                new_features[f"Price_Range_Normalized_{window}h"] = price_range / (data["close"] + 1e-8)
            
            # 2. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆä½ãƒœãƒ© = RANGEï¼‰
            # éå»ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†ä½æ•°ã‚’è¨ˆç®—
            if "Realized_Vol_20" in data.columns:
                realized_vol = data["Realized_Vol_20"]
                
                # éå»30æ—¥ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†ä½æ•°
                vol_rank = realized_vol.rolling(window=720).apply(  # 30æ—¥
                    lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
                )
                new_features["Volatility_Regime_Rank"] = vol_rank
                
                # ä½ãƒœãƒ©ãƒ•ãƒ©ã‚°ï¼ˆä¸‹ä½25%ï¼‰
                new_features["Low_Volatility_Flag"] = (vol_rank < 0.25).astype(int)
            
            # 3. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®æ¬ å¦‚
            # ADXãŒä½ã„ = ãƒˆãƒ¬ãƒ³ãƒ‰ãªã— = RANGE
            if "ADX" in data.columns:
                # ADXãŒ25æœªæº€ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãªã—ï¼ˆæ¨™æº–çš„ãªé–¾å€¤ï¼‰
                new_features["Weak_Trend_Flag"] = (data["ADX"] < 25).astype(int)
                
                # ADXã®å¤‰åŒ–ç‡ï¼ˆæ¸›å°‘å‚¾å‘ = ãƒˆãƒ¬ãƒ³ãƒ‰å¼±åŒ–ï¼‰
                new_features["ADX_Momentum"] = data["ADX"].pct_change(periods=24)
            
            # 4. ChoppinessæŒ‡æ¨™ï¼ˆæ—¢å­˜ã®CHOPã‚’åˆ©ç”¨ï¼‰
            if "CHOP" in data.columns:
                # CHOPãŒ61.8ä»¥ä¸Šã¯å¼·ã„RANGEç›¸å ´ï¼ˆæ¨™æº–çš„ãªé–¾å€¤ï¼‰
                new_features["Strong_Range_Flag"] = (data["CHOP"] > 61.8).astype(int)
                
                # CHOPã®ç§»å‹•å¹³å‡ï¼ˆæŒç¶šçš„ãªRANGEã‚’æ¤œå‡ºï¼‰
                new_features["CHOP_MA_24h"] = data["CHOP"].rolling(window=24).mean()
            
            # 5. ä¾¡æ ¼ã®å¾€å¾©é‹å‹•ï¼ˆDirectionå¤‰åŒ–ã®é »åº¦ï¼‰
            # çŸ­æœŸé–“ã§æ–¹å‘ãŒé »ç¹ã«å¤‰ã‚ã‚‹ = RANGE
            price_direction = (data["close"].diff() > 0).astype(int)  # 1=ä¸Šæ˜‡, 0=ä¸‹é™
            direction_changes = (price_direction != price_direction.shift(1)).astype(int)
            
            # éå»24æ™‚é–“ã®æ–¹å‘è»¢æ›å›æ•°
            new_features["Direction_Change_Count_24h"] = direction_changes.rolling(window=24).sum()
            
            # 6. ä¾¡æ ¼å¯†åº¦ï¼ˆç‹­ã„ãƒ¬ãƒ³ã‚¸å†…ã«ä¾¡æ ¼ãŒé›†ä¸­ï¼‰
            # éå»Nãƒãƒ¼ã®ä¾¡æ ¼æ¨™æº–åå·®ã‚’å¹³å‡ä¾¡æ ¼ã§æ­£è¦åŒ–
            for window in [24, 72]:
                price_std = data["close"].rolling(window=window).std()
                price_mean = data["close"].rolling(window=window).mean()
                new_features[f"Price_Density_{window}h"] = price_std / (price_mean + 1e-8)
            
            # 7. ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰åç¸®åº¦ï¼ˆSqueezeï¼‰
            if "BBW" in data.columns:
                # BBWãŒéå»ã®æœ€ä½æ°´æº–ã«è¿‘ã„ = Squeeze = RANGEå¾Œã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆæº–å‚™
                bbw_rank = data["BBW"].rolling(window=720).apply(  # 30æ—¥
                    lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
                )
                new_features["BBW_Squeeze_Rank"] = bbw_rank
                
                # Squeezeãƒ•ãƒ©ã‚°ï¼ˆä¸‹ä½10%ï¼‰
                new_features["BB_Squeeze_Flag"] = (bbw_rank < 0.10).astype(int)
            
            # 8. ä¾¡æ ¼å¤‰åŒ–ã®çµ¶å¯¾å€¤å¹³å‡ï¼ˆå°ã•ã„ = RANGEï¼‰
            # å¤§ããªä¾¡æ ¼å¤‰å‹•ãŒãªã„çŠ¶æ…‹ã‚’æ¤œå‡º
            abs_returns = data["close"].pct_change().abs()
            new_features["Abs_Returns_MA_24h"] = abs_returns.rolling(window=24).mean()
            
            # å°å¤‰å‹•ãƒ•ãƒ©ã‚°ï¼ˆéå»30æ—¥ã®ä¸‹ä½25%ï¼‰
            abs_returns_rank = abs_returns.rolling(window=720).apply(
                lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
            )
            new_features["Small_Movement_Flag"] = (abs_returns_rank < 0.25).astype(int)
            
            # 9. RANGEç·åˆã‚¹ã‚³ã‚¢ï¼ˆè¤‡æ•°æŒ‡æ¨™ã®çµ±åˆï¼‰
            # 0-1ã®ç¯„å›²ã§ã€1ã«è¿‘ã„ã»ã©RANGEç›¸å ´ã®å¯èƒ½æ€§ãŒé«˜ã„
            range_signals = []
            
            if "Low_Volatility_Flag" in new_features.columns:
                range_signals.append(new_features["Low_Volatility_Flag"])
            if "Weak_Trend_Flag" in new_features.columns:
                range_signals.append(new_features["Weak_Trend_Flag"])
            if "Strong_Range_Flag" in new_features.columns:
                range_signals.append(new_features["Strong_Range_Flag"])
            if "BB_Squeeze_Flag" in new_features.columns:
                range_signals.append(new_features["BB_Squeeze_Flag"])
            if "Small_Movement_Flag" in new_features.columns:
                range_signals.append(new_features["Small_Movement_Flag"])
            
            if range_signals:
                # è¤‡æ•°ã‚·ã‚°ãƒŠãƒ«ã®å¹³å‡ï¼ˆ0-1ã®é€£ç¶šå€¤ï¼‰
                new_features["RANGE_Composite_Score"] = pd.concat(range_signals, axis=1).mean(axis=1)
            
            # çµåˆ
            result = pd.concat([data, new_features], axis=1)
            
            added_cols = len(result.columns) - len(data.columns)
            logger.info(f"RANGEæ¤œå‡ºç‰¹åŒ–ç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return result
            
        except Exception as e:
            logger.warning(f"RANGEæ¤œå‡ºç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return data


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
advanced_feature_engineer = AdvancedFeatureEngineer()
