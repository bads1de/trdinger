"""
é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã¨ãƒ©ã‚°ç‰¹å¾´é‡ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ç¾åœ¨ã®40.55%ã‹ã‚‰60%ä»¥ä¸Šã¸ã®ç²¾åº¦å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
"""

import logging
from typing import Optional

import numpy as np
import pandas as pd
import pandas_ta as ta

from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)


class AdvancedFeatureEngineer:
    """é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.scaler = StandardScaler()

    # æ—§APIäº’æ›ï¼ˆcreate_features -> create_advanced_featuresï¼‰
    def create_features(self, ohlcv_data: pd.DataFrame) -> pd.DataFrame:
        return self.create_advanced_features(ohlcv_data)

    def create_advanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ

        Args:
            ohlcv_data: OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿

        Returns:
            é«˜åº¦ãªç‰¹å¾´é‡ã‚’å«ã‚€DataFrame
        """
        logger.info("ğŸš€ é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")

        features = ohlcv_data.copy()

        # 1. ãƒ©ã‚°ç‰¹å¾´é‡
        features = self._add_lag_features(features)

        # 2. é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™
        features = self._add_advanced_technical_indicators(features)

        # 3. çµ±è¨ˆçš„ç‰¹å¾´é‡
        features = self._add_statistical_features(features)

        # 4. æ™‚ç³»åˆ—ç‰¹å¾´é‡
        features = self._add_time_series_features(features)

        # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
        features = self._add_volatility_features(features)

        # 6. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡
        if funding_rate_data is not None:
            features = self._add_funding_rate_features(features, funding_rate_data)

        if open_interest_data is not None:
            features = self._add_open_interest_features(features, open_interest_data)

        # 7. ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
        features = self._add_interaction_features(features)

        # 8. å­£ç¯€æ€§ç‰¹å¾´é‡
        features = self._add_seasonal_features(features)

        logger.info(f"âœ… é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features.shape[1]}å€‹ã®ç‰¹å¾´é‡")

        return features

    def _add_lag_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆæœ€é©åŒ–ç‰ˆï¼šæœŸé–“å‰Šæ¸›ï¼‰"""
        logger.info("ğŸ“Š ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã®ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆæœŸé–“ã‚’å‰Šæ¸›: 6â†’3æœŸé–“ï¼‰
        lag_periods = [1, 6, 24]  # 1h, 6h, 24h

        for period in lag_periods:
            new_features[f"close_lag_{period}"] = data["close"].shift(period)
            new_features[f"volume_lag_{period}"] = data["volume"].shift(period)

        # ä¾¡æ ¼å¤‰åŒ–ç‡ã®ãƒ©ã‚°
        new_features["returns"] = data["close"].pct_change()
        for period in lag_periods:
            new_features[f"returns_lag_{period}"] = new_features["returns"].shift(period)

        # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¸»è¦æœŸé–“ã®ã¿ï¼‰
        for period in [6, 24]:
            new_features[f"cumulative_returns_{period}"] = new_features["returns"].rolling(period).sum()

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_advanced_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ """
        logger.info("ğŸ“ˆ é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        data["high"].values
        data["low"].values
        data["close"].values
        data["volume"].values

        try:
            import pandas_ta as ta

            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            stoch_result = ta.stoch(
                high=data["high"], low=data["low"], close=data["close"]
            )
            if stoch_result is not None and not stoch_result.empty:
                new_features["stochastic_k"] = stoch_result.iloc[:, 0]  # STOCHk
                new_features["stochastic_d"] = stoch_result.iloc[:, 1]  # STOCHd

            williams_r_result = ta.willr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            if williams_r_result is not None:
                new_features["williams_r"] = williams_r_result

            cci_result = ta.cci(high=data["high"], low=data["low"], close=data["close"])
            if cci_result is not None:
                new_features["cci"] = cci_result

            mfi_result = ta.mfi(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            if mfi_result is not None:
                new_features["mfi"] = mfi_result

            uo_result = ta.uo(high=data["high"], low=data["low"], close=data["close"])
            if uo_result is not None:
                new_features["ultimate_oscillator"] = uo_result

            # ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            adx_result = ta.adx(high=data["high"], low=data["low"], close=data["close"])
            if adx_result is not None and not adx_result.empty:
                new_features["ADX"] = adx_result["ADX_14"]
                new_features["DI_Plus"] = adx_result["DMP_14"]
                new_features["DI_Minus"] = adx_result["DMN_14"]

            aroon_result = ta.aroon(high=data["high"], low=data["low"])
            if aroon_result is not None and not aroon_result.empty:
                new_features["Aroon_Up"] = aroon_result["AROONU_14"]
                new_features["Aroon_Down"] = aroon_result["AROOND_14"]

            aroon_osc_result = ta.aroon(high=data["high"], low=data["low"], scalar=100)
            if aroon_osc_result is not None and not aroon_osc_result.empty:
                new_features["AROONOSC"] = aroon_osc_result["AROONOSC_14"]

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            new_features["ATR"] = ta.atr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["NATR"] = ta.natr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["TRANGE"] = ta.true_range(
                high=data["high"], low=data["low"], close=data["close"]
            )

            # å‡ºæ¥é«˜æŒ‡æ¨™ï¼ˆpandas-taä½¿ç”¨ï¼‰
            new_features["OBV"] = ta.obv(close=data["close"], volume=data["volume"])
            new_features["AD"] = ta.ad(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            new_features["ADOSC"] = ta.adosc(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )

        except Exception as e:
            logger.warning(f"pandas-taæŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_statistical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}
        windows = [5, 10, 20, 50]

        for window in windows:
            # ç§»å‹•çµ±è¨ˆ
            new_features[f"Close_mean_{window}"] = data["close"].rolling(window).mean()
            new_features[f"Close_std_{window}"] = data["close"].rolling(window).std()
            new_features[f"Close_skew_{window}"] = data["close"].rolling(window).skew()
            new_features[f"Close_kurt_{window}"] = data["close"].rolling(window).kurt()

            # åˆ†ä½æ•°
            new_features[f"Close_q25_{window}"] = data["close"].rolling(window).quantile(0.25)
            new_features[f"Close_q75_{window}"] = data["close"].rolling(window).quantile(0.75)
            new_features[f"Close_median_{window}"] = data["close"].rolling(window).median()

            # ç¯„å›²çµ±è¨ˆ
            high_max = data["high"].rolling(window).max()
            low_min = data["low"].rolling(window).min()
            new_features[f"Close_range_{window}"] = high_max - low_min

            q75 = new_features[f"Close_q75_{window}"]
            q25 = new_features[f"Close_q25_{window}"]
            new_features[f"Close_iqr_{window}"] = q75 - q25

            # å‡ºæ¥é«˜çµ±è¨ˆ
            new_features[f"Volume_mean_{window}"] = data["volume"].rolling(window).mean()
            new_features[f"Volume_std_{window}"] = data["volume"].rolling(window).std()

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_time_series_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("â° æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # å·®åˆ†ç‰¹å¾´é‡
        for period in [1, 6, 24]:
            new_features[f"Close_diff_{period}"] = data["close"].diff(period)
            new_features[f"Volume_diff_{period}"] = data["volume"].diff(period)

        # å¤‰åŒ–ç‡
        for period in [1, 6, 12, 24]:
            new_features[f"Close_pct_change_{period}"] = data["close"].pct_change(period)
            new_features[f"Volume_pct_change_{period}"] = data["volume"].pct_change(period)

        # ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢
        for window in [5, 10, 20]:
            ma = data["close"].rolling(window).mean()
            new_features[f"Close_deviation_from_ma_{window}"] = (data["close"] - ma) / ma

        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆpandas-taä½¿ç”¨ï¼‰
        for window in [10, 20, 50]:
            new_features[f"Trend_strength_{window}"] = ta.linreg(
                data["close"], length=window, slope=True
            )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_volatility_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ“Š ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # å®Ÿç¾ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        new_features["Returns"] = data["close"].pct_change()

        for window in [5, 10, 20, 50]:
            new_features[f"Realized_Vol_{window}"] = new_features["Returns"].rolling(
                window
            ).std() * np.sqrt(
                24
            )  # æ—¥æ¬¡æ›ç®—
            new_features[f"Vol_of_Vol_{window}"] = (
                new_features[f"Realized_Vol_{window}"].rolling(window).std()
            )

        # Parkinsonæ¨å®šé‡ï¼ˆé«˜å€¤ãƒ»å®‰å€¤ãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
        for window in [10, 20]:
            hl_ratio = np.log(data["high"] / data["low"])
            new_features[f"Parkinson_Vol_{window}"] = hl_ratio.rolling(window).var() * (
                1 / (4 * np.log(2))
            )

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
        vol_20 = new_features["Returns"].rolling(20).std()
        new_features["Vol_Regime"] = pd.cut(
            vol_20, bins=3, labels=[0, 1, 2]
        )  # ä½ãƒ»ä¸­ãƒ»é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_funding_rate_features(
        self, data: pd.DataFrame, fr_data: pd.DataFrame
    ) -> pd.DataFrame:
        """ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ’° ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        if "funding_rate" in fr_data.columns:
            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã®çµ±è¨ˆ
            for window in [3, 7, 14]:  # 3å›ã€7å›ã€14å›åˆ†ï¼ˆ24h, 56h, 112hï¼‰
                new_features[f"FR_mean_{window}"] = (
                    fr_data["funding_rate"].rolling(window).mean()
                )
                new_features[f"FR_std_{window}"] = fr_data["funding_rate"].rolling(window).std()
                new_features[f"FR_sum_{window}"] = fr_data["funding_rate"].rolling(window).sum()

            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã®å¤‰åŒ–
            new_features["FR_change"] = fr_data["funding_rate"].diff()
            new_features["FR_change_abs"] = new_features["FR_change"].abs()

            # æ¥µç«¯ãªãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ
            new_features["FR_extreme_positive"] = (
                fr_data["funding_rate"] > fr_data["funding_rate"].quantile(0.95)
            ).astype(int)
            new_features["FR_extreme_negative"] = (
                fr_data["funding_rate"] < fr_data["funding_rate"].quantile(0.05)
            ).astype(int)

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_open_interest_features(
        self, data: pd.DataFrame, oi_data: pd.DataFrame
    ) -> pd.DataFrame:
        """å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ“Š å»ºç‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        if "open_interest" in oi_data.columns:
            # å»ºç‰æ®‹é«˜ã®å¤‰åŒ–ç‡
            for period in [1, 6, 24]:
                new_features[f"OI_pct_change_{period}"] = oi_data["open_interest"].pct_change(
                    period
                )

            # å»ºç‰æ®‹é«˜ã®ç§»å‹•å¹³å‡
            for window in [6, 24, 168]:  # 6h, 24h, 168h(1é€±é–“)
                new_features[f"OI_ma_{window}"] = (
                    oi_data["open_interest"].rolling(window).mean()
                )
                new_features[f"OI_deviation_{window}"] = (
                    oi_data["open_interest"] - new_features[f"OI_ma_{window}"]
                ) / new_features[f"OI_ma_{window}"]

            # å»ºç‰æ®‹é«˜ã¨ä¾¡æ ¼ã®é–¢ä¿‚
            new_features["OI_Price_Correlation"] = (
                oi_data["open_interest"].rolling(24).corr(data["close"])
            )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_interaction_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ”— ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã¨å‡ºæ¥é«˜ã®ç›¸äº’ä½œç”¨
        new_features["Price_Volume_Product"] = data["close"] * data["volume"]
        new_features["Price_Volume_Ratio"] = data["close"] / (data["volume"] + 1e-8)

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å‡ºæ¥é«˜
        if "Realized_Vol_20" in data.columns:
            new_features["Vol_Volume_Product"] = data["Realized_Vol_20"] * data["volume"]

        # æŠ€è¡“æŒ‡æ¨™ã®çµ„ã¿åˆã‚ã›
        if "RSI" in data.columns and "Stochastic_K" in data.columns:
            new_features["RSI_Stoch_Avg"] = (data["RSI"] + data["Stochastic_K"]) / 2
            new_features["RSI_Stoch_Diff"] = data["RSI"] - data["Stochastic_K"]

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_seasonal_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å­£ç¯€æ€§ç‰¹å¾´é‡ã‚’è¿½åŠ """
        logger.info("ğŸ“… å­£ç¯€æ€§ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # DatetimeIndexã®ç¢ºèª
        if not isinstance(data.index, pd.DatetimeIndex):
            logger.warning(
                "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒDatetimeIndexã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚é–“é–¢é€£ç‰¹å¾´é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )
            return data

        # æ™‚é–“ç‰¹å¾´é‡ï¼ˆgetattrã‚’ä½¿ç”¨ã—ã¦å±æ€§ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
        try:
            hour = getattr(data.index, "hour", 0)  # type: ignore
            dayofweek = getattr(data.index, "dayofweek", 0)  # type: ignore
            day = getattr(data.index, "day", 1)  # type: ignore
            month = getattr(data.index, "month", 1)  # type: ignore

            new_features["Hour"] = hour
            new_features["DayOfWeek"] = dayofweek
            new_features["DayOfMonth"] = day
            new_features["Month"] = month
        except (AttributeError, TypeError) as e:
            logger.warning(f"æ™‚é–“é–¢é€£ç‰¹å¾´é‡ã®ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {e}")
            new_features["Hour"] = 0
            new_features["DayOfWeek"] = 0
            new_features["DayOfMonth"] = 1
            new_features["Month"] = 1

        # å‘¨æœŸçš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        new_features["Hour_sin"] = np.sin(2 * np.pi * new_features["Hour"] / 24)
        new_features["Hour_cos"] = np.cos(2 * np.pi * new_features["Hour"] / 24)
        new_features["DayOfWeek_sin"] = np.sin(2 * np.pi * new_features["DayOfWeek"] / 7)
        new_features["DayOfWeek_cos"] = np.cos(2 * np.pi * new_features["DayOfWeek"] / 7)

        # å¸‚å ´æ™‚é–“ç‰¹å¾´é‡
        new_features["Is_Weekend"] = (new_features["DayOfWeek"] >= 5).astype(int)  # åœŸæ—¥
        new_features["Is_Asian_Hours"] = ((new_features["Hour"] >= 0) & (new_features["Hour"] < 8)).astype(int)
        new_features["Is_European_Hours"] = ((new_features["Hour"] >= 8) & (new_features["Hour"] < 16)).astype(
            int
        )
        new_features["Is_American_Hours"] = ((new_features["Hour"] >= 16) & (new_features["Hour"] < 24)).astype(
            int
        )

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
advanced_feature_engineer = AdvancedFeatureEngineer()
