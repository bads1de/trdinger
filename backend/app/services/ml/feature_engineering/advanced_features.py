"""
é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã¨ãƒ©ã‚°ç‰¹å¾´é‡ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ç¾åœ¨ã®40.55%ã‹ã‚‰60%ä»¥ä¸Šã¸ã®ç²¾åº¦å‘ä¸Šã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
"""

import logging
from typing import Optional

import numpy as np
import pandas as pd
import pandas_ta as ta
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)


class AdvancedFeatureEngineer:
    """é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.scaler = StandardScaler()

    # æ—§APIäº’æ›ï¼ˆcreate_features -> create_advanced_featuresï¼‰
    def create_features(self, ohlcv_data: pd.DataFrame) -> pd.DataFrame:
        return self.create_advanced_features(ohlcv_data)

    def create_advanced_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> pd.DataFrame:
        """
        é«˜åº¦ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆ

        Args:
            ohlcv_data: OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            open_interest_data: å»ºçŽ‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿

        Returns:
            é«˜åº¦ãªç‰¹å¾´é‡ã‚’å«ã‚€DataFrame
        """
        logger.info("ðŸš€ é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹")

        features = ohlcv_data.copy()

        # 1. ãƒ©ã‚°ç‰¹å¾´é‡
        features = self._add_lag_features(features)

        # 2. é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™
        features = self._add_advanced_technical_indicators(features)

        # 3. çµ±è¨ˆçš„ç‰¹å¾´é‡
        features = self._add_statistical_features(features)

        # 4. æ™‚ç³»åˆ—ç‰¹å¾´é‡
        features = self._add_time_series_features(features)

        # 5. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡
        features = self._add_volatility_features(features)

        # 6. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡
        if funding_rate_data is not None:
            features = self._add_funding_rate_features(features, funding_rate_data)

        if open_interest_data is not None:
            features = self._add_open_interest_features(features, open_interest_data)

        # 7. ç›¸äº’ä½œç”¨ç‰¹å¾´é‡
        features = self._add_interaction_features(features)

        # 8. å­£ç¯€æ€§ç‰¹å¾´é‡
        features = self._add_seasonal_features(features)

        # 9. ãƒžãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ (MTF)ç‰¹å¾´é‡ (2025-11-23è¿½åŠ : 4h, 24h)
        features = self._add_mtf_features(features, ohlcv_data, timeframe_hours=4)
        features = self._add_mtf_features(features, ohlcv_data, timeframe_hours=24)

        # 10. å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ (OI/FR/Priceã®ç›¸äº’ä½œç”¨) (2025-11-23è¿½åŠ )
        if funding_rate_data is not None and open_interest_data is not None:
            features = self._add_market_dynamics_features(
                features, ohlcv_data, funding_rate_data, open_interest_data
            )
            
        # 11. RANGEæ¤œå‡ºç‰¹åŒ–ç‰¹å¾´é‡ (2025-11-24è¿½åŠ )
        features = self._add_range_detection_features(features)

        logger.info(f"âœ… é«˜åº¦ãªç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {features.shape[1]}å€‹ã®ç‰¹å¾´é‡")

        return features

    def _add_lag_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªæœŸé–“ã®ã¿ï¼‰"""
        logger.info("ðŸ“Š ãƒ©ã‚°ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã®ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆæœ€é‡è¦æœŸé–“ã®ã¿: 1h, 24hï¼‰
        lag_periods = [1, 24]

        for period in lag_periods:
            new_features[f"close_lag_{period}"] = data["close"].shift(period)

        # ä¾¡æ ¼å¤‰åŒ–çŽ‡ã®ãƒ©ã‚°ï¼ˆ24hã®ã¿ï¼‰
        # FutureWarningå¯¾å¿œ: fill_method=None
        returns_temp = data["close"].pct_change(fill_method=None)
        new_features["returns_lag_24"] = returns_temp.shift(24)

        # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ24hã®ã¿ï¼‰
        new_features["cumulative_returns_24"] = returns_temp.rolling(24).sum()

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_advanced_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ """
        logger.info("ðŸ“ˆ é«˜åº¦ãªæŠ€è¡“æŒ‡æ¨™ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        try:
            # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™
            williams_r_result = ta.willr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            if williams_r_result is not None:
                new_features["williams_r"] = williams_r_result

            cci_result = ta.cci(high=data["high"], low=data["low"], close=data["close"])
            if cci_result is not None:
                new_features["cci"] = cci_result

            mfi_result = ta.mfi(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            if mfi_result is not None:
                new_features["mfi"] = mfi_result

            uo_result = ta.uo(high=data["high"], low=data["low"], close=data["close"])
            if uo_result is not None:
                new_features["ultimate_oscillator"] = uo_result

            # === ãƒ¬ãƒ³ã‚¸/ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šå¼·åŒ– ===
            # 1. Choppiness Index (CHOP)
            chop_result = ta.chop(high=data["high"], low=data["low"], close=data["close"])
            if chop_result is not None:
                new_features["CHOP"] = chop_result

            # 2. Vortex Indicator (VI)
            vortex_result = ta.vortex(high=data["high"], low=data["low"], close=data["close"])
            if vortex_result is not None and not vortex_result.empty:
                new_features["VI_Plus"] = vortex_result["VTXP_14"]
                new_features["VI_Minus"] = vortex_result["VTXM_14"]

            # 3. Bollinger Bandwidth (BBW)
            bbands = ta.bbands(close=data["close"])
            if bbands is not None and not bbands.empty:
                if "BBB_5_2.0" in bbands.columns:
                    new_features["BBW"] = bbands["BBB_5_2.0"]
                if "BBP_5_2.0" in bbands.columns:
                    new_features["BB_Percent"] = bbands["BBP_5_2.0"]

            # ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™
            adx_result = ta.adx(high=data["high"], low=data["low"], close=data["close"])
            if adx_result is not None and not adx_result.empty:
                new_features["ADX"] = adx_result["ADX_14"]
                new_features["DI_Plus"] = adx_result["DMP_14"]
                new_features["DI_Minus"] = adx_result["DMN_14"]

            aroon_result = ta.aroon(high=data["high"], low=data["low"])
            if aroon_result is not None and not aroon_result.empty:
                new_features["Aroon_Up"] = aroon_result["AROONU_14"]
                new_features["Aroon_Down"] = aroon_result["AROOND_14"]

            aroon_osc_result = ta.aroon(high=data["high"], low=data["low"], scalar=100)
            if aroon_osc_result is not None and not aroon_osc_result.empty:
                new_features["AROONOSC"] = aroon_osc_result["AROONOSC_14"]

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™
            new_features["ATR"] = ta.atr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["NATR"] = ta.natr(
                high=data["high"], low=data["low"], close=data["close"]
            )
            new_features["TRANGE"] = ta.true_range(
                high=data["high"], low=data["low"], close=data["close"]
            )

            # å‡ºæ¥é«˜æŒ‡æ¨™
            new_features["OBV"] = ta.obv(close=data["close"], volume=data["volume"])
            new_features["AD"] = ta.ad(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )
            new_features["ADOSC"] = ta.adosc(
                high=data["high"],
                low=data["low"],
                close=data["close"],
                volume=data["volume"],
            )

        except Exception as e:
            logger.warning(f"pandas-taæŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

        # ä¸€æ‹¬ã§çµåˆ
        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_statistical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆä¸»è¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã¿ï¼‰"""
        logger.info("ðŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}
        windows = [20, 50]

        for window in windows:
            # ç§»å‹•çµ±è¨ˆï¼ˆæ¨™æº–åå·®ã®ã¿æ®‹ã™ï¼‰
            new_features[f"Close_std_{window}"] = data["close"].rolling(window).std()

            # ç¯„å›²çµ±è¨ˆ
            high_max = data["high"].rolling(window).max()
            low_min = data["low"].rolling(window).min()
            new_features[f"Close_range_{window}"] = high_max - low_min

        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_time_series_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªæœŸé–“ã®ã¿ï¼‰"""
        logger.info("â° æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        ma_20 = data["close"].rolling(20).mean()
        new_features["Close_deviation_from_ma_20"] = (data["close"] - ma_20) / ma_20

        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        new_features["Trend_strength_20"] = ta.linreg(
            data["close"], length=20, slope=True
        )

        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_volatility_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé«˜å¯„ä¸Žåº¦ã®ã¿ï¼‰"""
        logger.info("ðŸ“Š ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # å®Ÿç¾ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        # FutureWarningå¯¾å¿œ: fill_method=None
        returns_temp = data["close"].pct_change(fill_method=None)
        new_features["Realized_Vol_20"] = returns_temp.rolling(20).std() * np.sqrt(24)

        # ParkinsonæŽ¨å®šé‡ï¼ˆ20æœŸé–“ã®ã¿ï¼‰
        hl_ratio = np.log(data["high"] / data["low"])
        new_features["Parkinson_Vol_20"] = hl_ratio.rolling(20).var() * (
            1 / (4 * np.log(2))
        )

        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_funding_rate_features(
        self, data: pd.DataFrame, fr_data: pd.DataFrame
    ) -> pd.DataFrame:
        """
        ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ï¼ˆæ–°è¨­è¨ˆ: Tier 1ç‰¹å¾´é‡ï¼‰
        """
        logger.info("ðŸ’° ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        from .funding_rate_features import FundingRateFeatureCalculator

        try:
            fr_calculator = FundingRateFeatureCalculator()
            result_df = fr_calculator.calculate_features(data, fr_data)

            fr_features = [col for col in result_df.columns if col.startswith("fr_")]
            logger.info(f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã‚’è¿½åŠ : {len(fr_features)}å€‹")

            return result_df
        except Exception as e:
            logger.warning(f"ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç‰¹å¾´é‡ã®è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return data

    def _add_open_interest_features(
        self, data: pd.DataFrame, oi_data: pd.DataFrame
    ) -> pd.DataFrame:
        """å»ºçŽ‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆä¸»è¦æŒ‡æ¨™ã®ã¿ï¼‰"""
        logger.info("ðŸ“Š å»ºçŽ‰æ®‹é«˜ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        if "open_interest" in oi_data.columns:
            # å»ºçŽ‰æ®‹é«˜ã®å¤‰åŒ–çŽ‡ï¼ˆ24hã®ã¿ï¼‰
            # FutureWarningå¯¾å¿œ
            new_features["OI_pct_change_24"] = oi_data["open_interest"].pct_change(24, fill_method=None)

            # å»ºçŽ‰æ®‹é«˜ã®ç§»å‹•å¹³å‡ï¼ˆ24hã®ã¿ï¼‰
            new_features["OI_ma_24"] = oi_data["open_interest"].rolling(24).mean()
            new_features["OI_deviation_24"] = (
                oi_data["open_interest"] - new_features["OI_ma_24"]
            ) / new_features["OI_ma_24"]

            # å»ºçŽ‰æ®‹é«˜ã¨ä¾¡æ ¼ã®é–¢ä¿‚
            new_features["OI_Price_Correlation"] = (
                oi_data["open_interest"].rolling(24).corr(data["close"])
            )

        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_interaction_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ˆé‡è¦ãªçµ„ã¿åˆã‚ã›ã®ã¿ï¼‰"""
        logger.info("ðŸ”— ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        new_features = {}

        # ä¾¡æ ¼ã¨å‡ºæ¥é«˜ã®ç›¸äº’ä½œç”¨
        new_features["Price_Volume_Ratio"] = data["close"] / (data["volume"] + 1e-8)

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å‡ºæ¥é«˜
        if "Realized_Vol_20" in data.columns:
            new_features["Vol_Volume_Product"] = (
                data["Realized_Vol_20"] * data["volume"]
            )

        new_df = pd.concat([data, pd.DataFrame(new_features, index=data.index)], axis=1)
        return new_df

    def _add_seasonal_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å­£ç¯€æ€§ç‰¹å¾´é‡ï¼ˆå‰Šé™¤ï¼‰"""
        logger.info("ðŸ“… å­£ç¯€æ€§ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")
        return data

    def _add_mtf_features(
        self, features: pd.DataFrame, ohlcv: pd.DataFrame, timeframe_hours: int = 4
    ) -> pd.DataFrame:
        """
        ãƒžãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç‰¹å¾´é‡ã‚’è¿½åŠ 
        ä¸Šä½è¶³ï¼ˆ4hãªã©ï¼‰ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹
        """
        logger.info(f"ðŸŒ MTFç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­ ({timeframe_hours}h)...")

        try:
            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (1h -> 4h)
            # æ–‡å­—åˆ—ã® "first", "last" ãŒå†…éƒ¨ã§ NDFrame.first/last ã‚’å‘¼ã³å‡ºã—ã€
            # ãã‚ŒãŒ offset å¼•æ•°ã‚’è¦æ±‚ã—ã¦ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€é–¢æ•°ã«ç½®ãæ›ãˆã‚‹
            agg_dict = {
                "open": lambda x: x.iloc[0] if len(x) > 0 else np.nan,
                "high": "max",
                "low": "min",
                "close": lambda x: x.iloc[-1] if len(x) > 0 else np.nan,
                "volume": "sum",
            }
            
            # ç¢ºå®Ÿã«DatetimeIndexã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if not isinstance(ohlcv.index, pd.DatetimeIndex):
                logger.warning(f"MTFç‰¹å¾´é‡è¨ˆç®—ã‚¹ã‚­ãƒƒãƒ—: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒDatetimeIndexã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                return features

            resampled = ohlcv.resample(f"{timeframe_hours}h").agg(agg_dict).dropna()

            if resampled.empty:
                logger.warning(f"MTFç‰¹å¾´é‡è¨ˆç®—: ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ ({timeframe_hours}h)")
                return features

            mtf_features = pd.DataFrame(index=resampled.index)
            
            # ä¸Šä½è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰ (RSI, EMAä¹–é›¢)
            mtf_features[f"MTF_{timeframe_hours}h_RSI"] = ta.rsi(resampled["close"], length=14)
            
            ema_50 = ta.ema(resampled["close"], length=50)
            if ema_50 is not None:
                mtf_features[f"MTF_{timeframe_hours}h_EMA50_Diff"] = (resampled["close"] - ema_50) / ema_50

            # ä¸Šä½è¶³ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ (BBW)
            bbands = ta.bbands(resampled["close"], length=20, std=2)
            if bbands is not None and "BBB_20_2.0" in bbands.columns:
                mtf_features[f"MTF_{timeframe_hours}h_BBW"] = bbands["BBB_20_2.0"]

            # ä¸Šä½è¶³ã®ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ (ADX)
            adx = ta.adx(resampled["high"], resampled["low"], resampled["close"], length=14)
            if adx is not None and "ADX_14" in adx.columns:
                mtf_features[f"MTF_{timeframe_hours}h_ADX"] = adx["ADX_14"]

            # å…ƒã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (ffillã§ç›´å‰ã®å€¤ã‚’æŽ¡ç”¨ = æœªæ¥ã®æƒ…å ±ã‚’ãƒªãƒ¼ã‚¯ã•ã›ãªã„)
            mtf_features_aligned = mtf_features.reindex(features.index).ffill()

            # çµåˆ
            new_df = pd.concat([features, mtf_features_aligned], axis=1)
            
            added_cols = len(new_df.columns) - len(features.columns)
            logger.info(f"MTFç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return new_df

        except Exception as e:
            logger.warning(f"MTFç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.warning(traceback.format_exc())
            return features

    def _add_market_dynamics_features(
        self,
        features: pd.DataFrame,
        ohlcv: pd.DataFrame,
        fr_data: pd.DataFrame,
        oi_data: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ  (OI/FR/Priceã®é«˜åº¦ãªç›¸äº’ä½œç”¨)
        """
        logger.info("ðŸŒªï¸ å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")

        try:
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ (ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã—ã¦çµåˆ)
            combined = features[["close"]].copy()
            
            # Funding Rateã®çµåˆ
            if "funding_rate" in fr_data.columns:
                fr_aligned = fr_data["funding_rate"].reindex(features.index).ffill()
                combined["fr"] = fr_aligned
            
            # Open Interestã®çµåˆ
            if "open_interest" in oi_data.columns:
                oi_aligned = oi_data["open_interest"].reindex(features.index).ffill()
                combined["oi"] = oi_aligned

            # å¿…é ˆã‚«ãƒ©ãƒ ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
            if "fr" not in combined.columns or "oi" not in combined.columns:
                logger.warning("FRã¾ãŸã¯OIãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                return features

            new_features_dict = {}

            # 1. OI Weighted FR
            new_features_dict["OI_Weighted_FR"] = combined["fr"] * combined["oi"]
            
            # 2. Cumulative OI Weighted FR
            new_features_dict["Cumulative_OI_Weighted_FR_24h"] = new_features_dict["OI_Weighted_FR"].rolling(24).sum()

            # 3. OI/Price Divergence
            price_pct = combined["close"].pct_change(fill_method=None)
            oi_pct = combined["oi"].pct_change(fill_method=None)
            epsilon = 1e-6
            new_features_dict["OI_Price_Divergence"] = oi_pct / (price_pct.abs() + epsilon)

            # 4. FR/Price Divergence
            new_features_dict["FR_Price_Correlation_24h"] = combined["fr"].rolling(24).corr(combined["close"])

            # çµåˆ
            new_features_df = pd.DataFrame(new_features_dict, index=features.index)
            new_df = pd.concat([features, new_features_df], axis=1)
            
            added_cols = len(new_df.columns) - len(features.columns)
            logger.info(f"å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return new_df

        except Exception as e:
            logger.warning(f"å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return features
    
    def _add_range_detection_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        RANGEæ¤œå‡ºã«ç‰¹åŒ–ã—ãŸç‰¹å¾´é‡
        """
        logger.info("ðŸŽ¯ RANGEæ¤œå‡ºç‰¹åŒ–ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")
        
        try:
            new_features_dict = {}
            
            # 1. ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ã®ç‹­ã•ï¼ˆæ­£è¦åŒ–ï¼‰
            for window in [24, 72, 168]:
                high_max = data["high"].rolling(window=window).max()
                low_min = data["low"].rolling(window=window).min()
                price_range = high_max - low_min
                new_features_dict[f"Price_Range_Normalized_{window}h"] = price_range / (data["close"] + 1e-8)
            
            # 2. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¬ã‚¸ãƒ¼ãƒ 
            if "Realized_Vol_20" in data.columns:
                realized_vol = data["Realized_Vol_20"]
                vol_rank = realized_vol.rolling(window=720).apply(
                    lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
                )
                new_features_dict["Volatility_Regime_Rank"] = vol_rank
                new_features_dict["Low_Volatility_Flag"] = (vol_rank < 0.25).astype(int)
            
            # 3. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã®æ¬ å¦‚
            if "ADX" in data.columns:
                new_features_dict["Weak_Trend_Flag"] = (data["ADX"] < 25).astype(int)
                new_features_dict["ADX_Momentum"] = data["ADX"].pct_change(periods=24, fill_method=None)
            
            # 4. ChoppinessæŒ‡æ¨™
            if "CHOP" in data.columns:
                new_features_dict["Strong_Range_Flag"] = (data["CHOP"] > 61.8).astype(int)
                new_features_dict["CHOP_MA_24h"] = data["CHOP"].rolling(window=24).mean()
            
            # 5. ä¾¡æ ¼ã®å¾€å¾©é‹å‹•
            price_direction = (data["close"].diff() > 0).astype(int)
            direction_changes = (price_direction != price_direction.shift(1)).astype(int)
            new_features_dict["Direction_Change_Count_24h"] = direction_changes.rolling(window=24).sum()
            
            # 6. ä¾¡æ ¼å¯†åº¦
            for window in [24, 72]:
                price_std = data["close"].rolling(window=window).std()
                price_mean = data["close"].rolling(window=window).mean()
                new_features_dict[f"Price_Density_{window}h"] = price_std / (price_mean + 1e-8)
            
            # 7. ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰åŽç¸®åº¦
            if "BBW" in data.columns:
                bbw_rank = data["BBW"].rolling(window=720).apply(
                    lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
                )
                new_features_dict["BBW_Squeeze_Rank"] = bbw_rank
                new_features_dict["BB_Squeeze_Flag"] = (bbw_rank < 0.10).astype(int)
            
            # 8. ä¾¡æ ¼å¤‰åŒ–ã®çµ¶å¯¾å€¤å¹³å‡
            abs_returns = data["close"].pct_change(fill_method=None).abs()
            new_features_dict["Abs_Returns_MA_24h"] = abs_returns.rolling(window=24).mean()
            
            abs_returns_rank = abs_returns.rolling(window=720).apply(
                lambda x: pd.Series(x).rank(pct=True).iloc[-1] if len(x) > 0 else 0.5
            )
            new_features_dict["Small_Movement_Flag"] = (abs_returns_rank < 0.25).astype(int)
            
            # 9. RANGEç·åˆã‚¹ã‚³ã‚¢
            # ä¸€æ—¦DataFrameã«ã—ã¦è¨ˆç®—
            temp_df = pd.DataFrame(new_features_dict)
            range_signals = []
            signal_cols = ["Low_Volatility_Flag", "Weak_Trend_Flag", "Strong_Range_Flag", "BB_Squeeze_Flag", "Small_Movement_Flag"]
            
            for col in signal_cols:
                if col in temp_df.columns:
                    range_signals.append(temp_df[col])
            
            if range_signals:
                new_features_dict["RANGE_Composite_Score"] = pd.concat(range_signals, axis=1).mean(axis=1)
            
            # çµåˆ
            new_features_df = pd.DataFrame(new_features_dict, index=data.index)
            result = pd.concat([data, new_features_df], axis=1)
            
            added_cols = len(result.columns) - len(data.columns)
            logger.info(f"RANGEæ¤œå‡ºç‰¹åŒ–ç‰¹å¾´é‡ã‚’è¿½åŠ : {added_cols}å€‹")
            
            return result
            
        except Exception as e:
            logger.warning(f"RANGEæ¤œå‡ºç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return data


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
advanced_feature_engineer = AdvancedFeatureEngineer()