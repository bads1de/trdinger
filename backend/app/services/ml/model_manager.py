"""
çµ±åˆMLãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹

ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ãƒ»ä¸€è¦§ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ä¸€å…ƒç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚
ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãªã©ã®é«˜æ©Ÿèƒ½ã‚‚æä¾›ã—ã¾ã™ã€‚
æ—¢å­˜ã®APIã¨ã®äº’æ›æ€§ã‚’ä¿æŒã—ãªãŒã‚‰ã€æ‹¡å¼µæ©Ÿèƒ½ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚
"""

import glob
import hashlib
import logging
import os
import warnings
 
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import joblib
import pandas as pd

from .config import ml_config

from ...utils.unified_error_handler import UnifiedModelError, safe_ml_operation

logger = logging.getLogger(__name__)


class PerformanceMetric(Enum):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™"""

    ACCURACY = "accuracy"
    BALANCED_ACCURACY = "balanced_accuracy"
    F1_SCORE = "f1_score"
    ROC_AUC = "roc_auc"
    PR_AUC = "pr_auc"
    PRECISION = "precision"
    RECALL = "recall"


@dataclass
class PerformanceMonitoringConfig:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–è¨­å®š"""

    enable_monitoring: bool = True
    alert_threshold: float = 0.05  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã®é–¾å€¤
    monitoring_window: int = 100  # ç›£è¦–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
    auto_retrain_threshold: float = 0.10  # è‡ªå‹•å†å­¦ç¿’ã®é–¾å€¤
    max_performance_history: int = 1000


class ModelManager:
    """
    çµ±åˆMLãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹

    ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã€èª­ã¿è¾¼ã¿ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãªã©ã€
    ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã«é–¢ã™ã‚‹å…¨ã¦ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
    æ—¢å­˜ã®APIã¨ã®äº’æ›æ€§ã‚’ä¿æŒã—ãªãŒã‚‰ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã€
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãªã©ã®é«˜æ©Ÿèƒ½ã‚‚æä¾›ã—ã¾ã™ã€‚
    """

    def __init__(self, monitoring_config: PerformanceMonitoringConfig = None):
        """
        åˆæœŸåŒ–

        Args:
            monitoring_config: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–è¨­å®š
        """
        # æ—¢å­˜è¨­å®šã®åˆæœŸåŒ–
        self.config = ml_config.model
        self._ensure_directories()

        # æ‹¡å¼µæ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰
        self.base_path = Path(self.config.MODEL_SAVE_PATH)
        self.monitoring_config = monitoring_config or PerformanceMonitoringConfig()

    def _ensure_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        os.makedirs(self.config.MODEL_SAVE_PATH, exist_ok=True)

    # ========================================
    # æ—¢å­˜APIï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
    # ========================================

    def _extract_algorithm_name(
        self, model: Any, metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã‚’æŠ½å‡º

        Args:
            model: ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å
        """
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ best_algorithm ã‚’å–å¾—ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®å ´åˆï¼‰
            if metadata and "best_algorithm" in metadata:
                algorithm = metadata["best_algorithm"]
                if algorithm:
                    return algorithm.lower()

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ model_type ã‚’å–å¾—
            if metadata and "model_type" in metadata:
                model_type = metadata["model_type"]
                if model_type and model_type != "unknown":
                    # EnsembleTrainer ãªã©ã®ã‚¯ãƒ©ã‚¹åã‹ã‚‰æ¨å®š
                    if "ensemble" in model_type.lower():
                        return "ensemble"
                    elif "single" in model_type.lower():
                        return "single"
                    else:
                        return model_type.lower()

            # ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒ©ã‚¹åã‹ã‚‰æ¨å®š
            model_class_name = type(model).__name__.lower()

            # AlgorithmRegistry ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã‚’å–å¾—
            from .common.algorithm_registry import algorithm_registry

            algorithm_name = algorithm_registry.get_algorithm_name(model_class_name)

            if algorithm_name != "unknown":
                logger.debug(
                    f"AlgorithmRegistryã‹ã‚‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã‚’å–å¾—: {model_class_name} -> {algorithm_name}"
                )
                return algorithm_name

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            return "unknown"

        except Exception as e:
            logger.warning(f"ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã®æŠ½å‡ºã«å¤±æ•—: {e}")
            return "unknown"

    @safe_ml_operation(default_return=None, context="ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    def save_model(
        self,
        model: Any,
        model_name: str,
        metadata: Optional[Dict[str, Any]] = None,
        scaler: Optional[Any] = None,
        feature_columns: Optional[List[str]] = None,
    ) -> Optional[str]:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ï¼ˆæ—¢å­˜APIï¼‰

        Args:
            model: ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            model_name: ãƒ¢ãƒ‡ãƒ«å
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            scaler: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            feature_columns: ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            UnifiedModelError: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã«å¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            if model is None:
                raise UnifiedModelError("ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒNullã§ã™")

            # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã‚’å–å¾—
            algorithm_name = self._extract_algorithm_name(model, metadata)

            # æ—¥ä»˜ã®ã¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆï¼ˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å_æ—¥ä»˜å½¢å¼ï¼‰
            date_stamp = datetime.now().strftime("%Y%m%d")
            base_filename = f"{algorithm_name}_{date_stamp}"

            # åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯é€£ç•ªã‚’è¿½åŠ 
            counter = 1
            filename = f"{base_filename}{self.config.MODEL_FILE_EXTENSION}"
            model_path = os.path.join(self.config.MODEL_SAVE_PATH, filename)

            while os.path.exists(model_path):
                filename = (
                    f"{base_filename}_{counter:02d}{self.config.MODEL_FILE_EXTENSION}"
                )
                model_path = os.path.join(self.config.MODEL_SAVE_PATH, filename)
                counter += 1

            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
            model_data = {
                "model": model,
                "scaler": scaler,
                "feature_columns": feature_columns,
                "timestamp": date_stamp,
                "model_name": algorithm_name,  # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã‚’ä¿å­˜
                "original_model_name": model_name,  # å…ƒã®ãƒ¢ãƒ‡ãƒ«åã‚‚ä¿æŒ
                "metadata": metadata or {},
            }

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¿½åŠ 
            model_data["metadata"].update(
                {
                    "created_at": datetime.now().isoformat(),
                    "file_size_bytes": 0,  # å¾Œã§æ›´æ–°
                    "python_version": f"{__import__('sys').version_info.major}.{__import__('sys').version_info.minor}",
                    "model_type": type(model).__name__,
                }
            )

            # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            joblib.dump(model_data, model_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’æ›´æ–°
            file_size = os.path.getsize(model_path)
            model_data["metadata"]["file_size_bytes"] = file_size
            joblib.dump(model_data, model_path)

            logger.info(
                f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {filename} (ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {algorithm_name}, ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f}MB)"
            )

            # å¤ã„ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_old_models(model_name)

            return model_path

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise UnifiedModelError(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    @safe_ml_operation(
        default_return=None, context="ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )
    def load_model(self, model_path: str) -> Optional[Dict[str, Any]]:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜APIï¼‰

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿

        Raises:
            UnifiedModelError: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
        """
        try:
            if not os.path.exists(model_path):
                raise UnifiedModelError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")

            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            from sklearn.exceptions import InconsistentVersionWarning
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", InconsistentVersionWarning)
                model_data = joblib.load(model_path)
 
            # å¤ã„å½¢å¼ã¨ã®äº’æ›æ€§ã‚’ä¿ã¤
            if not isinstance(model_data, dict):
                # å¤ã„å½¢å¼ï¼ˆç›´æ¥ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã®å ´åˆ
                model_data = {
                    "model": model_data,
                    "scaler": None,
                    "feature_columns": None,
                    "timestamp": None,
                    "model_name": os.path.basename(model_path),
                    "metadata": {},
                }

            # å¿…è¦ãªã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
            if "model" not in model_data:
                raise UnifiedModelError("ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã«'model'ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            model_data.setdefault("scaler", None)
            model_data.setdefault("feature_columns", None)
            model_data.setdefault("metadata", {})

            logger.info(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {os.path.basename(model_path)}")
            return model_data

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            raise UnifiedModelError(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def get_latest_model(self, model_name_pattern: str = "*") -> Optional[str]:
        """
        æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—

        Args:
            model_name_pattern: ãƒ¢ãƒ‡ãƒ«åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ä½¿ç”¨å¯èƒ½ï¼‰

        Returns:
            æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            # è¤‡æ•°ã®æ¤œç´¢ãƒ‘ã‚¹ã‹ã‚‰æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
            all_model_files = []

            for search_path in ml_config.get_model_search_paths():
                if os.path.exists(search_path):
                    # .pkl ã¨ .joblib ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                    pattern_pkl = os.path.join(
                        search_path, f"{model_name_pattern}*.pkl"
                    )
                    pattern_joblib = os.path.join(
                        search_path, f"{model_name_pattern}*.joblib"
                    )

                    pkl_files = glob.glob(pattern_pkl)
                    joblib_files = glob.glob(pattern_joblib)
                    all_model_files.extend(pkl_files + joblib_files)

            if not all_model_files:
                logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_name_pattern}")
                return None

            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆæ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼‰
            latest_model = max(all_model_files, key=os.path.getmtime)
            logger.info(f"æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ç™ºè¦‹: {os.path.basename(latest_model)}")

            return latest_model

        except Exception as e:
            logger.error(f"æœ€æ–°ãƒ¢ãƒ‡ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def list_models(self, model_name_pattern: str = "*") -> List[Dict[str, Any]]:
        """
        ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’å–å¾—

        Args:
            model_name_pattern: ãƒ¢ãƒ‡ãƒ«åã®ãƒ‘ã‚¿ãƒ¼ãƒ³

        Returns:
            ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        try:
            models = []
            seen_files = set()  # é‡è¤‡ã‚’é˜²ããŸã‚ã®ã‚»ãƒƒãƒˆ

            for search_path in ml_config.get_model_search_paths():
                if not os.path.exists(search_path):
                    continue

                pattern_pkl = os.path.join(search_path, f"{model_name_pattern}*.pkl")
                pattern_joblib = os.path.join(
                    search_path, f"{model_name_pattern}*.joblib"
                )

                for pattern in [pattern_pkl, pattern_joblib]:
                    for model_path in glob.glob(pattern):
                        try:
                            # çµ¶å¯¾ãƒ‘ã‚¹ã§æ­£è¦åŒ–ã—ã¦é‡è¤‡ãƒã‚§ãƒƒã‚¯
                            normalized_path = os.path.abspath(model_path)
                            if normalized_path in seen_files:
                                continue
                            seen_files.add(normalized_path)

                            stat = os.stat(model_path)
                            models.append(
                                {
                                    "path": model_path,
                                    "name": os.path.basename(model_path),
                                    "size_mb": stat.st_size / 1024 / 1024,
                                    "modified_at": datetime.fromtimestamp(
                                        stat.st_mtime
                                    ),
                                    "directory": os.path.dirname(model_path),
                                }
                            )
                        except Exception as e:
                            logger.warning(
                                f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ {model_path}: {e}"
                            )

            # æ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
            models.sort(key=lambda x: x["modified_at"], reverse=True)

            return models

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def cleanup_expired_models(self):
        """æœŸé™åˆ‡ã‚Œã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            cutoff_date = datetime.now() - timedelta(
                days=self.config.MODEL_RETENTION_DAYS
            )

            for search_path in ml_config.get_model_search_paths():
                if not os.path.exists(search_path):
                    continue

                for model_file in glob.glob(
                    os.path.join(search_path, f"*{self.config.MODEL_FILE_EXTENSION}")
                ):
                    try:
                        file_time = datetime.fromtimestamp(os.path.getmtime(model_file))
                        if file_time < cutoff_date:
                            os.remove(model_file)
                            logger.info(
                                f"æœŸé™åˆ‡ã‚Œãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤: {os.path.basename(model_file)}"
                            )
                    except Exception as e:
                        logger.warning(f"æœŸé™åˆ‡ã‚Œãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {model_file}: {e}")

        except Exception as e:
            logger.error(f"æœŸé™åˆ‡ã‚Œãƒ¢ãƒ‡ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_old_models(self, model_name: str):
        """å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # åŒã˜ãƒ¢ãƒ‡ãƒ«åã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            pattern = os.path.join(
                self.config.MODEL_SAVE_PATH,
                f"{model_name}_*{self.config.MODEL_FILE_EXTENSION}",
            )
            model_files = glob.glob(pattern)

            if len(model_files) <= self.config.MAX_MODEL_VERSIONS:
                return

            # æ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„é †ï¼‰
            model_files.sort(key=os.path.getmtime)

            # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆæœ€æ–°ã®Nå€‹ã‚’æ®‹ã™ï¼‰
            files_to_delete = model_files[: -self.config.MAX_MODEL_VERSIONS]

            for file_path in files_to_delete:
                try:
                    os.remove(file_path)
                    logger.info(
                        f"å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {os.path.basename(file_path)}"
                    )
                except Exception as e:
                    logger.warning(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    # ========================================
    # æ‹¡å¼µAPIï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    # ========================================

    def register_model(
        self,
        model: Any,
        model_name: str,
        algorithm: str,
        training_data: pd.DataFrame,
        performance_metrics: Dict[str, float],
        validation_metrics: Dict[str, float] = None,
        hyperparameters: Dict[str, Any] = None,
        feature_selection_config: Dict[str, Any] = None,
        preprocessing_config: Dict[str, Any] = None,
        tags: List[str] = None,
        description: str = "",
        author: str = "system",
    ) -> str:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²ï¼ˆæ‹¡å¼µæ©Ÿèƒ½ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
            model_name: ãƒ¢ãƒ‡ãƒ«å
            algorithm: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å
            training_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
            performance_metrics: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
            validation_metrics: æ¤œè¨¼æŒ‡æ¨™
            hyperparameters: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            feature_selection_config: ç‰¹å¾´é‡é¸æŠè¨­å®š
            preprocessing_config: å‰å‡¦ç†è¨­å®š
            tags: ã‚¿ã‚°
            description: èª¬æ˜
            author: ä½œæˆè€…

        Returns:
            ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logger.info(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«ç™»éŒ²é–‹å§‹: {model_name}")

        # æ‹¡å¼µãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        extended_metadata = {
            "algorithm": algorithm,
            "performance_metrics": performance_metrics,
            "validation_metrics": validation_metrics or {},
            "hyperparameters": hyperparameters or {},
            "feature_selection_config": feature_selection_config or {},
            "preprocessing_config": preprocessing_config or {},
            "tags": tags or [],
            "description": description,
            "author": author,
            "feature_count": training_data.shape[1],
            "sample_count": training_data.shape[0],
            "training_data_hash": self._calculate_data_hash(training_data),
        }

        # æ—¢å­˜ã®save_modelãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆæ‹¡å¼µãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰
        model_path = self.save_model(
            model=model,
            model_name=model_name,
            metadata=extended_metadata,
            scaler=None,
            feature_columns=(
                list(training_data.columns)
                if hasattr(training_data, "columns")
                else None
            ),
        )

        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ç™»éŒ²å®Œäº†: {model_path}")
        return model_path

    def load_model_enhanced(self, model_path: str) -> Tuple[Any, Dict[str, Any]]:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆæ‹¡å¼µæ©Ÿèƒ½ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ãƒ—ãƒ«
        """
        # æ—¢å­˜ã®load_modelãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        model_data = self.load_model(model_path)

        if model_data is None:
            raise ValueError(f"ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")

        # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
        model = model_data["model"]
        metadata = model_data.get("metadata", {})

        logger.info(f"æ‹¡å¼µãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†: {os.path.basename(model_path)}")
        return model, metadata

    def get_best_model(
        self,
        metric: PerformanceMetric = PerformanceMetric.BALANCED_ACCURACY,
        algorithm: Optional[str] = None,
        tags: Optional[List[str]] = None,
    ) -> Optional[str]:
        """
        æœ€é«˜æ€§èƒ½ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            metric: è©•ä¾¡æŒ‡æ¨™
            algorithm: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ åã§ãƒ•ã‚£ãƒ«ã‚¿
            tags: ã‚¿ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿

        Returns:
            æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        models = self.list_models("*")
        candidates = []

        for model_info in models:
            try:
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                model_data = self.load_model(model_info["path"])
                if not model_data:
                    continue

                metadata = model_data.get("metadata", {})

                # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                if algorithm and metadata.get("algorithm") != algorithm:
                    continue

                if tags and not any(tag in metadata.get("tags", []) for tag in tags):
                    continue

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’å–å¾—
                performance_metrics = metadata.get("performance_metrics", {})
                metric_value = performance_metrics.get(metric.value, 0.0)

                candidates.append((model_info["path"], metric_value))

            except Exception as e:
                logger.warning(
                    f"ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {model_info['path']}: {e}"
                )
                continue

        if not candidates:
            return None

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        best_model_path, _ = max(candidates, key=lambda x: x[1])
        return best_model_path

    def get_model_list_enhanced(
        self, algorithm: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆæ‹¡å¼µæ©Ÿèƒ½ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ï¼‰"""
        models = self.list_models("*")
        enhanced_models = []

        for model_info in models:
            try:
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                model_data = self.load_model(model_info["path"])
                if not model_data:
                    continue

                metadata = model_data.get("metadata", {})

                # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                if algorithm and metadata.get("algorithm") != algorithm:
                    continue

                # æ‹¡å¼µæƒ…å ±ã‚’è¿½åŠ 
                enhanced_info = {
                    **model_info,
                    "algorithm": metadata.get("algorithm", "unknown"),
                    "performance_metrics": metadata.get("performance_metrics", {}),
                    "validation_metrics": metadata.get("validation_metrics", {}),
                    "feature_count": metadata.get("feature_count", 0),
                    "sample_count": metadata.get("sample_count", 0),
                    "tags": metadata.get("tags", []),
                    "description": metadata.get("description", ""),
                    "author": metadata.get("author", "unknown"),
                }

                enhanced_models.append(enhanced_info)

            except Exception as e:
                logger.warning(
                    f"ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {model_info['path']}: {e}"
                )
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¯è¿½åŠ 
                enhanced_models.append(
                    {
                        **model_info,
                        "algorithm": "unknown",
                        "performance_metrics": {},
                        "validation_metrics": {},
                        "feature_count": 0,
                        "sample_count": 0,
                        "tags": [],
                        "description": "",
                        "author": "unknown",
                    }
                )

        # æ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        enhanced_models.sort(key=lambda x: x["modified_at"], reverse=True)
        return enhanced_models

    # ========================================
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================

    def _calculate_data_hash(self, data: pd.DataFrame) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        try:
            data_str = data.to_string()
            return hashlib.md5(data_str.encode()).hexdigest()
        except Exception:
            # DataFrame ã§ãªã„/ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¤±æ•—ãªã©ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return "unknown"


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
model_manager = ModelManager()
