"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ±åˆç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹
APIãƒ«ãƒ¼ã‚¿ãƒ¼å†…ã«æ•£åœ¨ã—ã¦ã„ãŸMLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£ã®ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆç®¡ç†ã—ã¾ã™ã€‚

"""

import logging
import os
from datetime import datetime
from typing import Any, Dict

from sqlalchemy.orm import Session

from app.services.ml.ml_training_service import MLTrainingService
from app.services.ml.orchestration.background_task_manager import (
    background_task_manager,
)
from app.services.ml.model_manager import model_manager
from app.utils.response import api_response
from app.utils.error_handler import safe_ml_operation
from database.repositories.funding_rate_repository import FundingRateRepository
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.open_interest_repository import OpenInterestRepository

logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ç®¡ç†
training_status = {
    "is_training": False,
    "progress": 0,
    "status": "idle",
    "message": "å¾…æ©Ÿä¸­",
    "start_time": None,
    "end_time": None,
    "model_info": None,
    "error": None,
}


class MLTrainingOrchestrationService:
    """
    MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ±åˆç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹

    MLãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€çŠ¶æ…‹ç®¡ç†ã€ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ç­‰ã®
    çµ±ä¸€çš„ãªå‡¦ç†ã‚’æ‹…å½“ã—ã¾ã™ã€‚
    """

    def __init__(self):
        """åˆæœŸåŒ–"""

    def get_data_service(self, db: Session):
        """ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥"""
        # å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’é¿ã‘ã‚‹ãŸã‚ã€é–¢æ•°å†…ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from app.services.backtest.backtest_data_service import BacktestDataService

        ohlcv_repo = OHLCVRepository(db)
        oi_repo = OpenInterestRepository(db)
        fr_repo = FundingRateRepository(db)
        return BacktestDataService(ohlcv_repo, oi_repo, fr_repo)

    def validate_training_config(self, config) -> None:
        """
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã®æ¤œè¨¼

        Args:
            config: MLTrainingConfig

        Raises:
            ValueError: è¨­å®šãŒç„¡åŠ¹ãªå ´åˆ
        """
        # æ—¢ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if training_status["is_training"]:
            raise ValueError("æ—¢ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œä¸­ã§ã™")

        # è¨­å®šã®æ¤œè¨¼
        start_date = datetime.fromisoformat(config.start_date)
        end_date = datetime.fromisoformat(config.end_date)

        if start_date >= end_date:
            raise ValueError("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")

        if (end_date - start_date).days < 7:
            raise ValueError("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã¯æœ€ä½7æ—¥é–“å¿…è¦ã§ã™")

    async def start_training(
        self, config, background_tasks, db: Session
    ) -> Dict[str, Any]:
        """
        MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹

        Args:
            config: MLTrainingConfig
            background_tasks: BackgroundTasks
            db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³

        Returns:
            ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹çµæœ
        """
        try:
            # è¨­å®šã®æ¤œè¨¼ã¨ãƒ­ã‚°å‡ºåŠ›
            self._log_and_validate_config(config)

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
            background_tasks.add_task(self._train_ml_model_background, config, db)

            return api_response(
                success=True,
                message="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
                data={
                    "training_id": f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                },
            )

        except ValueError as e:
            logger.error(f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            raise
        except Exception as e:
            logger.error(f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _log_and_validate_config(self, config) -> None:
        """
        è¨­å®šã®ãƒ­ã‚°å‡ºåŠ›ã¨æ¤œè¨¼

        Args:
            config: MLTrainingConfig

        Raises:
            ValueError: è¨­å®šãŒç„¡åŠ¹ãªå ´åˆ
        """
        # è¨­å®šã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
        logger.info(f"ğŸ“‹ å—ä¿¡ã—ãŸconfigå…¨ä½“: {config}")
        logger.info(f"ğŸ“‹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š: {config.ensemble_config}")
        logger.info(
            f"ğŸ“‹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šenabled: {config.ensemble_config.enabled if config.ensemble_config else 'None'}"
        )
        logger.info(f"ğŸ“‹ å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š: {config.single_model_config}")
        logger.info(
            f"ğŸ“‹ å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {config.single_model_config.model_type if config.single_model_config else 'None'}"
        )
        logger.info(f"ğŸ“‹ æœ€é©åŒ–è¨­å®š: {config.optimization_settings}")

        # è¨­å®šã®è©³ç´°ç¢ºèª
        if config.ensemble_config:
            ensemble_dict = config.ensemble_config.model_dump()
            logger.info(f"ğŸ“‹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šè¾æ›¸: {ensemble_dict}")
            logger.info(
                f"ğŸ“‹ enabledå€¤ç¢ºèª: {ensemble_dict.get('enabled')} (å‹: {type(ensemble_dict.get('enabled'))})"
            )

        if config.single_model_config:
            single_dict = config.single_model_config.model_dump()
            logger.info(f"ğŸ“‹ å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šè¾æ›¸: {single_dict}")

        # æ—¢å­˜ã®æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
        self.validate_training_config(config)

    async def get_training_status(self) -> Dict[str, Any]:
        """
        MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®çŠ¶æ…‹ã‚’å–å¾—

        Returns:
            ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹
        """
        return dict(training_status)

    async def get_model_info(self) -> Dict[str, Any]:
        """
        ç¾åœ¨ã®MLãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—

        Returns:
            ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        """
        try:
            latest_model = model_manager.get_latest_model("*")
            if latest_model and os.path.exists(latest_model):
                try:
                    model_data = model_manager.load_model(latest_model)
                    if model_data and "metadata" in model_data:
                        metadata = model_data["metadata"]
                        model_status = {
                            "is_loaded": True,
                            "model_path": latest_model,
                            "model_type": metadata.get("model_type", "Unknown"),
                            "feature_count": metadata.get("feature_count", 0),
                            "training_samples": metadata.get("training_samples", 0),
                            "accuracy": metadata.get("accuracy", 0.0),
                        }
                    else:
                        model_status = {
                            "is_loaded": True,
                            "model_path": latest_model,
                            "model_type": None,
                            "feature_count": 0,
                            "training_samples": 0,
                            "accuracy": 0.0,
                        }
                except Exception as e:
                    logger.warning(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    model_status = {
                        "is_loaded": False,
                        "model_path": None,
                        "model_type": None,
                        "feature_count": 0,
                        "training_samples": 0,
                        "accuracy": 0.0,
                    }
            else:
                model_status = {
                    "is_loaded": False,
                    "model_path": None,
                    "model_type": None,
                    "feature_count": 0,
                    "training_samples": 0,
                    "accuracy": 0.0,
                }

            return api_response(
                success=True,
                message="MLãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ",
                data={
                    "model_status": model_status,
                    "last_training": training_status.get("model_info"),
                },
            )
        except Exception as e:
            logger.error(f"MLãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def stop_training(self) -> Dict[str, Any]:
        """
        MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢

        Returns:
            åœæ­¢çµæœ
        """
        global training_status

        try:
            if not training_status["is_training"]:
                raise ValueError("å®Ÿè¡Œä¸­ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")

            # AutoMLãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†ã‚’å®Ÿè¡Œ
            self._cleanup_automl_processes()

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚‚å®Ÿè¡Œ
            background_task_manager.cleanup_all_tasks()

            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
            training_status.update(
                {
                    "is_training": False,
                    "status": "stopped",
                    "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ",
                    "end_time": datetime.now().isoformat(),
                }
            )

            return api_response(success=True, message="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢ã—ã¾ã—ãŸ")

        except ValueError as e:
            logger.error(f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        except Exception as e:
            logger.error(f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def _train_ml_model_background(self, config, db: Session):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§MLãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"""
        global training_status

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
        with background_task_manager.managed_task(
            task_name=f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°_{config.symbol}_{config.timeframe}",
            cleanup_callbacks=[self._cleanup_automl_processes],
        ) as task_id:
            try:
                # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
                training_status.update(
                    {
                        "is_training": True,
                        "progress": 0,
                        "status": "starting",
                        "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...",
                        "start_time": datetime.now().isoformat(),
                        "end_time": None,
                        "error": None,
                        "task_id": task_id,
                    }
                )

                logger.info(f"ğŸš€ MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ (ã‚¿ã‚¹ã‚¯ID: {task_id})")

                # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®å–å¾—
                data_service = self.get_data_service(db)

                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                training_status.update(
                    {
                        "progress": 10,
                        "status": "loading_data",
                        "message": "ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...",
                    }
                )

                # çµ±åˆã•ã‚ŒãŸMLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆOHLCV + OI + FRï¼‰
                training_data = data_service.get_ml_training_data(
                    symbol=config.symbol,
                    timeframe=config.timeframe,
                    start_date=datetime.fromisoformat(config.start_date),
                    end_date=datetime.fromisoformat(config.end_date),
                )

                # MLã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
                training_status.update(
                    {
                        "progress": 30,
                        "status": "initializing",
                        "message": "MLã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ä¸­...",
                    }
                )

                # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—ã®æ±ºå®š
                ensemble_config_dict = None
                single_model_config_dict = None
                trainer_type = "ensemble"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

                try:
                    logger.info("ğŸ” ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")

                    if config.ensemble_config:
                        logger.info(
                            f"ğŸ“‹ å—ä¿¡ã—ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š: {config.ensemble_config}"
                        )
                        ensemble_config_dict = config.ensemble_config.model_dump()
                        logger.info(
                            f"ğŸ“‹ å¤‰æ›å¾Œã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šè¾æ›¸: {ensemble_config_dict}"
                        )

                        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                        enabled_value = ensemble_config_dict.get("enabled", True)
                        logger.info(
                            f"ğŸ” enabledå€¤ã®ç¢ºèª: {enabled_value} (å‹: {type(enabled_value)})"
                        )

                        if not enabled_value:
                            trainer_type = "single"
                            logger.info(
                                "ğŸ”„ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™"
                            )
                            logger.info(
                                f"ğŸ“‹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šç¢ºèª: enabled={enabled_value}"
                            )
                        else:
                            logger.info(
                                "ğŸ”— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™"
                            )
                    else:
                        logger.info(
                            "ğŸ“‹ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™"
                        )
                        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šã‚’ä½œæˆ
                        ensemble_config_dict = {
                            "enabled": True,
                            "method": "stacking",
                            "bagging_params": {
                                "n_estimators": 5,
                                "bootstrap_fraction": 0.8,
                                "base_model_type": "lightgbm",
                                "random_state": 42,
                            },
                            "stacking_params": {
                                "base_models": [
                                    "lightgbm",
                                    "xgboost",
                                    "tabnet",
                                ],
                                "meta_model": "lightgbm",
                                "cv_folds": 5,
                                "use_probas": True,
                                "random_state": 42,
                            },
                        }

                    # å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šã®æº–å‚™
                    if config.single_model_config:
                        logger.info(
                            f"ğŸ“‹ å—ä¿¡ã—ãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š: {config.single_model_config}"
                        )
                        single_model_config_dict = (
                            config.single_model_config.model_dump()
                        )
                        logger.info(
                            f"ğŸ“‹ å¤‰æ›å¾Œã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šè¾æ›¸: {single_model_config_dict}"
                        )

                        if trainer_type == "single":
                            logger.info(
                                f"ğŸ“‹ å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä½¿ç”¨: {single_model_config_dict}"
                            )
                    else:
                        logger.info("ğŸ“‹ å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                        if trainer_type == "single":
                            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹ãŒè¨­å®šãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
                            single_model_config_dict = {"model_type": "lightgbm"}
                            logger.info(
                                f"ğŸ“‹ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ä½¿ç”¨: {single_model_config_dict}"
                            )

                except Exception as e:
                    logger.error(f"âŒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—æ±ºå®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
                    logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {str(e)}")
                    logger.warning(
                        "âš ï¸ ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™"
                    )
                    trainer_type = "ensemble"

                # AutoMLè¨­å®šã®æº–å‚™
                automl_config_dict = None
                if config.automl_config:
                    automl_config_dict = config.automl_config.model_dump()

                # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—ã®æœ€çµ‚ç¢ºèª
                logger.info(f"ğŸ¯ æœ€çµ‚æ±ºå®šã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—: {trainer_type}")
                if trainer_type == "single":
                    logger.info("ğŸ¤– å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™")
                    logger.info(
                        f"ğŸ¤– ä½¿ç”¨ã™ã‚‹å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š: {single_model_config_dict}"
                    )
                else:
                    logger.info("ğŸ”— ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™")
                    logger.info(f"ğŸ”— ä½¿ç”¨ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š: {ensemble_config_dict}")

                # MLã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
                self._execute_ml_training_with_error_handling(
                    trainer_type,
                    automl_config_dict,
                    ensemble_config_dict,
                    single_model_config_dict,
                    config,
                    training_data,
                )
            except Exception as e:
                logger.error(
                    f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}",
                    exc_info=True,
                )
                training_status.update(
                    {
                        "is_training": False,
                        "status": "error",
                        "message": f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}",
                        "end_time": datetime.now().isoformat(),
                        "error": str(e),
                    }
                )

    def _cleanup_automl_processes(self):
        """AutoMLãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        try:
            logger.info("ğŸ§¹ AutoMLãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨˜éŒ²
            import psutil

            process = psutil.Process()
            memory_before = process.memory_info().rss / 1024 / 1024

            # AutoMLé–¢é€£ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_enhanced_feature_service()
            self._cleanup_ml_training_service()
            self._cleanup_data_processor()

            # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc

            collected = gc.collect()

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–ã‚’è¨˜éŒ²
            memory_after = process.memory_info().rss / 1024 / 1024
            memory_freed = memory_before - memory_after

            logger.info(
                f"âœ… AutoMLã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: "
                f"{collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å, "
                f"{memory_freed:.2f}MBè§£æ”¾"
            )

        except Exception as e:
            logger.error(f"AutoMLã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_enhanced_feature_service(self):
        """FeatureEngineeringServiceé–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # FeatureEngineeringServiceã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            from app.services.ml.feature_engineering.feature_engineering_service import (
                FeatureEngineeringService,
            )

            # ä¸€æ™‚çš„ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            temp_service = FeatureEngineeringService()
            temp_service.cleanup_resources()

            # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å‰Šé™¤
            del temp_service

        except Exception as e:
            logger.warning(f"FeatureEngineeringServiceã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_ml_training_service(self):
        """MLTrainingServiceé–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«MLTrainingServiceã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            from app.services.ml.ml_training_service import ml_training_service

            if hasattr(ml_training_service, "cleanup_resources"):
                ml_training_service.cleanup_resources()

        except Exception as e:
            logger.warning(f"MLTrainingServiceã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_data_processor(self):
        """DataProcessoré–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«DataProcessorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            from app.utils.data_processing import data_processor

            if hasattr(data_processor, "clear_cache"):
                data_processor.clear_cache()

        except Exception as e:
            logger.warning(f"DataProcessorã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    @safe_ml_operation(context="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ")
    def _execute_ml_training_with_error_handling(
        self,
        trainer_type: str,
        automl_config_dict: Dict[str, Any],
        ensemble_config_dict: Dict[str, Any],
        single_model_config_dict: Dict[str, Any],
        config,
        training_data,
    ) -> None:
        """
        ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãMLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ

        Args:
            trainer_type: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—
            automl_config_dict: AutoMLè¨­å®šè¾æ›¸
            ensemble_config_dict: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šè¾æ›¸
            single_model_config_dict: å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šè¾æ›¸
            config: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
            training_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        """
        global training_status

        try:
            logger.info("ğŸ”§ MLTrainingServiceåˆæœŸåŒ–é–‹å§‹")
            ml_service = MLTrainingService(
                trainer_type=trainer_type,
                automl_config=automl_config_dict,
                ensemble_config=ensemble_config_dict,
                single_model_config=single_model_config_dict,
            )
            logger.info(
                f"âœ… MLTrainingServiceåˆæœŸåŒ–å®Œäº†: trainer_type={ml_service.trainer_type}"
            )

            # å®Ÿéš›ã«ä½œæˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®ç¢ºèª
            trainer_class_name = type(ml_service.trainer).__name__
            logger.info(f"âœ… ä½œæˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼: {trainer_class_name}")

            if hasattr(ml_service.trainer, "model_type"):
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {ml_service.trainer.model_type}")

        except Exception as e:
            logger.error(f"âŒ MLTrainingServiceåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}: {str(e)}")
            raise

        # æœ€é©åŒ–è¨­å®šã®æº–å‚™
        optimization_settings = None
        if config.optimization_settings and config.optimization_settings.enabled:
            optimization_settings = config.optimization_settings

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        training_status.update(
            {
                "progress": 50,
                "status": "training",
                "message": "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...",
            }
        )

        training_result = ml_service.train_model(
            training_data=training_data,
            save_model=config.save_model,
            optimization_settings=optimization_settings,
            automl_config=automl_config_dict,
            test_size=1 - config.train_test_split,
            random_state=config.random_state,
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
        self._cleanup_automl_processes()

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†
        training_status.update(
            {
                "is_training": False,
                "progress": 100,
                "status": "completed",
                "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ",
                "end_time": datetime.now().isoformat(),
                "model_info": training_result,
            }
        )

        logger.info("âœ… MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
