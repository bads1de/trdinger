"""
MLå­¦ç¿’åŸºç›¤ã‚¯ãƒ©ã‚¹

MLTrainingServiceã¨MLIndicatorServiceã§é‡è¤‡ã—ã¦ã„ãŸå­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’çµ±åˆã—ã€
å…±é€šã®å­¦ç¿’åŸºç›¤ã‚’æä¾›ã—ã¾ã™ã€‚SOLIDåŸå‰‡ã«å¾“ã„ã€è²¬ä»»ã‚’æ˜ç¢ºåŒ–ã—ã¾ã™ã€‚
"""

import logging
import pandas as pd
import numpy as np
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Tuple, cast
from datetime import datetime
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler


from .config import ml_config
from ...utils.unified_error_handler import (
    UnifiedDataError,
    UnifiedModelError,
    safe_ml_operation,
    ml_operation_context,
)
from .feature_engineering.feature_engineering_service import FeatureEngineeringService
from .feature_engineering.enhanced_feature_engineering_service import (
    EnhancedFeatureEngineeringService,
)
from .feature_engineering.automl_features.automl_config import AutoMLConfig
from .model_manager import model_manager
from ...utils.label_generation import LabelGenerator, ThresholdMethod
from database.connection import SessionLocal
from database.repositories.fear_greed_repository import FearGreedIndexRepository

logger = logging.getLogger(__name__)


class BaseMLTrainer(ABC):
    """
    MLå­¦ç¿’åŸºç›¤ã‚¯ãƒ©ã‚¹

    å…±é€šã®å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ã‚’æä¾›ã—ã€å…·ä½“çš„ãªå®Ÿè£…ã¯ç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§è¡Œã„ã¾ã™ã€‚
    å˜ä¸€è²¬ä»»åŸå‰‡ã«å¾“ã„ã€å­¦ç¿’ã«é–¢ã™ã‚‹è²¬ä»»ã®ã¿ã‚’æŒã¡ã¾ã™ã€‚
    """

    def __init__(self, automl_config: Optional[Dict[str, Any]] = None):
        """
        åˆæœŸåŒ–

        Args:
            automl_config: AutoMLè¨­å®šï¼ˆè¾æ›¸å½¢å¼ï¼‰
        """
        self.config = ml_config

        # AutoMLè¨­å®šã®å‡¦ç†
        if automl_config:
            # è¾æ›¸ã‹ã‚‰AutoMLConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            automl_config_obj = self._create_automl_config_from_dict(automl_config)
            self.feature_service = EnhancedFeatureEngineeringService(automl_config_obj)
            self.use_automl = True
            logger.info("ğŸ¤– AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
        else:
            # å¾“æ¥ã®åŸºæœ¬ç‰¹å¾´é‡ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
            self.feature_service = FeatureEngineeringService()
            self.use_automl = False
            logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")

        self.scaler = StandardScaler()
        self.feature_columns = None
        self.is_trained = False
        self.model = None
        self.automl_config = automl_config

    def _create_automl_config_from_dict(
        self, config_dict: Dict[str, Any]
    ) -> AutoMLConfig:
        """
        è¾æ›¸ã‹ã‚‰AutoMLConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ

        Args:
            config_dict: AutoMLè¨­å®šè¾æ›¸

        Returns:
            AutoMLConfigã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        from .feature_engineering.automl_features.automl_config import (
            TSFreshConfig,
            FeaturetoolsConfig,
            AutoFeatConfig,
        )

        # TSFreshè¨­å®š
        tsfresh_dict = config_dict.get("tsfresh", {})
        tsfresh_config = TSFreshConfig(
            enabled=tsfresh_dict.get("enabled", True),
            feature_selection=tsfresh_dict.get("feature_selection", True),
            fdr_level=tsfresh_dict.get("fdr_level", 0.05),
            feature_count_limit=tsfresh_dict.get("feature_count_limit", 100),
            parallel_jobs=tsfresh_dict.get("parallel_jobs", 2),
        )

        # Featuretoolsè¨­å®š
        featuretools_dict = config_dict.get("featuretools", {})
        featuretools_config = FeaturetoolsConfig(
            enabled=featuretools_dict.get("enabled", True),
            max_depth=featuretools_dict.get("max_depth", 2),
            max_features=featuretools_dict.get("max_features", 50),
        )

        # AutoFeatè¨­å®š
        autofeat_dict = config_dict.get("autofeat", {})
        autofeat_config = AutoFeatConfig(
            enabled=autofeat_dict.get("enabled", True),
            max_features=autofeat_dict.get("max_features", 50),
            feateng_steps=autofeat_dict.get(
                "feateng_steps", autofeat_dict.get("generations", 10)
            ),  # feateng_stepsã¾ãŸã¯generationsã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
            max_gb=autofeat_dict.get("max_gb", 1.0),
        )

        return AutoMLConfig(
            tsfresh_config=tsfresh_config,
            featuretools_config=featuretools_config,
            autofeat_config=autofeat_config,
        )

    @safe_ml_operation(default_return={}, context="MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    def train_model(
        self,
        training_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
        save_model: bool = True,
        model_name: Optional[str] = None,
        **training_params,
    ) -> Dict[str, Any]:
        """
        MLãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

        Args:
            training_data: å­¦ç¿’ç”¨OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            save_model: ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‹
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            **training_params: è¿½åŠ ã®å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            å­¦ç¿’çµæœã®è¾æ›¸

        Raises:
            UnifiedDataError: ãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ãªå ´åˆ
            UnifiedModelError: å­¦ç¿’ã«å¤±æ•—ã—ãŸå ´åˆ
        """
        with ml_operation_context("MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’"):
            # 1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
            self._validate_training_data(training_data)

            # 2. ç‰¹å¾´é‡ã‚’è¨ˆç®—
            features_df = self._calculate_features(
                training_data, funding_rate_data, open_interest_data
            )

            # 3. å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            X, y = self._prepare_training_data(features_df, **training_params)

            # 4. ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            use_cross_validation = training_params.get("use_cross_validation", False)

            if use_cross_validation:
                # æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                cv_result = self._time_series_cross_validate(X, y, **training_params)

                # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
                logger.info("ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ä¸­...")
                X_scaled = self._preprocess_data(X, X)[0]  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

                # ãƒ€ãƒŸãƒ¼ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€å¾Œã®20%ï¼‰ã‚’ä½œæˆ
                test_size = training_params.get("test_size", 0.2)
                n_samples = len(X)
                train_size = int(n_samples * (1 - test_size))

                X_train_final = X_scaled.iloc[:train_size]
                X_test_final = X_scaled.iloc[train_size:]
                y_train_final = y.iloc[:train_size]
                y_test_final = y.iloc[train_size:]

                training_result = self._train_model_impl(
                    X_train_final,
                    X_test_final,
                    y_train_final,
                    y_test_final,
                    **training_params,
                )

                # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’è¿½åŠ 
                training_result.update(cv_result)

            else:
                # é€šå¸¸ã®å˜ä¸€åˆ†å‰²å­¦ç¿’
                # 4. ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
                X_train, X_test, y_train, y_test = self._split_data(
                    X, y, **training_params
                )

                # 5. ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†
                X_train_scaled, X_test_scaled = self._preprocess_data(X_train, X_test)

                # 6. ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ï¼ˆç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰
                training_result = self._train_model_impl(
                    X_train_scaled, X_test_scaled, y_train, y_test, **training_params
                )

            # 7. å­¦ç¿’å®Œäº†ãƒ•ãƒ©ã‚°ã‚’è¨­å®šï¼ˆä¿å­˜å‰ã«è¨­å®šï¼‰
            self.is_trained = True

            # 8. ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
            if save_model:
                # training_resultã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                model_metadata = {
                    # åŸºæœ¬æ€§èƒ½æŒ‡æ¨™
                    "accuracy": training_result.get("accuracy", 0.0),
                    "precision": training_result.get("precision", 0.0),
                    "recall": training_result.get("recall", 0.0),
                    "f1_score": training_result.get("f1_score", 0.0),
                    # AUCæŒ‡æ¨™
                    "auc_score": training_result.get("auc_score", 0.0),
                    "auc_roc": training_result.get("auc_roc", 0.0),
                    "auc_pr": training_result.get("auc_pr", 0.0),
                    # é«˜åº¦ãªæŒ‡æ¨™
                    "balanced_accuracy": training_result.get("balanced_accuracy", 0.0),
                    "matthews_corrcoef": training_result.get("matthews_corrcoef", 0.0),
                    "cohen_kappa": training_result.get("cohen_kappa", 0.0),
                    # å°‚é–€æŒ‡æ¨™
                    "specificity": training_result.get("specificity", 0.0),
                    "sensitivity": training_result.get("sensitivity", 0.0),
                    "npv": training_result.get("npv", 0.0),
                    "ppv": training_result.get("ppv", 0.0),
                    # ç¢ºç‡æŒ‡æ¨™
                    "log_loss": training_result.get("log_loss", 0.0),
                    "brier_score": training_result.get("brier_score", 0.0),
                    # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
                    "training_samples": training_result.get("train_samples", 0),
                    "test_samples": training_result.get("test_samples", 0),
                    "feature_count": (
                        len(self.feature_columns) if self.feature_columns else 0
                    ),
                    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
                    "feature_importance": training_result.get("feature_importance", {}),
                    "classification_report": training_result.get(
                        "classification_report", {}
                    ),
                    "best_iteration": training_result.get("best_iteration", 0),
                    "num_classes": training_result.get("num_classes", 2),
                    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    "train_test_split": training_params.get("train_test_split", 0.8),
                    "random_state": training_params.get("random_state", 42),
                }

                logger.info(
                    f"ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: ç²¾åº¦={model_metadata['accuracy']:.4f}, F1={model_metadata['f1_score']:.4f}"
                )

                model_path = self.save_model(
                    model_name or self.config.model.AUTO_STRATEGY_MODEL_NAME,
                    model_metadata,
                )
                training_result["model_path"] = model_path

            # 9. å­¦ç¿’çµæœã‚’æ•´å½¢
            result = self._format_training_result(training_result, X, y)

            logger.info("MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
            return result

    @safe_ml_operation(default_return={}, context="ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    def evaluate_model(
        self,
        test_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> Dict[str, Any]:
        """
        å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡

        Args:
            test_data: ãƒ†ã‚¹ãƒˆç”¨OHLCVãƒ‡ãƒ¼ã‚¿
            funding_rate_data: ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            open_interest_data: å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            è©•ä¾¡çµæœã®è¾æ›¸
        """
        if not self.is_trained:
            raise UnifiedModelError("è©•ä¾¡å¯¾è±¡ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        # ç‰¹å¾´é‡ã‚’è¨ˆç®—
        features_df = self._calculate_features(
            test_data, funding_rate_data, open_interest_data
        )

        # äºˆæ¸¬ã‚’å®Ÿè¡Œ
        predictions = self.predict(features_df)

        # è©•ä¾¡çµæœã‚’ä½œæˆ
        evaluation_result = {
            "predictions": predictions,
            "test_samples": len(test_data),
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
            "model_status": "trained" if self.is_trained else "not_trained",
        }

        return evaluation_result

    @abstractmethod
    def predict(self, features_df: pd.DataFrame) -> np.ndarray:
        """
        äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰

        Args:
            features_df: ç‰¹å¾´é‡DataFrame

        Returns:
            äºˆæ¸¬çµæœ
        """
        pass

    @abstractmethod
    def _train_model_impl(
        self,
        X_train: pd.DataFrame,
        X_test: pd.DataFrame,
        y_train: pd.Series,
        y_test: pd.Series,
        **training_params,
    ) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å…·ä½“çš„ãªå®Ÿè£…ï¼ˆç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰

        Args:
            X_train: å­¦ç¿’ç”¨ç‰¹å¾´é‡
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_train: å­¦ç¿’ç”¨ãƒ©ãƒ™ãƒ«
            y_test: ãƒ†ã‚¹ãƒˆç”¨ãƒ©ãƒ™ãƒ«
            **training_params: å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            å­¦ç¿’çµæœ
        """
        pass

    def _validate_training_data(self, training_data: pd.DataFrame) -> None:
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        if training_data is None or training_data.empty:
            raise UnifiedDataError("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

        required_columns = ["Open", "High", "Low", "Close", "Volume"]
        missing_columns = [
            col for col in required_columns if col not in training_data.columns
        ]
        if missing_columns:
            raise UnifiedDataError(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_columns}")

        if len(training_data) < 100:
            raise UnifiedDataError("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½100è¡Œå¿…è¦ï¼‰")

    def _calculate_features(
        self,
        ohlcv_data: pd.DataFrame,
        funding_rate_data: Optional[pd.DataFrame] = None,
        open_interest_data: Optional[pd.DataFrame] = None,
    ) -> pd.DataFrame:
        """ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆFear & Greed Indexãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰"""
        try:
            # Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            fear_greed_data = self._get_fear_greed_data(ohlcv_data)

            # AutoMLã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œ
            if self.use_automl and isinstance(
                self.feature_service, EnhancedFeatureEngineeringService
            ):
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’è¨ˆç®—ï¼ˆAutoMLç‰¹å¾´é‡ç”Ÿæˆç”¨ï¼‰
                target = self._calculate_target_for_automl(ohlcv_data)

                logger.info("ğŸ¤– AutoMLæ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")
                return self.feature_service.calculate_enhanced_features(
                    ohlcv_data=ohlcv_data,
                    funding_rate_data=funding_rate_data,
                    open_interest_data=open_interest_data,
                    fear_greed_data=fear_greed_data,
                    automl_config=self.automl_config,
                    target=target,
                )
            else:
                # åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—
                logger.info("ğŸ“Š åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—ã‚’å®Ÿè¡Œä¸­...")
                return self.feature_service.calculate_advanced_features(
                    ohlcv_data=ohlcv_data,
                    funding_rate_data=funding_rate_data,
                    open_interest_data=open_interest_data,
                    fear_greed_data=fear_greed_data,
                )

        except Exception as e:
            logger.warning(f"æ‹¡å¼µç‰¹å¾´é‡è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ã€åŸºæœ¬ç‰¹å¾´é‡ã®ã¿ä½¿ç”¨: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬ç‰¹å¾´é‡ã®ã¿
            return self.feature_service.calculate_advanced_features(
                ohlcv_data, funding_rate_data, open_interest_data
            )

    def _calculate_target_for_automl(
        self, ohlcv_data: pd.DataFrame
    ) -> Optional[pd.Series]:
        """
        AutoMLç‰¹å¾´é‡ç”Ÿæˆç”¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’è¨ˆç®—

        Args:
            ohlcv_data: OHLCVãƒ‡ãƒ¼ã‚¿

        Returns:
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®Seriesï¼ˆè¨ˆç®—ã§ããªã„å ´åˆã¯Noneï¼‰
        """
        try:
            if ohlcv_data.empty or "Close" not in ohlcv_data.columns:
                logger.warning("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°è¨ˆç®—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return None

            # ä¾¡æ ¼å¤‰åŒ–ç‡ã‚’è¨ˆç®—ï¼ˆæ¬¡ã®æœŸé–“ã®ä¾¡æ ¼å¤‰åŒ–ï¼‰
            close_prices = ohlcv_data["Close"].copy()

            # å°†æ¥ã®ä¾¡æ ¼å¤‰åŒ–ç‡ã‚’è¨ˆç®—ï¼ˆ24æ™‚é–“å¾Œã®å¤‰åŒ–ç‡ï¼‰
            prediction_horizon = getattr(self.config.training, "PREDICTION_HORIZON", 24)
            future_returns = close_prices.pct_change(periods=prediction_horizon).shift(
                -prediction_horizon
            )

            # é–¾å€¤ã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒ©ã‚¹åˆ†é¡
            threshold_up = getattr(self.config.training, "THRESHOLD_UP", 0.02)
            threshold_down = getattr(self.config.training, "THRESHOLD_DOWN", -0.02)

            # 3ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼š0=ä¸‹è½ã€1=æ¨ªã°ã„ã€2=ä¸Šæ˜‡
            target = pd.Series(1, index=future_returns.index)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ¨ªã°ã„
            target[future_returns > threshold_up] = 2  # ä¸Šæ˜‡
            target[future_returns < threshold_down] = 0  # ä¸‹è½

            # NaNã‚’é™¤å»
            target = target.dropna()

            logger.info(f"AutoMLç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’è¨ˆç®—: {len(target)}ã‚µãƒ³ãƒ—ãƒ«")
            logger.info(
                f"ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ - ä¸‹è½: {(target == 0).sum()}, æ¨ªã°ã„: {(target == 1).sum()}, ä¸Šæ˜‡: {(target == 2).sum()}"
            )

            return target

        except Exception as e:
            logger.warning(f"AutoMLç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _get_fear_greed_data(self, ohlcv_data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """
        Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            ohlcv_data: OHLCVãƒ‡ãƒ¼ã‚¿ï¼ˆæœŸé–“ã®å‚è€ƒç”¨ï¼‰

        Returns:
            Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ã®DataFrameï¼ˆå–å¾—ã§ããªã„å ´åˆã¯Noneï¼‰
        """
        try:
            if ohlcv_data.empty:
                return None

            # ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã‚’å–å¾—
            if "timestamp" in ohlcv_data.columns:
                start_date_val = ohlcv_data["timestamp"].min()
                end_date_val = ohlcv_data["timestamp"].max()
            else:
                start_date_val = ohlcv_data.index.min()
                end_date_val = ohlcv_data.index.max()

            # datetimeå‹ã«å¤‰æ›
            start_date = cast(datetime, pd.to_datetime(start_date_val).to_pydatetime())
            end_date = cast(datetime, pd.to_datetime(end_date_val).to_pydatetime())

            with SessionLocal() as db:
                repository = FearGreedIndexRepository(db)

                # Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                fear_greed_data = repository.get_fear_greed_data(
                    start_time=start_date, end_time=end_date
                )

                if not fear_greed_data:
                    logger.info("Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    return None

                # DataFrameã«å¤‰æ›
                df = pd.DataFrame(
                    [
                        {
                            "timestamp": data.data_timestamp,
                            "value": data.value,
                            "value_classification": data.value_classification,
                        }
                        for data in fear_greed_data
                    ]
                )

                if df.empty:
                    return None

                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
                df["timestamp"] = pd.to_datetime(df["timestamp"])
                df.set_index("timestamp", inplace=True)

                logger.info(f"Fear & Greed Indexãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—: {len(df)}è¡Œ")
                return df

        except Exception as e:
            logger.warning(f"Fear & Greed Indexãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _generate_dynamic_labels(
        self, price_data: pd.Series, **training_params
    ) -> Tuple[pd.Series, Dict[str, Any]]:
        """
        å‹•çš„ãƒ©ãƒ™ãƒ«ç”Ÿæˆ

        Args:
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆCloseä¾¡æ ¼ï¼‰
            **training_params: å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            ãƒ©ãƒ™ãƒ«Series, é–¾å€¤æƒ…å ±ã®è¾æ›¸
        """
        try:
            # ãƒ©ãƒ™ãƒ«ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
            label_generator = LabelGenerator()

            # é–¾å€¤è¨ˆç®—æ–¹æ³•ã‚’æ±ºå®š
            threshold_method_str = training_params.get(
                "threshold_method", "std_deviation"
            )

            # æ–‡å­—åˆ—ã‹ã‚‰Enumã«å¤‰æ›
            method_mapping = {
                "fixed": ThresholdMethod.FIXED,
                "quantile": ThresholdMethod.QUANTILE,
                "std_deviation": ThresholdMethod.STD_DEVIATION,
                "adaptive": ThresholdMethod.ADAPTIVE,
            }

            threshold_method = method_mapping.get(
                threshold_method_str, ThresholdMethod.STD_DEVIATION
            )

            # ç›®æ¨™åˆ†å¸ƒã‚’è¨­å®š
            target_distribution = training_params.get(
                "target_distribution", {"up": 0.33, "down": 0.33, "range": 0.34}
            )

            # æ–¹æ³•å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™
            method_params = {}

            if threshold_method == ThresholdMethod.FIXED:
                method_params["threshold"] = training_params.get("threshold_up", 0.02)
            elif threshold_method == ThresholdMethod.STD_DEVIATION:
                method_params["std_multiplier"] = training_params.get(
                    "std_multiplier", 0.25
                )
            elif threshold_method in [
                ThresholdMethod.QUANTILE,
                ThresholdMethod.ADAPTIVE,
            ]:
                method_params["target_distribution"] = target_distribution

            # ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ
            labels, threshold_info = label_generator.generate_labels(
                price_data,
                method=threshold_method,
                target_distribution=target_distribution,
                **method_params,
            )

            # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’æ¤œè¨¼
            validation_result = LabelGenerator.validate_label_distribution(labels)

            if not validation_result["is_valid"]:
                logger.warning("ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
                for error in validation_result["errors"]:
                    logger.warning(f"  ã‚¨ãƒ©ãƒ¼: {error}")
                for warning in validation_result["warnings"]:
                    logger.warning(f"  è­¦å‘Š: {warning}")

                # 1ã‚¯ãƒ©ã‚¹ã—ã‹ãªã„å ´åˆã¯é©å¿œçš„æ–¹æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if labels.nunique() <= 1:
                    logger.info("é©å¿œçš„é–¾å€¤è¨ˆç®—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    labels, threshold_info = label_generator.generate_labels(
                        price_data,
                        method=ThresholdMethod.ADAPTIVE,
                        target_distribution=target_distribution,
                    )

            return labels, threshold_info

        except Exception as e:
            logger.error(f"å‹•çš„ãƒ©ãƒ™ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ã®å›ºå®šé–¾å€¤
            logger.info("å¾“æ¥ã®å›ºå®šé–¾å€¤ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            price_change = price_data.pct_change().shift(-1)
            threshold_up = training_params.get("threshold_up", 0.02)
            threshold_down = training_params.get("threshold_down", -0.02)

            labels = pd.Series(1, index=price_change.index, dtype=int)
            labels[price_change > threshold_up] = 2
            labels[price_change < threshold_down] = 0
            labels = labels.iloc[:-1]

            threshold_info = {
                "method": "fixed_fallback",
                "threshold_up": threshold_up,
                "threshold_down": threshold_down,
                "description": f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å›ºå®šé–¾å€¤Â±{threshold_up*100:.2f}%",
            }

            return labels, threshold_info

    def _prepare_training_data(
        self, features_df: pd.DataFrame, **training_params
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½ï¼‰"""
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè£…ï¼šæœ€å¾Œã®åˆ—ã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦ä½¿ç”¨
        if features_df.empty:
            raise UnifiedDataError("ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

        # æ•°å€¤åˆ—ã®ã¿ã‚’é¸æŠ
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        features_df_numeric = features_df[numeric_columns]

        # NaNã‚’0ã§åŸ‹ã‚ã‚‹
        features_df_clean = features_df_numeric.fillna(0)

        # ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã‚’åˆ†é›¢ï¼ˆæ”¹å–„ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        if "Close" in features_df_clean.columns:
            # å‹•çš„ãƒ©ãƒ™ãƒ«ç”Ÿæˆã‚’ä½¿ç”¨
            labels, threshold_info = self._generate_dynamic_labels(
                features_df_clean["Close"], **training_params
            )

            # é–¾å€¤æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"ãƒ©ãƒ™ãƒ«ç”Ÿæˆæ–¹æ³•: {threshold_info['description']}")
            logger.info(
                f"ä½¿ç”¨é–¾å€¤: {threshold_info['threshold_down']:.6f} ï½ {threshold_info['threshold_up']:.6f}"
            )

            # æœ€å¾Œã®è¡Œã¯äºˆæ¸¬ã§ããªã„ã®ã§é™¤å¤–
            features_df_clean = features_df_clean.iloc[:-1]
        else:
            raise UnifiedDataError("ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆCloseï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–
        valid_mask = ~(features_df_clean.isnull().any(axis=1) | labels.isnull())
        features_clean = features_df_clean[valid_mask]
        labels_clean = labels[valid_mask]

        if len(features_clean) == 0:
            raise UnifiedDataError("æœ‰åŠ¹ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        self.feature_columns = features_clean.columns.tolist()

        logger.info(
            f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(features_clean)}ã‚µãƒ³ãƒ—ãƒ«, {len(self.feature_columns)}ç‰¹å¾´é‡"
        )
        logger.info(
            f"ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: ä¸‹è½={sum(labels_clean==0)}, ãƒ¬ãƒ³ã‚¸={sum(labels_clean==1)}, ä¸Šæ˜‡={sum(labels_clean==2)}"
        )

        return features_clean, labels_clean

    def _split_data(
        self, X: pd.DataFrame, y: pd.Series, **training_params
    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ï¼ˆæ™‚ç³»åˆ—å¯¾å¿œï¼‰

        æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€å°†æ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ã“ã¨ã‚’é˜²ããŸã‚ã€
        æ™‚é–“é †åºã‚’ä¿æŒã—ãŸåˆ†å‰²ã‚’è¡Œã„ã¾ã™ã€‚
        """
        test_size = training_params.get("test_size", 0.2)
        random_state = training_params.get("random_state", 42)
        use_time_series_split = training_params.get("use_time_series_split", True)

        if use_time_series_split:
            # æ™‚ç³»åˆ—åˆ†å‰²ï¼šæ™‚é–“é †åºã‚’ä¿æŒã—ã¦åˆ†å‰²
            logger.info("ğŸ•’ æ™‚ç³»åˆ—åˆ†å‰²ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰")

            # ãƒ‡ãƒ¼ã‚¿ã®é•·ã•ã‚’å–å¾—
            n_samples = len(X)
            train_size = int(n_samples * (1 - test_size))

            # æ™‚é–“é †åºã‚’ä¿æŒã—ã¦åˆ†å‰²
            X_train = X.iloc[:train_size].copy()
            X_test = X.iloc[train_size:].copy()
            y_train = y.iloc[:train_size].copy()
            y_test = y.iloc[train_size:].copy()

            logger.info(
                f"æ™‚ç³»åˆ—åˆ†å‰²çµæœ: å­¦ç¿’={len(X_train)}ã‚µãƒ³ãƒ—ãƒ«, ãƒ†ã‚¹ãƒˆ={len(X_test)}ã‚µãƒ³ãƒ—ãƒ«"
            )
            logger.info(f"å­¦ç¿’æœŸé–“: {X_train.index[0]} ï½ {X_train.index[-1]}")
            logger.info(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {X_test.index[0]} ï½ {X_test.index[-1]}")

        else:
            # å¾“æ¥ã®ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ï¼ˆéæ¨å¥¨ï¼‰
            logger.warning("âš ï¸ ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ã‚’ä½¿ç”¨ï¼ˆæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ã¯éæ¨å¥¨ï¼‰")

            # å±¤åŒ–æŠ½å‡ºã¯ã€ãƒ©ãƒ™ãƒ«ãŒ2ç¨®é¡ä»¥ä¸Šã‚ã‚‹å ´åˆã«ã®ã¿æœ‰åŠ¹
            stratify_param = y if y.nunique() > 1 else None
            if stratify_param is None:
                logger.warning(
                    "ãƒ©ãƒ™ãƒ«ãŒ1ç¨®é¡ä»¥ä¸‹ã®ãŸã‚ã€å±¤åŒ–æŠ½å‡ºãªã—ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚"
                )

            # train_test_splitã¯ãƒªã‚¹ãƒˆã‚’è¿”ã™ãŸã‚ã€ä¸€åº¦å¤‰æ•°ã«å—ã‘ã¦ã‹ã‚‰ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹
            splits = train_test_split(
                X,
                y,
                test_size=test_size,
                random_state=random_state,
                stratify=stratify_param,
            )

            # å‹ãƒã‚§ãƒƒã‚«ãƒ¼ã®ãŸã‚ã«æ˜ç¤ºçš„ã«ã‚­ãƒ£ã‚¹ãƒˆ
            X_train = cast(pd.DataFrame, splits[0])
            X_test = cast(pd.DataFrame, splits[1])
            y_train = cast(pd.Series, splits[2])
            y_test = cast(pd.Series, splits[3])

        # åˆ†å‰²å¾Œã®ãƒ©ãƒ™ãƒ«åˆ†å¸ƒã‚’ç¢ºèª
        logger.info("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
        for label_value in sorted(y_train.unique()):
            count = (y_train == label_value).sum()
            percentage = count / len(y_train) * 100
            logger.info(f"  ãƒ©ãƒ™ãƒ« {label_value}: {count}ã‚µãƒ³ãƒ—ãƒ« ({percentage:.1f}%)")

        logger.info("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
        for label_value in sorted(y_test.unique()):
            count = (y_test == label_value).sum()
            percentage = count / len(y_test) * 100
            logger.info(f"  ãƒ©ãƒ™ãƒ« {label_value}: {count}ã‚µãƒ³ãƒ—ãƒ« ({percentage:.1f}%)")

        return X_train, X_test, y_train, y_test

    def _time_series_cross_validate(
        self, X: pd.DataFrame, y: pd.Series, **training_params
    ) -> Dict[str, Any]:
        """
        æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

        ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼ã‚’è¡Œã„ã€ã‚ˆã‚Šå …ç‰¢ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’æä¾›ã—ã¾ã™ã€‚

        Args:
            X: ç‰¹å¾´é‡DataFrame
            y: ãƒ©ãƒ™ãƒ«Series
            **training_params: å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

        Returns:
            ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®è¾æ›¸
        """
        n_splits = training_params.get("cv_splits", 5)
        max_train_size = training_params.get("max_train_size", None)

        logger.info(f"ğŸ”„ æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆ{n_splits}åˆ†å‰²ï¼‰")

        # TimeSeriesSplitã‚’åˆæœŸåŒ–
        tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=max_train_size)

        cv_scores = []
        fold_results = []

        for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):
            logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ {fold}/{n_splits} ã‚’å®Ÿè¡Œä¸­...")

            # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
            X_train_cv = X.iloc[train_idx]
            X_test_cv = X.iloc[test_idx]
            y_train_cv = y.iloc[train_idx]
            y_test_cv = y.iloc[test_idx]

            # ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†
            X_train_scaled, X_test_scaled = self._preprocess_data(X_train_cv, X_test_cv)

            try:
                # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ï¼ˆç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰
                fold_result = self._train_model_impl(
                    X_train_scaled,
                    X_test_scaled,
                    y_train_cv,
                    y_test_cv,
                    **training_params,
                )

                cv_scores.append(fold_result.get("accuracy", 0.0))
                fold_results.append(
                    {
                        "fold": fold,
                        "train_samples": len(X_train_cv),
                        "test_samples": len(X_test_cv),
                        "train_period": f"{X_train_cv.index[0]} ï½ {X_train_cv.index[-1]}",
                        "test_period": f"{X_test_cv.index[0]} ï½ {X_test_cv.index[-1]}",
                        **fold_result,
                    }
                )

                logger.info(
                    f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ {fold} å®Œäº†: ç²¾åº¦={fold_result.get('accuracy', 0.0):.4f}"
                )

            except Exception as e:
                logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ {fold} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                cv_scores.append(0.0)
                fold_results.append({"fold": fold, "error": str(e), "accuracy": 0.0})

        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’é›†è¨ˆ
        cv_result = {
            "cv_scores": cv_scores,
            "cv_mean": np.mean(cv_scores),
            "cv_std": np.std(cv_scores),
            "cv_min": np.min(cv_scores),
            "cv_max": np.max(cv_scores),
            "fold_results": fold_results,
            "n_splits": n_splits,
        }

        logger.info("æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†:")
        logger.info(
            f"  å¹³å‡ç²¾åº¦: {cv_result['cv_mean']:.4f} Â± {cv_result['cv_std']:.4f}"
        )
        logger.info(f"  æœ€å°ç²¾åº¦: {cv_result['cv_min']:.4f}")
        logger.info(f"  æœ€å¤§ç²¾åº¦: {cv_result['cv_max']:.4f}")

        return cv_result

    def _preprocess_data(
        self, X_train: pd.DataFrame, X_test: pd.DataFrame
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰"""
        # LightGBMãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¸è¦
        if hasattr(self, "model_type") and "LightGBM" in str(self.model_type):
            return X_train, X_test

        # ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
        assert self.scaler is not None, "ScalerãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        X_train_scaled = pd.DataFrame(
            self.scaler.fit_transform(X_train),
            columns=X_train.columns,
            index=X_train.index,
        )

        X_test_scaled = pd.DataFrame(
            self.scaler.transform(X_test), columns=X_test.columns, index=X_test.index
        )

        return X_train_scaled, X_test_scaled

    def save_model(
        self, model_name: str, metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        if not self.is_trained:
            raise UnifiedModelError("å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        # åŸºæœ¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        final_metadata = {
            "model_type": self.__class__.__name__,
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
            "is_trained": self.is_trained,
        }
        # æä¾›ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°
        if metadata:
            final_metadata.update(metadata)

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯å°‚ç”¨ã®ä¿å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
        if self.__class__.__name__ == "EnsembleTrainer":
            model_path = model_manager.save_ensemble_model(
                ensemble_trainer=self,
                model_name=model_name,
                metadata=final_metadata,
            )
        else:
            # é€šå¸¸ã®ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            model_path = model_manager.save_model(
                model=self.model,
                model_name=model_name,
                metadata=final_metadata,
                scaler=self.scaler,
                feature_columns=self.feature_columns,
            )

        logger.info(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
        return model_path

    def _format_training_result(
        self, training_result: Dict[str, Any], X: pd.DataFrame, y: pd.Series
    ) -> Dict[str, Any]:
        """å­¦ç¿’çµæœã‚’æ•´å½¢"""
        result = {
            "success": True,
            "feature_count": len(self.feature_columns) if self.feature_columns else 0,
            "total_samples": len(X),
            **training_result,
        }

        return result

    @safe_ml_operation(
        default_return=False, context="ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    )
    def load_model(self, model_path: str) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã¿æˆåŠŸãƒ•ãƒ©ã‚°
        """
        model_data = model_manager.load_model(model_path)

        if model_data is None:
            return False

        # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„è¦ç´ ã‚’å–å¾—
        self.model = model_data.get("model")
        self.scaler = model_data.get("scaler")
        self.feature_columns = model_data.get("feature_columns")

        if self.model is None:
            raise UnifiedModelError("ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ãƒ¢ãƒ‡ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")

        self.is_trained = True
        logger.info(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_path}")
        return True
