"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚µãƒ¼ãƒ“ã‚¹

backtesting.pyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
Open Interest (OI) ã¨ Funding Rate (FR) ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆæ©Ÿèƒ½ã‚’å«ã¿ã¾ã™ã€‚
"""

import logging
import pandas as pd
from datetime import datetime
from typing import List, Optional
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.open_interest_repository import OpenInterestRepository
from database.repositories.funding_rate_repository import FundingRateRepository
from database.repositories.fear_greed_repository import FearGreedIndexRepository
from database.models import (
    OHLCVData,
    OpenInterestData,
    FundingRateData,
    FearGreedIndexData,
)


logger = logging.getLogger(__name__)


class BacktestDataService:
    """
    backtesting.pyç”¨ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚µãƒ¼ãƒ“ã‚¹

    OHLCVãƒ‡ãƒ¼ã‚¿ã«Open Interest (OI)ã¨Funding Rate (FR)ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã€
    backtesting.pyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ä½¿ç”¨å¯èƒ½ãªpandas.DataFrameå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        ohlcv_repo: Optional[OHLCVRepository] = None,
        oi_repo: Optional[OpenInterestRepository] = None,
        fr_repo: Optional[FundingRateRepository] = None,
        fear_greed_repo: Optional[FearGreedIndexRepository] = None,
    ):
        """
        åˆæœŸåŒ–

        Args:
            ohlcv_repo: OHLCVãƒªãƒã‚¸ãƒˆãƒªï¼ˆãƒ†ã‚¹ãƒˆæ™‚ã«ãƒ¢ãƒƒã‚¯ã‚’æ³¨å…¥å¯èƒ½ï¼‰
            oi_repo: Open Interestãƒªãƒã‚¸ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            fr_repo: Funding Rateãƒªãƒã‚¸ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            fear_greed_repo: Fear & Greedãƒªãƒã‚¸ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.ohlcv_repo = ohlcv_repo
        self.oi_repo = oi_repo
        self.fr_repo = fr_repo
        self.fear_greed_repo = fear_greed_repo

    def get_data_for_backtest(
        self, symbol: str, timeframe: str, start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """
        OHLCVã€OIã€FRãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦backtesting.pyå½¢å¼ã«å¤‰æ›

        Args:
            symbol: å–å¼•ãƒšã‚¢ï¼ˆä¾‹: BTC/USDTï¼‰
            timeframe: æ™‚é–“è»¸ï¼ˆä¾‹: 1h, 4h, 1dï¼‰
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            backtesting.pyç”¨ã®DataFrameï¼ˆOpen, High, Low, Close, Volume, open_interest, funding_rateã‚«ãƒ©ãƒ ï¼‰

        Raises:
            ValueError: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        """
        if self.ohlcv_repo is None:
            raise ValueError("OHLCVRepositoryãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        # 1. OHLCVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        ohlcv_data = self.ohlcv_repo.get_ohlcv_data(
            symbol=symbol, timeframe=timeframe, start_time=start_date, end_time=end_date
        )

        if not ohlcv_data:
            raise ValueError(
                f"{symbol} {timeframe}ã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            )

        # 2. OHLCVãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        df = self._convert_to_dataframe(ohlcv_data)

        # 3. OI/FRãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        df = self._merge_additional_data(df, symbol, start_date, end_date)

        # 4. ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã¨ã‚½ãƒ¼ãƒˆ
        self._validate_extended_dataframe(df)
        df = df.sort_index()  # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ

        return df

    def _convert_to_dataframe(self, ohlcv_data: List[OHLCVData]) -> pd.DataFrame:
        """
        OHLCVDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            ohlcv_data: OHLCVDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            backtesting.pyç”¨ã®DataFrame
        """
        # åŠ¹ç‡çš„ã«DataFrameã‚’ä½œæˆ
        data = {
            "Open": [r.open for r in ohlcv_data],
            "High": [r.high for r in ohlcv_data],
            "Low": [r.low for r in ohlcv_data],
            "Close": [r.close for r in ohlcv_data],
            "Volume": [r.volume for r in ohlcv_data],
        }

        df = pd.DataFrame(data)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’datetimeã«è¨­å®š
        df.index = pd.DatetimeIndex([r.timestamp for r in ohlcv_data])

        return df

    def _merge_additional_data(
        self, df: pd.DataFrame, symbol: str, start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """
        OHLCVãƒ‡ãƒ¼ã‚¿ã«OI/FRãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸

        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ã®DataFrame
            symbol: å–å¼•ãƒšã‚¢
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            OI/FRãƒ‡ãƒ¼ã‚¿ãŒãƒãƒ¼ã‚¸ã•ã‚ŒãŸDataFrame
        """
        logger.info(
            f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸é–‹å§‹ - OHLCV: {len(df)}è¡Œ, æœŸé–“: {start_date} - {end_date}"
        )

        # Open Interestãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        if self.oi_repo:
            try:
                oi_data = self.oi_repo.get_open_interest_data(
                    symbol=symbol, start_time=start_date, end_time=end_date
                )
                logger.info(
                    f"ğŸ“ˆ å–å¾—ã—ãŸOIãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(oi_data) if oi_data else 0}"
                )

                if oi_data:
                    oi_df = self._convert_oi_to_dataframe(oi_data)
                    logger.info(
                        f"ğŸ“ˆ OI DataFrame: {len(oi_df)}è¡Œ, æœŸé–“: {oi_df.index.min()} - {oi_df.index.max()}"
                    )

                    # toleranceã‚’è¨­å®šï¼ˆ1æ—¥ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼‰
                    df = pd.merge_asof(
                        df.sort_index(),
                        oi_df.sort_index(),
                        left_index=True,
                        right_index=True,
                        direction="backward",
                        tolerance=pd.Timedelta(days=1),
                    )

                    valid_oi_count = df["open_interest"].notna().sum()
                    logger.info(
                        f"ğŸ“ˆ OIãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†: {valid_oi_count}/{len(df)}è¡Œã«å€¤ã‚ã‚Š ({valid_oi_count/len(df)*100:.1f}%)"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ ã‚·ãƒ³ãƒœãƒ« {symbol} ã®Open Interestãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    )
                    df["open_interest"] = pd.NA
            except Exception as e:
                logger.warning(
                    f"âŒ Open Interestãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                )
                df["open_interest"] = pd.NA
        else:
            logger.info("â„¹ï¸ OIãƒªãƒã‚¸ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            df["open_interest"] = pd.NA

        # Funding Rateãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        if self.fr_repo:
            try:
                fr_data = self.fr_repo.get_funding_rate_data(
                    symbol=symbol, start_time=start_date, end_time=end_date
                )
                logger.info(
                    f"ğŸ’° å–å¾—ã—ãŸFRãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(fr_data) if fr_data else 0}"
                )

                if fr_data:
                    fr_df = self._convert_fr_to_dataframe(fr_data)
                    logger.info(
                        f"ğŸ’° FR DataFrame: {len(fr_df)}è¡Œ, æœŸé–“: {fr_df.index.min()} - {fr_df.index.max()}"
                    )

                    # toleranceã‚’è¨­å®šï¼ˆ12æ™‚é–“ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ã€Funding Rateã¯8æ™‚é–“é–“éš”ï¼‰
                    df = pd.merge_asof(
                        df.sort_index(),
                        fr_df.sort_index(),
                        left_index=True,
                        right_index=True,
                        direction="backward",
                        tolerance=pd.Timedelta(hours=12),
                    )

                    valid_fr_count = df["funding_rate"].notna().sum()
                    logger.info(
                        f"ğŸ’° FRãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†: {valid_fr_count}/{len(df)}è¡Œã«å€¤ã‚ã‚Š ({valid_fr_count/len(df)*100:.1f}%)"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ ã‚·ãƒ³ãƒœãƒ« {symbol} ã®Funding Rateãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    )
                    df["funding_rate"] = pd.NA
            except Exception as e:
                logger.warning(
                    f"âŒ Funding Rateãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                )
                df["funding_rate"] = pd.NA
        else:
            logger.info("â„¹ï¸ FRãƒªãƒã‚¸ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            df["funding_rate"] = pd.NA

        # æ¬ æå€¤ã‚’å‰æ–¹ãƒ‡ãƒ¼ã‚¿ã§åŸ‹ã‚ã€ãã‚Œã§ã‚‚æ®‹ã‚‹å ´åˆã¯0ã§åŸ‹ã‚ã‚‹
        if "open_interest" in df.columns:
            # FutureWarningã‚’å›é¿ã™ã‚‹ãŸã‚ã€æ˜ç¤ºçš„ã«å‹ã‚’æŒ‡å®š
            oi_series = df["open_interest"].astype("float64")
            df["open_interest"] = oi_series.ffill().fillna(0.0)
        if "funding_rate" in df.columns:
            # FutureWarningã‚’å›é¿ã™ã‚‹ãŸã‚ã€æ˜ç¤ºçš„ã«å‹ã‚’æŒ‡å®š
            fr_series = df["funding_rate"].astype("float64")
            df["funding_rate"] = fr_series.ffill().fillna(0.0)

        return df

    def _merge_fear_greed_data(
        self, df: pd.DataFrame, start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """
        Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸

        Args:
            df: æ—¢å­˜ã®DataFrame
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            Fear & Greedãƒ‡ãƒ¼ã‚¿ãŒãƒãƒ¼ã‚¸ã•ã‚ŒãŸDataFrame
        """
        # Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        if self.fear_greed_repo:
            try:
                fear_greed_data = self.fear_greed_repo.get_fear_greed_data(
                    start_time=start_date, end_time=end_date
                )
                logger.info(
                    f"ğŸ˜¨ å–å¾—ã—ãŸFear & Greedãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(fear_greed_data) if fear_greed_data else 0}"
                )

                if fear_greed_data:
                    fear_greed_df = self._convert_fear_greed_to_dataframe(
                        fear_greed_data
                    )
                    logger.info(
                        f"ğŸ˜¨ Fear & Greed DataFrame: {len(fear_greed_df)}è¡Œ, æœŸé–“: {fear_greed_df.index.min()} - {fear_greed_df.index.max()}"
                    )

                    # toleranceã‚’è¨­å®šï¼ˆ3æ—¥ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ã€Fear & Greedã¯1æ—¥é–“éš”ï¼‰
                    df = pd.merge_asof(
                        df.sort_index(),
                        fear_greed_df.sort_index(),
                        left_index=True,
                        right_index=True,
                        direction="backward",
                        tolerance=pd.Timedelta(days=3),
                    )

                    valid_fg_count = df["fear_greed_value"].notna().sum()
                    logger.info(
                        f"ğŸ˜¨ Fear & Greedãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†: {valid_fg_count}/{len(df)}è¡Œã«å€¤ã‚ã‚Š ({valid_fg_count/len(df)*100:.1f}%)"
                    )
                else:
                    logger.warning("âš ï¸ Fear & Greedãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    df["fear_greed_value"] = pd.NA
                    df["fear_greed_classification"] = pd.NA
            except Exception as e:
                logger.warning(
                    f"âŒ Fear & Greedãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                )
                df["fear_greed_value"] = pd.NA
                df["fear_greed_classification"] = pd.NA
        else:
            logger.info("â„¹ï¸ Fear & Greedãƒªãƒã‚¸ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            df["fear_greed_value"] = pd.NA
            df["fear_greed_classification"] = pd.NA

        return df

    def _improve_data_interpolation(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ãƒ‡ãƒ¼ã‚¿è£œé–“ã®æ”¹å–„

        Args:
            df: å¯¾è±¡ã®DataFrame

        Returns:
            è£œé–“å‡¦ç†ã•ã‚ŒãŸDataFrame
        """
        logger.info("ğŸ”§ ãƒ‡ãƒ¼ã‚¿è£œé–“å‡¦ç†ã‚’é–‹å§‹")

        # Open Interest: forward fillã§è£œé–“ã€æ®‹ã‚Šã¯0ã§åŸ‹ã‚ã‚‹
        if "open_interest" in df.columns:
            before_count = df["open_interest"].notna().sum()
            oi_series = df["open_interest"].astype("float64")
            df["open_interest"] = oi_series.ffill().fillna(0.0)
            after_count = df["open_interest"].notna().sum()
            logger.info(f"ğŸ“ˆ OIè£œé–“: {before_count} â†’ {after_count} è¡Œ")

        # Funding Rate: forward fillã§è£œé–“ã€æ®‹ã‚Šã¯0ã§åŸ‹ã‚ã‚‹
        if "funding_rate" in df.columns:
            before_count = df["funding_rate"].notna().sum()
            fr_series = df["funding_rate"].astype("float64")
            df["funding_rate"] = fr_series.ffill().fillna(0.0)
            after_count = df["funding_rate"].notna().sum()
            logger.info(f"ğŸ’° FRè£œé–“: {before_count} â†’ {after_count} è¡Œ")

        # Fear & Greed: forward fillã§è£œé–“ã€æ®‹ã‚Šã¯ä¸­ç«‹å€¤50ã§åŸ‹ã‚ã‚‹
        if "fear_greed_value" in df.columns:
            before_count = df["fear_greed_value"].notna().sum()
            fg_series = df["fear_greed_value"].astype("float64")
            df["fear_greed_value"] = fg_series.ffill().fillna(50.0)  # ä¸­ç«‹å€¤50
            after_count = df["fear_greed_value"].notna().sum()
            logger.info(f"ğŸ˜¨ Fear & Greedå€¤è£œé–“: {before_count} â†’ {after_count} è¡Œ")

        if "fear_greed_classification" in df.columns:
            before_count = df["fear_greed_classification"].notna().sum()
            fg_class_series = df["fear_greed_classification"].astype("string")
            df["fear_greed_classification"] = fg_class_series.ffill().fillna("Neutral")
            after_count = df["fear_greed_classification"].notna().sum()
            logger.info(f"ğŸ˜¨ Fear & Greedåˆ†é¡è£œé–“: {before_count} â†’ {after_count} è¡Œ")

        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
        self._log_data_quality_report(df)

        return df

    def _log_data_quality_report(self, df: pd.DataFrame) -> None:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›

        Args:
            df: å¯¾è±¡ã®DataFrame
        """
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ:")
        logger.info(f"   ç·è¡Œæ•°: {len(df)}")
        logger.info(f"   æœŸé–“: {df.index.min()} - {df.index.max()}")

        # å„ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿å“è³ª
        for col in df.columns:
            if col in ["Open", "High", "Low", "Close", "Volume"]:
                continue  # OHLCVã¯å¿…é ˆãªã®ã§ã‚¹ã‚­ãƒƒãƒ—

            valid_count = df[col].notna().sum()
            coverage = valid_count / len(df) * 100
            logger.info(f"   {col}: {valid_count}/{len(df)} è¡Œ ({coverage:.1f}%)")

        return df

    def get_ml_training_data(
        self, symbol: str, timeframe: str, start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """
        MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«OHLCVã€OIã€FRã€Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ

        Args:
            symbol: å–å¼•ãƒšã‚¢ï¼ˆä¾‹: BTC/USDTï¼‰
            timeframe: æ™‚é–“è»¸ï¼ˆä¾‹: 1h, 4h, 1dï¼‰
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            çµ±åˆã•ã‚ŒãŸDataFrameï¼ˆOpen, High, Low, Close, Volume, open_interest, funding_rate, fear_greed_valueï¼‰

        Raises:
            ValueError: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        """
        if self.ohlcv_repo is None:
            raise ValueError("OHLCVRepositoryãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        # 1. OHLCVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        ohlcv_data = self.ohlcv_repo.get_ohlcv_data(
            symbol=symbol, timeframe=timeframe, start_time=start_date, end_time=end_date
        )

        if not ohlcv_data:
            raise ValueError(
                f"{symbol} {timeframe}ã®OHLCVãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            )

        # 2. OHLCVãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        df = self._convert_to_dataframe(ohlcv_data)

        # 3. OI/FRãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        df = self._merge_additional_data(df, symbol, start_date, end_date)

        # 4. Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        df = self._merge_fear_greed_data(df, start_date, end_date)

        # 5. ãƒ‡ãƒ¼ã‚¿è£œé–“ã®æ”¹å–„
        df = self._improve_data_interpolation(df)

        # 6. ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã¨ã‚½ãƒ¼ãƒˆ
        self._validate_ml_training_dataframe(df)
        df = df.sort_index()  # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ

        return df

    def _merge_fear_greed_data(
        self, df: pd.DataFrame, start_date: datetime, end_date: datetime
    ) -> pd.DataFrame:
        """
        Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸

        Args:
            df: æ—¢å­˜ã®DataFrame
            start_date: é–‹å§‹æ—¥æ™‚
            end_date: çµ‚äº†æ—¥æ™‚

        Returns:
            Fear & Greedãƒ‡ãƒ¼ã‚¿ãŒãƒãƒ¼ã‚¸ã•ã‚ŒãŸDataFrame
        """
        # Fear & Greedãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        if self.fear_greed_repo:
            try:
                fear_greed_data = self.fear_greed_repo.get_fear_greed_data(
                    start_time=start_date, end_time=end_date
                )
                if fear_greed_data:
                    fear_greed_df = self._convert_fear_greed_to_dataframe(
                        fear_greed_data
                    )
                    df = pd.merge_asof(
                        df.sort_index(),
                        fear_greed_df.sort_index(),
                        left_index=True,
                        right_index=True,
                        direction="backward",
                    )
                else:
                    logger.warning("Fear & Greedãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    df["fear_greed_value"] = pd.NA
                    df["fear_greed_classification"] = pd.NA
            except Exception as e:
                logger.warning(
                    f"Fear & Greedãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                )
                df["fear_greed_value"] = pd.NA
                df["fear_greed_classification"] = pd.NA
        else:
            logger.info("Fear & Greedãƒªãƒã‚¸ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            df["fear_greed_value"] = pd.NA
            df["fear_greed_classification"] = pd.NA

        # æ¬ æå€¤ã‚’å‰æ–¹ãƒ‡ãƒ¼ã‚¿ã§åŸ‹ã‚ã€ãã‚Œã§ã‚‚æ®‹ã‚‹å ´åˆã¯ä¸­ç«‹å€¤ã§åŸ‹ã‚ã‚‹
        if "fear_greed_value" in df.columns:
            fg_series = df["fear_greed_value"].astype("float64")
            df["fear_greed_value"] = fg_series.ffill().fillna(50.0)  # ä¸­ç«‹å€¤50ã§åŸ‹ã‚ã‚‹
        if "fear_greed_classification" in df.columns:
            fg_class_series = df["fear_greed_classification"].astype("string")
            df["fear_greed_classification"] = fg_class_series.ffill().fillna("Neutral")

        return df

    def _convert_fear_greed_to_dataframe(
        self, fear_greed_data: List[FearGreedIndexData]
    ) -> pd.DataFrame:
        """
        FearGreedIndexDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            fear_greed_data: FearGreedIndexDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Fear & Greedã®DataFrame
        """
        data = {
            "fear_greed_value": [r.value for r in fear_greed_data],
            "fear_greed_classification": [
                r.value_classification for r in fear_greed_data
            ],
        }
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.data_timestamp for r in fear_greed_data])
        return df

    def _validate_ml_training_dataframe(self, df: pd.DataFrame) -> None:
        """
        MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨DataFrameã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯

        Args:
            df: æ¤œè¨¼å¯¾è±¡ã®DataFrame

        Raises:
            ValueError: DataFrameãŒç„¡åŠ¹ãªå ´åˆ
        """
        required_columns = [
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "open_interest",
            "funding_rate",
            "fear_greed_value",
            "fear_greed_classification",
        ]
        self._perform_common_validation(df, required_columns[:5])  # OHLCVéƒ¨åˆ†ã®ã¿å¿…é ˆ

        # NaNå€¤ã®ãƒã‚§ãƒƒã‚¯
        # OHLCVéƒ¨åˆ†ã«NaNãŒã‚ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        ohlcv_cols = ["Open", "High", "Low", "Close", "Volume"]
        if df[ohlcv_cols].isnull().any().any():
            raise ValueError("OHLCVãƒ‡ãƒ¼ã‚¿ã«NaNå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")

        # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®NaNã¯æ—¢ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã¯ãšã ãŒã€å¿µã®ãŸã‚ãƒ­ã‚°å‡ºåŠ›
        additional_cols = ["open_interest", "funding_rate", "fear_greed_value"]
        if any(col in df.columns for col in additional_cols):
            if df[additional_cols].isnull().any().any():
                logger.warning("è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã«äºˆæœŸã›ã¬NaNå€¤ãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚")

    def _convert_oi_to_dataframe(self, oi_data: List[OpenInterestData]) -> pd.DataFrame:
        """
        OpenInterestDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            oi_data: OpenInterestDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Open Interestã®DataFrame
        """
        data = {"open_interest": [r.open_interest_value for r in oi_data]}
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.data_timestamp for r in oi_data])
        return df

    def _convert_fr_to_dataframe(self, fr_data: List[FundingRateData]) -> pd.DataFrame:
        """
        FundingRateDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            fr_data: FundingRateDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Funding Rateã®DataFrame
        """
        data = {"funding_rate": [r.funding_rate for r in fr_data]}
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.funding_timestamp for r in fr_data])
        return df

    def _perform_common_validation(
        self, df: pd.DataFrame, required_columns: List[str]
    ) -> None:
        """
        DataFrameã®å…±é€šæ¤œè¨¼ã‚’å®Ÿè¡Œ

        Args:
            df: æ¤œè¨¼å¯¾è±¡ã®DataFrame
            required_columns: å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ

        Raises
            ValueError: DataFrameãŒç„¡åŠ¹ãªå ´åˆ
        """
        if df.empty:
            raise ValueError("DataFrameãŒç©ºã§ã™ã€‚")

        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_columns}")

        # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
        for col in required_columns:
            if not pd.api.types.is_numeric_dtype(df[col]):
                raise ValueError(f"ã‚«ãƒ©ãƒ  {col} ã¯æ•°å€¤å‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

    def _validate_extended_dataframe(self, df: pd.DataFrame) -> None:
        """
        æ‹¡å¼µã•ã‚ŒãŸDataFrameï¼ˆOI/FRå«ã‚€ï¼‰ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯

        Args:
            df: æ¤œè¨¼å¯¾è±¡ã®DataFrame

        Raises:
            ValueError: DataFrameãŒç„¡åŠ¹ãªå ´åˆ
        """
        required_columns = [
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "open_interest",
            "funding_rate",
        ]
        self._perform_common_validation(df, required_columns)

        # NaNå€¤ã®ãƒã‚§ãƒƒã‚¯
        # OHLCVéƒ¨åˆ†ã«NaNãŒã‚ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        ohlcv_cols = ["Open", "High", "Low", "Close", "Volume"]
        if df[ohlcv_cols].isnull().any().any():
            raise ValueError("OHLCVãƒ‡ãƒ¼ã‚¿ã«NaNå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")

        # OI/FRã®NaNã¯æ—¢ã«ffill/fillna(0.0)ã§å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã¯ãšã ãŒã€å¿µã®ãŸã‚ãƒ­ã‚°å‡ºåŠ›
        if "open_interest" in df.columns and "funding_rate" in df.columns:
            if df[["open_interest", "funding_rate"]].isnull().any().any():
                logger.warning("OI/FRãƒ‡ãƒ¼ã‚¿ã«äºˆæœŸã›ã¬NaNå€¤ãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚")

    def get_data_summary(self, df: pd.DataFrame) -> dict:
        """
        ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦æƒ…å ±ã‚’å–å¾—ï¼ˆOI/FRå«ã‚€ï¼‰

        Args:
            df: å¯¾è±¡ã®DataFrame

        Returns:
            ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã®è¾æ›¸
        """
        if df.empty:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"}

        summary = {
            "total_records": len(df),
            "start_date": df.index.min().isoformat(),
            "end_date": df.index.max().isoformat(),
            "price_range": {
                "min": float(df["Low"].min()),
                "max": float(df["High"].max()),
                "first_close": float(df["Close"].iloc[0]),
                "last_close": float(df["Close"].iloc[-1]),
            },
            "volume_stats": {
                "total": float(df["Volume"].sum()),
                "average": float(df["Volume"].mean()),
                "max": float(df["Volume"].max()),
            },
        }

        # OI/FRãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ æƒ…å ±ã‚’å«ã‚ã‚‹
        if "open_interest" in df.columns:
            summary["open_interest_stats"] = {
                "average": float(df["open_interest"].mean()),
                "min": float(df["open_interest"].min()),
                "max": float(df["open_interest"].max()),
                "first": float(df["open_interest"].iloc[0]),
                "last": float(df["open_interest"].iloc[-1]),
            }

        if "funding_rate" in df.columns:
            summary["funding_rate_stats"] = {
                "average": float(df["funding_rate"].mean()),
                "min": float(df["funding_rate"].min()),
                "max": float(df["funding_rate"].max()),
                "first": float(df["funding_rate"].iloc[0]),
                "last": float(df["funding_rate"].iloc[-1]),
            }

        # Fear & Greedãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è¿½åŠ æƒ…å ±ã‚’å«ã‚ã‚‹
        if "fear_greed_value" in df.columns:
            summary["fear_greed_stats"] = {
                "average": float(df["fear_greed_value"].mean()),
                "min": float(df["fear_greed_value"].min()),
                "max": float(df["fear_greed_value"].max()),
                "first": float(df["fear_greed_value"].iloc[0]),
                "last": float(df["fear_greed_value"].iloc[-1]),
            }

        if "fear_greed_classification" in df.columns:
            # åˆ†é¡ã®åˆ†å¸ƒã‚’å–å¾—
            classification_counts = (
                df["fear_greed_classification"].value_counts().to_dict()
            )
            summary["fear_greed_classification_distribution"] = {
                str(k): int(v) for k, v in classification_counts.items()
            }

        return summary

    def _convert_fear_greed_to_dataframe(
        self, fear_greed_data: List[FearGreedIndexData]
    ) -> pd.DataFrame:
        """
        FearGreedIndexDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            fear_greed_data: FearGreedIndexDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Fear & Greedã®DataFrame
        """
        data = {
            "fear_greed_value": [r.value for r in fear_greed_data],
            "fear_greed_classification": [
                r.value_classification for r in fear_greed_data
            ],
        }
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.data_timestamp for r in fear_greed_data])
        return df

    def _convert_oi_to_dataframe(self, oi_data: List[OpenInterestData]) -> pd.DataFrame:
        """
        OpenInterestDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            oi_data: OpenInterestDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Open Interestã®DataFrame
        """
        data = {"open_interest": [r.open_interest_value for r in oi_data]}
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.data_timestamp for r in oi_data])
        return df

    def _convert_fr_to_dataframe(self, fr_data: List[FundingRateData]) -> pd.DataFrame:
        """
        FundingRateDataãƒªã‚¹ãƒˆã‚’pandas.DataFrameã«å¤‰æ›

        Args:
            fr_data: FundingRateDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ

        Returns:
            Funding Rateã®DataFrame
        """
        data = {"funding_rate": [r.funding_rate for r in fr_data]}
        df = pd.DataFrame(data)
        df.index = pd.DatetimeIndex([r.funding_timestamp for r in fr_data])
        return df
