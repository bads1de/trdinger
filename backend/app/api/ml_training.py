"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°API

æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ç®¡ç†ã‚’è¡Œã†APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

import logging
from datetime import datetime
from typing import Dict, Any, Optional
from fastapi import APIRouter, BackgroundTasks
from pydantic import BaseModel, Field

from app.core.services.ml.ml_training_service import MLTrainingService
from app.core.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
from app.core.services.backtest_data_service import BacktestDataService
from app.core.utils.unified_error_handler import UnifiedErrorHandler
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.open_interest_repository import OpenInterestRepository
from database.repositories.funding_rate_repository import FundingRateRepository

# AutoMLè¨­å®šãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.api.routes.automl_features import (
    AutoMLConfigModel,
    TSFreshConfigModel,
    FeaturetoolsConfigModel,
    AutoFeatConfigModel,
)

from database.connection import get_db

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/ml-training", tags=["ML Training"])


def get_default_automl_config() -> AutoMLConfigModel:
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®AutoMLè¨­å®šã‚’å–å¾—"""
    return AutoMLConfigModel(
        tsfresh=TSFreshConfigModel(
            enabled=True,
            feature_selection=True,
            fdr_level=0.05,
            feature_count_limit=100,
            parallel_jobs=2,
        ),
        featuretools=FeaturetoolsConfigModel(
            enabled=True,
            max_depth=2,
            max_features=50,
        ),
        autofeat=AutoFeatConfigModel(
            enabled=True,
            max_features=50,
            generations=10,  # APIå±¤ã§ã¯generationsã‚’ä½¿ç”¨
            population_size=30,
            tournament_size=3,
        ),
    )


def get_financial_optimized_automl_config() -> AutoMLConfigModel:
    """é‡‘èãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–AutoMLè¨­å®šã‚’å–å¾—"""
    return AutoMLConfigModel(
        tsfresh=TSFreshConfigModel(
            enabled=True,
            feature_selection=True,
            fdr_level=0.01,  # ã‚ˆã‚Šå³ã—ã„é¸æŠ
            feature_count_limit=200,  # é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨ã«å¢—åŠ 
            parallel_jobs=4,
        ),
        featuretools=FeaturetoolsConfigModel(
            enabled=True,
            max_depth=3,  # ã‚ˆã‚Šæ·±ã„ç‰¹å¾´é‡åˆæˆ
            max_features=100,  # é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨ã«å¢—åŠ 
        ),
        autofeat=AutoFeatConfigModel(
            enabled=True,
            max_features=100,
            generations=20,  # ã‚ˆã‚Šå¤šãã®ä¸–ä»£ï¼ˆAPIå±¤ã§ã¯generationsã‚’ä½¿ç”¨ï¼‰
            population_size=50,
            tournament_size=3,
        ),
    )


class ParameterSpaceConfig(BaseModel):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“è¨­å®š"""

    type: str = Field(..., description="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‹ (real, integer, categorical)")
    low: Optional[float] = Field(None, description="æœ€å°å€¤ (real, integer)")
    high: Optional[float] = Field(None, description="æœ€å¤§å€¤ (real, integer)")
    categories: Optional[list] = Field(None, description="ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ (categorical)")


class OptimizationSettingsConfig(BaseModel):
    """æœ€é©åŒ–è¨­å®š"""

    enabled: bool = Field(default=False, description="æœ€é©åŒ–ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹")
    method: str = Field(default="optuna", description="æœ€é©åŒ–æ‰‹æ³• (optuna)")
    n_calls: int = Field(default=50, description="æœ€é©åŒ–è©¦è¡Œå›æ•°")
    parameter_space: Dict[str, ParameterSpaceConfig] = Field(
        default_factory=dict, description="ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“è¨­å®š"
    )


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ç®¡ç†
training_status = {
    "is_training": False,
    "progress": 0,
    "status": "idle",
    "message": "",
    "start_time": None,
    "end_time": None,
    "model_info": None,
    "error": None,
}


class MLTrainingConfig(BaseModel):
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š"""

    symbol: str = Field(..., description="å–å¼•ãƒšã‚¢ï¼ˆä¾‹: BTC/USDT:USDTï¼‰")
    timeframe: str = Field(default="1h", description="æ™‚é–“è»¸")
    start_date: str = Field(..., description="é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰")
    end_date: str = Field(..., description="çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰")
    validation_split: float = Field(default=0.2, description="æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ¯”ç‡")
    prediction_horizon: int = Field(default=24, description="äºˆæ¸¬æœŸé–“ï¼ˆæ™‚é–“ï¼‰")
    threshold_up: float = Field(default=0.02, description="ä¸Šæ˜‡åˆ¤å®šé–¾å€¤")
    threshold_down: float = Field(default=-0.02, description="ä¸‹è½åˆ¤å®šé–¾å€¤")
    save_model: bool = Field(default=True, description="ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‹")
    # æ–°ã—ã„è¨­å®šé …ç›®
    train_test_split: float = Field(
        default=0.8, description="ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/ãƒ†ã‚¹ãƒˆåˆ†å‰²æ¯”ç‡"
    )
    cross_validation_folds: int = Field(
        default=5, description="ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²æ•°"
    )
    random_state: int = Field(default=42, description="ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰")
    early_stopping_rounds: int = Field(default=100, description="æ—©æœŸåœæ­¢ãƒ©ã‚¦ãƒ³ãƒ‰æ•°")
    max_depth: int = Field(default=10, description="æœ€å¤§æ·±åº¦")
    n_estimators: int = Field(default=100, description="æ¨å®šå™¨æ•°")
    learning_rate: float = Field(default=0.1, description="å­¦ç¿’ç‡")

    # æœ€é©åŒ–è¨­å®š
    optimization_settings: Optional[OptimizationSettingsConfig] = Field(
        None, description="ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–è¨­å®š"
    )

    # AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¨­å®š
    automl_config: Optional[AutoMLConfigModel] = Field(
        None, description="AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¨­å®š"
    )


class MLTrainingResponse(BaseModel):
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¿œç­”"""

    success: bool
    message: str
    training_id: Optional[str] = None


class MLStatusResponse(BaseModel):
    """MLã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¿œç­”"""

    is_training: bool
    progress: int
    status: str
    message: str
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    model_info: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


def get_data_service():
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥"""
    db = next(get_db())
    try:
        ohlcv_repo = OHLCVRepository(db)
        oi_repo = OpenInterestRepository(db)
        fr_repo = FundingRateRepository(db)
        return BacktestDataService(ohlcv_repo, oi_repo, fr_repo)
    finally:
        db.close()


async def train_ml_model_background(config: MLTrainingConfig):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§MLãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"""
    global training_status

    try:
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
        training_status.update(
            {
                "is_training": True,
                "progress": 0,
                "status": "starting",
                "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...",
                "start_time": datetime.now().isoformat(),
                "end_time": None,
                "error": None,
            }
        )

        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        data_service = get_data_service()

        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        training_status.update(
            {
                "progress": 10,
                "status": "loading_data",
                "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...",
            }
        )

        start_date = datetime.fromisoformat(config.start_date)
        end_date = datetime.fromisoformat(config.end_date)

        training_data = data_service.get_data_for_backtest(
            symbol=config.symbol,
            timeframe=config.timeframe,
            start_date=start_date,
            end_date=end_date,
        )

        if training_data.empty:
            raise ValueError(f"æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config.symbol}")

        # MLã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        training_status.update(
            {
                "progress": 20,
                "status": "initializing",
                "message": "MLã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...",
            }
        )

        ml_service = MLTrainingService()

        # ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        training_status.update(
            {
                "progress": 30,
                "status": "training",
                "message": "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ã¾ã™...",
            }
        )

        # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¬ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢
        funding_rate_data = None
        open_interest_data = None

        if "FundingRate" in training_data.columns:
            funding_rate_data = training_data[["FundingRate"]].copy()

        if "OpenInterest" in training_data.columns:
            open_interest_data = training_data[["OpenInterest"]].copy()

        # OHLCVãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡º
        ohlcv_data = training_data[["Open", "High", "Low", "Close", "Volume"]].copy()

        # æœ€é©åŒ–è¨­å®šã‚’æº–å‚™
        optimization_settings = None
        if config.optimization_settings and config.optimization_settings.enabled:
            from app.core.services.ml.ml_training_service import OptimizationSettings

            logger.info("=" * 60)
            logger.info("ğŸ¯ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")
            logger.info("ğŸ“Š æœ€é©åŒ–æ‰‹æ³•: optuna")
            logger.info(f"ğŸ”„ è©¦è¡Œå›æ•°: {config.optimization_settings.n_calls}")
            logger.info(
                f"ğŸ“‹ æœ€é©åŒ–å¯¾è±¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {len(config.optimization_settings.parameter_space)}"
            )

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
            for (
                param_name,
                param_config,
            ) in config.optimization_settings.parameter_space.items():
                if param_config.type in ["real", "integer"]:
                    logger.info(
                        f"  - {param_name} ({param_config.type}): [{param_config.low}, {param_config.high}]"
                    )
                else:
                    logger.info(
                        f"  - {param_name} ({param_config.type}): {param_config.categories}"
                    )
            logger.info("=" * 60)

            # ParameterSpaceConfigã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
            parameter_space_dict = {}
            for (
                param_name,
                param_config,
            ) in config.optimization_settings.parameter_space.items():
                parameter_space_dict[param_name] = {
                    "type": param_config.type,
                    "low": param_config.low,
                    "high": param_config.high,
                    "categories": param_config.categories,
                }

            optimization_settings = OptimizationSettings(
                enabled=config.optimization_settings.enabled,
                n_calls=config.optimization_settings.n_calls,
                parameter_space=parameter_space_dict,
            )

            training_status.update(
                {
                    "message": f"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­ ({config.optimization_settings.method})"
                }
            )
        else:
            logger.info("ğŸ“ é€šå¸¸ã®MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆæœ€é©åŒ–ãªã—ï¼‰")

        # AutoMLè¨­å®šã®å‡¦ç†
        automl_config = config.automl_config
        if automl_config is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®AutoMLè¨­å®šã‚’ä½¿ç”¨
            automl_config = get_financial_optimized_automl_config()
            logger.info("ğŸ¤– ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é‡‘èæœ€é©åŒ–AutoMLè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
        else:
            logger.info("ğŸ¤– ã‚«ã‚¹ã‚¿ãƒ AutoMLè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")

        # AutoMLè¨­å®šã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        automl_config_dict = {
            "tsfresh": automl_config.tsfresh.model_dump(),
            "featuretools": automl_config.featuretools.model_dump(),
            "autofeat": automl_config.autofeat.model_dump(),
        }

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        training_result = ml_service.train_model(
            training_data=ohlcv_data,
            funding_rate_data=funding_rate_data,
            open_interest_data=open_interest_data,
            save_model=config.save_model,
            optimization_settings=optimization_settings,
            automl_config=automl_config_dict,  # AutoMLè¨­å®šã‚’è¿½åŠ 
            # æ–°ã—ã„MLTrainingServiceã¯è¨­å®šã‹ã‚‰è‡ªå‹•çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
            test_size=1 - config.train_test_split,
            random_state=config.random_state,
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†
        training_status.update(
            {
                "progress": 100,
                "status": "completed",
                "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ",
                "end_time": datetime.now().isoformat(),
                "is_training": False,
                "model_info": {
                    "accuracy": training_result.get("accuracy", 0.0),
                    "loss": training_result.get("loss", 0.0),
                    "model_path": training_result.get("model_path", ""),
                    "feature_count": training_result.get("feature_count", 0),
                    "training_samples": len(training_data),
                    "validation_split": config.validation_split,
                },
            }
        )

        logger.info(f"MLãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†: {config.symbol}")

    except Exception as e:
        logger.error(f"MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        training_status.update(
            {
                "is_training": False,
                "status": "error",
                "message": f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "end_time": datetime.now().isoformat(),
                "error": str(e),
            }
        )


@router.post("/train", response_model=MLTrainingResponse)
async def start_ml_training(
    config: MLTrainingConfig, background_tasks: BackgroundTasks
):
    """
    MLãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹
    """
    logger.info("ğŸš€ /api/ml-training/train ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")
    logger.info(f"ğŸ“‹ æœ€é©åŒ–è¨­å®š: {config.optimization_settings}")
    global training_status

    async def _start_training():
        # æ—¢ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if training_status["is_training"]:
            from fastapi import HTTPException

            raise HTTPException(status_code=400, detail="æ—¢ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œä¸­ã§ã™")

        # è¨­å®šã®æ¤œè¨¼
        start_date = datetime.fromisoformat(config.start_date)
        end_date = datetime.fromisoformat(config.end_date)

        if start_date >= end_date:
            raise ValueError("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")

        if (end_date - start_date).days < 7:
            raise ValueError("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã¯æœ€ä½7æ—¥é–“å¿…è¦ã§ã™")

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
        background_tasks.add_task(train_ml_model_background, config)

        return MLTrainingResponse(
            success=True,
            message="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
            training_id=f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        )

    return await UnifiedErrorHandler.safe_execute_async(_start_training)


@router.get("/training/status", response_model=MLStatusResponse)
async def get_ml_training_status():
    """
    MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®çŠ¶æ…‹ã‚’å–å¾—
    """
    return MLStatusResponse(**training_status)


@router.get("/model-info")
async def get_ml_model_info():
    """
    ç¾åœ¨ã®MLãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
    """

    async def _get_model_info():
        ml_orchestrator = MLOrchestrator()
        model_status = ml_orchestrator.get_model_status()

        return {
            "success": True,
            "model_status": model_status,
            "last_training": training_status.get("model_info"),
        }

    return await UnifiedErrorHandler.safe_execute_async(_get_model_info)


@router.post("/stop")
async def stop_ml_training():
    """
    MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢
    """
    global training_status

    async def _stop_training():
        if not training_status["is_training"]:
            from fastapi import HTTPException

            raise HTTPException(
                status_code=400, detail="å®Ÿè¡Œä¸­ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚ã‚Šã¾ã›ã‚“"
            )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åœæ­¢ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
        training_status.update(
            {
                "is_training": False,
                "status": "stopped",
                "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ",
                "end_time": datetime.now().isoformat(),
            }
        )

        return {"success": True, "message": "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åœæ­¢ã—ã¾ã—ãŸ"}

    return await UnifiedErrorHandler.safe_execute_async(_stop_training)
