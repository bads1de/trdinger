"""
MLç®¡ç†API

ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®MLç®¡ç†æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

import logging
from typing import Any, Dict

from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.services.backtest.backtest_data_service import BacktestDataService
from app.services.ml.orchestration.ml_management_orchestration_service import (
    MLManagementOrchestrationService,
)
from app.utils.api_utils import APIResponseHelper
from app.utils.unified_error_handler import UnifiedErrorHandler
from database.connection import get_db
from database.repositories.funding_rate_repository import FundingRateRepository
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.open_interest_repository import OpenInterestRepository

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/ml", tags=["ml_management"])


@router.get("/models")
async def get_models(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’å–å¾—

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰

    Returns:
        ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    """

    async def _get_models():
        return await ml_service.get_formatted_models()

    return await UnifiedErrorHandler.safe_execute_async(_get_models)


# å…¨å‰Šé™¤ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ‘ã‚¹ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚åˆ¥ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼‰
@router.delete("/models-all")
async def delete_all_models(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """
    logger.info("ğŸ—‘ï¸ å…¨ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")

    async def _delete_all_models():
        return await ml_service.delete_all_models()

    return await UnifiedErrorHandler.safe_execute_async(_delete_all_models)


# å¾“æ¥ã® /models/all ãƒ‘ã‚¹ã‚‚ç¶­æŒï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
@router.delete("/models/all")
async def delete_all_models_legacy(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ãƒ‘ã‚¹ï¼‰

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """
    logger.info("ğŸ—‘ï¸ å…¨ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")

    async def _delete_all_models():
        return await ml_service.delete_all_models()

    return await UnifiedErrorHandler.safe_execute_async(_delete_all_models)


# å€‹åˆ¥å‰Šé™¤ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆ"all" ã‚’é™¤å¤–ã™ã‚‹åˆ¶ç´„ä»˜ãï¼‰
@router.delete("/models/{model_id}")
async def delete_model(
    model_id: str,
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤

    Args:
        model_id: ãƒ¢ãƒ‡ãƒ«IDï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """
    # "all" ãŒæ¸¡ã•ã‚ŒãŸå ´åˆã¯å…¨å‰Šé™¤ãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
    if model_id.lower() == "all":
        logger.info(
            "ğŸ—‘ï¸ model_id='all' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚å…¨å‰Šé™¤ãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã—ã¾ã™"
        )

        async def _delete_all_models():
            return await ml_service.delete_all_models()

        return await UnifiedErrorHandler.safe_execute_async(_delete_all_models)

    logger.info(
        f"ğŸ—‘ï¸ å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ: model_id={model_id}"
    )

    async def _delete_model():
        return await ml_service.delete_model(model_id)

    return await UnifiedErrorHandler.safe_execute_async(_delete_model)


@router.get("/status")
async def get_ml_status(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    MLãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰

    Returns:
        ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹æƒ…å ±
    """

    async def _get_ml_status():
        return await ml_service.get_ml_status()

    return await UnifiedErrorHandler.safe_execute_async(_get_ml_status)


@router.get("/feature-importance")
async def get_feature_importance(
    top_n: int = 10,
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—

    Args:
        top_n: ä¸Šä½Nä»¶ã®ç‰¹å¾´é‡ã‚’å–å¾—
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """

    async def _get_feature_importance():
        return await ml_service.get_feature_importance(top_n)

    return await UnifiedErrorHandler.safe_execute_async(_get_feature_importance)


@router.post("/models/{model_name}/load")
async def load_model(
    model_name: str,
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿

    Args:
        model_name: èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«å
    """

    async def _load_model():
        return await ml_service.load_model(model_name)

    return await UnifiedErrorHandler.safe_execute_async(_load_model)


@router.get("/models/current")
async def get_current_model(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    ç¾åœ¨èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
    """

    async def _get_current_model():
        return await ml_service.get_current_model_info()

    return await UnifiedErrorHandler.safe_execute_async(_get_current_model)


@router.get("/automl-feature-analysis")
async def get_automl_feature_analysis(
    top_n: int = 20,
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    AutoMLç‰¹å¾´é‡åˆ†æçµæœã‚’å–å¾—

    Args:
        top_n: ä¸Šä½Nä»¶ã®ç‰¹å¾´é‡ã‚’å–å¾—
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """

    async def _get_automl_feature_analysis():
        return await ml_service.get_automl_feature_analysis(top_n)

    return await UnifiedErrorHandler.safe_execute_async(_get_automl_feature_analysis)


@router.get("/config")
async def get_ml_config(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    MLè¨­å®šã‚’å–å¾—

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰

    Returns:
        MLè¨­å®š
    """

    async def _get_ml_config():
        return ml_service.get_ml_config_dict()

    return await UnifiedErrorHandler.safe_execute_async(_get_ml_config)


@router.put("/config")
async def update_ml_config(
    config_data: Dict[str, Any],
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    MLè¨­å®šã‚’æ›´æ–°

    Args:
        config_data: æ›´æ–°ã™ã‚‹è¨­å®šãƒ‡ãƒ¼ã‚¿
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """

    async def _update_ml_config():
        logger.info(f"MLè¨­å®šæ›´æ–°è¦æ±‚: {config_data}")
        result = await ml_service.update_ml_config(config_data)

        if result["success"]:
            return APIResponseHelper.api_response(
                success=True,
                message=result["message"],
                data=result.get("updated_config"),
            )
        else:
            return APIResponseHelper.api_response(
                success=False, message=result["message"]
            )

    return await UnifiedErrorHandler.safe_execute_async(_update_ml_config)


@router.post("/config/reset")
async def reset_ml_config(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    MLè¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆ

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """

    async def _reset_ml_config():
        logger.info("MLè¨­å®šãƒªã‚»ãƒƒãƒˆè¦æ±‚")
        result = await ml_service.reset_ml_config()

        if result["success"]:
            return APIResponseHelper.api_response(
                success=True, message=result["message"], data=result.get("config")
            )
        else:
            return APIResponseHelper.api_response(
                success=False, message=result["message"]
            )

    return await UnifiedErrorHandler.safe_execute_async(_reset_ml_config)


@router.post("/models/cleanup")
async def cleanup_old_models(
    ml_service: MLManagementOrchestrationService = Depends(
        MLManagementOrchestrationService
    ),
):
    """
    å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

    Args:
        ml_service: MLç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆä¾å­˜æ€§æ³¨å…¥ï¼‰
    """

    async def _cleanup_old_models():
        return await ml_service.cleanup_old_models()

    return await UnifiedErrorHandler.safe_execute_async(_cleanup_old_models)


def get_data_service(db: Session = Depends(get_db)) -> BacktestDataService:
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥"""
    ohlcv_repo = OHLCVRepository(db)
    oi_repo = OpenInterestRepository(db)
    fr_repo = FundingRateRepository(db)
    return BacktestDataService(ohlcv_repo, oi_repo, fr_repo)
