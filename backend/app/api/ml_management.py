"""
MLç®¡ç†API

ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®MLç®¡ç†æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""

from fastapi import APIRouter, Depends
from typing import Dict, Any
import logging
from sqlalchemy.orm import Session
from datetime import datetime
import os

from app.core.services.ml.model_manager import model_manager
from app.core.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
from app.core.services.ml.config import ml_config
from app.core.services.ml.performance_extractor import performance_extractor
from app.core.utils.unified_error_handler import UnifiedErrorHandler

from app.core.services.backtest_data_service import BacktestDataService
from backend.app.core.utils.api_utils import APIResponseHelper
from database.repositories.ohlcv_repository import OHLCVRepository
from database.repositories.open_interest_repository import OpenInterestRepository
from database.repositories.funding_rate_repository import FundingRateRepository
from database.connection import get_db


router = APIRouter(prefix="/api/ml", tags=["ml_management"])
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
ml_orchestrator = MLOrchestrator()


@router.get("/models")
async def get_models():
    """
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’å–å¾—

    Returns:
        ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
    """

    async def _get_models():
        models = model_manager.list_models("*")

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’æ•´å½¢
        formatted_models = []
        for model in models:
            # åŸºæœ¬æƒ…å ±
            model_info = {
                "id": model["name"],
                "name": model["name"],
                "path": model["path"],
                "size_mb": model["size_mb"],
                "modified_at": model["modified_at"].isoformat(),
                "directory": model["directory"],
                "is_active": False,  # TODO: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ‡ãƒ«ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
            }

            # ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            try:
                model_data = model_manager.load_model(model["path"])
                if model_data and "metadata" in model_data:
                    metadata = model_data["metadata"]

                    # æ€§èƒ½æŒ‡æ¨™ã‚’è¿½åŠ 
                    model_info.update(
                        {
                            "accuracy": metadata.get("accuracy", 0.0),
                            "precision": metadata.get("precision", 0.0),
                            "recall": metadata.get("recall", 0.0),
                            "f1_score": metadata.get("f1_score", 0.0),
                            "feature_count": metadata.get("feature_count", 0),
                            "model_type": metadata.get("model_type", "LightGBM"),
                            "training_samples": metadata.get("training_samples", 0),
                        }
                    )

                    # classification_reportã‹ã‚‰è©³ç´°æŒ‡æ¨™ã‚’æŠ½å‡º
                    if "classification_report" in metadata:
                        report = metadata["classification_report"]
                        if isinstance(report, dict) and "macro avg" in report:
                            macro_avg = report["macro avg"]
                            model_info.update(
                                {
                                    "precision": macro_avg.get(
                                        "precision", model_info.get("precision", 0.0)
                                    ),
                                    "recall": macro_avg.get(
                                        "recall", model_info.get("recall", 0.0)
                                    ),
                                    "f1_score": macro_avg.get(
                                        "f1-score", model_info.get("f1_score", 0.0)
                                    ),
                                }
                            )

                    logger.info(
                        f"âœ… ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±ã‚’å–å¾—: {model['name']} - ç²¾åº¦: {model_info.get('accuracy', 0.0):.3f}, F1: {model_info.get('f1_score', 0.0):.3f}, ç‰¹å¾´é‡: {model_info.get('feature_count', 0)}å€‹"
                    )

            except Exception as e:
                logger.warning(f"ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ {model['name']}: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                model_info.update(
                    {
                        "accuracy": 0.0,
                        "precision": 0.0,
                        "recall": 0.0,
                        "f1_score": 0.0,
                        "feature_count": 0,
                        "model_type": "Unknown",
                        "training_samples": 0,
                    }
                )

            formatted_models.append(model_info)

        return {"models": formatted_models}

    return await UnifiedErrorHandler.safe_execute_async(_get_models)


@router.delete("/models/{model_id}")
async def delete_model(model_id: str):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤

    Args:
        model_id: ãƒ¢ãƒ‡ãƒ«IDï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
    """

    async def _delete_model():
        logger.info(f"ãƒ¢ãƒ‡ãƒ«å‰Šé™¤è¦æ±‚: {model_id}")

        # ãƒ¢ãƒ‡ãƒ«IDã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆURLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        from urllib.parse import unquote

        decoded_model_id = unquote(model_id)

        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        models = model_manager.list_models("*")
        target_model = None

        for model in models:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¯”è¼ƒï¼ˆæ‹¡å¼µå­ã‚‚å«ã‚€ï¼‰
            if model["name"] == decoded_model_id or model["name"] == model_id:
                target_model = model
                break

        if not target_model:
            logger.warning(f"ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {decoded_model_id}")
            logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {[m['name'] for m in models]}")
            from fastapi import HTTPException

            raise HTTPException(
                status_code=404, detail=f"ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {decoded_model_id}"
            )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        import os

        if not os.path.exists(target_model["path"]):
            logger.warning(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {target_model['path']}")
            from fastapi import HTTPException

            raise HTTPException(status_code=404, detail="ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

        # ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤
        try:
            os.remove(target_model["path"])
            logger.info(f"ãƒ¢ãƒ‡ãƒ«å‰Šé™¤å®Œäº†: {decoded_model_id} -> {target_model['path']}")
            return {"message": "ãƒ¢ãƒ‡ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ"}
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            raise HTTPException(
                status_code=500, detail="ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )

    return await UnifiedErrorHandler.safe_execute_async(_delete_model)


@router.get("/status")
async def get_ml_status():
    """
    MLãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—

    Returns:
        ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹æƒ…å ±
    """

    async def _get_ml_status():
        status = ml_orchestrator.get_model_status()

        latest_model = model_manager.get_latest_model("*")

        if latest_model and os.path.exists(latest_model):
            try:
                model_data = model_manager.load_model(latest_model)
                if model_data and "metadata" in model_data:
                    metadata = model_data["metadata"]
                    model_info = {
                        # åŸºæœ¬æ€§èƒ½æŒ‡æ¨™
                        "accuracy": metadata.get("accuracy", 0.0),
                        "precision": metadata.get("precision", 0.0),
                        "recall": metadata.get("recall", 0.0),
                        "f1_score": metadata.get("f1_score", 0.0),
                        # AUCæŒ‡æ¨™
                        "auc_score": metadata.get("auc_score", 0.0),
                        "auc_roc": metadata.get("auc_roc", 0.0),
                        "auc_pr": metadata.get("auc_pr", 0.0),
                        # é«˜åº¦ãªæŒ‡æ¨™
                        "balanced_accuracy": metadata.get("balanced_accuracy", 0.0),
                        "matthews_corrcoef": metadata.get("matthews_corrcoef", 0.0),
                        "cohen_kappa": metadata.get("cohen_kappa", 0.0),
                        # å°‚é–€æŒ‡æ¨™
                        "specificity": metadata.get("specificity", 0.0),
                        "sensitivity": metadata.get("sensitivity", 0.0),
                        "npv": metadata.get("npv", 0.0),
                        "ppv": metadata.get("ppv", 0.0),
                        # ç¢ºç‡æŒ‡æ¨™
                        "log_loss": metadata.get("log_loss", 0.0),
                        "brier_score": metadata.get("brier_score", 0.0),
                        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
                        "model_type": metadata.get("model_type", "LightGBM"),
                        "last_updated": datetime.fromtimestamp(
                            os.path.getmtime(latest_model)
                        ).isoformat(),
                        "training_samples": metadata.get("training_samples", 0),
                        "test_samples": metadata.get("test_samples", 0),
                        "file_size_mb": os.path.getsize(latest_model) / (1024 * 1024),
                        "feature_count": metadata.get("feature_count", 0),
                        "num_classes": metadata.get("num_classes", 2),
                        "best_iteration": metadata.get("best_iteration", 0),
                        # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                        "train_test_split": metadata.get("train_test_split", 0.8),
                        "random_state": metadata.get("random_state", 42),
                        # ç‰¹å¾´é‡é‡è¦åº¦ã¨ãƒ¬ãƒãƒ¼ãƒˆ
                        "feature_importance": metadata.get("feature_importance", {}),
                        "classification_report": metadata.get(
                            "classification_report", {}
                        ),
                    }

                    # classification_reportã‹ã‚‰è©³ç´°æŒ‡æ¨™ã‚’æŠ½å‡ºï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ç›´æ¥ãªã„å ´åˆï¼‰
                    if "classification_report" in metadata:
                        report = metadata["classification_report"]
                        if isinstance(report, dict) and "macro avg" in report:
                            macro_avg = report["macro avg"]
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ç›´æ¥å€¤ãŒãªã„å ´åˆã®ã¿ä¸Šæ›¸ã
                            if model_info["precision"] == 0.0:
                                model_info["precision"] = macro_avg.get(
                                    "precision", 0.0
                                )
                            if model_info["recall"] == 0.0:
                                model_info["recall"] = macro_avg.get("recall", 0.0)
                            if model_info["f1_score"] == 0.0:
                                model_info["f1_score"] = macro_avg.get("f1-score", 0.0)

                    logger.info(
                        f"ğŸ“Š ML Status API - ãƒ¢ãƒ‡ãƒ«è©³ç´°æƒ…å ±ã‚’å–å¾—: ç²¾åº¦={model_info['accuracy']:.4f}, F1={model_info['f1_score']:.4f}, ç‰¹å¾´é‡={model_info['feature_count']}å€‹"
                    )
                else:
                    model_info = {
                        "accuracy": 0.0,
                        "model_type": "LightGBM",
                        "last_updated": datetime.fromtimestamp(
                            os.path.getmtime(latest_model)
                        ).isoformat(),
                        "training_samples": 0,
                        "file_size_mb": os.path.getsize(latest_model) / (1024 * 1024),
                        "feature_count": 0,
                    }
                status["model_info"] = model_info

                performance_metrics = performance_extractor.extract_performance_metrics(
                    latest_model
                )
                status["performance_metrics"] = performance_metrics
            except Exception as e:
                logger.warning(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                status["model_info"] = {
                    "accuracy": 0.0,
                    "model_type": "Unknown",
                    "last_updated": datetime.fromtimestamp(
                        os.path.getmtime(latest_model)
                    ).isoformat(),
                    "training_samples": 0,
                    "file_size_mb": os.path.getsize(latest_model) / (1024 * 1024),
                    "feature_count": 0,
                }
                status["performance_metrics"] = {
                    # åŸºæœ¬æŒ‡æ¨™
                    "accuracy": 0.0,
                    "precision": 0.0,
                    "recall": 0.0,
                    "f1_score": 0.0,
                    # AUCæŒ‡æ¨™
                    "auc_score": 0.0,
                    "auc_roc": 0.0,
                    "auc_pr": 0.0,
                    # é«˜åº¦ãªæŒ‡æ¨™
                    "balanced_accuracy": 0.0,
                    "matthews_corrcoef": 0.0,
                    "cohen_kappa": 0.0,
                    # å°‚é–€æŒ‡æ¨™
                    "specificity": 0.0,
                    "sensitivity": 0.0,
                    "npv": 0.0,
                    "ppv": 0.0,
                    # ç¢ºç‡æŒ‡æ¨™
                    "log_loss": 0.0,
                    "brier_score": 0.0,
                    # ãã®ä»–
                    "loss": 0.0,
                    "val_accuracy": 0.0,
                    "val_loss": 0.0,
                    "training_time": 0.0,
                }

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹æƒ…å ±ã‚’è¿½åŠ 
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ã¯ ml_training.py ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å–å¾—
        # ã“ã“ã§ã¯çŠ¶æ…‹ã‚’è¿”ã•ãªã„

        return status

    return await UnifiedErrorHandler.safe_execute_async(_get_ml_status)


@router.get("/feature-importance")
async def get_feature_importance(top_n: int = 10):
    """
    ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—

    Args:
        top_n: ä¸Šä½Nå€‹ã®ç‰¹å¾´é‡

    Returns:
        ç‰¹å¾´é‡é‡è¦åº¦
    """

    async def _get_feature_importance():
        feature_importance = ml_orchestrator.get_feature_importance(top_n)
        return {"feature_importance": feature_importance}

    return await UnifiedErrorHandler.safe_execute_async(_get_feature_importance)


@router.get("/automl-feature-analysis")
async def get_automl_feature_analysis(top_n: int = 20):
    """
    AutoMLç‰¹å¾´é‡åˆ†æçµæœã‚’å–å¾—

    Args:
        top_n: åˆ†æã™ã‚‹ä¸Šä½ç‰¹å¾´é‡æ•°

    Returns:
        AutoMLç‰¹å¾´é‡åˆ†æçµæœ
    """

    async def _get_automl_feature_analysis():
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        feature_importance = ml_orchestrator.get_feature_importance(
            100
        )  # ã‚ˆã‚Šå¤šãã®ç‰¹å¾´é‡ã‚’å–å¾—

        if not feature_importance:
            return {"error": "ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}

        # AutoMLç‰¹å¾´é‡åˆ†æã‚’å®Ÿè¡Œ
        from app.core.services.ml.feature_engineering.automl_feature_analyzer import (
            AutoMLFeatureAnalyzer,
        )

        analyzer = AutoMLFeatureAnalyzer()
        analysis_result = analyzer.analyze_feature_importance(feature_importance, top_n)

        return analysis_result

    return await UnifiedErrorHandler.safe_execute_async(_get_automl_feature_analysis)


@router.get("/automl-presets")
async def get_automl_presets():
    """
    AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—

    Returns:
        AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§
    """

    async def _get_automl_presets():
        from app.core.services.ml.feature_engineering.automl_preset_service import (
            AutoMLPresetService,
        )

        preset_service = AutoMLPresetService()
        presets = preset_service.get_all_presets()

        return {
            "presets": [
                {
                    "name": preset.name,
                    "description": preset.description,
                    "market_condition": preset.market_condition.value,
                    "trading_strategy": preset.trading_strategy.value,
                    "data_size": preset.data_size.value,
                    "config": preset.config,
                    "performance_notes": preset.performance_notes,
                }
                for preset in presets
            ],
            "summary": preset_service.get_preset_summary(),
        }

    return await UnifiedErrorHandler.safe_execute_async(_get_automl_presets)


@router.get("/automl-presets/{preset_name}")
async def get_automl_preset(preset_name: str):
    """
    ç‰¹å®šã®AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆã‚’å–å¾—

    Args:
        preset_name: ãƒ—ãƒªã‚»ãƒƒãƒˆå

    Returns:
        AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆ
    """

    async def _get_automl_preset():
        from app.core.services.ml.feature_engineering.automl_preset_service import (
            AutoMLPresetService,
        )

        try:
            preset_service = AutoMLPresetService()
            preset = preset_service.get_preset_by_name(preset_name)

            return {
                "name": preset.name,
                "description": preset.description,
                "market_condition": preset.market_condition.value,
                "trading_strategy": preset.trading_strategy.value,
                "data_size": preset.data_size.value,
                "config": preset.config,
                "performance_notes": preset.performance_notes,
            }
        except ValueError as e:
            return {"error": str(e)}

    return await UnifiedErrorHandler.safe_execute_async(_get_automl_preset)


@router.post("/automl-presets/recommend")
async def recommend_automl_preset(
    market_condition: str = None, trading_strategy: str = None, data_size: str = None
):
    """
    æ¡ä»¶ã«åŸºã¥ã„ã¦AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆã‚’æ¨å¥¨

    Args:
        market_condition: å¸‚å ´æ¡ä»¶
        trading_strategy: å–å¼•æˆ¦ç•¥
        data_size: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º

    Returns:
        æ¨å¥¨AutoMLè¨­å®šãƒ—ãƒªã‚»ãƒƒãƒˆ
    """

    async def _recommend_automl_preset():
        from app.core.services.ml.feature_engineering.automl_preset_service import (
            AutoMLPresetService,
            MarketCondition,
            TradingStrategy,
            DataSize,
        )

        preset_service = AutoMLPresetService()

        # æ–‡å­—åˆ—ã‚’Enumã«å¤‰æ›
        market_cond = None
        if market_condition:
            try:
                market_cond = MarketCondition(market_condition)
            except ValueError:
                pass

        trading_strat = None
        if trading_strategy:
            try:
                trading_strat = TradingStrategy(trading_strategy)
            except ValueError:
                pass

        data_sz = None
        if data_size:
            try:
                data_sz = DataSize(data_size)
            except ValueError:
                pass

        # ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’æ¨å¥¨
        preset = preset_service.recommend_preset(
            market_condition=market_cond,
            trading_strategy=trading_strat,
            data_size=data_sz,
        )

        return {
            "recommended_preset": {
                "name": preset.name,
                "description": preset.description,
                "market_condition": preset.market_condition.value,
                "trading_strategy": preset.trading_strategy.value,
                "data_size": preset.data_size.value,
                "config": preset.config,
                "performance_notes": preset.performance_notes,
            },
            "recommendation_criteria": {
                "market_condition": market_condition,
                "trading_strategy": trading_strategy,
                "data_size": data_size,
            },
        }

    return await UnifiedErrorHandler.safe_execute_async(_recommend_automl_preset)


@router.get("/config")
async def get_ml_config():
    """
    MLè¨­å®šã‚’å–å¾—

    Returns:
        MLè¨­å®š
    """

    async def _get_ml_config():
        config_dict = {
            "data_processing": {
                "max_ohlcv_rows": ml_config.data_processing.MAX_OHLCV_ROWS,
                "max_feature_rows": ml_config.data_processing.MAX_FEATURE_ROWS,
                "feature_calculation_timeout": ml_config.data_processing.FEATURE_CALCULATION_TIMEOUT,
                "model_training_timeout": ml_config.data_processing.MODEL_TRAINING_TIMEOUT,
            },
            "model": {
                "model_save_path": ml_config.model.MODEL_SAVE_PATH,
                "max_model_versions": ml_config.model.MAX_MODEL_VERSIONS,
                "model_retention_days": ml_config.model.MODEL_RETENTION_DAYS,
            },
            "lightgbm": {
                "learning_rate": ml_config.lightgbm.LEARNING_RATE,
                "num_leaves": ml_config.lightgbm.NUM_LEAVES,
                "feature_fraction": ml_config.lightgbm.FEATURE_FRACTION,
                "bagging_fraction": ml_config.lightgbm.BAGGING_FRACTION,
                "num_boost_round": ml_config.lightgbm.NUM_BOOST_ROUND,
                "early_stopping_rounds": ml_config.lightgbm.EARLY_STOPPING_ROUNDS,
            },
            "training": {
                "train_test_split": ml_config.training.TRAIN_TEST_SPLIT,
                "prediction_horizon": ml_config.training.PREDICTION_HORIZON,
                "threshold_up": ml_config.training.THRESHOLD_UP,
                "threshold_down": ml_config.training.THRESHOLD_DOWN,
                "min_training_samples": ml_config.training.MIN_TRAINING_SAMPLES,
            },
            "prediction": {
                "default_up_prob": ml_config.prediction.DEFAULT_UP_PROB,
                "default_down_prob": ml_config.prediction.DEFAULT_DOWN_PROB,
                "default_range_prob": ml_config.prediction.DEFAULT_RANGE_PROB,
            },
        }

        return config_dict

    return await UnifiedErrorHandler.safe_execute_async(_get_ml_config)


@router.put("/config")
async def update_ml_config(config_data: Dict[str, Any]):
    """
    MLè¨­å®šã‚’æ›´æ–°

    Args:
        config_data: æ›´æ–°ã™ã‚‹è¨­å®šãƒ‡ãƒ¼ã‚¿
    """

    async def _update_ml_config():
        # TODO: è¨­å®šã®æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        # ç¾åœ¨ã¯èª­ã¿å–ã‚Šå°‚ç”¨ã¨ã—ã¦æ‰±ã†
        logger.info(f"MLè¨­å®šæ›´æ–°è¦æ±‚: {config_data}")
        return APIResponseHelper.api_response(
            success=True, message="è¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸï¼ˆç¾åœ¨ã¯èª­ã¿å–ã‚Šå°‚ç”¨ï¼‰"
        )

    return await UnifiedErrorHandler.safe_execute_async(_update_ml_config)


@router.post("/config/reset")
async def reset_ml_config():
    """
    MLè¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆ
    """

    async def _reset_ml_config():
        # TODO: è¨­å®šã®ãƒªã‚»ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        logger.info("MLè¨­å®šãƒªã‚»ãƒƒãƒˆè¦æ±‚")
        return {
            "message": "è¨­å®šãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸï¼ˆç¾åœ¨ã¯èª­ã¿å–ã‚Šå°‚ç”¨ï¼‰"
        }

    return await UnifiedErrorHandler.safe_execute_async(_reset_ml_config)


@router.post("/models/cleanup")
async def cleanup_old_models():
    """
    å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    """

    async def _cleanup_old_models():
        model_manager.cleanup_expired_models()
        return {"message": "å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ"}

    return await UnifiedErrorHandler.safe_execute_async(_cleanup_old_models)


def get_data_service(db: Session = Depends(get_db)) -> BacktestDataService:
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥"""
    ohlcv_repo = OHLCVRepository(db)
    oi_repo = OpenInterestRepository(db)
    fr_repo = FundingRateRepository(db)
    return BacktestDataService(ohlcv_repo, oi_repo, fr_repo)
