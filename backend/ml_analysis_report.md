# 【最終報告書】MLモデルの精度およびAutoMLのメモリ使用率に関する調査

## 1. 総括：システムの致命的な欠陥「Garbage In, Garbage Out」

本調査の結果、MLモデルの精度が低い問題とAutoMLのメモリ使用率が高い問題は、単なる個別機能のバグではなく、**システム全体の設計と連携における構造的な欠陥**に起因することが判明した。

現在のシステムは、信頼性の低い、あるいは全く無意味なML予測（Garbage In）を入力として、遺伝的アルゴリズムがそのノイズに対して最適化を行い、結果として**全く実用性のない取引戦略（Garbage Out）を量産する**という、致命的な「負の連鎖」に陥っている。

この状態では、システムは一見正常に動作しているように見えながら、その実、**資産を危険に晒す可能性のある取引戦略を生成し続けている**危険性が極めて高い。

---

## 2. 問題の核心：「負の連鎖」のメカニズム

なぜ「Garbage In, Garbage Out」が発生するのか。そのメカニズムは、以下の4つのステップで構成される。

### ステップ1：【入力】信頼性の低いMLモデルの生成

MLモデルのトレーニング段階には、以下の深刻な問題が存在し、これが全ての元凶となっている。

*   **AutoML機能の未統合:** 高度な特徴量生成を行う`EnhancedFeatureEngineeringService`が、最終的な予測パイプラインである`MLOrchestrator`から**一切呼び出されていない**。
*   **非効率な処理フロー:** トレーニング時の特徴量生成フローは、メモリ消費の激しいライブラリ（特に`Featuretools`）を無制御に使用し、最後にまとめて特徴量選択を行うため、メモリを圧迫し、しばしばトレーニングの失敗を引き起こす。
*   **不適切なデータ処理:** 欠損値を単純に`0`で埋めるなど、モデルの精度を低下させる不適切なデータ前処理が行われている。
*   **リソース解放の欠如:** トレーニング終了後、使用したリソースを解放するクリーンアップ処理が実装されておらず、メモリリークを引き起こしている。

これらの結果、生成されるMLモデルは**「AutoMLの恩恵を全く受けていない」「低品質なデータで学習した」「そもそも学習が完了していない」**という、信頼性に著しく欠けるものとなる。

### ステップ2：【隠蔽】エラーを隠蔽し、無意味な予測値を生成

予測を担う`MLOrchestrator`は、ステップ1で生成された信頼性の低いモデルを使って予測を行う。しかし、ここにはさらに深刻な問題が存在する。

*   **異常の隠蔽:** モデルの予測時に何らかのエラーが発生した場合、システムは**エラーを記録せず、事前に定義された固定のデフォルト確率（例: UP 0.4, DOWN 0.3）を返す**。

この「偽りの正常応答」により、モデル学習の失敗や予測エラーといった**致命的な異常が完全に隠蔽**され、無意味な数値が後続の処理に渡される。

### ステップ3：【解釈】無意味な数値を「指標」として無批判に受容

`IndicatorCalculator`は、`MLOrchestrator`から渡された数値を、RSIやMACDといった伝統的なテクニカル指標と全く同列の**「ML指標」として無批判に受け入れる**。

渡された数値が、信頼性の低いモデルによる予測結果なのか、あるいは単なる固定のデフォルト値なのかを検証する仕組みは一切存在しない。

### ステップ4：【出力】ゴミ指標に基づいた「最適化」という名のランダムウォーク

システムの最終段である`GeneticAlgorithmEngine`は、この信頼性ゼロの「ML指標」を判断材料として、取引戦略の優劣を評価（バックテスト）し、その結果に基づいて「最適化」を行う。

これは、**ノイズや偶然に対して最適化を行っている**に等しく、生成される「最良戦略」は、特定の期間のデータに過剰適合しただけの、全く実用性のないものとなる。

---

## 3. 改善提言：MLパイプラインの全面的な再設計

この負の連鎖を断ち切るには、小手先の修正ではなく、システムの安定化と信頼性確保を目的とした、抜本的な改善が不可欠である。

### 3.1. 緊急対応（システムの即時安定化）

1.  **Featuretoolsの利用停止:** メモリ問題の主犯であり、現状では効果的に利用できていない`Featuretools`は、**MLパイプラインから完全に削除する**。
2.  **フォールバック処理の厳格化:** `MLOrchestrator`が安易にデフォルト値を返すのをやめ、**予測エラー時には明確なエラーを発生させ、処理を停止させる**。システムの異常を可視化することが最優先である。
3.  **クリーンアップ処理の実装:** `MLTrainingOrchestrationService`に、トレーニングプロセス終了時に必ずリソースを解放する処理を実装する。

### 3.2. 中期対応（MLパイプラインの再設計）

1.  **予測パイプラインへのAutoML統合:** `MLOrchestrator`が、`EnhancedFeatureEngineeringService`を正しく呼び出すように、処理フローを全面的に修正する。
2.  **特徴量生成フローの効率化:** `EnhancedFeatureEngineeringService`の処理フローを、以下の**ステップ・バイ・ステップ方式**にリファクタリングする。これにより、メモリ負荷を低減し、各ステップで特徴量の質を担保する。
    *   ① 手動特徴量を計算。
    *   ② **TSFresh**で特徴量を生成 → 即座に**特徴量選択**。
    *   ③ **AutoFeat**を実行 → 即座に**特徴量選択**。
    *   ④ 各ステップで厳選された特徴量を結合し、最終的なモデル学習に利用する。
3.  **データ前処理の改善:** 欠損値処理を`fillna(0)`から、`SimpleImputer`を使った**平均値や中央値による補完**に全面的に切り替える。

### 3.3. 長期対応（開発・運用プロセスの改善）

1.  **統合テストの義務化:** 新しいML機能を開発した際は、必ずトレーニングから戦略生成までの一連の流れを検証する**統合テスト**を作成し、パスすることを必須とする。
2.  **モデル性能の継続的な監視:** 本番環境で稼働しているモデルの精度（Accuracy, F1-scoreなど）を定期的に監視し、一定の閾値を下回った場合に**アラートを発する仕組み**を導入する。

これにて、本調査を完了とする。