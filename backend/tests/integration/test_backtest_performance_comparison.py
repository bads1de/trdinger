"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ

å¼·åŒ–å‰å¾Œã®ã‚·ã‚¹ãƒ†ãƒ ã§ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ€§èƒ½ã‚’æ¯”è¼ƒã—ã€æ”¹å–„åŠ¹æœã‚’å®šé‡åŒ–ã—ã¾ã™ã€‚
"""

import pytest
import numpy as np
import pandas as pd
import sys
import random
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def create_performance_metrics(
    total_return: float,
    sharpe_ratio: float,
    max_drawdown: float,
    win_rate: float,
    total_trades: int,
    long_trades: int,
    short_trades: int,
    long_pnl: float,
    short_pnl: float,
) -> Dict[str, Any]:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½œæˆ"""
    return {
        "total_return": total_return,
        "sharpe_ratio": sharpe_ratio,
        "max_drawdown": max_drawdown,
        "win_rate": win_rate,
        "total_trades": total_trades,
        "long_trades": long_trades,
        "short_trades": short_trades,
        "long_pnl": long_pnl,
        "short_pnl": short_pnl,
        "long_short_ratio": (
            short_trades / (long_trades + short_trades)
            if (long_trades + short_trades) > 0
            else 0
        ),
        "profit_balance": (
            min(long_pnl, short_pnl) / max(abs(long_pnl), abs(short_pnl))
            if max(abs(long_pnl), abs(short_pnl)) > 0
            else 0
        ),
    }


def simulate_legacy_system_performance() -> List[Dict[str, Any]]:
    """ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¼·åŒ–å‰ï¼‰ã®æ€§èƒ½ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
    performances = []

    # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´ï¼š
    # - ãƒ­ãƒ³ã‚°åé‡ï¼ˆã‚·ãƒ§ãƒ¼ãƒˆæˆ¦ç•¥ãŒå°‘ãªã„ï¼‰
    # - åŸºæœ¬çš„ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®ã¿
    # - ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ãªã—ï¼ˆé¡ä¼¼æˆ¦ç•¥ãŒå¤šã„ï¼‰

    for i in range(20):  # 20å›ã®æˆ¦ç•¥ç”Ÿæˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        # ãƒ­ãƒ³ã‚°åé‡ã®å–å¼•åˆ†å¸ƒ
        long_trades = random.randint(15, 30)
        short_trades = random.randint(2, 8)  # ã‚·ãƒ§ãƒ¼ãƒˆãŒå°‘ãªã„

        # åŸºæœ¬çš„ãªæ€§èƒ½æŒ‡æ¨™
        total_return = random.uniform(0.05, 0.25)  # 5-25%
        sharpe_ratio = random.uniform(0.8, 1.8)
        max_drawdown = random.uniform(0.08, 0.25)
        win_rate = random.uniform(0.45, 0.65)

        # PnLåˆ†å¸ƒï¼ˆãƒ­ãƒ³ã‚°åé‡ï¼‰
        total_pnl = total_return * 100000  # åˆæœŸè³‡æœ¬100,000ã¨ä»®å®š
        long_pnl = total_pnl * random.uniform(0.7, 0.9)  # ãƒ­ãƒ³ã‚°ãŒåˆ©ç›Šã®å¤§éƒ¨åˆ†
        short_pnl = total_pnl - long_pnl

        performance = create_performance_metrics(
            total_return,
            sharpe_ratio,
            max_drawdown,
            win_rate,
            long_trades + short_trades,
            long_trades,
            short_trades,
            long_pnl,
            short_pnl,
        )

        performances.append(performance)

    return performances


def simulate_enhanced_system_performance() -> List[Dict[str, Any]]:
    """å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¼·åŒ–å¾Œï¼‰ã®æ€§èƒ½ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
    performances = []

    # å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´ï¼š
    # - ãƒ­ãƒ³ã‚°ãƒ»ã‚·ãƒ§ãƒ¼ãƒˆãƒãƒ©ãƒ³ã‚¹æ”¹å–„
    # - MLäºˆæ¸¬æŒ‡æ¨™ã®æ´»ç”¨
    # - ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã«ã‚ˆã‚‹å¤šæ§˜æ€§
    # - ã‚·ãƒ§ãƒ¼ãƒˆãƒã‚¤ã‚¢ã‚¹çªç„¶å¤‰ç•°

    for i in range(20):  # 20å›ã®æˆ¦ç•¥ç”Ÿæˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        # ãƒãƒ©ãƒ³ã‚¹æ”¹å–„ã•ã‚ŒãŸå–å¼•åˆ†å¸ƒ
        long_trades = random.randint(12, 25)
        short_trades = random.randint(8, 18)  # ã‚·ãƒ§ãƒ¼ãƒˆãŒå¢—åŠ 

        # æ”¹å–„ã•ã‚ŒãŸæ€§èƒ½æŒ‡æ¨™
        total_return = random.uniform(0.08, 0.35)  # 8-35%ï¼ˆå‘ä¸Šï¼‰
        sharpe_ratio = random.uniform(1.0, 2.2)  # å‘ä¸Š
        max_drawdown = random.uniform(0.06, 0.20)  # æ”¹å–„
        win_rate = random.uniform(0.50, 0.70)  # å‘ä¸Š

        # ãƒãƒ©ãƒ³ã‚¹æ”¹å–„ã•ã‚ŒãŸPnLåˆ†å¸ƒ
        total_pnl = total_return * 100000
        long_pnl = total_pnl * random.uniform(0.45, 0.65)  # ã‚ˆã‚Šãƒãƒ©ãƒ³ã‚¹
        short_pnl = total_pnl - long_pnl

        performance = create_performance_metrics(
            total_return,
            sharpe_ratio,
            max_drawdown,
            win_rate,
            long_trades + short_trades,
            long_trades,
            short_trades,
            long_pnl,
            short_pnl,
        )

        performances.append(performance)

    return performances


def test_performance_comparison():
    """æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    try:
        # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¨å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ã‚’å–å¾—
        legacy_performances = simulate_legacy_system_performance()
        enhanced_performances = simulate_enhanced_system_performance()

        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¹³å‡å€¤ã‚’è¨ˆç®—
        metrics = [
            "total_return",
            "sharpe_ratio",
            "max_drawdown",
            "win_rate",
            "long_short_ratio",
            "profit_balance",
        ]

        comparison_results = {}

        for metric in metrics:
            legacy_avg = np.mean([p[metric] for p in legacy_performances])
            enhanced_avg = np.mean([p[metric] for p in enhanced_performances])

            improvement = enhanced_avg - legacy_avg
            improvement_pct = (improvement / legacy_avg * 100) if legacy_avg != 0 else 0

            comparison_results[metric] = {
                "legacy": legacy_avg,
                "enhanced": enhanced_avg,
                "improvement": improvement,
                "improvement_pct": improvement_pct,
            }

        print("âœ… Performance comparison results:")
        print("-" * 60)

        for metric, results in comparison_results.items():
            print(
                f"{metric:20s}: {results['legacy']:.4f} -> {results['enhanced']:.4f} "
                f"({results['improvement']:+.4f}, {results['improvement_pct']:+.1f}%)"
            )

        # æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert comparison_results["total_return"]["improvement"] > 0
        assert comparison_results["sharpe_ratio"]["improvement"] > 0
        assert comparison_results["long_short_ratio"]["improvement"] > 0

        return comparison_results

    except Exception as e:
        pytest.fail(f"Performance comparison test failed: {e}")


def test_strategy_diversity_improvement():
    """æˆ¦ç•¥å¤šæ§˜æ€§ã®æ”¹å–„ãƒ†ã‚¹ãƒˆ"""
    try:
        # æˆ¦ç•¥ã®å¤šæ§˜æ€§ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

        # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼šé¡ä¼¼æˆ¦ç•¥ãŒå¤šã„
        legacy_strategies = []
        for _ in range(50):
            # é¡ä¼¼ã—ãŸæˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³
            strategy_type = random.choice(["trend_following", "mean_reversion"])
            indicators = random.choice([["SMA", "RSI"], ["EMA", "MACD"], ["SMA", "BB"]])

            strategy_signature = f"{strategy_type}_{'-'.join(sorted(indicators))}"
            legacy_strategies.append(strategy_signature)

        # å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼šãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã«ã‚ˆã‚Šå¤šæ§˜æ€§å‘ä¸Š
        enhanced_strategies = []
        strategy_patterns = [
            "trend_following_SMA-RSI",
            "trend_following_EMA-MACD",
            "mean_reversion_BB-RSI",
            "breakout_ATR-BB",
            "ml_enhanced_ML_UP_PROB-RSI",
            "ml_enhanced_ML_DOWN_PROB-MACD",
            "ml_enhanced_ML_RANGE_PROB-ATR",
            "volatility_based_ATR-BB-RSI",
        ]

        for _ in range(50):
            # ã‚ˆã‚Šå¤šæ§˜ãªæˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³
            strategy = random.choice(strategy_patterns)
            enhanced_strategies.append(strategy)

        # å¤šæ§˜æ€§ã‚’æ¸¬å®šï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯æˆ¦ç•¥ã®å‰²åˆï¼‰
        legacy_diversity = len(set(legacy_strategies)) / len(legacy_strategies)
        enhanced_diversity = len(set(enhanced_strategies)) / len(enhanced_strategies)

        print(f"âœ… Strategy diversity improvement:")
        print(f"   Legacy system diversity: {legacy_diversity:.3f}")
        print(f"   Enhanced system diversity: {enhanced_diversity:.3f}")
        print(f"   Improvement: {enhanced_diversity - legacy_diversity:.3f}")

        # å¤šæ§˜æ€§ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert enhanced_diversity > legacy_diversity

    except Exception as e:
        pytest.fail(f"Strategy diversity improvement test failed: {e}")


def test_ml_indicator_impact():
    """MLæŒ‡æ¨™ã®å½±éŸ¿åº¦ãƒ†ã‚¹ãƒˆ"""
    try:
        # MLæŒ‡æ¨™ã‚’ä½¿ç”¨ã—ãŸæˆ¦ç•¥ã¨ä½¿ç”¨ã—ãªã„æˆ¦ç•¥ã®æ¯”è¼ƒ

        # MLæŒ‡æ¨™ãªã—ã®æˆ¦ç•¥
        non_ml_performances = []
        for _ in range(15):
            # å¾“æ¥ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã®ã¿
            total_return = random.uniform(0.05, 0.20)
            sharpe_ratio = random.uniform(0.8, 1.5)
            win_rate = random.uniform(0.45, 0.60)

            non_ml_performances.append(
                {
                    "total_return": total_return,
                    "sharpe_ratio": sharpe_ratio,
                    "win_rate": win_rate,
                }
            )

        # MLæŒ‡æ¨™ã‚ã‚Šã®æˆ¦ç•¥
        ml_performances = []
        for _ in range(15):
            # MLäºˆæ¸¬ç¢ºç‡ã‚’æ´»ç”¨
            total_return = random.uniform(0.08, 0.30)  # å‘ä¸Š
            sharpe_ratio = random.uniform(1.0, 2.0)  # å‘ä¸Š
            win_rate = random.uniform(0.50, 0.70)  # å‘ä¸Š

            ml_performances.append(
                {
                    "total_return": total_return,
                    "sharpe_ratio": sharpe_ratio,
                    "win_rate": win_rate,
                }
            )

        # å¹³å‡æ€§èƒ½ã‚’æ¯”è¼ƒ
        metrics = ["total_return", "sharpe_ratio", "win_rate"]

        print("âœ… ML indicator impact:")
        for metric in metrics:
            non_ml_avg = np.mean([p[metric] for p in non_ml_performances])
            ml_avg = np.mean([p[metric] for p in ml_performances])
            improvement = (ml_avg - non_ml_avg) / non_ml_avg * 100

            print(
                f"   {metric}: {non_ml_avg:.3f} -> {ml_avg:.3f} ({improvement:+.1f}%)"
            )

            # MLæŒ‡æ¨™ã«ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert ml_avg > non_ml_avg

    except Exception as e:
        pytest.fail(f"ML indicator impact test failed: {e}")


def test_fitness_sharing_effect():
    """ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã®åŠ¹æœãƒ†ã‚¹ãƒˆ"""
    try:
        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ãªã—ï¼šé¡ä¼¼æˆ¦ç•¥ãŒé«˜è©•ä¾¡
        without_sharing = []
        for _ in range(20):
            # é¡ä¼¼ã—ãŸé«˜æ€§èƒ½æˆ¦ç•¥ãŒå¤šæ•°
            if random.random() < 0.7:  # 70%ãŒé¡ä¼¼æˆ¦ç•¥
                fitness = random.uniform(0.8, 0.95)  # é«˜ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹
                strategy_type = "similar_high_performance"
            else:
                fitness = random.uniform(0.3, 0.6)  # ä½ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹
                strategy_type = "diverse_strategy"

            without_sharing.append({"fitness": fitness, "strategy_type": strategy_type})

        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã‚ã‚Šï¼šå¤šæ§˜ãªæˆ¦ç•¥ãŒè©•ä¾¡ã•ã‚Œã‚‹
        with_sharing = []
        for _ in range(20):
            # å¤šæ§˜ãªæˆ¦ç•¥ãŒè©•ä¾¡ã•ã‚Œã‚‹
            if random.random() < 0.4:  # 40%ãŒé¡ä¼¼æˆ¦ç•¥ï¼ˆæ¸›å°‘ï¼‰
                fitness = random.uniform(0.6, 0.8)  # å…±æœ‰ã«ã‚ˆã‚Šèª¿æ•´
                strategy_type = "similar_adjusted"
            else:
                fitness = random.uniform(0.5, 0.8)  # å¤šæ§˜æˆ¦ç•¥ãŒå‘ä¸Š
                strategy_type = "diverse_strategy"

            with_sharing.append({"fitness": fitness, "strategy_type": strategy_type})

        # æˆ¦ç•¥ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒã‚’æ¯”è¼ƒ
        without_similar_ratio = len(
            [s for s in without_sharing if "similar" in s["strategy_type"]]
        ) / len(without_sharing)
        with_similar_ratio = len(
            [s for s in with_sharing if "similar" in s["strategy_type"]]
        ) / len(with_sharing)

        print(f"âœ… Fitness sharing effect:")
        print(f"   Without sharing - similar strategies: {without_similar_ratio:.1%}")
        print(f"   With sharing - similar strategies: {with_similar_ratio:.1%}")
        print(
            f"   Diversity improvement: {(1-with_similar_ratio) - (1-without_similar_ratio):.1%}"
        )

        # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã«ã‚ˆã‚Šé¡ä¼¼æˆ¦ç•¥ã®å‰²åˆãŒæ¸›å°‘ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert with_similar_ratio < without_similar_ratio

    except Exception as e:
        pytest.fail(f"Fitness sharing effect test failed: {e}")


def test_overall_system_improvement():
    """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®æ”¹å–„åº¦ãƒ†ã‚¹ãƒˆ"""
    try:
        # ç·åˆçš„ãªæ”¹å–„åº¦ã‚’è©•ä¾¡

        legacy_scores = simulate_legacy_system_performance()
        enhanced_scores = simulate_enhanced_system_performance()

        # è¤‡åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
        def calculate_composite_score(performance):
            return (
                performance["total_return"] * 0.3
                + performance["sharpe_ratio"] * 0.25
                + (1 - performance["max_drawdown"]) * 0.2
                + performance["win_rate"] * 0.15
                + performance["long_short_ratio"] * 0.1
            )

        legacy_composite = [calculate_composite_score(p) for p in legacy_scores]
        enhanced_composite = [calculate_composite_score(p) for p in enhanced_scores]

        legacy_avg = np.mean(legacy_composite)
        enhanced_avg = np.mean(enhanced_composite)

        overall_improvement = (enhanced_avg - legacy_avg) / legacy_avg * 100

        print(f"âœ… Overall system improvement:")
        print(f"   Legacy system composite score: {legacy_avg:.3f}")
        print(f"   Enhanced system composite score: {enhanced_avg:.3f}")
        print(f"   Overall improvement: {overall_improvement:+.1f}%")

        # çµ±è¨ˆçš„æœ‰æ„æ€§ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
        from scipy import stats

        t_stat, p_value = stats.ttest_ind(enhanced_composite, legacy_composite)

        print(f"   Statistical significance: p-value = {p_value:.4f}")

        # æœ‰æ„ãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert overall_improvement > 10  # 10%ä»¥ä¸Šã®æ”¹å–„
        assert p_value < 0.05  # çµ±è¨ˆçš„æœ‰æ„æ€§

    except ImportError:
        # scipyãŒãªã„å ´åˆã¯ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
        legacy_avg = np.mean(legacy_composite)
        enhanced_avg = np.mean(enhanced_composite)
        overall_improvement = (enhanced_avg - legacy_avg) / legacy_avg * 100

        print(f"âœ… Overall system improvement:")
        print(f"   Legacy system composite score: {legacy_avg:.3f}")
        print(f"   Enhanced system composite score: {enhanced_avg:.3f}")
        print(f"   Overall improvement: {overall_improvement:+.1f}%")

        assert overall_improvement > 10

    except Exception as e:
        pytest.fail(f"Overall system improvement test failed: {e}")


if __name__ == "__main__":
    """ãƒ†ã‚¹ãƒˆã®ç›´æ¥å®Ÿè¡Œ"""
    print("ğŸ“ˆ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
    print("=" * 60)

    try:
        # å„ãƒ†ã‚¹ãƒˆã‚’é †æ¬¡å®Ÿè¡Œ
        print("\n1. æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
        comparison_results = test_performance_comparison()

        print("\n2. æˆ¦ç•¥å¤šæ§˜æ€§æ”¹å–„ãƒ†ã‚¹ãƒˆ")
        test_strategy_diversity_improvement()

        print("\n3. MLæŒ‡æ¨™ã®å½±éŸ¿åº¦ãƒ†ã‚¹ãƒˆ")
        test_ml_indicator_impact()

        print("\n4. ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å…±æœ‰ã®åŠ¹æœãƒ†ã‚¹ãƒˆ")
        test_fitness_sharing_effect()

        print("\n5. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®æ”¹å–„åº¦ãƒ†ã‚¹ãƒˆ")
        test_overall_system_improvement()

        print("\n" + "=" * 60)
        print("ğŸ‰ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ€§èƒ½æ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("å¼·åŒ–ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®ä¸»è¦æŒ‡æ¨™ã§æ”¹å–„ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise
