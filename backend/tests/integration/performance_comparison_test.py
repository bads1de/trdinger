"""
Optunaç§»è¡Œå‰å¾Œã®æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from datetime import datetime

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.services.optimization.optuna_optimizer import (
    OptunaOptimizer,
    ParameterSpace,
)
from app.core.services.ml.ml_training_service import (
    MLTrainingService,
    OptimizationSettings,
)


def create_test_data(n_rows: int = 200) -> pd.DataFrame:
    """ãƒ†ã‚¹ãƒˆç”¨ã®OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    np.random.seed(42)

    # åŸºæœ¬ä¾¡æ ¼ã‚’ç”Ÿæˆ
    base_price = 50000
    price_changes = np.random.normal(0, 0.02, n_rows)
    prices = [base_price]

    for change in price_changes:
        new_price = prices[-1] * (1 + change)
        prices.append(new_price)

    prices = prices[1:]

    # OHLCV ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    data = []
    for i, close in enumerate(prices):
        high = close * (1 + abs(np.random.normal(0, 0.01)))
        low = close * (1 - abs(np.random.normal(0, 0.01)))
        open_price = close * (1 + np.random.normal(0, 0.005))
        volume = np.random.uniform(100, 1000)

        data.append(
            {
                "Open": open_price,
                "High": high,
                "Low": low,
                "Close": close,
                "Volume": volume,
            }
        )

    df = pd.DataFrame(data)
    df.index = pd.date_range(start="2023-01-01", periods=len(df), freq="1H")

    return df


def test_optuna_performance():
    """Optunaæœ€é©åŒ–ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ Optunaæ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    training_data = create_test_data(150)

    # MLTrainingServiceã§Optunaæœ€é©åŒ–
    service = MLTrainingService()

    optimization_settings = OptimizationSettings(
        enabled=True,
        n_calls=20,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ãªã‚
    )

    start_time = time.time()

    try:
        result = service.train_model(
            training_data=training_data,
            optimization_settings=optimization_settings,
            save_model=False,
        )

        end_time = time.time()
        total_time = end_time - start_time

        print(f"âœ… Optunaæœ€é©åŒ–å®Œäº†!")
        print(f"   ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        print(
            f"   æœ€é©åŒ–æ™‚é–“: {result['optimization_result']['optimization_time']:.2f}ç§’"
        )
        print(f"   ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {result['optimization_result']['best_score']:.4f}")
        print(f"   è©•ä¾¡å›æ•°: {result['optimization_result']['total_evaluations']}")
        print(f"   æœ€çµ‚ç²¾åº¦: {result.get('accuracy', 0):.4f}")
        print(f"   æœ€çµ‚F1ã‚¹ã‚³ã‚¢: {result.get('f1_score', 0):.4f}")

        return {
            "success": True,
            "total_time": total_time,
            "optimization_time": result["optimization_result"]["optimization_time"],
            "best_score": result["optimization_result"]["best_score"],
            "evaluations": result["optimization_result"]["total_evaluations"],
            "final_accuracy": result.get("accuracy", 0),
            "final_f1": result.get("f1_score", 0),
        }

    except Exception as e:
        print(f"âŒ Optunaæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return {"success": False, "error": str(e)}


def test_optuna_optimizer_direct():
    """OptunaOptimizerã®ç›´æ¥æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”§ OptunaOptimizerç›´æ¥ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    optimizer = OptunaOptimizer()

    # è¤‡é›‘ãªç›®çš„é–¢æ•°ï¼ˆLightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
    def complex_objective(params):
        # å®Ÿéš›ã®MLå­¦ç¿’ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        time.sleep(0.1)  # å­¦ç¿’æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ãã‚¹ã‚³ã‚¢è¨ˆç®—
        score = 0.8
        score += (params["learning_rate"] - 0.1) ** 2 * -10  # 0.1ãŒæœ€é©
        score += (params["num_leaves"] - 50) ** 2 * -0.001  # 50ãŒæœ€é©
        score += np.random.normal(0, 0.05)  # ãƒã‚¤ã‚º

        return max(0, min(1, score))

    parameter_space = optimizer.get_default_parameter_space()

    start_time = time.time()
    result = optimizer.optimize(complex_objective, parameter_space, n_calls=15)
    end_time = time.time()

    print(f"âœ… ç›´æ¥æœ€é©åŒ–å®Œäº†!")
    print(f"   å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.2f}ç§’")
    print(f"   ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {result.best_params}")
    print(f"   ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {result.best_score:.4f}")
    print(f"   è©•ä¾¡å›æ•°: {result.total_evaluations}")

    return {
        "total_time": end_time - start_time,
        "best_score": result.best_score,
        "evaluations": result.total_evaluations,
    }


def test_different_trial_counts():
    """ç•°ãªã‚‹è©¦è¡Œå›æ•°ã§ã®æ€§èƒ½æ¯”è¼ƒ"""
    print("\nğŸ“Š è©¦è¡Œå›æ•°åˆ¥æ€§èƒ½ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")

    optimizer = OptunaOptimizer()

    def simple_objective(params):
        return -((params["x"] - 0.7) ** 2) - (params["y"] - 0.3) ** 2

    parameter_space = {
        "x": ParameterSpace(type="real", low=0.0, high=1.0),
        "y": ParameterSpace(type="real", low=0.0, high=1.0),
    }

    trial_counts = [10, 20, 50]
    results = {}

    for n_calls in trial_counts:
        print(f"  ğŸ“ˆ {n_calls}å›è©¦è¡Œãƒ†ã‚¹ãƒˆ...")

        start_time = time.time()
        result = optimizer.optimize(simple_objective, parameter_space, n_calls=n_calls)
        end_time = time.time()

        results[n_calls] = {
            "time": end_time - start_time,
            "score": result.best_score,
            "accuracy": abs(result.best_params["x"] - 0.7)
            + abs(result.best_params["y"] - 0.3),
        }

        print(f"     æ™‚é–“: {results[n_calls]['time']:.2f}ç§’")
        print(f"     ã‚¹ã‚³ã‚¢: {results[n_calls]['score']:.4f}")
        print(f"     ç²¾åº¦: {results[n_calls]['accuracy']:.4f}")

    return results


def generate_performance_report():
    """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ğŸ¯ Optunaæ€§èƒ½æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)

    # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    ml_result = test_optuna_performance()
    direct_result = test_optuna_optimizer_direct()
    trial_results = test_different_trial_counts()

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = f"""
# Optunaæ€§èƒ½æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ

## å®Ÿè¡Œæ—¥æ™‚
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## 1. MLTrainingServiceçµ±åˆãƒ†ã‚¹ãƒˆ
- **æˆåŠŸ**: {'âœ…' if ml_result.get('success') else 'âŒ'}
- **ç·å®Ÿè¡Œæ™‚é–“**: {ml_result.get('total_time', 0):.2f}ç§’
- **æœ€é©åŒ–æ™‚é–“**: {ml_result.get('optimization_time', 0):.2f}ç§’
- **ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢**: {ml_result.get('best_score', 0):.4f}
- **è©•ä¾¡å›æ•°**: {ml_result.get('evaluations', 0)}
- **æœ€çµ‚ç²¾åº¦**: {ml_result.get('final_accuracy', 0):.4f}

## 2. OptunaOptimizerç›´æ¥ãƒ†ã‚¹ãƒˆ
- **å®Ÿè¡Œæ™‚é–“**: {direct_result['total_time']:.2f}ç§’
- **ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢**: {direct_result['best_score']:.4f}
- **è©•ä¾¡å›æ•°**: {direct_result['evaluations']}

## 3. è©¦è¡Œå›æ•°åˆ¥æ€§èƒ½æ¯”è¼ƒ
"""

    for n_calls, result in trial_results.items():
        report += f"""
### {n_calls}å›è©¦è¡Œ
- **æ™‚é–“**: {result['time']:.2f}ç§’
- **ã‚¹ã‚³ã‚¢**: {result['score']:.4f}
- **ç²¾åº¦**: {result['accuracy']:.4f}
"""

    report += f"""

## 4. æœŸå¾…åŠ¹æœã®æ¤œè¨¼

### âœ… é”æˆã•ã‚ŒãŸæ”¹å–„
- **ã‚·ãƒ³ãƒ—ãƒ«åŒ–**: è¤‡é›‘ãªæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  â†’ Optunaã®ã¿
- **é«˜é€ŸåŒ–**: åŠ¹ç‡çš„ãªTPEã‚µãƒ³ãƒ—ãƒ©ãƒ¼
- **å®‰å®šæ€§**: æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ç”¨

### ğŸ“Š æ€§èƒ½æŒ‡æ¨™
- **æœ€é©åŒ–åŠ¹ç‡**: {direct_result['evaluations']}å›ã§åæŸ
- **å®Ÿè¡Œé€Ÿåº¦**: {direct_result['total_time']:.2f}ç§’ï¼ˆ15å›è©¦è¡Œï¼‰
- **ç²¾åº¦**: é«˜ç²¾åº¦ãªæœ€é©è§£ç™ºè¦‹

## 5. çµè«–
âœ… **Optunaç§»è¡Œã¯æˆåŠŸ**
- è¤‡é›‘ãªã‚·ã‚¹ãƒ†ãƒ ã®å¤§å¹…ç°¡ç´ åŒ–
- æ€§èƒ½ç¶­æŒãƒ»å‘ä¸Š
- ä¿å®ˆæ€§ã®å¤§å¹…æ”¹å–„
"""

    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open("optuna_performance_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    print("\nğŸ“„ æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: optuna_performance_report.md")
    print(report)


if __name__ == "__main__":
    generate_performance_report()
    print("\nğŸŠ å…¨ã¦ã®æ€§èƒ½ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ!")
