#!/usr/bin/env python3
"""
ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®é™ç•Œå€¤ã¨ç•°å¸¸çŠ¶æ³ã§ã®å‹•ä½œã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
- ã‚·ã‚¹ãƒ†ãƒ é™ç•Œå€¤ãƒ†ã‚¹ãƒˆ
- ç•°å¸¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ
- ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡çŠ¶æ³ãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ©ãƒ¼å›å¾©èƒ½åŠ›ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import logging
import pandas as pd
import numpy as np
import time
import psutil
import gc
from typing import Dict, List, Any
from dataclasses import dataclass, field
import threading

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
backend_path = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
sys.path.insert(0, backend_path)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class StressTestResult:
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""

    test_name: str
    stress_type: str
    success: bool
    execution_time: float
    error_recovery: bool
    system_stability: bool
    resource_usage: Dict[str, float] = field(default_factory=dict)
    error_message: str = ""
    recovery_details: Dict[str, Any] = field(default_factory=dict)


class StressTestSuite:
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.results: List[StressTestResult] = []
        self.process = psutil.Process()

    def create_corrupted_data(
        self, corruption_type: str, rows: int = 1000
    ) -> pd.DataFrame:
        """ç ´æãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        logger.info(f"ğŸ”¥ {corruption_type}ã‚¿ã‚¤ãƒ—ã®ç ´æãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ: {rows}è¡Œ")

        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        dates = pd.date_range("2024-01-01", periods=rows, freq="h")
        base_data = {
            "Open": np.random.normal(50000, 1000, rows),
            "High": np.random.normal(51000, 1000, rows),
            "Low": np.random.normal(49000, 1000, rows),
            "Close": np.random.normal(50000, 1000, rows),
            "Volume": np.random.lognormal(10, 0.5, rows),
        }

        df = pd.DataFrame(base_data, index=dates)

        if corruption_type == "infinite_values":
            # ç„¡é™å¤§å€¤ã‚’æŒ¿å…¥
            df.iloc[100:110, :] = np.inf
            df.iloc[200:210, :] = -np.inf

        elif corruption_type == "extreme_outliers":
            # æ¥µç«¯ãªå¤–ã‚Œå€¤ã‚’æŒ¿å…¥
            df.iloc[50:60, :] *= 1000000
            df.iloc[150:160, :] /= 1000000

        elif corruption_type == "all_nan":
            # å…¨ã¦NaNã®æœŸé–“ã‚’ä½œæˆ
            df.iloc[300:400, :] = np.nan

        elif corruption_type == "negative_prices":
            # è² ã®ä¾¡æ ¼ã‚’æŒ¿å…¥
            df.iloc[250:300, ["Open", "High", "Low", "Close"]] *= -1

        elif corruption_type == "zero_volume":
            # ã‚¼ãƒ­ãƒœãƒªãƒ¥ãƒ¼ãƒ æœŸé–“
            df.iloc[400:500, "Volume"] = 0

        elif corruption_type == "inconsistent_ohlc":
            # OHLCæ•´åˆæ€§é•å
            df.iloc[500:600, "High"] = df.iloc[500:600, "Low"] - 1000

        elif corruption_type == "duplicate_timestamps":
            # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            duplicate_indices = [dates[i] for i in range(100, 200)]
            df.index = list(df.index[:100]) + duplicate_indices + list(df.index[200:])

        elif corruption_type == "missing_columns":
            # å¿…é ˆã‚«ãƒ©ãƒ ã‚’å‰Šé™¤
            df = df.drop(columns=["Volume", "High"])

        elif corruption_type == "wrong_data_types":
            # é–“é•ã£ãŸãƒ‡ãƒ¼ã‚¿å‹
            df["Close"] = df["Close"].astype(str)
            df["Volume"] = ["invalid"] * len(df)

        elif corruption_type == "time_gaps":
            # æ™‚ç³»åˆ—ã‚®ãƒ£ãƒƒãƒ—
            gap_start = 500
            gap_end = 700
            df = pd.concat([df.iloc[:gap_start], df.iloc[gap_end:]])

        return df

    def test_corrupted_data_handling(self):
        """ç ´æãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”¥ ç ´æãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

        corruption_types = [
            "infinite_values",
            "extreme_outliers",
            "all_nan",
            "negative_prices",
            "zero_volume",
            "inconsistent_ohlc",
            "duplicate_timestamps",
            "missing_columns",
            "wrong_data_types",
            "time_gaps",
        ]

        for corruption_type in corruption_types:
            logger.info(f"ğŸ§ª {corruption_type}ç ´æãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ")

            start_time = time.time()
            initial_memory = self.process.memory_info().rss / 1024**2

            try:
                # ç ´æãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                corrupted_data = self.create_corrupted_data(corruption_type, rows=1000)

                # MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦è¡Œ
                from app.services.ml.single_model.single_model_trainer import (
                    SingleModelTrainer,
                )

                trainer = SingleModelTrainer(model_type="lightgbm")

                result = trainer.train_model(
                    training_data=corrupted_data,
                    save_model=False,
                    threshold_up=0.02,
                    threshold_down=-0.02,
                )

                execution_time = time.time() - start_time
                final_memory = self.process.memory_info().rss / 1024**2

                # æˆåŠŸã—ãŸå ´åˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ©Ÿèƒ½ï¼‰
                self.results.append(
                    StressTestResult(
                        test_name=f"ç ´æãƒ‡ãƒ¼ã‚¿å‡¦ç†_{corruption_type}",
                        stress_type="data_corruption",
                        success=True,
                        execution_time=execution_time,
                        error_recovery=True,
                        system_stability=True,
                        resource_usage={
                            "memory_usage_mb": final_memory - initial_memory,
                            "peak_memory_mb": final_memory,
                        },
                        recovery_details={
                            "data_cleaned": True,
                            "accuracy": result.get("accuracy", 0),
                            "feature_count": result.get("feature_count", 0),
                        },
                    )
                )

                logger.info(
                    f"âœ… {corruption_type}ç ´æãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {execution_time:.2f}ç§’"
                )

            except Exception as e:
                execution_time = time.time() - start_time

                # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
                error_handled_properly = any(
                    keyword in str(e).lower()
                    for keyword in [
                        "ãƒ‡ãƒ¼ã‚¿",
                        "data",
                        "ç„¡åŠ¹",
                        "invalid",
                        "ä¸æ­£",
                        "corrupt",
                    ]
                )

                self.results.append(
                    StressTestResult(
                        test_name=f"ç ´æãƒ‡ãƒ¼ã‚¿å‡¦ç†_{corruption_type}",
                        stress_type="data_corruption",
                        success=False,
                        execution_time=execution_time,
                        error_recovery=error_handled_properly,
                        system_stability=True,  # ã‚·ã‚¹ãƒ†ãƒ ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦ã„ãªã„
                        error_message=str(e),
                        recovery_details={
                            "error_type": type(e).__name__,
                            "error_handled": error_handled_properly,
                        },
                    )
                )

                logger.warning(f"âš ï¸ {corruption_type}ç ´æãƒ‡ãƒ¼ã‚¿ã§ã‚¨ãƒ©ãƒ¼: {e}")

    def test_resource_exhaustion(self):
        """ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ’¾ ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆ
        logger.info("ğŸ§  ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆ")

        start_time = time.time()
        initial_memory = self.process.memory_info().rss / 1024**2

        try:
            # æ®µéšçš„ã«ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å¢—åŠ 
            memory_hogs = []
            max_memory_mb = 500  # 500MBåˆ¶é™

            while True:
                current_memory = self.process.memory_info().rss / 1024**2
                if current_memory - initial_memory > max_memory_mb:
                    break

                # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»
                large_data = self.create_corrupted_data("extreme_outliers", rows=5000)
                memory_hogs.append(large_data)

                # MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
                from app.services.ml.single_model.single_model_trainer import (
                    SingleModelTrainer,
                )

                trainer = SingleModelTrainer(model_type="lightgbm")
                result = trainer.train_model(
                    training_data=large_data,
                    save_model=False,
                    threshold_up=0.02,
                    threshold_down=-0.02,
                )

                logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {current_memory - initial_memory:.2f}MB")

                if len(memory_hogs) > 3:  # å®‰å…¨åˆ¶é™
                    break

            execution_time = time.time() - start_time
            final_memory = self.process.memory_info().rss / 1024**2

            self.results.append(
                StressTestResult(
                    test_name="ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆ",
                    stress_type="resource_exhaustion",
                    success=True,
                    execution_time=execution_time,
                    error_recovery=True,
                    system_stability=True,
                    resource_usage={
                        "memory_usage_mb": final_memory - initial_memory,
                        "peak_memory_mb": final_memory,
                        "memory_objects_created": len(memory_hogs),
                    },
                    recovery_details={
                        "max_memory_reached": final_memory - initial_memory,
                        "system_responsive": True,
                    },
                )
            )

            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            del memory_hogs
            gc.collect()

            logger.info(f"âœ… ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆå®Œäº†: {execution_time:.2f}ç§’")

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                StressTestResult(
                    test_name="ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆ",
                    stress_type="resource_exhaustion",
                    success=False,
                    execution_time=execution_time,
                    error_recovery=True,
                    system_stability=True,
                    error_message=str(e),
                    recovery_details={
                        "error_type": type(e).__name__,
                        "memory_at_failure": self.process.memory_info().rss / 1024**2
                        - initial_memory,
                    },
                )
            )

            logger.error(f"âŒ ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_concurrent_stress(self):
        """ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("âš¡ ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()

        try:
            # è¤‡æ•°ã®ä¸¦è¡Œå‡¦ç†ã‚’é–‹å§‹
            threads = []
            results = []

            def worker_function(worker_id: int):
                try:
                    # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ç•°ãªã‚‹ç ´æãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                    corruption_types = [
                        "extreme_outliers",
                        "all_nan",
                        "negative_prices",
                    ]
                    corruption_type = corruption_types[
                        worker_id % len(corruption_types)
                    ]

                    corrupted_data = self.create_corrupted_data(
                        corruption_type, rows=500
                    )

                    from app.services.ml.single_model.single_model_trainer import (
                        SingleModelTrainer,
                    )

                    trainer = SingleModelTrainer(model_type="lightgbm")
                    result = trainer.train_model(
                        training_data=corrupted_data,
                        save_model=False,
                        threshold_up=0.02,
                        threshold_down=-0.02,
                    )

                    results.append(
                        {
                            "worker_id": worker_id,
                            "success": True,
                            "accuracy": result.get("accuracy", 0),
                        }
                    )

                except Exception as e:
                    results.append(
                        {"worker_id": worker_id, "success": False, "error": str(e)}
                    )

            # 3ã¤ã®ä¸¦è¡Œãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’é–‹å§‹
            for i in range(3):
                thread = threading.Thread(target=worker_function, args=(i,))
                threads.append(thread)
                thread.start()

            # å…¨ã¦ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã®å®Œäº†ã‚’å¾…æ©Ÿ
            for thread in threads:
                thread.join(timeout=60)  # 60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

            execution_time = time.time() - start_time

            # çµæœã‚’è©•ä¾¡
            successful_workers = sum(1 for r in results if r["success"])
            total_workers = len(results)

            self.results.append(
                StressTestResult(
                    test_name="ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ",
                    stress_type="concurrent_stress",
                    success=successful_workers > 0,
                    execution_time=execution_time,
                    error_recovery=True,
                    system_stability=True,
                    resource_usage={
                        "concurrent_workers": total_workers,
                        "successful_workers": successful_workers,
                        "success_rate": successful_workers / max(1, total_workers),
                    },
                    recovery_details={
                        "worker_results": results,
                        "all_threads_completed": len(results) == 3,
                    },
                )
            )

            logger.info(
                f"âœ… ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†: {successful_workers}/{total_workers}æˆåŠŸ"
            )

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                StressTestResult(
                    test_name="ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ",
                    stress_type="concurrent_stress",
                    success=False,
                    execution_time=execution_time,
                    error_recovery=False,
                    system_stability=True,
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ ä¸¦è¡Œå‡¦ç†ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_rapid_requests(self):
        """é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸš€ é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()

        try:
            # çŸ­æ™‚é–“ã§å¤§é‡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            request_count = 10
            successful_requests = 0
            failed_requests = 0

            for i in range(request_count):
                try:
                    # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜é€Ÿå‡¦ç†
                    test_data = self.create_corrupted_data("extreme_outliers", rows=200)

                    from app.services.ml.single_model.single_model_trainer import (
                        SingleModelTrainer,
                    )

                    trainer = SingleModelTrainer(model_type="lightgbm")
                    result = trainer.train_model(
                        training_data=test_data,
                        save_model=False,
                        threshold_up=0.02,
                        threshold_down=-0.02,
                    )

                    successful_requests += 1
                    logger.info(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆ {i+1}/{request_count} æˆåŠŸ")

                except Exception as e:
                    failed_requests += 1
                    logger.warning(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆ {i+1}/{request_count} å¤±æ•—: {e}")

                # çŸ­ã„é–“éš”
                time.sleep(0.1)

            execution_time = time.time() - start_time

            self.results.append(
                StressTestResult(
                    test_name="é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ",
                    stress_type="rapid_requests",
                    success=successful_requests > 0,
                    execution_time=execution_time,
                    error_recovery=True,
                    system_stability=True,
                    resource_usage={
                        "total_requests": request_count,
                        "successful_requests": successful_requests,
                        "failed_requests": failed_requests,
                        "success_rate": successful_requests / request_count,
                        "requests_per_second": request_count / execution_time,
                    },
                    recovery_details={"system_responsive": True, "no_crashes": True},
                )
            )

            logger.info(
                f"âœ… é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆå®Œäº†: {successful_requests}/{request_count}æˆåŠŸ"
            )

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                StressTestResult(
                    test_name="é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ",
                    stress_type="rapid_requests",
                    success=False,
                    execution_time=execution_time,
                    error_recovery=False,
                    system_stability=False,
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ é«˜é »åº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")


if __name__ == "__main__":
    logger.info("ğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")

    test_suite = StressTestSuite()

    # å„ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    test_suite.test_corrupted_data_handling()
    test_suite.test_resource_exhaustion()
    test_suite.test_concurrent_stress()
    test_suite.test_rapid_requests()

    # çµæœã‚µãƒãƒªãƒ¼
    total_tests = len(test_suite.results)
    successful_tests = sum(1 for r in test_suite.results if r.success)
    recovered_tests = sum(1 for r in test_suite.results if r.error_recovery)
    stable_tests = sum(1 for r in test_suite.results if r.system_stability)

    print("\n" + "=" * 80)
    print("ğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 80)
    print(f"ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"âœ… æˆåŠŸ: {successful_tests}")
    print(f"âŒ å¤±æ•—: {total_tests - successful_tests}")
    print(f"ğŸ”„ ã‚¨ãƒ©ãƒ¼å›å¾©: {recovered_tests}")
    print(f"ğŸ›¡ï¸ ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§: {stable_tests}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {(successful_tests/total_tests*100):.1f}%")
    print(f"ğŸ”„ å›å¾©ç‡: {(recovered_tests/total_tests*100):.1f}%")
    print(f"ğŸ›¡ï¸ å®‰å®šæ€§: {(stable_tests/total_tests*100):.1f}%")

    print("\nğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆè©³ç´°:")
    for result in test_suite.results:
        status = "âœ…" if result.success else "âŒ"
        recovery = "ğŸ”„" if result.error_recovery else "âŒ"
        stability = "ğŸ›¡ï¸" if result.system_stability else "âŒ"
        print(f"{status} {result.test_name}")
        print(f"   å®Ÿè¡Œæ™‚é–“: {result.execution_time:.2f}ç§’")
        print(f"   ã‚¨ãƒ©ãƒ¼å›å¾©: {recovery}")
        print(f"   ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§: {stability}")
        if result.error_message:
            print(f"   ã‚¨ãƒ©ãƒ¼: {result.error_message[:100]}...")

    print("=" * 80)

    logger.info("ğŸ¯ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Œäº†")
