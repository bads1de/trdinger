"""
æ”¹å–„ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ

ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å°å…¥ã«ã‚ˆã‚Š
ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸æ•´åˆå•é¡ŒãŒè§£æ±ºã•ã‚Œã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
"""

import pandas as pd
import numpy as np
import logging
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.ml.feature_engineering.feature_engineering_service import (
    FeatureEngineeringService,
)

logger = logging.getLogger(__name__)


class TestImprovedFeatureScaling:
    """æ”¹å–„ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def generate_sample_data(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        dates = pd.date_range(start="2023-01-01", periods=500, freq="h")
        np.random.seed(42)

        # ç¾å®Ÿçš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        base_price = 50000
        price_changes = np.random.normal(0, 0.02, len(dates))
        prices = [base_price]

        for change in price_changes[1:]:
            new_price = prices[-1] * (1 + change)
            prices.append(new_price)

        prices = np.array(prices)

        # OHLCV ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        data = {
            "timestamp": dates,
            "Open": prices * np.random.uniform(0.995, 1.005, len(prices)),
            "High": prices * np.random.uniform(1.001, 1.02, len(prices)),
            "Low": prices * np.random.uniform(0.98, 0.999, len(prices)),
            "Close": prices,
            "Volume": np.random.uniform(100, 1000, len(prices)),
        }

        df = pd.DataFrame(data)
        df.set_index("timestamp", inplace=True)
        return df

    def generate_sample_funding_rate_data(self, ohlcv_data):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        return pd.DataFrame(
            {
                "timestamp": ohlcv_data.index,
                "funding_rate": np.random.normal(0.0001, 0.0005, len(ohlcv_data)),
            }
        ).set_index("timestamp")

    def generate_sample_open_interest_data(self, ohlcv_data):
        """ãƒ†ã‚¹ãƒˆç”¨ã®å»ºç‰æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        return pd.DataFrame(
            {
                "timestamp": ohlcv_data.index,
                "open_interest": np.random.uniform(1000000, 5000000, len(ohlcv_data)),
            }
        ).set_index("timestamp")

    def test_feature_scaling_improvement(self):
        """ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®æ”¹å–„ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ”¹å–„ãƒ†ã‚¹ãƒˆ ===")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        sample_data = self.generate_sample_data()
        funding_data = self.generate_sample_funding_rate_data(sample_data)
        oi_data = self.generate_sample_open_interest_data(sample_data)

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        feature_service = FeatureEngineeringService()

        # ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆæ”¹å–„ã•ã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä»˜ãï¼‰
        features_df = feature_service.calculate_advanced_features(
            ohlcv_data=sample_data,
            funding_rate_data=funding_data,
            open_interest_data=oi_data,
        )

        # æ•°å€¤ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ç¢ºèª
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        feature_stats = {}

        for col in numeric_columns[:15]:  # æœ€åˆã®15å€‹ã®ç‰¹å¾´é‡ã‚’ãƒã‚§ãƒƒã‚¯
            if col not in ["Open", "High", "Low", "Close", "Volume"]:
                series = features_df[col].dropna()
                if len(series) > 0:
                    feature_stats[col] = {
                        "mean": series.mean(),
                        "std": series.std(),
                        "min": series.min(),
                        "max": series.max(),
                        "range": series.max() - series.min(),
                    }

        logger.info(f"ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ï¼ˆæœ€åˆã®15å€‹ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œï¼‰:")
        for col, stats in feature_stats.items():
            logger.info(
                f"  {col}: å¹³å‡={stats['mean']:.4f}, æ¨™æº–åå·®={stats['std']:.4f}, ç¯„å›²={stats['range']:.4f}"
            )

        # ã‚¹ã‚±ãƒ¼ãƒ«ã®æ•´åˆæ€§ã‚’æ¤œè¨¼
        ranges = [stats["range"] for stats in feature_stats.values()]
        if len(ranges) > 1:
            max_range = max(ranges)
            min_range = min([r for r in ranges if r > 0])
            scale_ratio = max_range / min_range if min_range > 0 else 1

            logger.info(f"ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡ï¼ˆæœ€å¤§ç¯„å›²/æœ€å°ç¯„å›²ï¼‰: {scale_ratio:.2f}")

            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã¯ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡ãŒå¤§å¹…ã«æ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã¯ãš
            if scale_ratio < 100:  # æ”¹å–„å‰ã¯205ä¸‡å€ã ã£ãŸ
                logger.info(
                    "âœ… ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€ã‚¹ã‚±ãƒ¼ãƒ«ä¸æ•´åˆãŒå¤§å¹…ã«æ”¹å–„ã•ã‚Œã¾ã—ãŸ"
                )
            else:
                logger.warning(
                    f"âš ï¸ ã‚¹ã‚±ãƒ¼ãƒ«ä¸æ•´åˆãŒæ®‹ã£ã¦ã„ã¾ã™ï¼ˆæ¯”ç‡: {scale_ratio:.2f}ï¼‰"
                )

        return {
            "feature_stats": feature_stats,
            "scale_ratio": scale_ratio if "scale_ratio" in locals() else 1,
            "feature_count": len(feature_stats),
        }

    def test_different_scaling_methods(self):
        """ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•ã®ãƒ†ã‚¹ãƒˆ ===")

        # ãƒ†ã‚¹ãƒˆç”¨ã®ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        np.random.seed(42)
        test_data = pd.DataFrame(
            {
                "feature1": np.random.normal(50000, 10000, 100),  # å¤§ããªã‚¹ã‚±ãƒ¼ãƒ«
                "feature2": np.random.normal(0.5, 0.1, 100),  # å°ã•ãªã‚¹ã‚±ãƒ¼ãƒ«
                "feature3": np.random.normal(1000, 200, 100),  # ä¸­é–“ã‚¹ã‚±ãƒ¼ãƒ«
            }
        )

        # å¤–ã‚Œå€¤ã‚’è¿½åŠ 
        test_data.iloc[0, 0] = 200000  # æ¥µç«¯ãªå¤–ã‚Œå€¤
        test_data.iloc[1, 1] = 5.0  # å¤–ã‚Œå€¤

        preprocessor = DataPreprocessor()

        scaling_methods = ["standard", "robust", "minmax"]
        results = {}

        for method in scaling_methods:
            logger.info(f"--- {method}ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ---")

            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
            scaled_data = preprocessor.preprocess_features(
                test_data.copy(),
                scale_features=True,
                remove_outliers=False,  # å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’ç¢ºèªã™ã‚‹ãŸã‚
                scaling_method=method,
            )

            # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            stats = {}
            for col in test_data.columns:
                series = scaled_data[col]
                stats[col] = {
                    "mean": series.mean(),
                    "std": series.std(),
                    "min": series.min(),
                    "max": series.max(),
                    "range": series.max() - series.min(),
                }

            # ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡ã‚’è¨ˆç®—
            ranges = [stats[col]["range"] for col in test_data.columns]
            max_range = max(ranges)
            min_range = min([r for r in ranges if r > 0])
            scale_ratio = max_range / min_range if min_range > 0 else 1

            logger.info(f"  ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡: {scale_ratio:.2f}")
            logger.info(
                f"  å¹³å‡å€¤ç¯„å›²: {min([stats[col]['mean'] for col in test_data.columns]):.4f} - {max([stats[col]['mean'] for col in test_data.columns]):.4f}"
            )

            results[method] = {
                "stats": stats,
                "scale_ratio": scale_ratio,
                "scaled_data": scaled_data,
            }

        # ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå¤–ã‚Œå€¤ã«å¼·ã„ã“ã¨ã‚’ç¢ºèª
        robust_ratio = results["robust"]["scale_ratio"]
        standard_ratio = results["standard"]["scale_ratio"]

        logger.info(f"ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¯”ç‡: {robust_ratio:.2f}")
        logger.info(f"æ¨™æº–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¯”ç‡: {standard_ratio:.2f}")

        if robust_ratio <= standard_ratio:
            logger.info("âœ… ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå¤–ã‚Œå€¤ã«å¯¾ã—ã¦ã‚ˆã‚Šå®‰å®šã—ã¦ã„ã¾ã™")
        else:
            logger.warning("âš ï¸ ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®åŠ¹æœãŒæœŸå¾…ã‚ˆã‚Šä½ã„ã§ã™")

        return results

    def test_scaling_with_outlier_removal(self):
        """å¤–ã‚Œå€¤é™¤å»ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å¤–ã‚Œå€¤é™¤å»+ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ ===")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        sample_data = self.generate_sample_data()
        funding_data = self.generate_sample_funding_rate_data(sample_data)
        oi_data = self.generate_sample_open_interest_data(sample_data)

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
        feature_service = FeatureEngineeringService()

        # ç‰¹å¾´é‡ã‚’è¨ˆç®—
        features_df = feature_service.calculate_advanced_features(
            ohlcv_data=sample_data,
            funding_rate_data=funding_data,
            open_interest_data=oi_data,
        )

        # æ•°å€¤ç‰¹å¾´é‡ã‚’é¸æŠ
        numeric_columns = features_df.select_dtypes(include=[np.number]).columns
        feature_subset = features_df[numeric_columns[:10]].copy()  # æœ€åˆã®10å€‹

        preprocessor = DataPreprocessor()

        # å¤–ã‚Œå€¤é™¤å»ãªã—ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaled_without_outlier_removal = preprocessor.preprocess_features(
            feature_subset.copy(),
            scale_features=True,
            remove_outliers=False,
            scaling_method="robust",
        )

        # å¤–ã‚Œå€¤é™¤å»ã‚ã‚Šã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaled_with_outlier_removal = preprocessor.preprocess_features(
            feature_subset.copy(),
            scale_features=True,
            remove_outliers=True,
            outlier_threshold=3.0,
            scaling_method="robust",
        )

        # çµæœã‚’æ¯”è¼ƒ
        def calculate_stability_metrics(df):
            """ãƒ‡ãƒ¼ã‚¿ã®å®‰å®šæ€§æŒ‡æ¨™ã‚’è¨ˆç®—"""
            metrics = {}
            for col in df.columns:
                series = df[col].dropna()
                if len(series) > 0:
                    metrics[col] = {
                        "std": series.std(),
                        "iqr": series.quantile(0.75) - series.quantile(0.25),
                        "range": series.max() - series.min(),
                    }
            return metrics

        metrics_without = calculate_stability_metrics(scaled_without_outlier_removal)
        metrics_with = calculate_stability_metrics(scaled_with_outlier_removal)

        # å®‰å®šæ€§ã®æ”¹å–„ã‚’è©•ä¾¡
        improvement_count = 0
        total_features = 0

        for col in metrics_without.keys():
            if col in metrics_with:
                total_features += 1
                # IQRãŒå°ã•ããªã£ã¦ã„ã‚Œã°æ”¹å–„
                if metrics_with[col]["iqr"] < metrics_without[col]["iqr"]:
                    improvement_count += 1

        improvement_ratio = (
            improvement_count / total_features if total_features > 0 else 0
        )

        logger.info(
            f"å¤–ã‚Œå€¤é™¤å»ã«ã‚ˆã‚‹å®‰å®šæ€§æ”¹å–„: {improvement_count}/{total_features} ({improvement_ratio*100:.1f}%)"
        )

        if improvement_ratio > 0.5:
            logger.info("âœ… å¤–ã‚Œå€¤é™¤å»ã«ã‚ˆã‚Šç‰¹å¾´é‡ã®å®‰å®šæ€§ãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸ")
        else:
            logger.warning("âš ï¸ å¤–ã‚Œå€¤é™¤å»ã®åŠ¹æœãŒé™å®šçš„ã§ã™")

        return {
            "improvement_ratio": improvement_ratio,
            "metrics_without": metrics_without,
            "metrics_with": metrics_with,
        }

    def test_overall_feature_engineering_improvement(self):
        """å…¨ä½“çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ”¹å–„ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å…¨ä½“çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ”¹å–„ãƒ†ã‚¹ãƒˆ ===")

        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        scaling_results = self.test_feature_scaling_improvement()
        method_results = self.test_different_scaling_methods()
        outlier_results = self.test_scaling_with_outlier_removal()

        # æ”¹å–„ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        improvement_score = 0

        # ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡æ”¹å–„ï¼ˆæœ€å¤§40ç‚¹ï¼‰
        scale_ratio = scaling_results["scale_ratio"]
        if scale_ratio < 10:
            improvement_score += 40
        elif scale_ratio < 50:
            improvement_score += 30
        elif scale_ratio < 100:
            improvement_score += 20
        elif scale_ratio < 1000:
            improvement_score += 10

        # ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹æœï¼ˆæœ€å¤§25ç‚¹ï¼‰
        robust_ratio = method_results["robust"]["scale_ratio"]
        standard_ratio = method_results["standard"]["scale_ratio"]
        if robust_ratio <= standard_ratio:
            improvement_score += 25
        elif robust_ratio <= standard_ratio * 1.2:
            improvement_score += 15

        # å¤–ã‚Œå€¤é™¤å»åŠ¹æœï¼ˆæœ€å¤§20ç‚¹ï¼‰
        outlier_improvement = outlier_results["improvement_ratio"]
        if outlier_improvement > 0.7:
            improvement_score += 20
        elif outlier_improvement > 0.5:
            improvement_score += 15
        elif outlier_improvement > 0.3:
            improvement_score += 10

        # ç‰¹å¾´é‡æ•°ï¼ˆæœ€å¤§15ç‚¹ï¼‰
        feature_count = scaling_results["feature_count"]
        if feature_count >= 10:
            improvement_score += 15
        elif feature_count >= 5:
            improvement_score += 10

        logger.info(f"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ”¹å–„ã‚¹ã‚³ã‚¢: {improvement_score}/100")

        if improvement_score >= 80:
            logger.info("ğŸ‰ å„ªç§€ãªæ”¹å–„åŠ¹æœãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif improvement_score >= 60:
            logger.info("âœ… è‰¯å¥½ãªæ”¹å–„åŠ¹æœãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif improvement_score >= 40:
            logger.info("âš ï¸ éƒ¨åˆ†çš„ãªæ”¹å–„åŠ¹æœãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        else:
            logger.warning("âŒ æ”¹å–„åŠ¹æœãŒä¸ååˆ†ã§ã™")

        return {
            "improvement_score": improvement_score,
            "scaling_results": scaling_results,
            "method_results": method_results,
            "outlier_results": outlier_results,
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
    import logging

    logging.basicConfig(level=logging.INFO)

    test_instance = TestImprovedFeatureScaling()

    # å…¨ä½“çš„ãªæ”¹å–„åŠ¹æœã‚’æ¤œè¨¼
    results = test_instance.test_overall_feature_engineering_improvement()

    print(f"\n=== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ”¹å–„çµæœã‚µãƒãƒªãƒ¼ ===")
    print(f"æ”¹å–„ã‚¹ã‚³ã‚¢: {results['improvement_score']}/100")
    print(f"ã‚¹ã‚±ãƒ¼ãƒ«æ¯”ç‡: {results['scaling_results']['scale_ratio']:.2f}")
    print(
        f"å¤–ã‚Œå€¤é™¤å»æ”¹å–„ç‡: {results['outlier_results']['improvement_ratio']*100:.1f}%"
    )
