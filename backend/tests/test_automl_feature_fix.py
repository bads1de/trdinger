"""
AutoMLç‰¹å¾´é‡åˆ†æä¿®æ­£ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä¿®æ­£å¾Œã®AutoMLç‰¹å¾´é‡åˆ†ææ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.ml.ml_training_service import MLTrainingService
from app.services.ml.model_manager import model_manager
from app.services.ml.feature_engineering.automl_feature_analyzer import AutoMLFeatureAnalyzer
from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator

logger = logging.getLogger(__name__)


def test_fixed_feature_importance_save():
    """ä¿®æ­£å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦ä¿å­˜ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("=" * 80)
    print("ä¿®æ­£å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦ä¿å­˜ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    try:
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        np.random.seed(42)
        n_samples = 500
        
        data = {
            "timestamp": pd.date_range("2023-01-01", periods=n_samples, freq="h"),
            "Open": 50000 + np.random.randn(n_samples) * 1000,
            "High": 50000 + np.random.randn(n_samples) * 1000 + 500,
            "Low": 50000 + np.random.randn(n_samples) * 1000 - 500,
            "Close": 50000 + np.random.randn(n_samples) * 1000,
            "Volume": np.random.uniform(100, 1000, n_samples),
        }
        
        df = pd.DataFrame(data)
        
        # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ä¿ã¤
        for i in range(len(df)):
            prices = [
                df.loc[i, "Open"],
                df.loc[i, "High"],
                df.loc[i, "Low"],
                df.loc[i, "Close"],
            ]
            df.loc[i, "High"] = max(prices)
            df.loc[i, "Low"] = min(prices)
        
        print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ: {len(df)}è¡Œ")
        
        # MLTrainingServiceã‚’åˆæœŸåŒ–
        ml_service = MLTrainingService(trainer_type="ensemble")
        
        print("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’é–‹å§‹...")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        result = ml_service.train_model(
            training_data=df,
            save_model=False,
            model_name=None
        )
        
        print("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        
        # ä¿®æ­£å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦å–å¾—ã‚’ãƒ†ã‚¹ãƒˆ
        print("\nä¿®æ­£å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦å–å¾—ãƒ†ã‚¹ãƒˆ:")
        print("-" * 60)
        
        trainer = ml_service.trainer
        feature_importance = trainer.get_feature_importance(top_n=100)
        
        if feature_importance:
            print(f"âœ… ç‰¹å¾´é‡é‡è¦åº¦å–å¾—æˆåŠŸ: {len(feature_importance)}å€‹")
            
            # ä¸Šä½5å€‹ã‚’è¡¨ç¤º
            sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
            for name, importance in sorted_importance:
                print(f"  {name}: {importance:.4f}")
        else:
            print("âŒ ç‰¹å¾´é‡é‡è¦åº¦ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚’ãƒ†ã‚¹ãƒˆ
        print("\nä¿®æ­£å¾Œã®ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ†ã‚¹ãƒˆ:")
        print("-" * 60)
        
        test_model_name = "test_fixed_feature_importance"
        
        try:
            model_path = trainer.save_model(test_model_name)
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
            
            # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
            saved_model_data = model_manager.load_model(model_path)
            if saved_model_data and "metadata" in saved_model_data:
                metadata = saved_model_data["metadata"]
                
                if "feature_importance" in metadata:
                    saved_feature_importance = metadata["feature_importance"]
                    print(f"âœ… ç‰¹å¾´é‡é‡è¦åº¦ãŒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™: {len(saved_feature_importance)}å€‹")
                    
                    # ä¸Šä½5å€‹ã‚’è¡¨ç¤º
                    sorted_importance = sorted(saved_feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
                    for name, importance in sorted_importance:
                        print(f"  {name}: {importance:.4f}")
                    
                    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    try:
                        os.remove(model_path)
                        print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {model_path}")
                    except Exception as e:
                        print(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    return True
                else:
                    print("âŒ ç‰¹å¾´é‡é‡è¦åº¦ãŒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    return False
            else:
                print("âŒ ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“")
                return False
                
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_automl_feature_analysis_fix():
    """ä¿®æ­£å¾Œã®AutoMLç‰¹å¾´é‡åˆ†æã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ä¿®æ­£å¾Œã®AutoMLç‰¹å¾´é‡åˆ†æãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    try:
        # MLOrchestratorã‚’åˆæœŸåŒ–
        orchestrator = MLOrchestrator()
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        feature_importance = orchestrator.get_feature_importance(100)
        print(f"ç‰¹å¾´é‡é‡è¦åº¦å–å¾—: {len(feature_importance)}å€‹")
        
        if not feature_importance:
            print("âŒ ç‰¹å¾´é‡é‡è¦åº¦ãŒå–å¾—ã§ãã¾ã›ã‚“")
            return False
        
        # AutoMLFeatureAnalyzerã§åˆ†æ
        analyzer = AutoMLFeatureAnalyzer()
        analysis_result = analyzer.analyze_feature_importance(feature_importance, top_n=20)
        
        print("\nAutoMLç‰¹å¾´é‡åˆ†æçµæœ:")
        print("-" * 60)
        
        if "error" in analysis_result:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_result['error']}")
            return False
        
        # çµæœã®è©³ç´°è¡¨ç¤º
        print(f"ç·ç‰¹å¾´é‡æ•°: {analysis_result.get('total_features', 0)}")
        
        # ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        type_stats = analysis_result.get("type_statistics", {})
        print("\nã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ:")
        for type_name, stats in type_stats.items():
            count = stats.get('count', 0)
            ratio = stats.get('importance_ratio', 0)
            print(f"  {type_name}: {count}å€‹ ({ratio:.1f}%)")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        category_stats = analysis_result.get("category_statistics", {})
        print("\nã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ:")
        for category_name, stats in category_stats.items():
            count = stats.get('count', 0)
            ratio = stats.get('importance_ratio', 0)
            print(f"  {category_name}: {count}å€‹ ({ratio:.1f}%)")
        
        # AutoMLåŠ¹æœ
        automl_impact = analysis_result.get("automl_impact", {})
        print("\nAutoMLåŠ¹æœ:")
        print(f"  AutoMLç‰¹å¾´é‡æ•°: {automl_impact.get('automl_features', 0)}å€‹")
        print(f"  AutoMLé‡è¦åº¦æ¯”ç‡: {automl_impact.get('automl_importance_ratio', 0):.1f}%")
        
        # ä¸Šä½ç‰¹å¾´é‡
        top_features = analysis_result.get("top_features", [])
        print(f"\nä¸Šä½ç‰¹å¾´é‡ (ä¸Šä½{min(10, len(top_features))}å€‹):")
        for i, feature in enumerate(top_features[:10]):
            print(f"  {i+1}. {feature['feature_name']} ({feature['feature_type']}) - {feature['importance']:.4f}")
        
        # åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
        if type_stats and category_stats:
            print("\nâœ… AutoMLç‰¹å¾´é‡åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            return True
        else:
            print("\nâŒ AutoMLç‰¹å¾´é‡åˆ†æãŒä¸å®Œå…¨ã§ã™")
            return False
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_automl_enabled_training():
    """AutoMLæœ‰åŠ¹ã§ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("AutoMLæœ‰åŠ¹ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    try:
        # AutoMLè¨­å®šã‚’ä½œæˆ
        automl_config = {
            "tsfresh": {
                "enabled": True,
                "feature_selection": True,
                "max_features": 50
            },
            "autofeat": {
                "enabled": True,
                "max_features": 30,
                "feateng_steps": 2
            }
        }
        
        print("AutoMLè¨­å®š:")
        print(f"  TSFresh: æœ‰åŠ¹, æœ€å¤§ç‰¹å¾´é‡æ•°: {automl_config['tsfresh']['max_features']}")
        print(f"  AutoFeat: æœ‰åŠ¹, æœ€å¤§ç‰¹å¾´é‡æ•°: {automl_config['autofeat']['max_features']}")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        np.random.seed(42)
        n_samples = 300  # AutoMLã®ãŸã‚å°‘ã—å°ã•ãã™ã‚‹
        
        data = {
            "timestamp": pd.date_range("2023-01-01", periods=n_samples, freq="h"),
            "Open": 50000 + np.random.randn(n_samples) * 1000,
            "High": 50000 + np.random.randn(n_samples) * 1000 + 500,
            "Low": 50000 + np.random.randn(n_samples) * 1000 - 500,
            "Close": 50000 + np.random.randn(n_samples) * 1000,
            "Volume": np.random.uniform(100, 1000, n_samples),
        }
        
        df = pd.DataFrame(data)
        
        # ä¾¡æ ¼ã®æ•´åˆæ€§ã‚’ä¿ã¤
        for i in range(len(df)):
            prices = [
                df.loc[i, "Open"],
                df.loc[i, "High"],
                df.loc[i, "Low"],
                df.loc[i, "Close"],
            ]
            df.loc[i, "High"] = max(prices)
            df.loc[i, "Low"] = min(prices)
        
        print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ: {len(df)}è¡Œ")
        
        # AutoMLæœ‰åŠ¹ã§MLTrainingServiceã‚’åˆæœŸåŒ–
        ml_service = MLTrainingService(
            trainer_type="ensemble",
            automl_config=automl_config
        )
        
        print("AutoMLæœ‰åŠ¹ã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’é–‹å§‹...")
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        result = ml_service.train_model(
            training_data=df,
            save_model=False,
            model_name=None
        )
        
        print("âœ… AutoMLãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’ç¢ºèª
        trainer = ml_service.trainer
        feature_importance = trainer.get_feature_importance(100)
        
        if feature_importance:
            print(f"ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {len(feature_importance)}")
            
            # AutoMLç‰¹å¾´é‡ã®ç¢ºèª
            ts_features = [name for name in feature_importance.keys() if name.startswith("TS_")]
            af_features = [name for name in feature_importance.keys() if name.startswith("AF_")]
            manual_features = [name for name in feature_importance.keys() if not (name.startswith("TS_") or name.startswith("AF_"))]
            
            print(f"TSFreshç‰¹å¾´é‡: {len(ts_features)}å€‹")
            print(f"AutoFeatç‰¹å¾´é‡: {len(af_features)}å€‹")
            print(f"æ‰‹å‹•ç‰¹å¾´é‡: {len(manual_features)}å€‹")
            
            if ts_features:
                print(f"TSFreshä¾‹: {ts_features[:3]}")
            if af_features:
                print(f"AutoFeatä¾‹: {af_features[:3]}")
            
            # AutoMLç‰¹å¾´é‡åˆ†æã‚’å®Ÿè¡Œ
            if ts_features or af_features:
                analyzer = AutoMLFeatureAnalyzer()
                analysis_result = analyzer.analyze_feature_importance(feature_importance, top_n=20)
                
                print("\nAutoMLç‰¹å¾´é‡åˆ†æçµæœ:")
                if "error" not in analysis_result:
                    automl_impact = analysis_result.get("automl_impact", {})
                    print(f"AutoMLç‰¹å¾´é‡æ¯”ç‡: {automl_impact.get('automl_feature_ratio', 0):.1f}%")
                    print(f"AutoMLé‡è¦åº¦æ¯”ç‡: {automl_impact.get('automl_importance_ratio', 0):.1f}%")
                    
                    return True
                else:
                    print(f"åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_result['error']}")
                    return False
            else:
                print("âš ï¸ AutoMLç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return False
        else:
            print("âŒ ç‰¹å¾´é‡é‡è¦åº¦ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("AutoMLç‰¹å¾´é‡åˆ†æä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    # 1. ä¿®æ­£å¾Œã®ç‰¹å¾´é‡é‡è¦åº¦ä¿å­˜ãƒ†ã‚¹ãƒˆ
    test1_result = test_fixed_feature_importance_save()
    
    # 2. ä¿®æ­£å¾Œã®AutoMLç‰¹å¾´é‡åˆ†æãƒ†ã‚¹ãƒˆ
    test2_result = test_automl_feature_analysis_fix()
    
    # 3. AutoMLæœ‰åŠ¹ã§ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ†ã‚¹ãƒˆï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚æœ€å¾Œï¼‰
    # test3_result = test_automl_enabled_training()
    
    print("\n" + "=" * 80)
    print("ãƒ†ã‚¹ãƒˆçµæœ:")
    print(f"1. ç‰¹å¾´é‡é‡è¦åº¦ä¿å­˜: {'âœ… æˆåŠŸ' if test1_result else 'âŒ å¤±æ•—'}")
    print(f"2. AutoMLç‰¹å¾´é‡åˆ†æ: {'âœ… æˆåŠŸ' if test2_result else 'âŒ å¤±æ•—'}")
    # print(f"3. AutoMLæœ‰åŠ¹å­¦ç¿’: {'âœ… æˆåŠŸ' if test3_result else 'âŒ å¤±æ•—'}")
    
    if test1_result and test2_result:
        print("\nğŸ‰ åŸºæœ¬çš„ãªä¿®æ­£ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    print("=" * 80)
