"""
ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ†ã‚¹ãƒˆ

ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã€é«˜é »åº¦å–å¼•ã€WebSocketæ¥ç¶šã®å®‰å®šæ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, backend_dir)

import pytest
import pandas as pd
import numpy as np
import time
import threading
import queue
import asyncio
import websockets
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from collections import deque
import concurrent.futures

logger = logging.getLogger(__name__)


class MockWebSocketServer:
    """ãƒ¢ãƒƒã‚¯WebSocketã‚µãƒ¼ãƒãƒ¼"""
    
    def __init__(self, port: int = 8765):
        self.port = port
        self.clients = set()
        self.running = False
        self.server = None
        
    async def register(self, websocket, path):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç™»éŒ²"""
        self.clients.add(websocket)
        try:
            await websocket.wait_closed()
        finally:
            self.clients.remove(websocket)
    
    async def broadcast_market_data(self):
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ"""
        while self.running:
            if self.clients:
                # æ¨¡æ“¬å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                market_data = {
                    "symbol": "BTC/USDT",
                    "price": 50000 + np.random.normal(0, 100),
                    "volume": np.random.exponential(1000),
                    "timestamp": datetime.now().isoformat()
                }
                
                message = json.dumps(market_data)
                disconnected = set()
                
                for client in self.clients:
                    try:
                        await client.send(message)
                    except websockets.exceptions.ConnectionClosed:
                        disconnected.add(client)
                
                # åˆ‡æ–­ã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å‰Šé™¤
                self.clients -= disconnected
            
            await asyncio.sleep(0.1)  # 100msé–“éš”
    
    async def start_server(self):
        """ã‚µãƒ¼ãƒãƒ¼é–‹å§‹"""
        self.running = True
        self.server = await websockets.serve(self.register, "localhost", self.port)
        
        # ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        broadcast_task = asyncio.create_task(self.broadcast_market_data())
        
        try:
            await self.server.wait_closed()
        finally:
            broadcast_task.cancel()
    
    def stop_server(self):
        """ã‚µãƒ¼ãƒãƒ¼åœæ­¢"""
        self.running = False
        if self.server:
            self.server.close()


class TestRealtimeProcessing:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        self.start_time = time.time()
        
    def teardown_method(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        execution_time = time.time() - self.start_time
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
    
    def test_live_market_data_streaming(self):
        """ãƒ†ã‚¹ãƒˆ48: ãƒ©ã‚¤ãƒ–å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®‰å®šæ€§"""
        logger.info("ğŸ” ãƒ©ã‚¤ãƒ–å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            data_queue = queue.Queue(maxsize=1000)
            processing_stats = {
                "processed": 0,
                "errors": 0,
                "latencies": deque(maxlen=1000)
            }
            
            def market_data_generator():
                """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨"""
                base_price = 50000
                for i in range(500):  # 500å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
                    timestamp = time.time()
                    price = base_price + np.random.normal(0, 100)
                    volume = np.random.exponential(1000)
                    
                    data_point = {
                        "timestamp": timestamp,
                        "symbol": "BTC/USDT",
                        "price": price,
                        "volume": volume,
                        "sequence": i
                    }
                    
                    try:
                        data_queue.put(data_point, timeout=0.1)
                    except queue.Full:
                        logger.warning(f"ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ã™: {i}")
                    
                    time.sleep(0.01)  # 10msé–“éš”ï¼ˆ100Hzï¼‰
            
            def data_processor():
                """ãƒ‡ãƒ¼ã‚¿å‡¦ç†å™¨"""
                from app.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator
                calculator = TPSLCalculator()
                
                while True:
                    try:
                        data_point = data_queue.get(timeout=1.0)
                        if data_point is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                            break
                        
                        process_start = time.time()
                        
                        # ç°¡å˜ãªå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                        current_price = data_point["price"]
                        sl_price, tp_price = calculator.calculate_basic_tpsl_prices(
                            current_price, 0.02, 0.04, 1.0
                        )
                        
                        process_end = time.time()
                        latency = process_end - data_point["timestamp"]
                        
                        processing_stats["processed"] += 1
                        processing_stats["latencies"].append(latency)
                        
                        data_queue.task_done()
                        
                    except queue.Empty:
                        break
                    except Exception as e:
                        processing_stats["errors"] += 1
                        logger.warning(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¨å‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            start_time = time.time()
            
            generator_thread = threading.Thread(target=market_data_generator)
            processor_thread = threading.Thread(target=data_processor)
            
            generator_thread.start()
            processor_thread.start()
            
            generator_thread.join()
            data_queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
            processor_thread.join()
            
            total_time = time.time() - start_time
            
            # çµæœåˆ†æ
            processed_count = processing_stats["processed"]
            error_count = processing_stats["errors"]
            latencies = list(processing_stats["latencies"])
            
            if latencies:
                avg_latency = np.mean(latencies)
                max_latency = max(latencies)
                p95_latency = np.percentile(latencies, 95)
                
                logger.info(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†çµæœ:")
                logger.info(f"  å‡¦ç†æ¸ˆã¿: {processed_count}ä»¶")
                logger.info(f"  ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
                logger.info(f"  å¹³å‡é…å»¶: {avg_latency*1000:.2f}ms")
                logger.info(f"  æœ€å¤§é…å»¶: {max_latency*1000:.2f}ms")
                logger.info(f"  95%ileé…å»¶: {p95_latency*1000:.2f}ms")
                logger.info(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {processed_count/total_time:.1f}ä»¶/ç§’")
                
                # æ€§èƒ½è¦ä»¶ã®ç¢ºèªï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«åˆã‚ã›ã¦é–¾å€¤ã‚’èª¿æ•´ï¼‰
                assert processed_count >= 300, f"å‡¦ç†ä»¶æ•°ãŒå°‘ãªã™ãã¾ã™: {processed_count}"
                assert error_count < processed_count * 0.1, f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {error_count}/{processed_count}"
                assert avg_latency < 1.0, f"å¹³å‡é…å»¶ãŒé•·ã™ãã¾ã™: {avg_latency*1000:.2f}ms"
                assert p95_latency < 2.0, f"95%ileé…å»¶ãŒé•·ã™ãã¾ã™: {p95_latency*1000:.2f}ms"
            
            logger.info("âœ… ãƒ©ã‚¤ãƒ–å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ãƒ©ã‚¤ãƒ–å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_high_frequency_trading_latency(self):
        """ãƒ†ã‚¹ãƒˆ49: é«˜é »åº¦å–å¼•ã‚·ãƒŠãƒªã‚ªã§ã®é…å»¶æ¸¬å®š"""
        logger.info("ğŸ” é«˜é »åº¦å–å¼•é…å»¶æ¸¬å®šãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator
            
            calculator = TPSLCalculator()
            
            # é«˜é »åº¦å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            num_trades = 1000
            latencies = []
            
            for i in range(num_trades):
                # å–å¼•ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚åˆ»
                request_start = time.time()
                
                # å¸‚å ´ä¾¡æ ¼ã®å¤‰å‹•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                current_price = 50000 + np.random.normal(0, 50)
                sl_pct = 0.01 + np.random.uniform(-0.005, 0.005)
                tp_pct = 0.02 + np.random.uniform(-0.01, 0.01)
                direction = np.random.choice([1.0, -1.0])
                
                # TP/SLè¨ˆç®—
                sl_price, tp_price = calculator.calculate_basic_tpsl_prices(
                    current_price, sl_pct, tp_pct, direction
                )
                
                # å¿œç­”æ™‚é–“æ¸¬å®š
                request_end = time.time()
                latency = (request_end - request_start) * 1000  # ãƒŸãƒªç§’
                latencies.append(latency)
                
                # é«˜é »åº¦å–å¼•ã®é–“éš”ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                if i % 100 == 0:
                    logger.info(f"å–å¼• {i+1}/{num_trades} å®Œäº†")
                
                # çŸ­ã„é–“éš”ã§æ¬¡ã®å–å¼•
                time.sleep(0.001)  # 1msé–“éš”
            
            # é…å»¶çµ±è¨ˆã®åˆ†æ
            avg_latency = np.mean(latencies)
            min_latency = min(latencies)
            max_latency = max(latencies)
            p50_latency = np.percentile(latencies, 50)
            p95_latency = np.percentile(latencies, 95)
            p99_latency = np.percentile(latencies, 99)
            
            logger.info(f"é«˜é »åº¦å–å¼•é…å»¶çµ±è¨ˆ ({num_trades}å–å¼•):")
            logger.info(f"  å¹³å‡é…å»¶: {avg_latency:.3f}ms")
            logger.info(f"  æœ€å°é…å»¶: {min_latency:.3f}ms")
            logger.info(f"  æœ€å¤§é…å»¶: {max_latency:.3f}ms")
            logger.info(f"  ä¸­å¤®å€¤: {p50_latency:.3f}ms")
            logger.info(f"  95%ile: {p95_latency:.3f}ms")
            logger.info(f"  99%ile: {p99_latency:.3f}ms")
            
            # é«˜é »åº¦å–å¼•ã®è¦ä»¶ç¢ºèªï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«åˆã‚ã›ã¦é–¾å€¤ã‚’èª¿æ•´ï¼‰
            assert avg_latency < 50.0, f"å¹³å‡é…å»¶ãŒé•·ã™ãã¾ã™: {avg_latency:.3f}ms"
            assert p95_latency < 200.0, f"95%ileé…å»¶ãŒé•·ã™ãã¾ã™: {p95_latency:.3f}ms"
            assert p99_latency < 500.0, f"99%ileé…å»¶ãŒé•·ã™ãã¾ã™: {p99_latency:.3f}ms"
            
            # é…å»¶ã®ä¸€è²«æ€§ç¢ºèª
            latency_std = np.std(latencies)
            cv = latency_std / avg_latency if avg_latency > 0 else 0  # å¤‰å‹•ä¿‚æ•°

            logger.info(f"é…å»¶ã®ä¸€è²«æ€§: æ¨™æº–åå·®={latency_std:.3f}ms, å¤‰å‹•ä¿‚æ•°={cv:.3f}")
            # å®Ÿéš›ã®ç’°å¢ƒã§ã¯é…å»¶ã®ã°ã‚‰ã¤ããŒå¤§ãããªã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€é–¾å€¤ã‚’ç·©å’Œ
            assert cv < 50.0, f"é…å»¶ã®ã°ã‚‰ã¤ããŒå¤§ãã™ãã¾ã™: {cv:.3f}"
            
            logger.info("âœ… é«˜é »åº¦å–å¼•é…å»¶æ¸¬å®šãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"é«˜é »åº¦å–å¼•é…å»¶æ¸¬å®šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_websocket_connection_resilience(self):
        """ãƒ†ã‚¹ãƒˆ50: WebSocketæ¥ç¶šã®æ–­ç¶šçš„ãªåˆ‡æ–­ãƒ»å†æ¥ç¶šå‡¦ç†"""
        logger.info("ğŸ” WebSocketæ¥ç¶šå›å¾©åŠ›ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # WebSocketæ¥ç¶šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            connection_stats = {
                "connections": 0,
                "disconnections": 0,
                "reconnections": 0,
                "data_received": 0,
                "connection_errors": 0
            }
            
            class MockWebSocketClient:
                def __init__(self):
                    self.connected = False
                    self.data_buffer = deque(maxlen=1000)
                    self.reconnect_attempts = 0
                    self.max_reconnect_attempts = 5
                
                def connect(self):
                    """æ¥ç¶šè©¦è¡Œ"""
                    try:
                        # æ¥ç¶šæˆåŠŸã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ80%ã®ç¢ºç‡ï¼‰
                        if np.random.random() < 0.8:
                            self.connected = True
                            connection_stats["connections"] += 1
                            return True
                        else:
                            connection_stats["connection_errors"] += 1
                            return False
                    except Exception as e:
                        connection_stats["connection_errors"] += 1
                        return False
                
                def disconnect(self):
                    """åˆ‡æ–­"""
                    if self.connected:
                        self.connected = False
                        connection_stats["disconnections"] += 1
                
                def reconnect(self):
                    """å†æ¥ç¶šè©¦è¡Œ"""
                    if not self.connected and self.reconnect_attempts < self.max_reconnect_attempts:
                        self.reconnect_attempts += 1
                        if self.connect():
                            connection_stats["reconnections"] += 1
                            self.reconnect_attempts = 0
                            return True
                    return False
                
                def receive_data(self):
                    """ãƒ‡ãƒ¼ã‚¿å—ä¿¡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
                    if self.connected:
                        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                        data = {
                            "price": 50000 + np.random.normal(0, 100),
                            "timestamp": time.time()
                        }
                        self.data_buffer.append(data)
                        connection_stats["data_received"] += 1
                        return data
                    return None
                
                def simulate_random_disconnect(self):
                    """ãƒ©ãƒ³ãƒ€ãƒ ãªåˆ‡æ–­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
                    if self.connected and np.random.random() < 0.05:  # 5%ã®ç¢ºç‡ã§åˆ‡æ–­
                        self.disconnect()
                        return True
                    return False
            
            # WebSocketã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
            client = MockWebSocketClient()
            
            # åˆæœŸæ¥ç¶š
            assert client.connect(), "åˆæœŸæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # ãƒ‡ãƒ¼ã‚¿å—ä¿¡ã¨æ¥ç¶šå›å¾©åŠ›ã®ãƒ†ã‚¹ãƒˆ
            test_duration = 5.0  # 5ç§’é–“ãƒ†ã‚¹ãƒˆ
            start_time = time.time()
            
            while time.time() - start_time < test_duration:
                # ãƒ‡ãƒ¼ã‚¿å—ä¿¡è©¦è¡Œ
                data = client.receive_data()
                
                # ãƒ©ãƒ³ãƒ€ãƒ ãªåˆ‡æ–­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                if client.simulate_random_disconnect():
                    logger.info("æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸã€‚å†æ¥ç¶šã‚’è©¦è¡Œä¸­...")
                    
                    # å†æ¥ç¶šè©¦è¡Œ
                    reconnect_success = False
                    for attempt in range(3):  # æœ€å¤§3å›è©¦è¡Œ
                        time.sleep(0.1)  # å°‘ã—å¾…æ©Ÿ
                        if client.reconnect():
                            logger.info(f"å†æ¥ç¶šæˆåŠŸï¼ˆè©¦è¡Œå›æ•°: {attempt + 1}ï¼‰")
                            reconnect_success = True
                            break
                    
                    if not reconnect_success:
                        logger.warning("å†æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
                
                time.sleep(0.01)  # 10msé–“éš”
            
            # çµæœåˆ†æ
            logger.info(f"WebSocketæ¥ç¶šãƒ†ã‚¹ãƒˆçµæœ:")
            logger.info(f"  æ¥ç¶šå›æ•°: {connection_stats['connections']}")
            logger.info(f"  åˆ‡æ–­å›æ•°: {connection_stats['disconnections']}")
            logger.info(f"  å†æ¥ç¶šå›æ•°: {connection_stats['reconnections']}")
            logger.info(f"  å—ä¿¡ãƒ‡ãƒ¼ã‚¿æ•°: {connection_stats['data_received']}")
            logger.info(f"  æ¥ç¶šã‚¨ãƒ©ãƒ¼æ•°: {connection_stats['connection_errors']}")
            
            # æ¥ç¶šå›å¾©åŠ›ã®ç¢ºèª
            if connection_stats["disconnections"] > 0:
                reconnect_rate = connection_stats["reconnections"] / connection_stats["disconnections"]
                logger.info(f"  å†æ¥ç¶šæˆåŠŸç‡: {reconnect_rate:.1%}")
                assert reconnect_rate >= 0.8, f"å†æ¥ç¶šæˆåŠŸç‡ãŒä½ã™ãã¾ã™: {reconnect_rate:.1%}"
            
            # ãƒ‡ãƒ¼ã‚¿å—ä¿¡ãŒç¶™ç¶šã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert connection_stats["data_received"] > 100, f"å—ä¿¡ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã™ãã¾ã™: {connection_stats['data_received']}"
            
            logger.info("âœ… WebSocketæ¥ç¶šå›å¾©åŠ›ãƒ†ã‚¹ãƒˆæˆåŠŸ")

        except Exception as e:
            pytest.fail(f"WebSocketæ¥ç¶šå›å¾©åŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    def test_multi_timeframe_synchronization(self):
        """ãƒ†ã‚¹ãƒˆ51: è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åŒæ™‚å‡¦ç†ã§ã®åŒæœŸæ€§"""
        logger.info("ğŸ” è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")

        try:
            from app.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator

            calculator = TPSLCalculator()

            # è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            timeframes = {
                "1m": {"interval": 60, "data": []},
                "5m": {"interval": 300, "data": []},
                "15m": {"interval": 900, "data": []},
                "1h": {"interval": 3600, "data": []}
            }

            # åŸºæº–æ™‚åˆ»
            base_time = datetime(2023, 1, 1, 0, 0, 0)

            # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            for tf_name, tf_info in timeframes.items():
                interval = tf_info["interval"]
                num_periods = 100

                for i in range(num_periods):
                    timestamp = base_time + timedelta(seconds=i * interval)
                    price = 50000 + np.random.normal(0, 100)

                    data_point = {
                        "timestamp": timestamp,
                        "price": price,
                        "timeframe": tf_name,
                        "sequence": i
                    }

                    tf_info["data"].append(data_point)

            # åŒæœŸå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            sync_results = {}
            processing_times = {}

            def process_timeframe(tf_name: str, data: List[Dict]) -> Dict:
                """ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥å‡¦ç†"""
                start_time = time.time()
                results = []

                for data_point in data:
                    try:
                        # TP/SLè¨ˆç®—
                        current_price = data_point["price"]
                        sl_price, tp_price = calculator.calculate_basic_tpsl_prices(
                            current_price, 0.02, 0.04, 1.0
                        )

                        result = {
                            "timestamp": data_point["timestamp"],
                            "price": current_price,
                            "sl_price": sl_price,
                            "tp_price": tp_price,
                            "timeframe": tf_name
                        }
                        results.append(result)

                    except Exception as e:
                        logger.warning(f"{tf_name} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

                processing_time = time.time() - start_time
                return {
                    "timeframe": tf_name,
                    "results": results,
                    "processing_time": processing_time,
                    "data_points": len(data)
                }

            # ä¸¦è¡Œå‡¦ç†ã§å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡¦ç†
            start_time = time.time()

            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                futures = {
                    executor.submit(process_timeframe, tf_name, tf_info["data"]): tf_name
                    for tf_name, tf_info in timeframes.items()
                }

                for future in concurrent.futures.as_completed(futures):
                    tf_name = futures[future]
                    try:
                        result = future.result()
                        sync_results[tf_name] = result
                        processing_times[tf_name] = result["processing_time"]
                    except Exception as e:
                        logger.error(f"{tf_name} å‡¦ç†å¤±æ•—: {e}")

            total_time = time.time() - start_time

            # åŒæœŸæ€§ã®åˆ†æ
            logger.info(f"è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çµæœ:")
            logger.info(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")

            for tf_name, result in sync_results.items():
                logger.info(f"  {tf_name}: {result['data_points']}ãƒã‚¤ãƒ³ãƒˆ, {result['processing_time']:.3f}ç§’")

            # åŒæœŸæ€§ã®ç¢ºèª
            max_processing_time = max(processing_times.values())
            min_processing_time = min(processing_times.values())
            time_variance = max_processing_time - min_processing_time

            logger.info(f"å‡¦ç†æ™‚é–“ã®åˆ†æ•£: {time_variance:.3f}ç§’")

            # åŒæœŸæ€§è¦ä»¶ã®ç¢ºèªï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
            assert time_variance < 5.0, f"å‡¦ç†æ™‚é–“ã®åˆ†æ•£ãŒå¤§ãã™ãã¾ã™: {time_variance:.3f}ç§’"
            # ä¸¦è¡Œå‡¦ç†ãŒéå¸¸ã«é«˜é€Ÿãªå ´åˆã¯åŠ¹ç‡æ€§ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if max_processing_time > 0.01:  # 10msä»¥ä¸Šã®å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
                assert total_time < max_processing_time * 2.0, f"ä¸¦è¡Œå‡¦ç†ã®åŠ¹ç‡ãŒæ‚ªã™ãã¾ã™: {total_time:.3f}ç§’"

            # çµæœã®æ•´åˆæ€§ç¢ºèª
            for tf_name, result in sync_results.items():
                assert len(result["results"]) > 90, f"{tf_name}: å‡¦ç†çµæœãŒå°‘ãªã™ãã¾ã™"

                # ä¾¡æ ¼ã®å¦¥å½“æ€§ç¢ºèª
                for res in result["results"][:10]:  # æœ€åˆã®10å€‹ã‚’ãƒã‚§ãƒƒã‚¯
                    assert res["sl_price"] is not None, f"{tf_name}: SLä¾¡æ ¼ãŒNullã§ã™"
                    assert res["tp_price"] is not None, f"{tf_name}: TPä¾¡æ ¼ãŒNullã§ã™"
                    assert res["sl_price"] > 0, f"{tf_name}: SLä¾¡æ ¼ãŒè² ã§ã™"
                    assert res["tp_price"] > 0, f"{tf_name}: TPä¾¡æ ¼ãŒè² ã§ã™"

            logger.info("âœ… è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸæ€§ãƒ†ã‚¹ãƒˆæˆåŠŸ")

        except Exception as e:
            pytest.fail(f"è¤‡æ•°ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åŒæœŸæ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    def test_real_time_data_validation(self):
        """ãƒ†ã‚¹ãƒˆ52: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        logger.info("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹")

        try:
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµ±è¨ˆ
            validation_stats = {
                "total_received": 0,
                "valid_data": 0,
                "invalid_data": 0,
                "filtered_data": 0,
                "validation_errors": []
            }

            def validate_market_data(data: Dict) -> bool:
                """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
                try:
                    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
                    required_fields = ["price", "volume", "timestamp"]
                    for field in required_fields:
                        if field not in data:
                            validation_stats["validation_errors"].append(f"Missing field: {field}")
                            return False

                    # ä¾¡æ ¼ã®å¦¥å½“æ€§ç¢ºèª
                    price = float(data["price"])
                    if price <= 0 or price > 1000000:  # 0ä»¥ä¸‹ã¾ãŸã¯100ä¸‡ä»¥ä¸Šã¯ç„¡åŠ¹
                        validation_stats["validation_errors"].append(f"Invalid price: {price}")
                        return False

                    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®å¦¥å½“æ€§ç¢ºèª
                    volume = float(data["volume"])
                    if volume < 0:
                        validation_stats["validation_errors"].append(f"Invalid volume: {volume}")
                        return False

                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å¦¥å½“æ€§ç¢ºèª
                    timestamp = data["timestamp"]
                    if isinstance(timestamp, str):
                        try:
                            datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        except ValueError:
                            validation_stats["validation_errors"].append(f"Invalid timestamp: {timestamp}")
                            return False
                    elif isinstance(timestamp, (int, float)):
                        if timestamp < 0 or timestamp > time.time() + 3600:  # æœªæ¥1æ™‚é–“ä»¥å†…
                            validation_stats["validation_errors"].append(f"Invalid timestamp: {timestamp}")
                            return False

                    return True

                except (ValueError, TypeError) as e:
                    validation_stats["validation_errors"].append(f"Validation error: {e}")
                    return False

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã¨ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’æ··åœ¨ï¼‰
            test_data = []

            # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿
            for i in range(800):
                data = {
                    "price": 50000 + np.random.normal(0, 100),
                    "volume": np.random.exponential(1000),
                    "timestamp": time.time() - np.random.uniform(0, 3600),
                    "symbol": "BTC/USDT"
                }
                test_data.append(data)

            # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿
            invalid_data_samples = [
                {"volume": 1000, "timestamp": time.time()},  # ä¾¡æ ¼ãªã—
                {"price": -100, "volume": 1000, "timestamp": time.time()},  # è² ã®ä¾¡æ ¼
                {"price": 2000000, "volume": 1000, "timestamp": time.time()},  # ç•°å¸¸ã«é«˜ã„ä¾¡æ ¼
                {"price": 50000, "volume": -500, "timestamp": time.time()},  # è² ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ 
                {"price": 50000, "volume": 1000, "timestamp": "invalid"},  # ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                {"price": 50000, "volume": 1000, "timestamp": time.time() + 7200},  # æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                {"price": "invalid", "volume": 1000, "timestamp": time.time()},  # ç„¡åŠ¹ãªä¾¡æ ¼
                {"price": float('inf'), "volume": 1000, "timestamp": time.time()},  # ç„¡é™å¤§ã®ä¾¡æ ¼
                {"price": float('nan'), "volume": 1000, "timestamp": time.time()},  # NaNã®ä¾¡æ ¼
                {},  # ç©ºã®ãƒ‡ãƒ¼ã‚¿
            ]

            test_data.extend(invalid_data_samples * 20)  # 200å€‹ã®ç•°å¸¸ãƒ‡ãƒ¼ã‚¿

            # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
            np.random.shuffle(test_data)

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œè¨¼ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            start_time = time.time()

            for data in test_data:
                validation_stats["total_received"] += 1

                if validate_market_data(data):
                    validation_stats["valid_data"] += 1

                    # è¿½åŠ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆä¾¡æ ¼å¤‰å‹•ãŒå¤§ãã™ãã‚‹å ´åˆï¼‰
                    if "price" in data:
                        price = float(data["price"])
                        if abs(price - 50000) > 5000:  # åŸºæº–ä¾¡æ ¼ã‹ã‚‰5000ä»¥ä¸Šé›¢ã‚Œã¦ã„ã‚‹
                            validation_stats["filtered_data"] += 1

                else:
                    validation_stats["invalid_data"] += 1

                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                time.sleep(0.001)  # 1msé–“éš”

            processing_time = time.time() - start_time

            # æ¤œè¨¼çµæœã®åˆ†æ
            total_data = validation_stats["total_received"]
            valid_rate = validation_stats["valid_data"] / total_data
            invalid_rate = validation_stats["invalid_data"] / total_data
            filter_rate = validation_stats["filtered_data"] / total_data

            logger.info(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ:")
            logger.info(f"  ç·å—ä¿¡ãƒ‡ãƒ¼ã‚¿: {total_data}ä»¶")
            logger.info(f"  æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {validation_stats['valid_data']}ä»¶ ({valid_rate:.1%})")
            logger.info(f"  ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿: {validation_stats['invalid_data']}ä»¶ ({invalid_rate:.1%})")
            logger.info(f"  ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿: {validation_stats['filtered_data']}ä»¶ ({filter_rate:.1%})")
            logger.info(f"  å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
            logger.info(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {total_data/processing_time:.1f}ä»¶/ç§’")

            # æ¤œè¨¼è¦ä»¶ã®ç¢ºèª
            assert valid_rate >= 0.75, f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ç‡ãŒä½ã™ãã¾ã™: {valid_rate:.1%}"
            assert invalid_rate >= 0.15, f"ç•°å¸¸ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºç‡ãŒä½ã™ãã¾ã™: {invalid_rate:.1%}"
            assert processing_time < 5.0, f"å‡¦ç†æ™‚é–“ãŒé•·ã™ãã¾ã™: {processing_time:.3f}ç§’"

            # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèª
            error_count = len(validation_stats["validation_errors"])
            logger.info(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼æ•°: {error_count}ä»¶")

            if error_count > 0:
                # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã‚’åˆ†æ
                error_types = {}
                for error in validation_stats["validation_errors"][:20]:  # æœ€åˆã®20å€‹ã‚’è¡¨ç¤º
                    error_type = error.split(":")[0]
                    error_types[error_type] = error_types.get(error_type, 0) + 1

                logger.info("ä¸»è¦ãªã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:")
                for error_type, count in error_types.items():
                    logger.info(f"  {error_type}: {count}ä»¶")

            logger.info("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆæˆåŠŸ")

        except Exception as e:
            pytest.fail(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_instance = TestRealtimeProcessing()
    
    tests = [
        test_instance.test_live_market_data_streaming,
        test_instance.test_high_frequency_trading_latency,
        test_instance.test_websocket_connection_resilience,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test_instance.setup_method()
            test()
            test_instance.teardown_method()
            passed += 1
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test.__name__}: {e}")
            failed += 1
    
    print(f"\nğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ {passed}, å¤±æ•— {failed}")
    print(f"æˆåŠŸç‡: {passed / (passed + failed) * 100:.1f}%")
