"""
ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ

æ¥µç«¯ãªæ¡ä»¶ä¸‹ã§ã®ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, backend_dir)

import pytest
import pandas as pd
import numpy as np
import time
import psutil
import logging

logger = logging.getLogger(__name__)


class TestEdgeCases:
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        self.start_time = time.time()
        self.start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
    def teardown_method(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        execution_time = end_time - self.start_time
        memory_delta = end_memory - self.start_memory
        
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
        logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å¤‰åŒ–: {memory_delta:+.2f}MB")
    
    def create_minimal_dataset(self, rows: int = 5) -> pd.DataFrame:
        """æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        dates = pd.date_range(start='2023-01-01', periods=rows, freq='h')
        base_price = 50000
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': [base_price] * rows,
            'High': [base_price + 100] * rows,
            'Low': [base_price - 100] * rows,
            'Close': [base_price] * rows,
            'Volume': [1000] * rows,
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def create_flat_price_dataset(self, rows: int = 100) -> pd.DataFrame:
        """å…¨ã¦åŒã˜ä¾¡æ ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        dates = pd.date_range(start='2023-01-01', periods=rows, freq='h')
        price = 50000
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': [price] * rows,
            'High': [price] * rows,
            'Low': [price] * rows,
            'Close': [price] * rows,
            'Volume': [1000] * rows,
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def create_high_missing_dataset(self, rows: int = 100, missing_rate: float = 0.9) -> pd.DataFrame:
        """æ¬ æå€¤ãŒå¤šã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=rows, freq='h')
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        base_price = 50000
        prices = base_price + np.cumsum(np.random.randn(rows) * 100)
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': prices,
            'High': prices * 1.01,
            'Low': prices * 0.99,
            'Close': prices,
            'Volume': np.random.exponential(1000, rows),
        })
        
        # æ¬ æå€¤ã‚’æŒ¿å…¥
        mask = np.random.random((rows, 5)) < missing_rate
        for i, col in enumerate(['Open', 'High', 'Low', 'Close', 'Volume']):
            data.loc[mask[:, i], col] = np.nan
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def create_extreme_volatility_dataset(self, rows: int = 100, volatility_factor: float = 10.0) -> pd.DataFrame:
        """æ¥µç«¯ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=rows, freq='h')
        
        base_price = 50000
        # æ¥µç«¯ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        returns = np.random.randn(rows) * 0.1 * volatility_factor  # é€šå¸¸ã®10å€ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        prices = [base_price]
        
        for ret in returns[1:]:
            new_price = max(prices[-1] * (1 + ret), 1000)  # æœ€ä½ä¾¡æ ¼åˆ¶é™
            prices.append(new_price)
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': [p * (1 + np.random.normal(0, 0.01)) for p in prices],
            'High': [p * (1 + abs(np.random.normal(0, 0.05))) for p in prices],
            'Low': [p * (1 - abs(np.random.normal(0, 0.05))) for p in prices],
            'Close': prices,
            'Volume': np.random.exponential(1000, rows),
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def test_minimal_dataset_processing(self):
        """ãƒ†ã‚¹ãƒˆ21: æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ<10è¡Œï¼‰ã§ã®å‡¦ç†"""
        logger.info("ğŸ” æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            # 5è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            minimal_data = self.create_minimal_dataset(5)
            
            ml_orchestrator = MLOrchestrator(enable_automl=False)  # è»½é‡åŒ–
            
            start_time = time.time()
            try:
                ml_indicators = ml_orchestrator.calculate_ml_indicators(minimal_data)
                processing_time = time.time() - start_time
                
                # çµæœã®æ¤œè¨¼
                if ml_indicators and "ML_UP_PROB" in ml_indicators:
                    assert len(ml_indicators["ML_UP_PROB"]) <= 5, "çµæœã‚µã‚¤ã‚ºãŒå…¥åŠ›ã‚’è¶…ãˆã¦ã„ã¾ã™"
                    logger.info(f"æ¥µå°ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {len(ml_indicators['ML_UP_PROB'])}å€‹ã®çµæœ")
                else:
                    logger.info("æ¥µå°ãƒ‡ãƒ¼ã‚¿ã§MLæŒ‡æ¨™ãŒç©ºï¼ˆæœŸå¾…ã•ã‚Œã‚‹å‹•ä½œï¼‰")
                
                logger.info(f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
                
            except Exception as e:
                logger.info(f"æ¥µå°ãƒ‡ãƒ¼ã‚¿ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")
            
            logger.info("âœ… æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_flat_price_processing(self):
        """ãƒ†ã‚¹ãƒˆ22: å…¨ã¦åŒã˜ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†"""
        logger.info("ğŸ” ãƒ•ãƒ©ãƒƒãƒˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            flat_data = self.create_flat_price_dataset(100)
            
            ml_orchestrator = MLOrchestrator(enable_automl=False)
            
            start_time = time.time()
            try:
                ml_indicators = ml_orchestrator.calculate_ml_indicators(flat_data)
                processing_time = time.time() - start_time
                
                # ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®çµæœæ¤œè¨¼
                if ml_indicators and "ML_UP_PROB" in ml_indicators:
                    # ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯äºˆæ¸¬ç¢ºç‡ãŒä¸­ç«‹çš„ã«ãªã‚‹ã“ã¨ã‚’æœŸå¾…
                    up_probs = [p for p in ml_indicators["ML_UP_PROB"] if not np.isnan(p)]
                    if up_probs:
                        avg_prob = np.mean(up_probs)
                        logger.info(f"ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®å¹³å‡ä¸Šæ˜‡ç¢ºç‡: {avg_prob:.3f}")
                        # æ¥µç«¯ã«åã£ã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
                        assert 0.2 <= avg_prob <= 0.8, f"ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¥µç«¯ãªäºˆæ¸¬: {avg_prob}"
                
                logger.info(f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
                
            except Exception as e:
                logger.info(f"ãƒ•ãƒ©ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")
            
            logger.info("âœ… ãƒ•ãƒ©ãƒƒãƒˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ãƒ•ãƒ©ãƒƒãƒˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_high_missing_data_processing(self):
        """ãƒ†ã‚¹ãƒˆ23: æ¬ æå€¤ãŒ90%ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†"""
        logger.info("ğŸ” é«˜æ¬ æç‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            high_missing_data = self.create_high_missing_dataset(100, 0.9)
            missing_rate = high_missing_data.isnull().sum().sum() / (high_missing_data.shape[0] * high_missing_data.shape[1])
            logger.info(f"ãƒ‡ãƒ¼ã‚¿æ¬ æç‡: {missing_rate:.1%}")
            
            ml_orchestrator = MLOrchestrator(enable_automl=False)
            
            start_time = time.time()
            try:
                ml_indicators = ml_orchestrator.calculate_ml_indicators(high_missing_data)
                processing_time = time.time() - start_time
                
                # é«˜æ¬ æãƒ‡ãƒ¼ã‚¿ã§ã®çµæœæ¤œè¨¼
                if ml_indicators and "ML_UP_PROB" in ml_indicators:
                    valid_predictions = sum(1 for p in ml_indicators["ML_UP_PROB"] if not np.isnan(p))
                    logger.info(f"æœ‰åŠ¹ãªäºˆæ¸¬æ•°: {valid_predictions}/{len(ml_indicators['ML_UP_PROB'])}")
                    
                    # ä¸€éƒ¨ã§ã‚‚æœ‰åŠ¹ãªäºˆæ¸¬ãŒã‚ã‚Œã°æˆåŠŸ
                    if valid_predictions > 0:
                        logger.info("é«˜æ¬ æãƒ‡ãƒ¼ã‚¿ã§ã‚‚ä¸€éƒ¨äºˆæ¸¬æˆåŠŸ")
                    else:
                        logger.info("é«˜æ¬ æãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ä¸å¯ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å‹•ä½œï¼‰")
                
                logger.info(f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
                
            except Exception as e:
                logger.info(f"é«˜æ¬ æãƒ‡ãƒ¼ã‚¿ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")
            
            logger.info("âœ… é«˜æ¬ æç‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"é«˜æ¬ æç‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_extreme_volatility_processing(self):
        """ãƒ†ã‚¹ãƒˆ24: ç•°å¸¸ã«é«˜ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã®å‡¦ç†"""
        logger.info("ğŸ” æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            # é€šå¸¸ã®10å€ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            extreme_data = self.create_extreme_volatility_dataset(100, 10.0)
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—
            returns = extreme_data['Close'].pct_change().dropna()
            volatility = returns.std() * np.sqrt(24)  # æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {volatility:.1%}")
            
            ml_orchestrator = MLOrchestrator(enable_automl=False)
            
            start_time = time.time()
            try:
                ml_indicators = ml_orchestrator.calculate_ml_indicators(extreme_data)
                processing_time = time.time() - start_time
                
                # æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã®çµæœæ¤œè¨¼
                if ml_indicators and "ML_UP_PROB" in ml_indicators:
                    valid_probs = [p for p in ml_indicators["ML_UP_PROB"] if not np.isnan(p)]
                    if valid_probs:
                        # ç¢ºç‡å€¤ãŒç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                        assert all(0 <= p <= 1 for p in valid_probs), "ç¢ºç‡å€¤ãŒç¯„å›²å¤–ã§ã™"
                        prob_std = np.std(valid_probs)
                        logger.info(f"äºˆæ¸¬ç¢ºç‡ã®æ¨™æº–åå·®: {prob_std:.3f}")
                
                logger.info(f"å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
                
            except Exception as e:
                logger.info(f"æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")
            
            logger.info("âœ… æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_extreme_tpsl_settings(self):
        """ãƒ†ã‚¹ãƒˆ25: TP/SLãŒ0%ã‚„100%ã®æ¥µç«¯ãªè¨­å®šã§ã®å‡¦ç†"""
        logger.info("ğŸ” æ¥µç«¯TP/SLè¨­å®šå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator
            
            calculator = TPSLCalculator()
            current_price = 50000
            
            # æ¥µç«¯ãªè¨­å®šã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            extreme_cases = [
                {"sl": 0.0, "tp": 0.01, "desc": "SL=0%"},
                {"sl": 0.01, "tp": 0.0, "desc": "TP=0%"},
                {"sl": 1.0, "tp": 2.0, "desc": "SL=100%"},
                {"sl": 0.01, "tp": 1.0, "desc": "TP=100%"},
                {"sl": 0.001, "tp": 0.001, "desc": "æ¥µå°å€¤"},
            ]
            
            for case in extreme_cases:
                try:
                    start_time = time.time()
                    sl_price, tp_price = calculator.calculate_basic_tpsl_prices(
                        current_price, case["sl"], case["tp"], 1.0  # ãƒ­ãƒ³ã‚°
                    )
                    processing_time = time.time() - start_time
                    
                    if sl_price is not None and tp_price is not None:
                        # åŸºæœ¬çš„ãªå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                        assert sl_price > 0, f"{case['desc']}: SLä¾¡æ ¼ãŒè² ã§ã™"
                        assert tp_price > 0, f"{case['desc']}: TPä¾¡æ ¼ãŒè² ã§ã™"
                        
                        logger.info(f"{case['desc']}: SL={sl_price:.2f}, TP={tp_price:.2f} ({processing_time:.3f}ç§’)")
                    else:
                        logger.info(f"{case['desc']}: è¨ˆç®—çµæœãŒNoneï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰")
                        
                except Exception as e:
                    logger.info(f"{case['desc']}: ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")
            
            logger.info("âœ… æ¥µç«¯TP/SLè¨­å®šå‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"æ¥µç«¯TP/SLè¨­å®šå‡¦ç†ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_instance = TestEdgeCases()
    
    tests = [
        test_instance.test_minimal_dataset_processing,
        test_instance.test_flat_price_processing,
        test_instance.test_high_missing_data_processing,
        test_instance.test_extreme_volatility_processing,
        test_instance.test_extreme_tpsl_settings,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test_instance.setup_method()
            test()
            test_instance.teardown_method()
            passed += 1
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test.__name__}: {e}")
            failed += 1
    
    print(f"\nğŸ“Š ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ {passed}, å¤±æ•— {failed}")
    print(f"æˆåŠŸç‡: {passed / (passed + failed) * 100:.1f}%")
