"""
ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼åŒ…æ‹¬çš„æ‹¡å¼µãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

å…¨39å€‹ã®ãƒ†ã‚¹ãƒˆã‚’çµ±åˆå®Ÿè¡Œã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®æœ¬ç•ªé‹ç”¨æº–å‚™çŠ¶æ³ã‚’è©•ä¾¡ã—ã¾ã™ã€‚
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, backend_dir)

import logging
import time
import psutil
from datetime import datetime
import traceback
from typing import Dict, List, Any

# ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tests.auto_strategy.test_auto_strategy_comprehensive import TestAutoStrategyComprehensive
from tests.auto_strategy.test_auto_strategy_advanced import TestAutoStrategyAdvanced
from tests.auto_strategy.test_auto_strategy_integration import TestAutoStrategyIntegration
from tests.auto_strategy.test_edge_cases import TestEdgeCases
from tests.auto_strategy.test_integration_scenarios import TestIntegrationScenarios
from tests.auto_strategy.test_precision_quality import TestPrecisionQuality
from tests.auto_strategy.test_performance import TestPerformance

logger = logging.getLogger(__name__)


class ComprehensiveExtendedTestSuite:
    """åŒ…æ‹¬çš„æ‹¡å¼µãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.start_time = None
        self.end_time = None
        self.total_tests = 39
        self.passed_tests = 0
        self.failed_tests = 0
        self.test_results = []
        self.system_metrics = {
            "start_memory": 0,
            "peak_memory": 0,
            "end_memory": 0,
            "start_cpu": 0,
            "peak_cpu": 0,
            "end_cpu": 0
        }
    
    def run_all_tests(self):
        """å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼åŒ…æ‹¬çš„æ‹¡å¼µãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
        logger.info("=" * 100)
        logger.info("MLã¨ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã®å®Œå…¨é€£æºãƒ»è¨ˆç®—ç²¾åº¦ãƒ»æœ¬ç•ªé‹ç”¨æº–å‚™çŠ¶æ³ã®åŒ…æ‹¬çš„æ¤œè¨¼")
        logger.info("=" * 100)
        
        self.start_time = time.time()
        self._record_system_metrics("start")
        
        # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        self._run_basic_comprehensive_tests()
        self._run_advanced_tests()
        self._run_integration_tests()
        self._run_edge_case_tests()
        self._run_integration_scenario_tests()
        self._run_precision_quality_tests()
        self._run_performance_tests()
        
        self.end_time = time.time()
        self._record_system_metrics("end")
        self._display_comprehensive_summary()
        
        return self.passed_tests == self.total_tests
    
    def _record_system_metrics(self, phase: str):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²"""
        try:
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            cpu_percent = psutil.cpu_percent(interval=1)
            
            if phase == "start":
                self.system_metrics["start_memory"] = memory_mb
                self.system_metrics["start_cpu"] = cpu_percent
                self.system_metrics["peak_memory"] = memory_mb
                self.system_metrics["peak_cpu"] = cpu_percent
            elif phase == "end":
                self.system_metrics["end_memory"] = memory_mb
                self.system_metrics["end_cpu"] = cpu_percent
            
            # ãƒ”ãƒ¼ã‚¯å€¤ã‚’æ›´æ–°
            if memory_mb > self.system_metrics["peak_memory"]:
                self.system_metrics["peak_memory"] = memory_mb
            if cpu_percent > self.system_metrics["peak_cpu"]:
                self.system_metrics["peak_cpu"] = cpu_percent
                
        except Exception as e:
            logger.warning(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_basic_comprehensive_tests(self):
        """åŸºæœ¬åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ1-10ï¼‰"""
        logger.info("\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒª1: åŸºæœ¬åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆï¼ˆåŸºæœ¬æ©Ÿèƒ½ãƒ»è¨ˆç®—ç²¾åº¦ï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestAutoStrategyComprehensive()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ1: MLã¨ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã®çµ±åˆ", test_instance.test_ml_auto_strategy_integration),
            ("ãƒ†ã‚¹ãƒˆ2: TP/SLè¨ˆç®—ç²¾åº¦", test_instance.test_tpsl_calculation_accuracy),
            ("ãƒ†ã‚¹ãƒˆ3: TP/SLè‡ªå‹•æ±ºå®šã‚µãƒ¼ãƒ“ã‚¹", test_instance.test_tpsl_auto_decision_service),
            ("ãƒ†ã‚¹ãƒˆ4: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµ±åˆ", test_instance.test_backtest_integration),
            ("ãƒ†ã‚¹ãƒˆ5: æˆ¦ç•¥éºä¼å­æ¤œè¨¼", test_instance.test_strategy_gene_validation),
            ("ãƒ†ã‚¹ãƒˆ6: ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼çµ±åˆç®¡ç†", test_instance.test_auto_strategy_orchestration),
            ("ãƒ†ã‚¹ãƒˆ7: MLäºˆæ¸¬ç²¾åº¦", test_instance.test_ml_prediction_accuracy),
            ("ãƒ†ã‚¹ãƒˆ8: ãƒªã‚¹ã‚¯ç®¡ç†è¨ˆç®—", test_instance.test_risk_management_calculations),
            ("ãƒ†ã‚¹ãƒˆ9: æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹", test_instance.test_strategy_performance_metrics),
            ("ãƒ†ã‚¹ãƒˆ10: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³", test_instance.test_data_validation_pipeline),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_advanced_tests(self):
        """é«˜åº¦ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ11-15ï¼‰"""
        logger.info("\nğŸ”¬ ã‚«ãƒ†ã‚´ãƒª2: é«˜åº¦ãƒ†ã‚¹ãƒˆï¼ˆGAæœ€é©åŒ–ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestAutoStrategyAdvanced()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ11: GAæœ€é©åŒ–çµ±åˆ", test_instance.test_ga_optimization_integration),
            ("ãƒ†ã‚¹ãƒˆ12: ä¸¦è¡Œæˆ¦ç•¥å®Ÿè¡Œ", test_instance.test_concurrent_strategy_execution),
            ("ãƒ†ã‚¹ãƒˆ13: æ¥µç«¯ãªå¸‚å ´æ¡ä»¶", test_instance.test_extreme_market_conditions),
            ("ãƒ†ã‚¹ãƒˆ14: ãƒ¡ãƒ¢ãƒªãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–", test_instance.test_memory_performance_optimization),
            ("ãƒ†ã‚¹ãƒˆ15: ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ»å¾©å…ƒåŠ›", test_instance.test_error_recovery_resilience),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_integration_tests(self):
        """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ16-20ï¼‰"""
        logger.info("\nğŸ”— ã‚«ãƒ†ã‚´ãƒª3: çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ»APIé€£æºï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestAutoStrategyIntegration()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ16: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰æˆ¦ç•¥ç”Ÿæˆ", test_instance.test_end_to_end_strategy_generation),
            ("ãƒ†ã‚¹ãƒˆ17: ML-ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³", test_instance.test_ml_auto_strategy_full_pipeline),
            ("ãƒ†ã‚¹ãƒˆ18: APIçµ±åˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", test_instance.test_api_integration_simulation),
            ("ãƒ†ã‚¹ãƒˆ19: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸€è²«æ€§", test_instance.test_data_flow_consistency),
            ("ãƒ†ã‚¹ãƒˆ20: è¨­å®šæ¤œè¨¼", test_instance.test_configuration_validation),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_edge_case_tests(self):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ21-25ï¼‰"""
        logger.info("\nâš ï¸ ã‚«ãƒ†ã‚´ãƒª4: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆæ¥µç«¯æ¡ä»¶ãƒ»å¢ƒç•Œå€¤ï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestEdgeCases()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ21: æ¥µå°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†", test_instance.test_minimal_dataset_processing),
            ("ãƒ†ã‚¹ãƒˆ22: ãƒ•ãƒ©ãƒƒãƒˆä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†", test_instance.test_flat_price_processing),
            ("ãƒ†ã‚¹ãƒˆ23: é«˜æ¬ æç‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†", test_instance.test_high_missing_data_processing),
            ("ãƒ†ã‚¹ãƒˆ24: æ¥µç«¯ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å‡¦ç†", test_instance.test_extreme_volatility_processing),
            ("ãƒ†ã‚¹ãƒˆ25: æ¥µç«¯TP/SLè¨­å®šå‡¦ç†", test_instance.test_extreme_tpsl_settings),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_integration_scenario_tests(self):
        """çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ26-30ï¼‰"""
        logger.info("\nğŸ”„ ã‚«ãƒ†ã‚´ãƒª5: çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆï¼ˆè¤‡é›‘çµ±åˆãƒ»é•·æ™‚é–“å®Ÿè¡Œï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestIntegrationScenarios()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ26: ä¸¦è¡Œæˆ¦ç•¥å®Ÿè¡Œç«¶åˆ", test_instance.test_concurrent_strategy_execution),
            ("ãƒ†ã‚¹ãƒˆ27: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º", test_instance.test_memory_leak_detection),
            ("ãƒ†ã‚¹ãƒˆ28: é«˜è² è·ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ", test_instance.test_high_load_concurrent_requests),
            ("ãƒ†ã‚¹ãƒˆ29: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼å›å¾©", test_instance.test_database_connection_error_recovery),
            ("ãƒ†ã‚¹ãƒˆ30: é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§", test_instance.test_long_running_stability),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_precision_quality_tests(self):
        """ç²¾åº¦ãƒ»å“è³ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ31-35ï¼‰"""
        logger.info("\nğŸ¯ ã‚«ãƒ†ã‚´ãƒª6: ç²¾åº¦ãƒ»å“è³ªãƒ†ã‚¹ãƒˆï¼ˆçµ±è¨ˆçš„æœ‰æ„æ€§ãƒ»æ•°å­¦çš„æ­£ç¢ºæ€§ï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestPrecisionQuality()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ31: MLäºˆæ¸¬çµ±è¨ˆçš„æœ‰æ„æ€§", test_instance.test_ml_prediction_statistical_significance),
            ("ãƒ†ã‚¹ãƒˆ32: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå†ç¾æ€§", test_instance.test_backtest_reproducibility),
            ("ãƒ†ã‚¹ãƒˆ33: TP/SLæ•°å­¦çš„æ­£ç¢ºæ€§", test_instance.test_tpsl_mathematical_accuracy),
            ("ãƒ†ã‚¹ãƒˆ34: ãƒªã‚¹ã‚¯ç®¡ç†å¢ƒç•Œå€¤", test_instance.test_risk_management_boundary_values),
            ("ãƒ†ã‚¹ãƒˆ35: å¸‚å ´æ¡ä»¶åˆ¥äºˆæ¸¬ç²¾åº¦", test_instance.test_market_condition_prediction_accuracy),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _run_performance_tests(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆ36-39ï¼‰"""
        logger.info("\nğŸš€ ã‚«ãƒ†ã‚´ãƒª7: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆå¤§è¦æ¨¡å‡¦ç†ãƒ»æœ€é©åŒ–ï¼‰")
        logger.info("-" * 80)
        
        test_instance = TestPerformance()
        
        tests = [
            ("ãƒ†ã‚¹ãƒˆ36: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†é€Ÿåº¦", test_instance.test_large_dataset_processing_speed),
            ("ãƒ†ã‚¹ãƒˆ37: åŒæ™‚æ¥ç¶šæ•°ä¸Šé™", test_instance.test_concurrent_connection_limit),
            ("ãƒ†ã‚¹ãƒˆ38: CPU/ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–", test_instance.test_cpu_memory_optimization),
            ("ãƒ†ã‚¹ãƒˆ39: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ä¸€è²«æ€§", test_instance.test_response_time_consistency),
        ]
        
        self._execute_test_category(test_instance, tests)
    
    def _execute_test_category(self, test_instance, tests):
        """ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’å®Ÿè¡Œ"""
        try:
            test_instance.setup_method()
        except:
            pass
        
        for test_name, test_method in tests:
            self._run_single_test(test_name, test_method, test_instance)
        
        try:
            test_instance.teardown_method()
        except:
            pass
    
    def _run_single_test(self, test_name, test_method, test_instance):
        """å˜ä¸€ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        try:
            logger.info(f"ğŸ” å®Ÿè¡Œä¸­: {test_name}")
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_method()
            
            execution_time = time.time() - start_time
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            memory_delta = end_memory - start_memory
            
            self.passed_tests += 1
            
            result = {
                "name": test_name,
                "status": "PASSED",
                "execution_time": execution_time,
                "memory_delta": memory_delta,
                "error": None
            }
            
            logger.info(f"âœ… æˆåŠŸ: {test_name} ({execution_time:.3f}ç§’, {memory_delta:+.1f}MB)")
            
        except Exception as e:
            execution_time = time.time() - start_time
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            memory_delta = end_memory - start_memory

            self.failed_tests += 1

            result = {
                "name": test_name,
                "status": "FAILED",
                "execution_time": execution_time,
                "memory_delta": memory_delta,
                "error": str(e)
            }

            logger.error(f"âŒ å¤±æ•—: {test_name} ({execution_time:.3f}ç§’)")
            logger.error(f"   ã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒ‡ãƒãƒƒã‚°ç”¨ã®è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±
            if logger.level <= logging.DEBUG:
                logger.debug(f"   ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:\n{traceback.format_exc()}")

        finally:
            if 'result' in locals():
                self.test_results.append(result)
            else:
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                self.test_results.append({
                    "name": test_name,
                    "status": "ERROR",
                    "execution_time": time.time() - start_time,
                    "memory_delta": 0,
                    "error": "Unknown error"
                })
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self._record_system_metrics("update")
            
            # ãƒ†ã‚¹ãƒˆé–“ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                test_instance.teardown_method()
                test_instance.setup_method()
            except:
                pass
    
    def _display_comprehensive_summary(self):
        """åŒ…æ‹¬çš„ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        total_time = self.end_time - self.start_time
        success_rate = (self.passed_tests / self.total_tests) * 100
        
        logger.info("\n" + "=" * 100)
        logger.info("ğŸ¯ ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼åŒ…æ‹¬çš„æ‹¡å¼µãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 100)
        
        # ç·åˆçµæœ
        logger.info(f"ğŸ“Š ç·åˆçµæœ:")
        logger.info(f"   â€¢ ç·ãƒ†ã‚¹ãƒˆæ•°: {self.total_tests}")
        logger.info(f"   â€¢ æˆåŠŸ: {self.passed_tests} âœ…")
        logger.info(f"   â€¢ å¤±æ•—: {self.failed_tests} âŒ")
        logger.info(f"   â€¢ æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"   â€¢ ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†)")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ
        logger.info(f"\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ:")
        
        categories = [
            ("åŸºæœ¬åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ", 0, 10),
            ("é«˜åº¦ãƒ†ã‚¹ãƒˆ", 10, 15),
            ("çµ±åˆãƒ†ã‚¹ãƒˆ", 15, 20),
            ("ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ", 20, 25),
            ("çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ", 25, 30),
            ("ç²¾åº¦ãƒ»å“è³ªãƒ†ã‚¹ãƒˆ", 30, 35),
            ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", 35, 39)
        ]
        
        for category_name, start_idx, end_idx in categories:
            category_results = self.test_results[start_idx:end_idx]
            category_passed = sum(1 for r in category_results if r["status"] == "PASSED")
            category_total = len(category_results)
            category_rate = (category_passed / category_total) * 100 if category_total > 0 else 0
            
            logger.info(f"   â€¢ {category_name}: {category_passed}/{category_total} ({category_rate:.1f}%)")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
        logger.info(f"\nğŸ’» ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡:")
        memory_delta = self.system_metrics["end_memory"] - self.system_metrics["start_memory"]
        memory_peak_delta = self.system_metrics["peak_memory"] - self.system_metrics["start_memory"]
        
        logger.info(f"   â€¢ ãƒ¡ãƒ¢ãƒª: é–‹å§‹={self.system_metrics['start_memory']:.1f}MB, "
                   f"ãƒ”ãƒ¼ã‚¯={self.system_metrics['peak_memory']:.1f}MB, "
                   f"çµ‚äº†={self.system_metrics['end_memory']:.1f}MB")
        logger.info(f"   â€¢ ãƒ¡ãƒ¢ãƒªå¤‰åŒ–: æœ€çµ‚={memory_delta:+.1f}MB, ãƒ”ãƒ¼ã‚¯å¢—åŠ ={memory_peak_delta:+.1f}MB")
        logger.info(f"   â€¢ CPU: é–‹å§‹={self.system_metrics['start_cpu']:.1f}%, "
                   f"ãƒ”ãƒ¼ã‚¯={self.system_metrics['peak_cpu']:.1f}%, "
                   f"çµ‚äº†={self.system_metrics['end_cpu']:.1f}%")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        execution_times = [r["execution_time"] for r in self.test_results]
        memory_deltas = [r["memory_delta"] for r in self.test_results]
        
        avg_time = sum(execution_times) / len(execution_times)
        max_time = max(execution_times)
        min_time = min(execution_times)
        
        avg_memory = sum(memory_deltas) / len(memory_deltas)
        max_memory = max(memory_deltas)
        min_memory = min(memory_deltas)
        
        logger.info(f"\nâ±ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ:")
        logger.info(f"   â€¢ å®Ÿè¡Œæ™‚é–“: å¹³å‡={avg_time:.3f}ç§’, æœ€é•·={max_time:.3f}ç§’, æœ€çŸ­={min_time:.3f}ç§’")
        logger.info(f"   â€¢ ãƒ¡ãƒ¢ãƒªå¤‰åŒ–: å¹³å‡={avg_memory:+.1f}MB, æœ€å¤§={max_memory:+.1f}MB, æœ€å°={min_memory:+.1f}MB")
        
        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°
        if self.failed_tests > 0:
            logger.info(f"\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
            for result in self.test_results:
                if result["status"] == "FAILED":
                    logger.info(f"   â€¢ {result['name']}: {result['error']}")
        
        # æœ¬ç•ªé‹ç”¨æº–å‚™çŠ¶æ³è©•ä¾¡
        logger.info(f"\nğŸ¯ æœ¬ç•ªé‹ç”¨æº–å‚™çŠ¶æ³è©•ä¾¡:")
        
        if success_rate >= 95:
            readiness_level = "å®Œå…¨æº–å‚™å®Œäº†"
            readiness_emoji = "ğŸŒŸ"
            readiness_desc = "å…¨ã¦ã®æ©Ÿèƒ½ãŒå®Œç’§ã«å‹•ä½œã—ã€æœ¬ç•ªé‹ç”¨ã«å®Œå…¨å¯¾å¿œå¯èƒ½ã§ã™ã€‚"
        elif success_rate >= 90:
            readiness_level = "æº–å‚™å®Œäº†"
            readiness_emoji = "âœ…"
            readiness_desc = "ã»ã¼å…¨ã¦ã®æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã€æœ¬ç•ªé‹ç”¨å¯èƒ½ã§ã™ã€‚"
        elif success_rate >= 80:
            readiness_level = "æº–å‚™ä¸­"
            readiness_emoji = "âš ï¸"
            readiness_desc = "ä¸€éƒ¨ã®æ©Ÿèƒ½ã§å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£å¾Œã«æœ¬ç•ªé‹ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        elif success_rate >= 70:
            readiness_level = "è¦æ”¹å–„"
            readiness_emoji = "ğŸ”§"
            readiness_desc = "é‡è¦ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç•ªé‹ç”¨å‰ã«ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚"
        else:
            readiness_level = "æœªæº–å‚™"
            readiness_emoji = "ğŸš¨"
            readiness_desc = "é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç•ªé‹ç”¨ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“ã€‚"
        
        logger.info(f"   {readiness_emoji} æº–å‚™çŠ¶æ³: {readiness_level} ({success_rate:.1f}%)")
        logger.info(f"   ğŸ“ è©•ä¾¡: {readiness_desc}")
        
        # æ¨å¥¨äº‹é …
        logger.info(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
        if success_rate >= 95:
            logger.info("   â€¢ ã‚·ã‚¹ãƒ†ãƒ ã¯æœ¬ç•ªé‹ç”¨ã«å®Œå…¨å¯¾å¿œã—ã¦ã„ã¾ã™")
            logger.info("   â€¢ å®šæœŸçš„ãªç›£è¦–ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„")
        elif success_rate >= 90:
            logger.info("   â€¢ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®åŸå› ã‚’èª¿æŸ»ã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„")
            logger.info("   â€¢ æœ¬ç•ªç’°å¢ƒã§ã®æ®µéšçš„å±•é–‹ã‚’æ¨å¥¨ã—ã¾ã™")
        else:
            logger.info("   â€¢ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‚’å„ªå…ˆçš„ã«ä¿®æ­£ã—ã¦ãã ã•ã„")
            logger.info("   â€¢ ä¿®æ­£å¾Œã«å†åº¦åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            logger.info("   â€¢ æœ¬ç•ªé‹ç”¨å‰ã«è¿½åŠ ã®æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„")
        
        logger.info("=" * 100)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    test_suite = ComprehensiveExtendedTestSuite()
    success = test_suite.run_all_tests()
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
