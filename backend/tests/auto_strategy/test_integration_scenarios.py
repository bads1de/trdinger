"""
ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ

è¤‡é›‘ãªçµ±åˆã‚·ãƒŠãƒªã‚ªã§ã®ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, backend_dir)

import pytest
import pandas as pd
import numpy as np
import time
import psutil
import threading
import concurrent.futures
import gc
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List
import sqlite3

logger = logging.getLogger(__name__)


class TestIntegrationScenarios:
    """çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        self.start_time = time.time()
        self.start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        self.memory_samples = []
        self.monitoring_active = True
        
        # ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self.memory_monitor_thread = threading.Thread(target=self._monitor_memory, daemon=True)
        self.memory_monitor_thread.start()
        
    def teardown_method(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.monitoring_active = False
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        execution_time = end_time - self.start_time
        memory_delta = end_memory - self.start_memory
        
        # ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ
        if self.memory_samples:
            max_memory = max(self.memory_samples)
            avg_memory = sum(self.memory_samples) / len(self.memory_samples)
            logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: é–‹å§‹={self.start_memory:.1f}MB, æœ€å¤§={max_memory:.1f}MB, å¹³å‡={avg_memory:.1f}MB, å¤‰åŒ–={memory_delta:+.1f}MB")
        
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“: {execution_time:.3f}ç§’")
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()
    
    def _monitor_memory(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–"""
        while self.monitoring_active:
            try:
                memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
                self.memory_samples.append(memory_mb)
                time.sleep(0.5)  # 0.5ç§’é–“éš”ã§ç›£è¦–
            except:
                break
    
    def create_test_data(self, size: int = 1000) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=size, freq='h')
        
        base_price = 50000
        returns = np.random.normal(0, 0.02, size)
        prices = [base_price]
        
        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': [p * (1 + np.random.normal(0, 0.001)) for p in prices],
            'High': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
            'Low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
            'Close': prices,
            'Volume': np.random.exponential(1000, size),
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def test_concurrent_strategy_execution(self):
        """ãƒ†ã‚¹ãƒˆ26: è¤‡æ•°ã®æˆ¦ç•¥ã‚’åŒæ™‚å®Ÿè¡Œã—ãŸå ´åˆã®ç«¶åˆå‡¦ç†"""
        logger.info("ğŸ” ä¸¦è¡Œæˆ¦ç•¥å®Ÿè¡Œç«¶åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            test_data = self.create_test_data(500)
            
            def run_strategy(strategy_id: int) -> Dict[str, Any]:
                """æˆ¦ç•¥ã‚’å®Ÿè¡Œ"""
                try:
                    start_time = time.time()
                    ml_orchestrator = MLOrchestrator(enable_automl=False)
                    
                    result = ml_orchestrator.calculate_ml_indicators(test_data)
                    execution_time = time.time() - start_time
                    
                    return {
                        "strategy_id": strategy_id,
                        "success": True,
                        "execution_time": execution_time,
                        "result_size": len(result.get("ML_UP_PROB", [])) if result else 0,
                        "error": None
                    }
                except Exception as e:
                    return {
                        "strategy_id": strategy_id,
                        "success": False,
                        "execution_time": time.time() - start_time,
                        "result_size": 0,
                        "error": str(e)
                    }
            
            # 5ã¤ã®æˆ¦ç•¥ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            num_strategies = 5
            start_time = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=num_strategies) as executor:
                futures = [executor.submit(run_strategy, i) for i in range(num_strategies)]
                results = [future.result(timeout=60) for future in futures]
            
            total_time = time.time() - start_time
            
            # çµæœåˆ†æ
            successful_results = [r for r in results if r["success"]]
            success_rate = len(successful_results) / len(results)
            
            if successful_results:
                avg_execution_time = sum(r["execution_time"] for r in successful_results) / len(successful_results)
                logger.info(f"ä¸¦è¡Œå®Ÿè¡Œçµæœ: {len(successful_results)}/{len(results)} æˆåŠŸ ({success_rate:.1%})")
                logger.info(f"å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_execution_time:.3f}ç§’, ç·æ™‚é–“: {total_time:.3f}ç§’")
                
                # ç«¶åˆã«ã‚ˆã‚‹å¤§å¹…ãªæ€§èƒ½åŠ£åŒ–ãŒãªã„ã“ã¨ã‚’ç¢ºèª
                assert success_rate >= 0.6, f"æˆåŠŸç‡ãŒä½ã™ãã¾ã™: {success_rate:.1%}"
            
            logger.info("âœ… ä¸¦è¡Œæˆ¦ç•¥å®Ÿè¡Œç«¶åˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ä¸¦è¡Œæˆ¦ç•¥å®Ÿè¡Œç«¶åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_memory_leak_detection(self):
        """ãƒ†ã‚¹ãƒˆ27: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®æ¤œå‡º"""
        logger.info("ğŸ” ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            test_data = self.create_test_data(200)
            initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            memory_measurements = []
            
            # 10å›ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–
            for i in range(10):
                try:
                    ml_orchestrator = MLOrchestrator(enable_automl=False)
                    result = ml_orchestrator.calculate_ml_indicators(test_data)
                    
                    # æ˜ç¤ºçš„ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤
                    del ml_orchestrator
                    del result
                    
                    # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
                    gc.collect()
                    
                    # ãƒ¡ãƒ¢ãƒªæ¸¬å®š
                    current_memory = psutil.Process().memory_info().rss / 1024 / 1024
                    memory_measurements.append(current_memory)
                    
                    logger.info(f"åå¾© {i+1}: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ {current_memory:.1f}MB")
                    
                except Exception as e:
                    logger.warning(f"åå¾© {i+1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            if len(memory_measurements) >= 5:
                # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯åˆ†æ
                final_memory = memory_measurements[-1]
                memory_increase = final_memory - initial_memory
                
                # ç·šå½¢å›å¸°ã§ãƒ¡ãƒ¢ãƒªå¢—åŠ å‚¾å‘ã‚’åˆ†æ
                x = np.arange(len(memory_measurements))
                y = np.array(memory_measurements)
                slope = np.polyfit(x, y, 1)[0]  # å‚¾ã
                
                logger.info(f"ãƒ¡ãƒ¢ãƒªå¤‰åŒ–: åˆæœŸ={initial_memory:.1f}MB, æœ€çµ‚={final_memory:.1f}MB, å¢—åŠ ={memory_increase:+.1f}MB")
                logger.info(f"ãƒ¡ãƒ¢ãƒªå¢—åŠ å‚¾å‘: {slope:+.2f}MB/åå¾©")
                
                # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®åˆ¤å®šï¼ˆ1åå¾©ã‚ãŸã‚Š5MBä»¥ä¸Šã®å¢—åŠ ã¯å•é¡Œï¼‰
                assert slope < 5.0, f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§: {slope:.2f}MB/åå¾©"
                assert memory_increase < 100, f"ç·ãƒ¡ãƒ¢ãƒªå¢—åŠ ãŒå¤§ãã™ãã¾ã™: {memory_increase:.1f}MB"
            
            logger.info("âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_high_load_concurrent_requests(self):
        """ãƒ†ã‚¹ãƒˆ28: å¤§é‡ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"""
        logger.info("ğŸ” é«˜è² è·ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator
            
            calculator = TPSLCalculator()
            
            def process_request(request_id: int) -> Dict[str, Any]:
                """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
                try:
                    start_time = time.time()
                    
                    # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§TP/SLè¨ˆç®—
                    current_price = 50000 + np.random.randint(-5000, 5000)
                    sl_pct = np.random.uniform(0.01, 0.05)
                    tp_pct = np.random.uniform(0.02, 0.08)
                    direction = np.random.choice([1.0, -1.0])
                    
                    sl_price, tp_price = calculator.calculate_basic_tpsl_prices(
                        current_price, sl_pct, tp_pct, direction
                    )
                    
                    execution_time = time.time() - start_time
                    
                    return {
                        "request_id": request_id,
                        "success": True,
                        "execution_time": execution_time,
                        "sl_price": sl_price,
                        "tp_price": tp_price,
                        "error": None
                    }
                except Exception as e:
                    return {
                        "request_id": request_id,
                        "success": False,
                        "execution_time": time.time() - start_time,
                        "sl_price": None,
                        "tp_price": None,
                        "error": str(e)
                    }
            
            # 50å€‹ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            num_requests = 50
            start_time = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
                futures = [executor.submit(process_request, i) for i in range(num_requests)]
                results = [future.result(timeout=30) for future in futures]
            
            total_time = time.time() - start_time
            
            # çµæœåˆ†æ
            successful_results = [r for r in results if r["success"]]
            success_rate = len(successful_results) / len(results)
            
            if successful_results:
                execution_times = [r["execution_time"] for r in successful_results]
                avg_time = sum(execution_times) / len(execution_times)
                max_time = max(execution_times)
                min_time = min(execution_times)
                
                logger.info(f"é«˜è² è·ãƒ†ã‚¹ãƒˆçµæœ: {len(successful_results)}/{len(results)} æˆåŠŸ ({success_rate:.1%})")
                logger.info(f"å®Ÿè¡Œæ™‚é–“: å¹³å‡={avg_time:.3f}ç§’, æœ€å¤§={max_time:.3f}ç§’, æœ€å°={min_time:.3f}ç§’")
                logger.info(f"ç·å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’, ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {len(results)/total_time:.1f}req/ç§’")
                
                # æ€§èƒ½è¦ä»¶ã®ç¢ºèª
                assert success_rate >= 0.9, f"æˆåŠŸç‡ãŒä½ã™ãã¾ã™: {success_rate:.1%}"
                assert avg_time < 1.0, f"å¹³å‡å¿œç­”æ™‚é–“ãŒé•·ã™ãã¾ã™: {avg_time:.3f}ç§’"
            
            logger.info("âœ… é«˜è² è·ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"é«˜è² è·ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_database_connection_error_recovery(self):
        """ãƒ†ã‚¹ãƒˆ29: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼æ™‚ã®å›å¾©å‡¦ç†"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            def simulate_db_error():
                """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
                raise sqlite3.OperationalError("database is locked")
            
            def simulate_db_recovery():
                """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å›å¾©ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
                return {"status": "recovered", "data": "test_data"}
            
            # ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ
            max_retries = 3
            retry_delay = 0.1
            
            for attempt in range(max_retries):
                try:
                    if attempt < 2:  # æœ€åˆã®2å›ã¯ã‚¨ãƒ©ãƒ¼
                        simulate_db_error()
                    else:  # 3å›ç›®ã§æˆåŠŸ
                        result = simulate_db_recovery()
                        logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å›å¾©æˆåŠŸ: è©¦è¡Œå›æ•°={attempt+1}")
                        assert result["status"] == "recovered", "å›å¾©çµæœãŒç„¡åŠ¹ã§ã™"
                        break
                        
                except sqlite3.OperationalError as e:
                    logger.info(f"è©¦è¡Œ {attempt+1}: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    else:
                        raise
            
            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã®ãƒ†ã‚¹ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            try:
                # ãƒ†ã‚¹ãƒˆç”¨ã®è»½é‡ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
                import tempfile
                with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as tmp_file:
                    test_db_path = tmp_file.name
                
                # æ¥ç¶šãƒ†ã‚¹ãƒˆ
                conn = sqlite3.connect(test_db_path, timeout=5.0)
                cursor = conn.cursor()
                cursor.execute("CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, data TEXT)")
                cursor.execute("INSERT INTO test (data) VALUES (?)", ("test_data",))
                conn.commit()
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
                cursor.execute("SELECT * FROM test")
                results = cursor.fetchall()
                assert len(results) > 0, "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãŒå¤±æ•—ã—ã¾ã—ãŸ"
                
                conn.close()
                os.unlink(test_db_path)  # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                
                logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆæˆåŠŸ")
                
            except Exception as e:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_long_running_stability(self):
        """ãƒ†ã‚¹ãƒˆ30: é•·æ™‚é–“å®Ÿè¡Œã§ã®å®‰å®šæ€§ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        logger.info("ğŸ” é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.auto_strategy.services.ml_orchestrator import MLOrchestrator
            
            test_data = self.create_test_data(100)  # è»½é‡åŒ–
            
            # é•·æ™‚é–“å®Ÿè¡Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã¯çŸ­æ™‚é–“ã§å¤šæ•°å®Ÿè¡Œï¼‰
            duration_seconds = 30  # ãƒ†ã‚¹ãƒˆç”¨ã«30ç§’ã«çŸ­ç¸®
            interval_seconds = 1
            
            start_time = time.time()
            execution_count = 0
            error_count = 0
            execution_times = []
            
            while time.time() - start_time < duration_seconds:
                try:
                    iteration_start = time.time()
                    
                    ml_orchestrator = MLOrchestrator(enable_automl=False)
                    result = ml_orchestrator.calculate_ml_indicators(test_data)
                    
                    iteration_time = time.time() - iteration_start
                    execution_times.append(iteration_time)
                    execution_count += 1
                    
                    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
                    current_memory = psutil.Process().memory_info().rss / 1024 / 1024
                    if execution_count % 5 == 0:
                        logger.info(f"å®Ÿè¡Œ {execution_count}: æ™‚é–“={iteration_time:.3f}ç§’, ãƒ¡ãƒ¢ãƒª={current_memory:.1f}MB")
                    
                    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    del ml_orchestrator
                    del result
                    
                    time.sleep(interval_seconds)
                    
                except Exception as e:
                    error_count += 1
                    logger.warning(f"å®Ÿè¡Œ {execution_count+1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            total_time = time.time() - start_time
            
            # å®‰å®šæ€§åˆ†æ
            if execution_times:
                avg_time = sum(execution_times) / len(execution_times)
                max_time = max(execution_times)
                min_time = min(execution_times)
                time_std = np.std(execution_times)
                
                error_rate = error_count / (execution_count + error_count) if (execution_count + error_count) > 0 else 0
                
                logger.info(f"é•·æ™‚é–“å®Ÿè¡Œçµæœ: ç·å®Ÿè¡Œ={execution_count}, ã‚¨ãƒ©ãƒ¼={error_count}, ã‚¨ãƒ©ãƒ¼ç‡={error_rate:.1%}")
                logger.info(f"å®Ÿè¡Œæ™‚é–“: å¹³å‡={avg_time:.3f}ç§’, æœ€å¤§={max_time:.3f}ç§’, æœ€å°={min_time:.3f}ç§’, æ¨™æº–åå·®={time_std:.3f}ç§’")
                logger.info(f"ç·æ™‚é–“: {total_time:.1f}ç§’")
                
                # å®‰å®šæ€§è¦ä»¶ã®ç¢ºèª
                assert error_rate < 0.1, f"ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™: {error_rate:.1%}"
                assert time_std < avg_time, f"å®Ÿè¡Œæ™‚é–“ã®ã°ã‚‰ã¤ããŒå¤§ãã™ãã¾ã™: {time_std:.3f}ç§’"
            
            logger.info("âœ… é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_instance = TestIntegrationScenarios()
    
    tests = [
        test_instance.test_concurrent_strategy_execution,
        test_instance.test_memory_leak_detection,
        test_instance.test_high_load_concurrent_requests,
        test_instance.test_database_connection_error_recovery,
        test_instance.test_long_running_stability,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test_instance.setup_method()
            test()
            test_instance.teardown_method()
            passed += 1
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test.__name__}: {e}")
            failed += 1
    
    print(f"\nğŸ“Š çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ {passed}, å¤±æ•— {failed}")
    print(f"æˆåŠŸç‡: {passed / (passed + failed) * 100:.1f}%")
