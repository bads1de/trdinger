"""
ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ

æ–°è¦å®Ÿè£…ã•ã‚ŒãŸç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pytest
import pandas as pd
import numpy as np
import asyncio
import tempfile
import shutil
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class TestMonitoringSystems:
    """ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        self.test_data = self.create_test_data()
        self.temp_dir = tempfile.mkdtemp()
    
    def teardown_method(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def create_test_data(self, size: int = 1000) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=size, freq='H')
        
        # åŸºæœ¬ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        close_prices = 50000 + np.cumsum(np.random.randn(size) * 100)
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': close_prices + np.random.randn(size) * 50,
            'High': close_prices + np.abs(np.random.randn(size)) * 100,
            'Low': close_prices - np.abs(np.random.randn(size)) * 100,
            'Close': close_prices,
            'Volume': np.random.exponential(1000, size),
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def test_data_drift_detector(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.monitoring.data_drift_detector import DataDriftDetector, DriftType
            
            detector = DataDriftDetector()
            
            # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            reference_data = self.test_data.iloc[:500]
            detector.set_reference_data(reference_data)
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‰ãƒªãƒ•ãƒˆã‚ã‚Šï¼‰
            current_data = self.test_data.iloc[500:].copy()
            # æ„å›³çš„ã«ãƒ‰ãƒªãƒ•ãƒˆã‚’ä½œæˆ
            current_data['Close'] *= 1.2  # 20%ã®ä¾¡æ ¼ä¸Šæ˜‡
            current_data['Volume'] *= 0.8  # 20%ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¸›å°‘
            
            # ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œ
            drift_results = detector.detect_drift(current_data)
            
            # çµæœã®æ¤œè¨¼
            assert len(drift_results) > 0, "ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºçµæœãŒç©ºã§ã™"
            
            # ãƒ‰ãƒªãƒ•ãƒˆãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            drift_detected = any(result.drift_type != DriftType.NO_DRIFT for result in drift_results)
            assert drift_detected, "ãƒ‰ãƒªãƒ•ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            
            # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’å–å¾—
            summary = detector.get_drift_summary(hours=1)
            assert isinstance(summary, dict), "ã‚µãƒãƒªãƒ¼æƒ…å ±ãŒç„¡åŠ¹ã§ã™"
            assert 'total_detections' in summary, "ã‚µãƒãƒªãƒ¼ã«æ¤œå‡ºæ•°ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            
            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºæˆåŠŸ: {len(drift_results)}å€‹ã®çµæœ")
            
        except Exception as e:
            pytest.fail(f"ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_realtime_monitor(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.monitoring.realtime_monitor import RealtimeMonitor
            
            monitor = RealtimeMonitor()
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
            received_alerts = []
            def alert_callback(alert):
                received_alerts.append(alert)
            
            monitor.add_alert_callback(alert_callback)
            
            # äºˆæ¸¬å®Ÿè¡Œã‚’è¨˜éŒ²
            monitor.record_prediction("test_model", 150.0, True)  # æ­£å¸¸
            monitor.record_prediction("test_model", 2000.0, False)  # é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ»ã‚¨ãƒ©ãƒ¼
            monitor.record_prediction("test_model", 100.0, True)  # æ­£å¸¸
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ‰‹å‹•å®Ÿè¡Œï¼‰
            monitor._check_system_metrics()
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ‰‹å‹•å®Ÿè¡Œï¼‰
            monitor._check_model_metrics()
            
            # ç›£è¦–çŠ¶æ…‹ã‚’å–å¾—
            status = monitor.get_monitoring_status()
            assert isinstance(status, dict), "ç›£è¦–çŠ¶æ…‹ãŒç„¡åŠ¹ã§ã™"
            assert 'is_running' in status, "ç›£è¦–çŠ¶æ…‹ã«å®Ÿè¡ŒçŠ¶æ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            assert 'monitored_models' in status, "ç›£è¦–çŠ¶æ…‹ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            assert 'test_model' in status['monitored_models'], "ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ãŒç›£è¦–å¯¾è±¡ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            
            logger.info(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–æˆåŠŸ: {len(received_alerts)}å€‹ã®ã‚¢ãƒ©ãƒ¼ãƒˆ")
            
        except Exception as e:
            pytest.fail(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_alert_system(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.monitoring.alert_system import AlertSystem
            from app.services.ml.monitoring.realtime_monitor import Alert, AlertLevel
            
            alert_system = AlertSystem()
            
            # ãƒ†ã‚¹ãƒˆç”¨ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆ
            test_alert = Alert(
                timestamp=datetime.now(),
                level=AlertLevel.WARNING,
                category="test",
                message="ãƒ†ã‚¹ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆ",
                details={"test_key": "test_value"}
            )
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆéåŒæœŸï¼‰
            async def test_alert_handling():
                await alert_system.handle_alert(test_alert)
                
                # ä¿ç•™ä¸­ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†
                await alert_system.process_pending_escalations()
                
                # çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
                stats = alert_system.get_alert_statistics()
                assert isinstance(stats, dict), "ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆãŒç„¡åŠ¹ã§ã™"
                assert 'enabled_channels' in stats, "çµ±è¨ˆã«æœ‰åŠ¹ãƒãƒ£ãƒãƒ«æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
                
                return True
            
            # éåŒæœŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
            result = asyncio.run(test_alert_handling())
            assert result, "ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ"
            
            logger.info("âœ… ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ æˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_backup_system(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.backup.backup_system import BackupSystem, BackupType, BackupConfig
            
            # ãƒ†ã‚¹ãƒˆç”¨è¨­å®š
            config = BackupConfig(
                model_directory=os.path.join(self.temp_dir, "models"),
                data_directory=os.path.join(self.temp_dir, "data"),
                config_directory=os.path.join(self.temp_dir, "config"),
                backup_root=os.path.join(self.temp_dir, "backups"),
                auto_backup_enabled=False,  # ãƒ†ã‚¹ãƒˆã§ã¯æ‰‹å‹•å®Ÿè¡Œ
                verify_backups=True
            )
            
            backup_system = BackupSystem(config)
            
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            os.makedirs(config.model_directory, exist_ok=True)
            os.makedirs(config.data_directory, exist_ok=True)
            os.makedirs(config.config_directory, exist_ok=True)
            
            # ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with open(os.path.join(config.model_directory, "test_model.pkl"), 'w') as f:
                f.write("test model data")
            
            with open(os.path.join(config.data_directory, "test_data.csv"), 'w') as f:
                f.write("test,data\n1,2\n3,4\n")
            
            with open(os.path.join(config.config_directory, "test_config.json"), 'w') as f:
                f.write('{"test": "config"}')
            
            # ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
            backup_record = backup_system.create_backup(BackupType.FULL)
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çµæœã‚’æ¤œè¨¼
            assert backup_record is not None, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨˜éŒ²ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            assert backup_record.files_count > 0, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            assert os.path.exists(backup_record.file_path), "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ã‚’å–å¾—
            status = backup_system.get_backup_status()
            assert isinstance(status, dict), "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ãŒç„¡åŠ¹ã§ã™"
            assert status['total_backups'] > 0, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°ãŒ0ã§ã™"
            
            # å¾©å…ƒãƒ†ã‚¹ãƒˆ
            restore_path = os.path.join(self.temp_dir, "restored")
            restore_success = backup_system.restore_backup(backup_record.backup_id, restore_path)
            assert restore_success, "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒãŒå¤±æ•—ã—ã¾ã—ãŸ"
            assert os.path.exists(restore_path), "å¾©å…ƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            
            logger.info(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ æˆåŠŸ: {backup_record.files_count}ãƒ•ã‚¡ã‚¤ãƒ«")
            
        except Exception as e:
            pytest.fail(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_integrated_monitoring_workflow(self):
        """çµ±åˆç›£è¦–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” çµ±åˆç›£è¦–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.monitoring.data_drift_detector import DataDriftDetector
            from app.services.ml.monitoring.realtime_monitor import RealtimeMonitor
            from app.services.ml.monitoring.alert_system import AlertSystem
            
            # å„ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
            drift_detector = DataDriftDetector()
            monitor = RealtimeMonitor()
            alert_system = AlertSystem()
            
            # çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
            
            # 1. ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
            reference_data = self.test_data.iloc[:300]
            drift_detector.set_reference_data(reference_data)
            
            current_data = self.test_data.iloc[300:600].copy()
            current_data['Close'] *= 1.5  # å¤§ããªãƒ‰ãƒªãƒ•ãƒˆã‚’ä½œæˆ
            
            drift_results = drift_detector.detect_drift(current_data)
            
            # 2. ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã§ã®è¨˜éŒ²
            monitor.record_prediction("integrated_test_model", 500.0, True)
            monitor.record_prediction("integrated_test_model", 3000.0, False)  # é«˜ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
            
            # 3. ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†
            received_alerts = []
            def integrated_alert_callback(alert):
                received_alerts.append(alert)
            
            # AlertSystemã«ã¯ç›´æ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ æ©Ÿèƒ½ãŒãªã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—
            
            # çµ±åˆãƒ†ã‚¹ãƒˆã®æ¤œè¨¼
            assert len(drift_results) > 0, "çµ±åˆãƒ†ã‚¹ãƒˆã§ãƒ‰ãƒªãƒ•ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            
            # ç›£è¦–çŠ¶æ…‹ã®ç¢ºèª
            monitor_status = monitor.get_monitoring_status()
            assert 'integrated_test_model' in monitor_status['monitored_models'], "çµ±åˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ãŒç›£è¦–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            logger.info("âœ… çµ±åˆç›£è¦–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"çµ±åˆç›£è¦–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_performance_and_scalability(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.monitoring.data_drift_detector import DataDriftDetector
            import time
            
            detector = DataDriftDetector()
            
            # å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ†ã‚¹ãƒˆ
            large_reference_data = self.create_test_data(5000)
            large_current_data = self.create_test_data(2000)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
            start_time = time.time()
            
            detector.set_reference_data(large_reference_data)
            drift_results = detector.detect_drift(large_current_data)
            
            processing_time = time.time() - start_time
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
            assert processing_time < 30.0, f"å‡¦ç†æ™‚é–“ãŒé•·ã™ãã¾ã™: {processing_time:.2f}ç§’"
            assert len(drift_results) > 0, "å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãŒå¤±æ•—ã—ã¾ã—ãŸ"
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèªï¼ˆç°¡æ˜“ï¼‰
            assert len(detector.drift_history) <= 10000, "ãƒ‰ãƒªãƒ•ãƒˆå±¥æ­´ãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™"
            
            logger.info(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆæˆåŠŸ: {processing_time:.3f}ç§’")
            
        except Exception as e:
            pytest.fail(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_instance = TestMonitoringSystems()
    test_instance.setup_method()
    
    # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    tests = [
        test_instance.test_data_drift_detector,
        test_instance.test_realtime_monitor,
        test_instance.test_alert_system,
        test_instance.test_backup_system,
        test_instance.test_integrated_monitoring_workflow,
        test_instance.test_performance_and_scalability,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test()
            passed += 1
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test.__name__}: {e}")
            failed += 1
        finally:
            # å„ãƒ†ã‚¹ãƒˆå¾Œã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                test_instance.teardown_method()
                test_instance.setup_method()
            except:
                pass
    
    # æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    test_instance.teardown_method()
    
    print(f"\nğŸ“Š ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ {passed}, å¤±æ•— {failed}")
    print(f"æˆåŠŸç‡: {passed / (passed + failed) * 100:.1f}%")
