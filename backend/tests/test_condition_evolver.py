"""
ConditionEvolver統合テスト - TDDアプローチ
"""

import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from unittest.mock import Mock, patch
from typing import Dict, Any

from app.services.auto_strategy.core.condition_evolver import (
    ConditionEvolver,
    YamlIndicatorUtils,
    Condition,
    EvolutionConfig
)
from app.services.backtest.backtest_service import BacktestService
from scripts.strategy_comparison import StrategyComparison


class TestConditionEvolverIntegration:
    """ConditionEvolver統合テスト"""

    @pytest.fixture
    def mock_backtest_service(self):
        """バックテストサービスのモック"""
        mock_service = Mock(spec=BacktestService)
        mock_service.run_backtest.return_value = {
            "success": True,
            "performance_metrics": {
                "total_return": 0.15,
                "sharpe_ratio": 1.5,
                "max_drawdown": -0.08,
                "total_trades": 25,
                "win_rate": 0.60
            }
        }
        return mock_service

    @pytest.fixture
    def yaml_indicator_utils(self):
        """メタデータ駆動の指標ユーティリティ"""
        return YamlIndicatorUtils()

    @pytest.fixture
    def condition_evolver(self, mock_backtest_service, yaml_indicator_utils):
        """ConditionEvolverインスタンス"""
        return ConditionEvolver(
            backtest_service=mock_backtest_service,
            yaml_indicator_utils=yaml_indicator_utils
        )

    def test_strategy_comparison_initialization(self, condition_evolver):
        """戦略比較スクリプトの初期化テスト"""
        assert condition_evolver is not None
        assert condition_evolver.backtest_service is not None
        assert condition_evolver.yaml_indicator_utils is not None

    def test_run_single_strategy_comparison(self, condition_evolver):
        """単一戦略比較テスト"""
        # テスト用のバックテスト設定
        backtest_config = {
            "strategy_name": "Test_Strategy",
            "symbol": "BTC/USDT:USDT",
            "timeframe": "1h",
            "start_date": datetime.now() - timedelta(days=30),
            "end_date": datetime.now(),
            "initial_capital": 100000,
            "commission_rate": 0.001
        }

        # 条件の作成
        condition = Condition(
            indicator_name="RSI",
            operator=">",
            threshold=70.0,
            direction="long"
        )

        # 適応度評価
        fitness = condition_evolver.evaluate_fitness(condition, backtest_config)

        assert isinstance(fitness, float)
        assert fitness >= 0.0  # 適応度は非負
        condition_evolver.backtest_service.run_backtest.assert_called_once()

    def test_multiple_strategy_comparison(self, condition_evolver):
        """複数戦略比較テスト"""
        # 複数の条件を作成
        conditions = [
            Condition("RSI", ">", 70.0, "long"),
            Condition("MACD", ">", 0.0, "long"),
            Condition("SMA", "<", 0.0, "short")
        ]

        backtest_config = {
            "strategy_name": "Multi_Strategy_Test",
            "symbol": "BTC/USDT:USDT",
            "timeframe": "1h",
            "start_date": datetime.now() - timedelta(days=30),
            "end_date": datetime.now(),
            "initial_capital": 100000,
            "commission_rate": 0.001
        }

        # 各戦略の適応度を評価
        fitness_scores = []
        for condition in conditions:
            fitness = condition_evolver.evaluate_fitness(condition, backtest_config)
            fitness_scores.append(fitness)

        assert len(fitness_scores) == len(conditions)
        assert all(isinstance(f, float) for f in fitness_scores)
        assert condition_evolver.backtest_service.run_backtest.call_count == len(conditions)

    def test_statistical_comparison_calculation(self, condition_evolver):
        """統計比較計算テスト"""
        # モックバックテスト結果の準備
        mock_results = [
            {
                "total_return": 0.15,
                "sharpe_ratio": 1.5,
                "max_drawdown": -0.08,
                "win_rate": 0.60,
                "total_trades": 25
            },
            {
                "total_return": 0.12,
                "sharpe_ratio": 1.2,
                "max_drawdown": -0.10,
                "win_rate": 0.55,
                "total_trades": 22
            }
        ]

        # 統計比較の計算
        comparison_stats = self._calculate_comparison_stats(mock_results)

        assert "total_return" in comparison_stats
        assert "sharpe_ratio" in comparison_stats
        assert "max_drawdown" in comparison_stats
        assert "win_rate" in comparison_stats
        assert isinstance(comparison_stats["total_return"]["mean"], float)

    def test_strategy_comparison_report_generation(self, condition_evolver):
        """戦略比較レポート生成テスト"""
        # テストデータ
        strategy_results = {
            "GA_Strategy": {
                "total_return": 0.15,
                "sharpe_ratio": 1.5,
                "max_drawdown": -0.08,
                "win_rate": 0.60,
                "total_trades": 25
            },
            "Random_Strategy": {
                "total_return": 0.12,
                "sharpe_ratio": 1.2,
                "max_drawdown": -0.10,
                "win_rate": 0.55,
                "total_trades": 22
            }
        }

        # レポート生成（HTML形式）
        report_html = self._generate_comparison_report(strategy_results)

        assert isinstance(report_html, str)
        assert "GA_Strategy" in report_html
        assert "Random_Strategy" in report_html
        # HTML内の日本語文字がエンコードされるため、英語の文字列でテスト
        assert "Strategy" in report_html
        assert "0.15" in report_html  # GA戦略のtotal_return値
        assert "1.5" in report_html   # GA戦略のsharpe_ratio値

    def _calculate_comparison_stats(self, results: list) -> Dict[str, Any]:
        """統計比較計算（ヘルパーメソッド）"""
        if not results:
            return {}

        df = pd.DataFrame(results)
        stats = {}

        for column in df.columns:
            stats[column] = {
                "mean": df[column].mean(),
                "std": df[column].std(),
                "min": df[column].min(),
                "max": df[column].max(),
                "median": df[column].median()
            }

        return stats

    def _generate_comparison_report(self, strategy_results: Dict[str, Any]) -> str:
        """比較レポート生成（HTML形式）"""
        html = f"""
        <html>
        <head><title>戦略比較レポート</title></head>
        <body>
        <h1>戦略比較レポート</h1>
        <table border="1">
        <tr><th>戦略名</th><th>総リターン</th><th>シャープレシオ</th><th>最大ドローダウン</th></tr>
        """

        for strategy_name, metrics in strategy_results.items():
            html += f"""
            <tr>
            <td>{strategy_name}</td>
            <td>{metrics['total_return']}</td>
            <td>{metrics['sharpe_ratio']}</td>
            <td>{metrics['max_drawdown']}</td>
            </tr>
            """

        html += "</table></body></html>"
        return html


class TestYamlIndicatorUtils:
    """YAML指標ユーティリティテスト"""

    def test_yaml_loading(self):
        """YAML設定ファイル読み込みテスト"""
        utils = YamlIndicatorUtils()

        indicators = utils.get_available_indicators()
        assert len(indicators) > 0
        assert "RSI" in indicators
        assert "MACD" in indicators

    def test_indicator_info_retrieval(self):
        """指標情報取得テスト"""
        utils = YamlIndicatorUtils()

        rsi_info = utils.get_indicator_info("RSI")
        assert "conditions" in rsi_info
        assert "scale_type" in rsi_info
        assert "thresholds" in rsi_info

    def test_indicator_types_classification(self):
        """指標タイプ分類テスト"""
        utils = YamlIndicatorUtils()

        types = utils.get_indicator_types()
        assert "momentum" in types
        assert "volatility" in types
        assert "volume" in types
        assert "trend" in types

        assert "RSI" in types["momentum"]
        assert len(types["momentum"]) > 0


class TestConditionEvolverIntegrationAdvanced:
    """ConditionEvolver 高度統合テスト"""

    def test_32_indicators_comprehensive_test(self):
        """32指標全てに対する包括的テスト"""
        # 32指標の設定を検証
        utils = YamlIndicatorUtils()

        indicators = utils.get_available_indicators()
        types = utils.get_indicator_types()

        # 32指標以上あることを確認
        assert len(indicators) >= 32, f"指標数が32未満です: {len(indicators)}"

        # 主要カテゴリの存在確認
        required_categories = ["momentum", "volatility", "volume", "trend"]
        for category in required_categories:
            assert category in types, f"カテゴリ '{category}' が見つかりません"
            assert len(types[category]) > 0, f"カテゴリ '{category}' に指標がありません"

        print(f"✅ 32指標テスト成功: 総指標数={len(indicators)}")
        print(f"   カテゴリ別: { {k: len(v) for k, v in types.items()} }")

    def test_strategy_comparison_end_to_end_workflow(self):
        """戦略比較のエンドツーエンドワークフローテスト"""
        # モックバックテスト結果の準備
        mock_ga_results = [
            {
                "total_return": 0.15,
                "sharpe_ratio": 1.5,
                "max_drawdown": -0.08,
                "win_rate": 0.60,
                "total_trades": 25
            },
            {
                "total_return": 0.18,
                "sharpe_ratio": 1.8,
                "max_drawdown": -0.06,
                "win_rate": 0.65,
                "total_trades": 28
            }
        ]

        mock_random_results = [
            {
                "total_return": 0.12,
                "sharpe_ratio": 1.2,
                "max_drawdown": -0.10,
                "win_rate": 0.55,
                "total_trades": 22
            },
            {
                "total_return": 0.10,
                "sharpe_ratio": 1.0,
                "max_drawdown": -0.12,
                "win_rate": 0.50,
                "total_trades": 20
            }
        ]

        # 分析実行
        comparison = StrategyComparison()

        # モックデータを直接使用してテスト
        analysis = comparison._analyze_comparison_results(mock_ga_results, mock_random_results)

        # 結果検証
        assert "ga_statistics" in analysis
        assert "random_statistics" in analysis
        assert "performance_comparison" in analysis
        assert "statistical_tests" in analysis

        # パフォーマンス比較の検証
        perf_comp = analysis["performance_comparison"]
        assert "total_return" in perf_comp
        assert perf_comp["total_return"]["ga_wins"]  # GA戦略が勝っていることを確認

        # 統計検定の検証
        stats_test = analysis["statistical_tests"]
        assert "total_return" in stats_test
        assert "t_statistic" in stats_test["total_return"]

        print("✅ エンドツーエンドワークフローテスト成功")

    def test_performance_metrics_calculation_accuracy(self):
        """パフォーマンスメトリクスの計算精度テスト"""
        # テストデータ
        test_results = [
            {"total_return": 0.15, "sharpe_ratio": 1.5, "max_drawdown": -0.08},
            {"total_return": 0.18, "sharpe_ratio": 1.8, "max_drawdown": -0.06},
            {"total_return": 0.12, "sharpe_ratio": 1.2, "max_drawdown": -0.10},
        ]

        df = pd.DataFrame(test_results)
        stats = self._calculate_statistics(df)

        # 計算結果の検証
        assert abs(stats["total_return"]["mean"] - 0.15) < 0.01  # 平均値の確認
        assert stats["total_return"]["count"] == 3  # データ数の確認
        assert stats["total_return"]["min"] == 0.12  # 最小値の確認
        assert stats["total_return"]["max"] == 0.18  # 最大値の確認

        print("✅ パフォーマンスメトリクス計算精度テスト成功")

    def test_statistical_significance_calculation(self):
        """統計的有意性の計算テスト"""
        comparison = StrategyComparison()

        # テストデータ（GA戦略が有意に良い結果）
        ga_data = pd.Series([0.15, 0.18, 0.16, 0.14, 0.17])
        random_data = pd.Series([0.10, 0.12, 0.08, 0.11, 0.09])

        test_result = comparison._perform_statistical_test(ga_data, random_data)

        # 結果検証
        assert "t_statistic" in test_result
        assert "p_value" in test_result
        assert "cohens_d" in test_result
        assert test_result["sample_size_ga"] == 5
        assert test_result["sample_size_random"] == 5

        print("✅ 統計的有意性計算テスト成功")

    def _calculate_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """統計量計算（ヘルパーメソッド）"""
        if df.empty:
            return {}

        stats = {}
        for column in df.columns:
            if df[column].dtype in ['int64', 'float64']:
                stats[column] = {
                    "mean": df[column].mean(),
                    "std": df[column].std(),
                    "min": df[column].min(),
                    "max": df[column].max(),
                    "median": df[column].median(),
                    "count": df[column].count()
                }

        return stats


class TestIntegrationWorkflow:
    """統合ワークフローテスト"""

    def test_full_strategy_comparison_workflow(self):
        """完全な戦略比較ワークフローテスト"""
        comparison = StrategyComparison()

        # 完全なワークフロー実行
        result = comparison.run_comparison(
            symbols=["BTC/USDT:USDT"],
            timeframes=["1h"],
            num_iterations=3,  # テスト用に少なめに設定
            initial_capital=100000.0
        )

        # 結果検証
        assert result["success"] is True
        assert "results" in result
        assert "statistical_summary" in result
        assert "report_path" in result

        # レポートファイルが生成されたことを確認
        import os
        assert os.path.exists(result["report_path"])

        # レポートの内容を確認
        with open(result["report_path"], 'r', encoding='utf-8') as f:
            report_content = f.read()
            assert "GA戦略 vs ランダム戦略" in report_content
            assert "BTC/USDT:USDT" in report_content
            assert "1h" in report_content

        print(f"✅ 完全な戦略比較ワークフローテスト成功: {result['report_path']}")

        # 統計的要約の検証
        stats = result["statistical_summary"]
        assert "overall_performance" in stats

        if stats["overall_performance"]:
            perf = stats["overall_performance"]
            assert "ga_average_return" in perf
            assert "random_average_return" in perf
            assert "overall_improvement" in perf

            print(f"   GA平均リターン: {perf['ga_average_return']:.2%}")
            print(f"   ランダム平均リターン: {perf['random_average_return']:.2%}")
            print(f"   改善率: {perf['overall_improvement']:+.1f}%")


# TDDアプローチによるテストケース
class TestTDDApproach:
    """TDDアプローチによるテスト"""

    def test_strategy_comparison_tdd_initialization(self):
        """TDD: 戦略比較の初期化"""
        # まず失敗するテストから開始
        comparison = StrategyComparison()

        # 初期状態の検証
        assert hasattr(comparison, 'results_dir')
        assert comparison.results_dir.exists()

        print("✅ TDD初期化テスト成功")

    def test_strategy_comparison_tdd_mock_data_analysis(self):
        """TDD: モックデータによる分析"""
        # テストデータ（要件に基づく）
        expected_ga_return = 0.15
        expected_random_return = 0.12

        # モックデータ生成
        ga_results = [{"total_return": expected_ga_return}]
        random_results = [{"total_return": expected_random_return}]

        # 分析実行
        comparison = StrategyComparison()
        analysis = comparison._analyze_comparison_results(ga_results, random_results)

        # 結果検証
        assert analysis["performance_comparison"]["total_return"]["ga_mean"] == expected_ga_return
        assert analysis["performance_comparison"]["total_return"]["random_mean"] == expected_random_return
        assert analysis["performance_comparison"]["total_return"]["ga_wins"] == True

        print("✅ TDDモックデータ分析テスト成功")

    def test_strategy_comparison_tdd_statistical_validity(self):
        """TDD: 統計的妥当性の検証"""
        # 統計的検定の要件
        sample_size = 5
        significance_level = 0.05

        comparison = StrategyComparison()

        # 十分なサンプルサイズのデータ生成
        ga_data = pd.Series([0.15] * sample_size)
        random_data = pd.Series([0.12] * sample_size)

        test_result = comparison._perform_statistical_test(ga_data, random_data)

        # 結果検証
        assert test_result["sample_size_ga"] == sample_size
        assert test_result["sample_size_random"] == sample_size
        assert "p_value" in test_result
        assert isinstance(test_result["p_value"], (int, float))

        print("✅ TDD統計的妥当性テスト成功")

    def test_strategy_comparison_tdd_report_generation(self):
        """TDD: レポート生成の検証"""
        # レポート生成の要件
        required_sections = ["GA戦略 パフォーマンス", "ランダム戦略 パフォーマンス", "統計的検定結果"]

        comparison = StrategyComparison()

        # テストデータ
        all_results = {
            "metadata": {
                "symbols": ["BTC/USDT:USDT"],
                "timeframes": ["1h"],
                "num_iterations": 3,
                "timestamp": "2025-09-23T08:00:00"
            },
            "results": [
                {
                    "symbol": "BTC/USDT:USDT",
                    "timeframe": "1h",
                    "comparison": {
                        "ga_statistics": {"total_return": {"mean": 0.15, "std": 0.02, "min": 0.12, "max": 0.18}},
                        "random_statistics": {"total_return": {"mean": 0.12, "std": 0.03, "min": 0.08, "max": 0.16}},
                        "statistical_tests": {"total_return": {"t_statistic": 2.5, "p_value": 0.02, "cohens_d": 1.2, "significant": True}},
                        "performance_comparison": {"total_return": {"ga_mean": 0.15, "random_mean": 0.12, "improvement_percent": 25.0, "ga_wins": True}}
                    }
                }
            ]
        }

        statistical_summary = {
            "overall_performance": {
                "ga_average_return": 0.15,
                "random_average_return": 0.12,
                "overall_improvement": 25.0
            }
        }

        # レポート生成
        report_path = comparison._generate_comparison_report(all_results, statistical_summary)

        # 結果検証
        assert report_path.exists()
        with open(report_path, 'r', encoding='utf-8') as f:
            report_content = f.read()

        # 必須セクションの確認
        for section in required_sections:
            assert section in report_content, f"セクション '{section}' が見つかりません"

        # データの確認
        assert "0.15" in report_content  # GA平均リターン
        assert "0.12" in report_content  # ランダム平均リターン
        assert "25.0%" in report_content  # 改善率

        print(f"✅ TDDレポート生成テスト成功: {report_path}")

    def test_strategy_comparison_tdd_edge_cases(self):
        """TDD: エッジケースのテスト"""
        comparison = StrategyComparison()

        # エッジケース1: 空のデータ
        empty_analysis = comparison._analyze_comparison_results([], [])
        assert "error" in empty_analysis

        # エッジケース2: 単一データポイント
        single_ga = [{"total_return": 0.15}]
        single_random = [{"total_return": 0.12}]
        single_analysis = comparison._analyze_comparison_results(single_ga, single_random)

        assert "ga_statistics" in single_analysis
        assert single_analysis["performance_comparison"]["total_return"]["ga_mean"] == 0.15
        assert single_analysis["performance_comparison"]["total_return"]["random_mean"] == 0.12

        # エッジケース3: 同一データ
        same_data = [{"total_return": 0.15}, {"total_return": 0.15}]
        same_analysis = comparison._analyze_comparison_results(same_data, same_data)
        assert same_analysis["performance_comparison"]["total_return"]["improvement_percent"] == 0

        print("✅ TDDエッジケーステスト成功")