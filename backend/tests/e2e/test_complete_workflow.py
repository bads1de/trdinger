"""
ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ

ã‚ªãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼æ©Ÿèƒ½ã®å®Œå…¨ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŠãƒªã‚ªã«åŸºã¥ã„ãŸåŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import pytest
import sys
import os
import time
import json
import threading
import psutil
from typing import Dict, Any, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹è¨­å®š
backend_path = os.path.join(os.path.dirname(__file__), "..", "..")
sys.path.insert(0, backend_path)

from app.core.services.auto_strategy.services.auto_strategy_service import (
    AutoStrategyService,
)
from app.core.services.auto_strategy.models.ga_config import GAConfig
from app.core.services.auto_strategy.models.gene_strategy import StrategyGene
from app.core.services.auto_strategy.generators.random_gene_generator import (
    RandomGeneGenerator,
)
from app.core.services.auto_strategy.calculators.tpsl_calculator import TPSLCalculator
from app.core.services.auto_strategy.calculators.position_sizing_calculator import (
    PositionSizingCalculatorService,
)
from app.core.services.indicators import TechnicalIndicatorService

from tests.utils.helpers import (
    TestExecutionHelper,
    performance_monitor,
    assert_financial_precision,
    ConcurrencyTestHelper,
)
from tests.utils.data_generators import TestDataGenerator, PerformanceTestHelper


@pytest.mark.e2e
class TestCompleteWorkflow:
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.config = GAConfig(
            population_size=5,
            generations=2,
            max_indicators=3,
            min_indicators=1,
            max_conditions=2,
            min_conditions=1,
        )
        self.generator = RandomGeneGenerator(self.config)
        self.indicator_service = TechnicalIndicatorService()
        self.data_generator = TestDataGenerator()
        self.performance_helper = PerformanceTestHelper()
        self.test_results = []

    @pytest.mark.slow
    def test_end_to_end_workflow(self):
        """å®Œå…¨ãªã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        with performance_monitor("å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"):
            # 1. æˆ¦ç•¥ç”Ÿæˆ
            strategy_gene = self._test_strategy_generation()

            # 2. ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿çµ±åˆç¢ºèª
            self._test_indicator_integration()

            # 3. ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼
            self._test_data_quality_and_integrity()

            # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
            self._test_performance_requirements()

            # 5. ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ
            self._test_concurrent_operations()

            # 6. ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆ
            self._test_error_recovery_mechanisms()

    def _test_strategy_generation(self) -> StrategyGene:
        """æˆ¦ç•¥ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š æˆ¦ç•¥ç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")

        strategy_gene = self.generator.generate_random_gene()

        # åŸºæœ¬çš„ãªæ¤œè¨¼
        assert strategy_gene is not None
        assert len(strategy_gene.indicators) >= self.config.min_indicators
        assert len(strategy_gene.indicators) <= self.config.max_indicators
        assert len(strategy_gene.conditions) >= self.config.min_conditions
        assert len(strategy_gene.conditions) <= self.config.max_conditions

        print(f"âœ“ æˆ¦ç•¥ç”ŸæˆæˆåŠŸ: {len(strategy_gene.indicators)}å€‹ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿")
        return strategy_gene

    def _test_indicator_integration(self):
        """ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")

        supported_indicators = self.indicator_service.get_supported_indicators()

        # æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        new_indicators = [
            "HT_DCPERIOD",
            "HT_DCPHASE",
            "HT_SINE",  # ã‚µã‚¤ã‚¯ãƒ«ç³»
            "BETA",
            "CORREL",
            "STDDEV",
            "VAR",  # çµ±è¨ˆç³»
            "ACOS",
            "ASIN",
            "COS",
            "SIN",
            "SQRT",  # æ•°å­¦å¤‰æ›ç³»
            "ADD",
            "SUB",
            "MULT",
            "DIV",  # æ•°å­¦æ¼”ç®—å­ç³»
            "CDL_DOJI",
            "CDL_HAMMER",
            "CDL_HANGING_MAN",  # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ç³»
        ]

        found_indicators = [
            ind for ind in new_indicators if ind in supported_indicators
        ]
        assert len(found_indicators) > 0, "æ–°ã—ã„ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

        print(f"âœ“ ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿çµ±åˆæˆåŠŸ: {len(found_indicators)}å€‹ã®æ–°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ç¢ºèª")

    def _test_data_quality_and_integrity(self):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã¨æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆé–‹å§‹")

        # æ§˜ã€…ãªå¸‚å ´ã‚·ãƒŠãƒªã‚ªã§ã®ãƒ†ã‚¹ãƒˆ
        market_scenarios = self.data_generator.generate_market_scenarios()

        for scenario_name, data in market_scenarios.items():
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
            assert not data.empty, f"{scenario_name}: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™"
            assert len(data) > 50, f"{scenario_name}: ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™"

            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®è«–ç†çš„æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            assert (data["high"] >= data["low"]).all(), f"{scenario_name}: é«˜å€¤ < å®‰å€¤"
            assert (data["high"] >= data["open"]).all(), f"{scenario_name}: é«˜å€¤ < å§‹å€¤"
            assert (
                data["high"] >= data["close"]
            ).all(), f"{scenario_name}: é«˜å€¤ < çµ‚å€¤"
            assert (data["low"] <= data["open"]).all(), f"{scenario_name}: å®‰å€¤ > å§‹å€¤"
            assert (data["low"] <= data["close"]).all(), f"{scenario_name}: å®‰å€¤ > çµ‚å€¤"

        print("âœ“ ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆæˆåŠŸ")

    def _test_performance_requirements(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆ< 100msï¼‰
        test_data = self.data_generator.generate_ohlcv_data(100)

        def process_market_data():
            return self.indicator_service.calculate_indicators(
                test_data, ["SMA", "RSI"]
            )

        result, execution_time = self.performance_helper.measure_execution_time(
            process_market_data
        )
        assert (
            execution_time < 0.1
        ), f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒé…ã™ãã¾ã™: {execution_time:.3f}ç§’"

        # æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆ< 500msï¼‰
        def generate_strategy_signal():
            return self.generator.generate_random_gene()

        result, execution_time = self.performance_helper.measure_execution_time(
            generate_strategy_signal
        )
        assert (
            execution_time < 0.5
        ), f"æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ç”ŸæˆãŒé…ã™ãã¾ã™: {execution_time:.3f}ç§’"

        print("âœ“ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆæˆåŠŸ")

    def _test_concurrent_operations(self):
        """ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")

        def concurrent_strategy_generation():
            return self.generator.generate_random_gene()

        # 5ã¤ã®ä¸¦è¡Œå‡¦ç†ã§æˆ¦ç•¥ç”Ÿæˆ
        results = ConcurrencyTestHelper.run_concurrent_operations(
            concurrent_strategy_generation, num_threads=5
        )

        assert len(results) == 5, "ä¸¦è¡Œå‡¦ç†ã§æœŸå¾…ã•ã‚Œã‚‹çµæœæ•°ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

        # å„çµæœãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        for result in results:
            assert result is not None
            assert hasattr(result, "indicators")
            assert hasattr(result, "conditions")

        print("âœ“ ä¸¦è¡Œå‡¦ç†ãƒ†ã‚¹ãƒˆæˆåŠŸ")

    def _test_error_recovery_mechanisms(self):
        """ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ“Š ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆé–‹å§‹")

        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
        invalid_data = self.data_generator.generate_ohlcv_data(5)  # å°‘ãªã™ãã‚‹ãƒ‡ãƒ¼ã‚¿

        try:
            # ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            result = self.indicator_service.calculate_indicators(invalid_data, ["SMA"])
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„å ´åˆã¯ã€é©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert (
                "insufficient data" in str(e).lower() or "not enough" in str(e).lower()
            )

        print("âœ“ ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆæˆåŠŸ")

    @pytest.mark.slow
    def test_scalability_and_performance(self):
        """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        with performance_monitor("ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"):
            # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
            large_dataset = self.data_generator.generate_ohlcv_data(1000)

            def process_large_dataset():
                return self.indicator_service.calculate_indicators(
                    large_dataset, ["SMA", "EMA", "RSI", "MACD"]
                )

            result, execution_time = self.performance_helper.measure_execution_time(
                process_large_dataset
            )
            result, memory_used = self.performance_helper.measure_memory_usage(
                process_large_dataset
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã®ç¢ºèª
            assert (
                execution_time < 5.0
            ), f"å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒé…ã™ãã¾ã™: {execution_time:.2f}ç§’"
            assert memory_used < 200, f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã™ãã¾ã™: {memory_used:.2f}MB"

    @pytest.mark.slow
    def test_security_and_robustness(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆ"""
        with performance_monitor("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"):
            # æ¥µç«¯ãªå¸‚å ´æ¡ä»¶ã§ã®ãƒ†ã‚¹ãƒˆ
            extreme_conditions = (
                self.data_generator.generate_extreme_market_conditions()
            )

            for condition_name, data in extreme_conditions.items():
                try:
                    # æ¥µç«¯ãªæ¡ä»¶ã§ã‚‚é©åˆ‡ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
                    result = self.indicator_service.calculate_indicators(
                        data, ["SMA", "RSI"]
                    )

                    # çµæœãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                    assert result is not None

                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€é©åˆ‡ã«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
                    assert "invalid" in str(e).lower() or "error" in str(e).lower()

    def teardown_method(self):
        """ãƒ†ã‚¹ãƒˆå¾Œå‡¦ç†"""
        # ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼å‡ºåŠ›
        if self.test_results:
            TestExecutionHelper.print_test_results(
                {
                    "passed": len(
                        [r for r in self.test_results if r.get("status") == "PASSED"]
                    ),
                    "failed": len(
                        [r for r in self.test_results if r.get("status") == "FAILED"]
                    ),
                    "total": len(self.test_results),
                    "details": self.test_results,
                }
            )
