"""
ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã€çµ±è¨ˆçš„ç‰¹æ€§ã€æ™‚ç³»åˆ—ã®é€£ç¶šæ€§ãªã©ã‚’æ¤œè¨¼ã—ã€
æ©Ÿæ¢°å­¦ç¿’ã®ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹æ½œåœ¨çš„ãªå•é¡Œã‚’ç™ºè¦‹ã—ã¾ã™ã€‚
"""

import logging
import os
import sys
import time
import warnings
from dataclasses import dataclass
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
from scipy import stats

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
backend_path = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class DataQualityTestResult:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆçµæœ"""

    test_name: str
    component_name: str
    success: bool
    execution_time: float
    quality_score: float
    data_size: int
    issues_found: List[str]
    error_message: Optional[str] = None
    statistical_metrics: Optional[Dict[str, float]] = None


class DataQualityTestSuite:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.results: List[DataQualityTestResult] = []

    def create_quality_test_data(self, size: int = 1000) -> pd.DataFrame:
        """å“è³ªãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range("2024-01-01", periods=size, freq="1H")

        # åŸºæœ¬çš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        base_price = 100
        price_changes = np.random.normal(0, 0.02, size)
        prices = [base_price]

        for change in price_changes[1:]:
            prices.append(prices[-1] * (1 + change))

        prices = np.array(prices)

        return pd.DataFrame(
            {
                "timestamp": dates,
                "Open": prices,
                "High": prices * (1 + np.abs(np.random.normal(0, 0.01, size))),
                "Low": prices * (1 - np.abs(np.random.normal(0, 0.01, size))),
                "Close": prices * (1 + np.random.normal(0, 0.005, size)),
                "Volume": np.random.lognormal(10, 1, size),
            }
        )

    def create_corrupted_data(self, size: int = 1000) -> pd.DataFrame:
        """å“è³ªå•é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        base_data = self.create_quality_test_data(size)

        # ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã‚’æ„å›³çš„ã«å°å…¥
        corrupted_data = base_data.copy()

        # 1. ä¾¡æ ¼ã®è«–ç†çš„ä¸æ•´åˆ
        corrupted_data.loc[10:20, "High"] = corrupted_data.loc[10:20, "Low"] * 0.9
        corrupted_data.loc[30:40, "Low"] = corrupted_data.loc[30:40, "High"] * 1.1

        # 2. ç•°å¸¸ãªä¾¡æ ¼ã‚¸ãƒ£ãƒ³ãƒ—
        corrupted_data.loc[50:55, "Close"] = corrupted_data.loc[50:55, "Close"] * 10

        # 3. è² ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ 
        corrupted_data.loc[70:80, "Volume"] = -corrupted_data.loc[70:80, "Volume"]

        # 4. æ¬ æå€¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
        corrupted_data.loc[100:120, ["Open", "High", "Low", "Close"]] = np.nan

        # 5. é‡è¤‡ã—ãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        corrupted_data.loc[200:205, "timestamp"] = corrupted_data.loc[200, "timestamp"]

        return corrupted_data

    def test_data_consistency(self):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        quality_score = 100.0
        issues_found = []

        try:
            # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã¨ç ´æãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’ãƒ†ã‚¹ãƒˆ
            normal_data = self.create_quality_test_data(500)
            corrupted_data = self.create_corrupted_data(500)

            # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
            try:
                from app.utils.data_validation import DataValidator

                validator = DataValidator()

                # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                normal_result = validator.validate_ohlcv_data(normal_data)
                if normal_result.get("is_valid", False):
                    logger.info("âœ… æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãæ¤œè¨¼")
                else:
                    quality_score -= 20.0
                    issues_found.append("æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã¨åˆ¤å®šã•ã‚ŒãŸ")

                # ç ´æãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                corrupted_result = validator.validate_ohlcv_data(corrupted_data)
                if not corrupted_result.get("is_valid", True):
                    logger.info("âœ… ç ´æãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãæ¤œå‡º")
                else:
                    quality_score -= 30.0
                    issues_found.append("ç ´æãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ã¨åˆ¤å®šã•ã‚ŒãŸ")

                # ã‚¨ãƒ©ãƒ¼è©³ç´°ã®ç¢ºèª
                errors = corrupted_result.get("errors", [])
                if len(errors) > 0:
                    logger.info(f"âœ… {len(errors)}å€‹ã®ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡Œã‚’æ¤œå‡º")
                else:
                    quality_score -= 25.0
                    issues_found.append("ãƒ‡ãƒ¼ã‚¿å“è³ªå•é¡ŒãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ")

            except Exception as e:
                quality_score -= 50.0
                issues_found.append(f"ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

            # OHLCè«–ç†æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            try:
                # High >= max(Open, Close) ã®ãƒã‚§ãƒƒã‚¯
                ohlc_issues = 0
                for data, name in [(normal_data, "æ­£å¸¸"), (corrupted_data, "ç ´æ")]:
                    high_violations = (
                        data["High"] < np.maximum(data["Open"], data["Close"])
                    ).sum()
                    low_violations = (
                        data["Low"] > np.minimum(data["Open"], data["Close"])
                    ).sum()

                    if name == "æ­£å¸¸" and (high_violations > 0 or low_violations > 0):
                        quality_score -= 15.0
                        issues_found.append(
                            f"æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã«OHLCè«–ç†é•å: H={high_violations}, L={low_violations}"
                        )

                    if name == "ç ´æ":
                        ohlc_issues = high_violations + low_violations

                if ohlc_issues > 0:
                    logger.info(f"âœ… {ohlc_issues}å€‹ã®OHLCè«–ç†é•åã‚’æ¤œå‡º")
                else:
                    quality_score -= 10.0
                    issues_found.append("OHLCè«–ç†é•åãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ")

            except Exception as e:
                quality_score -= 25.0
                issues_found.append(f"OHLCæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§",
                    component_name="DataValidator",
                    success=quality_score > 70.0,
                    execution_time=execution_time,
                    quality_score=quality_score,
                    data_size=len(normal_data) + len(corrupted_data),
                    issues_found=issues_found,
                )
            )

            logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆå®Œäº†: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.1f}%")

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§",
                    component_name="DataValidator",
                    success=False,
                    execution_time=execution_time,
                    quality_score=0.0,
                    data_size=0,
                    issues_found=["ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"],
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_statistical_anomalies(self):
        """çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        quality_score = 100.0
        issues_found = []
        statistical_metrics = {}

        try:
            test_data = self.create_corrupted_data(1000)

            # çµ±è¨ˆçš„ç•°å¸¸å€¤ã®æ¤œå‡º
            try:
                from app.utils.data_processing import DataProcessor

                processor = DataProcessor()

                # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆåˆ†æ
                price_columns = ["Open", "High", "Low", "Close"]
                for col in price_columns:
                    if col in test_data.columns:
                        data_series = test_data[col].dropna()
                        if len(data_series) > 0:
                            # Z-score ã«ã‚ˆã‚‹ç•°å¸¸å€¤æ¤œå‡º
                            z_scores = np.abs(stats.zscore(data_series))
                            outliers = (z_scores > 3).sum()
                            statistical_metrics[f"{col}_outliers"] = outliers

                            # å¤‰å‹•ä¿‚æ•°ã®è¨ˆç®—
                            cv = data_series.std() / data_series.mean()
                            statistical_metrics[f"{col}_cv"] = cv

                            if outliers > len(data_series) * 0.1:  # 10%ä»¥ä¸ŠãŒç•°å¸¸å€¤
                                quality_score -= 15.0
                                issues_found.append(
                                    f"{col}ã«éåº¦ã®ç•°å¸¸å€¤: {outliers}å€‹"
                                )

                # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ç•°å¸¸å€¤æ¤œå‡º
                if "Volume" in test_data.columns:
                    volume_data = test_data["Volume"].dropna()
                    negative_volume = (volume_data < 0).sum()
                    if negative_volume > 0:
                        quality_score -= 20.0
                        issues_found.append(f"è² ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ : {negative_volume}å€‹")
                        statistical_metrics["negative_volume_count"] = negative_volume

                    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®å¯¾æ•°æ­£è¦æ€§ãƒ†ã‚¹ãƒˆ
                    if len(volume_data[volume_data > 0]) > 10:
                        log_volume = np.log(volume_data[volume_data > 0])
                        _, p_value = stats.normaltest(log_volume)
                        statistical_metrics["volume_lognormal_pvalue"] = p_value

                        if p_value < 0.01:
                            quality_score -= 10.0
                            issues_found.append("ãƒœãƒªãƒ¥ãƒ¼ãƒ ãŒå¯¾æ•°æ­£è¦åˆ†å¸ƒã«å¾“ã‚ãªã„")

                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µã«ã‚ˆã‚‹å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ
                processed_data = processor.preprocess_features(test_data)

                # å‰å‡¦ç†å¾Œã®å“è³ªãƒã‚§ãƒƒã‚¯
                if processed_data.isna().any().any():
                    remaining_nan = processed_data.isna().sum().sum()
                    if remaining_nan > 0:
                        quality_score -= 15.0
                        issues_found.append(f"å‰å‡¦ç†å¾Œã«NaNæ®‹å­˜: {remaining_nan}å€‹")

                # ç„¡é™å¤§å€¤ã®ãƒã‚§ãƒƒã‚¯
                if (
                    np.isinf(processed_data.select_dtypes(include=[np.number]))
                    .any()
                    .any()
                ):
                    quality_score -= 20.0
                    issues_found.append("å‰å‡¦ç†å¾Œã«ç„¡é™å¤§å€¤ãŒæ®‹å­˜")

                logger.info("âœ… çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºå®Œäº†")

            except Exception as e:
                quality_score -= 50.0
                issues_found.append(f"çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")

            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡º",
                    component_name="DataProcessor",
                    success=quality_score > 70.0,
                    execution_time=execution_time,
                    quality_score=quality_score,
                    data_size=len(test_data),
                    issues_found=issues_found,
                    statistical_metrics=statistical_metrics,
                )
            )

            logger.info(
                f"âœ… çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºãƒ†ã‚¹ãƒˆå®Œäº†: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.1f}%"
            )

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡º",
                    component_name="DataProcessor",
                    success=False,
                    execution_time=execution_time,
                    quality_score=0.0,
                    data_size=0,
                    issues_found=["ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"],
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ çµ±è¨ˆçš„ç•°å¸¸å€¤æ¤œå‡ºãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_time_series_continuity(self):
        """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®é€£ç¶šæ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” æ™‚ç³»åˆ—é€£ç¶šæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        quality_score = 100.0
        issues_found = []
        statistical_metrics = {}

        try:
            # é€£ç¶šæ€§å•é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            base_data = self.create_quality_test_data(1000)

            # æ™‚ç³»åˆ—ã®å•é¡Œã‚’å°å…¥
            discontinuous_data = base_data.copy()

            # 1. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ã‚®ãƒ£ãƒƒãƒ—
            discontinuous_data = discontinuous_data.drop(index=range(100, 150))

            # 2. é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            duplicate_rows = discontinuous_data.iloc[200:205].copy()
            discontinuous_data = pd.concat(
                [discontinuous_data, duplicate_rows], ignore_index=True
            )

            # 3. é€†é †ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            discontinuous_data.loc[300:310, "timestamp"] = discontinuous_data.loc[
                300:310, "timestamp"
            ] - pd.Timedelta(days=1)

            # ãƒ‡ãƒ¼ã‚¿é »åº¦ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
            try:
                from app.services.ml.feature_engineering.data_frequency_manager import (
                    DataFrequencyManager,
                )

                freq_manager = DataFrequencyManager()

                # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                normal_result = freq_manager.validate_data_consistency(
                    base_data, None, None, "1h"
                )

                if normal_result.get("is_valid", False):
                    logger.info("âœ… æ­£å¸¸ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãæ¤œè¨¼")
                else:
                    quality_score -= 20.0
                    issues_found.append("æ­£å¸¸ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã¨åˆ¤å®š")

                # ä¸é€£ç¶šãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
                discontinuous_result = freq_manager.validate_data_consistency(
                    discontinuous_data, None, None, "1h"
                )

                if not discontinuous_result.get("is_valid", True):
                    logger.info("âœ… ä¸é€£ç¶šãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãæ¤œå‡º")
                else:
                    quality_score -= 30.0
                    issues_found.append("ä¸é€£ç¶šãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ã¨åˆ¤å®š")

            except Exception as e:
                quality_score -= 40.0
                issues_found.append(f"ãƒ‡ãƒ¼ã‚¿é »åº¦ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")

            # æ™‚ç³»åˆ—ã®çµ±è¨ˆçš„ç‰¹æ€§ãƒã‚§ãƒƒã‚¯
            try:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®é–“éš”ãƒã‚§ãƒƒã‚¯
                time_diffs = base_data["timestamp"].diff().dropna()
                expected_interval = pd.Timedelta(hours=1)

                # é–“éš”ã®ä¸€è²«æ€§
                irregular_intervals = (time_diffs != expected_interval).sum()
                statistical_metrics["irregular_intervals"] = irregular_intervals

                if irregular_intervals > 0:
                    quality_score -= 15.0
                    issues_found.append(f"ä¸è¦å‰‡ãªæ™‚é–“é–“éš”: {irregular_intervals}å€‹")

                # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒã‚§ãƒƒã‚¯
                duplicates = discontinuous_data["timestamp"].duplicated().sum()
                statistical_metrics["duplicate_timestamps"] = duplicates

                if duplicates > 0:
                    logger.info(f"âœ… é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ¤œå‡º: {duplicates}å€‹")
                else:
                    quality_score -= 10.0
                    issues_found.append("é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ")

                # æ™‚ç³»åˆ—ã®é †åºãƒã‚§ãƒƒã‚¯
                unsorted_count = (
                    discontinuous_data["timestamp"].diff() < pd.Timedelta(0)
                ).sum()
                statistical_metrics["unsorted_timestamps"] = unsorted_count

                if unsorted_count > 0:
                    logger.info(f"âœ… é€†é †ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ¤œå‡º: {unsorted_count}å€‹")

            except Exception as e:
                quality_score -= 30.0
                issues_found.append(f"æ™‚ç³»åˆ—çµ±è¨ˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="æ™‚ç³»åˆ—é€£ç¶šæ€§",
                    component_name="DataFrequencyManager",
                    success=quality_score > 70.0,
                    execution_time=execution_time,
                    quality_score=quality_score,
                    data_size=len(discontinuous_data),
                    issues_found=issues_found,
                    statistical_metrics=statistical_metrics,
                )
            )

            logger.info(f"âœ… æ™‚ç³»åˆ—é€£ç¶šæ€§ãƒ†ã‚¹ãƒˆå®Œäº†: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.1f}%")

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="æ™‚ç³»åˆ—é€£ç¶šæ€§",
                    component_name="DataFrequencyManager",
                    success=False,
                    execution_time=execution_time,
                    quality_score=0.0,
                    data_size=0,
                    issues_found=["ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"],
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ æ™‚ç³»åˆ—é€£ç¶šæ€§ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_feature_distribution_stability(self):
        """ç‰¹å¾´é‡åˆ†å¸ƒã®å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ç‰¹å¾´é‡åˆ†å¸ƒå®‰å®šæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        quality_score = 100.0
        issues_found = []
        statistical_metrics = {}

        try:
            # 2ã¤ã®æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆåˆ†å¸ƒãƒ‰ãƒªãƒ•ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
            period1_data = self.create_quality_test_data(500)
            period2_data = self.create_quality_test_data(500)

            # æœŸé–“2ã®ãƒ‡ãƒ¼ã‚¿ã«åˆ†å¸ƒãƒ‰ãƒªãƒ•ãƒˆã‚’å°å…¥
            period2_data["Close"] = period2_data["Close"] * 1.5  # ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã®å¤‰åŒ–
            period2_data["Volume"] = period2_data["Volume"] * 0.7  # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®å¤‰åŒ–

            # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿè¡Œ
            try:
                from app.services.ml.feature_engineering.feature_engineering_service import (
                    FeatureEngineeringService,
                )

                fe_service = FeatureEngineeringService()

                features1 = fe_service.calculate_advanced_features(period1_data)
                features2 = fe_service.calculate_advanced_features(period2_data)

                # å…±é€šã®ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’å–å¾—
                common_features = set(features1.columns) & set(features2.columns)
                numeric_features = [
                    col
                    for col in common_features
                    if features1[col].dtype in [np.float64, np.int64]
                ]

                # åˆ†å¸ƒã®æ¯”è¼ƒ
                distribution_shifts = 0
                for feature in numeric_features[:10]:  # æœ€åˆã®10å€‹ã®ç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆ
                    try:
                        data1 = features1[feature].dropna()
                        data2 = features2[feature].dropna()

                        if len(data1) > 10 and len(data2) > 10:
                            # Kolmogorov-Smirnov ãƒ†ã‚¹ãƒˆ
                            ks_stat, p_value = stats.ks_2samp(data1, data2)
                            statistical_metrics[f"{feature}_ks_pvalue"] = p_value

                            if p_value < 0.01:  # æœ‰æ„ãªåˆ†å¸ƒã®é•ã„
                                distribution_shifts += 1

                            # å¹³å‡ã¨åˆ†æ•£ã®å¤‰åŒ–
                            mean_change = abs(data2.mean() - data1.mean()) / (
                                data1.std() + 1e-8
                            )
                            var_change = abs(data2.var() - data1.var()) / (
                                data1.var() + 1e-8
                            )

                            statistical_metrics[f"{feature}_mean_change"] = mean_change
                            statistical_metrics[f"{feature}_var_change"] = var_change

                    except Exception as e:
                        logger.warning(f"ç‰¹å¾´é‡ {feature} ã®åˆ†å¸ƒæ¯”è¼ƒã§ã‚¨ãƒ©ãƒ¼: {e}")

                statistical_metrics["distribution_shifts"] = distribution_shifts

                if (
                    distribution_shifts > len(numeric_features) * 0.3
                ):  # 30%ä»¥ä¸Šã§åˆ†å¸ƒã‚·ãƒ•ãƒˆ
                    quality_score -= 30.0
                    issues_found.append(
                        f"éåº¦ã®åˆ†å¸ƒã‚·ãƒ•ãƒˆ: {distribution_shifts}å€‹ã®ç‰¹å¾´é‡"
                    )
                elif distribution_shifts > 0:
                    logger.info(f"âœ… åˆ†å¸ƒã‚·ãƒ•ãƒˆã‚’æ¤œå‡º: {distribution_shifts}å€‹ã®ç‰¹å¾´é‡")

                # ç‰¹å¾´é‡ã®ç›¸é–¢é–¢ä¿‚ã®å®‰å®šæ€§
                if len(numeric_features) > 5:
                    corr1 = features1[numeric_features[:5]].corr()
                    corr2 = features2[numeric_features[:5]].corr()

                    # ç›¸é–¢è¡Œåˆ—ã®å·®
                    corr_diff = np.abs(corr1 - corr2).mean().mean()
                    statistical_metrics["correlation_stability"] = 1 - corr_diff

                    if corr_diff > 0.2:
                        quality_score -= 20.0
                        issues_found.append(f"ç›¸é–¢é–¢ä¿‚ã®ä¸å®‰å®šæ€§: å·®={corr_diff:.3f}")

            except Exception as e:
                quality_score -= 50.0
                issues_found.append(f"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="ç‰¹å¾´é‡åˆ†å¸ƒå®‰å®šæ€§",
                    component_name="FeatureEngineeringService",
                    success=quality_score > 70.0,
                    execution_time=execution_time,
                    quality_score=quality_score,
                    data_size=len(period1_data) + len(period2_data),
                    issues_found=issues_found,
                    statistical_metrics=statistical_metrics,
                )
            )

            logger.info(
                f"âœ… ç‰¹å¾´é‡åˆ†å¸ƒå®‰å®šæ€§ãƒ†ã‚¹ãƒˆå®Œäº†: å“è³ªã‚¹ã‚³ã‚¢ {quality_score:.1f}%"
            )

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                DataQualityTestResult(
                    test_name="ç‰¹å¾´é‡åˆ†å¸ƒå®‰å®šæ€§",
                    component_name="FeatureEngineeringService",
                    success=False,
                    execution_time=execution_time,
                    quality_score=0.0,
                    data_size=0,
                    issues_found=["ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"],
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ ç‰¹å¾´é‡åˆ†å¸ƒå®‰å®šæ€§ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def run_all_tests(self):
        """ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")

        self.test_data_consistency()
        self.test_statistical_anomalies()
        self.test_time_series_continuity()
        self.test_feature_distribution_stability()

        # çµæœã®é›†è¨ˆ
        total_tests = len(self.results)
        successful_tests = sum(1 for result in self.results if result.success)
        total_execution_time = sum(result.execution_time for result in self.results)
        average_quality = (
            sum(result.quality_score for result in self.results) / total_tests
            if total_tests > 0
            else 0
        )
        total_issues = sum(len(result.issues_found) for result in self.results)

        logger.info("=" * 80)
        logger.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆçµæœ")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        logger.info(f"âœ… æˆåŠŸ: {successful_tests}")
        logger.info(f"âŒ å¤±æ•—: {total_tests - successful_tests}")
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {successful_tests / total_tests * 100:.1f}%")
        logger.info(f"ğŸ¯ å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {average_quality:.1f}%")
        logger.info(f"âš ï¸ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ: {total_issues}å€‹")
        logger.info(f"â±ï¸ ç·å®Ÿè¡Œæ™‚é–“: {total_execution_time:.2f}ç§’")

        logger.info("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆè©³ç´°:")
        for result in self.results:
            status = "âœ…" if result.success else "âŒ"
            logger.info(f"{status} {result.test_name}")
            logger.info(f"   ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {result.component_name}")
            logger.info(f"   å®Ÿè¡Œæ™‚é–“: {result.execution_time:.2f}ç§’")
            logger.info(f"   å“è³ªã‚¹ã‚³ã‚¢: {result.quality_score:.1f}%")
            logger.info(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {result.data_size}")
            logger.info(f"   ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ: {len(result.issues_found)}å€‹")

            if result.issues_found:
                for issue in result.issues_found[:3]:  # æœ€åˆã®3å€‹ã®å•é¡Œã‚’è¡¨ç¤º
                    logger.info(f"     - {issue}")
                if len(result.issues_found) > 3:
                    logger.info(f"     - ... ä»–{len(result.issues_found) - 3}å€‹")

            if result.error_message:
                logger.info(f"   ã‚¨ãƒ©ãƒ¼: {result.error_message[:100]}...")

        logger.info("=" * 80)
        logger.info("ğŸ¯ ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Œäº†")

        return self.results


if __name__ == "__main__":
    suite = DataQualityTestSuite()
    results = suite.run_all_tests()
