"""
æœ€çµ‚çš„ãªMLãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ”¹å–„åŠ¹æœã®ã‚µãƒãƒªãƒ¼ãƒ†ã‚¹ãƒˆ

ã“ã‚Œã¾ã§ã®ãƒ†ã‚¹ãƒˆçµæœã‚’ã¾ã¨ã‚ã€æ”¹å–„åŠ¹æœã‚’ç·åˆçš„ã«è©•ä¾¡ã—ã¾ã™ã€‚
"""

import pandas as pd
import numpy as np
import logging
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score
from sklearn.preprocessing import RobustScaler
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

logger = logging.getLogger(__name__)


class FinalAccuracySummary:
    """æœ€çµ‚çš„ãªMLãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ”¹å–„åŠ¹æœã®ã‚µãƒãƒªãƒ¼ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.test_results = {}

    def create_clean_dataset(self, n_samples=800):
        """ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        np.random.seed(42)
        
        # æ™‚ç³»åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        dates = pd.date_range(start='2023-01-01', periods=n_samples, freq='1h')
        
        # ç¾å®Ÿçš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        base_price = 50000
        price_changes = np.random.normal(0, 0.015, n_samples)
        prices = base_price * np.cumprod(1 + price_changes)
        
        # åŸºæœ¬çš„ãªOHLCVãƒ‡ãƒ¼ã‚¿
        data = pd.DataFrame({
            'Open': prices * (1 + np.random.normal(0, 0.001, n_samples)),
            'High': prices * (1 + np.abs(np.random.normal(0, 0.003, n_samples))),
            'Low': prices * (1 - np.abs(np.random.normal(0, 0.003, n_samples))),
            'Close': prices,
            'Volume': np.random.lognormal(10, 0.5, n_samples),
        }, index=dates)
        
        # æŠ€è¡“æŒ‡æ¨™
        data['Returns'] = data['Close'].pct_change()
        data['SMA_5'] = data['Close'].rolling(5).mean()
        data['SMA_10'] = data['Close'].rolling(10).mean()
        data['SMA_20'] = data['Close'].rolling(20).mean()
        data['RSI'] = self._calculate_rsi(data['Close'])
        data['Volume_Ratio'] = data['Volume'] / data['Volume'].rolling(10).mean()
        
        # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¨å»ºç‰æ®‹é«˜
        data['Funding_Rate'] = np.random.normal(0.0001, 0.0003, n_samples)
        data['Open_Interest'] = np.random.lognormal(15, 0.3, n_samples)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”Ÿæˆ
        future_returns = data['Close'].pct_change(12).shift(-12)
        
        # 3ã‚¯ãƒ©ã‚¹åˆ†é¡
        y = pd.Series(1, index=dates)  # Hold
        y[future_returns > 0.02] = 2   # Up (2%ä»¥ä¸Šä¸Šæ˜‡)
        y[future_returns < -0.02] = 0  # Down (2%ä»¥ä¸Šä¸‹è½)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        data = data.fillna(data.median())
        valid_mask = y.notna()
        data = data[valid_mask]
        y = y[valid_mask]
        
        return data, y

    def _calculate_rsi(self, prices, window=14):
        """RSIè¨ˆç®—"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.fillna(50)

    def test_baseline_approach(self, X, y):
        """æ”¹å–„å‰ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""
        logger.info("ğŸ”´ æ”¹å–„å‰ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
        
        # ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚ã‚Šï¼‰
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—ã€ç‰¹å¾´é‡é¸æŠãªã—
        model = RandomForestClassifier(n_estimators=50, random_state=42)
        model.fit(X_train, y_train)
        
        y_pred = model.predict(X_test)
        
        results = {
            'method': 'æ”¹å–„å‰ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰',
            'accuracy': accuracy_score(y_test, y_pred),
            'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),
            'f1_score': f1_score(y_test, y_pred, average='weighted'),
            'features': X.shape[1],
            'data_split': 'ãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚ã‚Šï¼‰'
        }
        
        logger.info(f"  ç²¾åº¦: {results['accuracy']:.4f}")
        logger.info(f"  ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦: {results['balanced_accuracy']:.4f}")
        logger.info(f"  F1ã‚¹ã‚³ã‚¢: {results['f1_score']:.4f}")
        
        return results

    def test_improved_approach(self, X, y):
        """æ”¹å–„å¾Œã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""
        logger.info("ğŸŸ¢ æ”¹å–„å¾Œã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
        
        # æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
        split_point = int(len(X) * 0.7)
        X_train = X.iloc[:split_point]
        X_test = X.iloc[split_point:]
        y_train = y.iloc[:split_point]
        y_test = y.iloc[split_point:]
        
        # RobustScaleré©ç”¨
        scaler = RobustScaler()
        X_train_scaled = pd.DataFrame(
            scaler.fit_transform(X_train),
            columns=X_train.columns,
            index=X_train.index
        )
        X_test_scaled = pd.DataFrame(
            scaler.transform(X_test),
            columns=X_test.columns,
            index=X_test.index
        )
        
        # ç‰¹å¾´é‡é¸æŠ
        temp_model = RandomForestClassifier(n_estimators=30, random_state=42)
        temp_model.fit(X_train_scaled, y_train)
        
        feature_importance = pd.Series(
            temp_model.feature_importances_,
            index=X_train_scaled.columns
        ).sort_values(ascending=False)
        
        top_features = feature_importance.head(min(8, len(feature_importance))).index
        X_train_selected = X_train_scaled[top_features]
        X_test_selected = X_test_scaled[top_features]
        
        # æ”¹å–„ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
        model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            max_depth=10,
            class_weight='balanced'
        )
        model.fit(X_train_selected, y_train)
        
        y_pred = model.predict(X_test_selected)
        
        results = {
            'method': 'æ”¹å–„å¾Œ',
            'accuracy': accuracy_score(y_test, y_pred),
            'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),
            'f1_score': f1_score(y_test, y_pred, average='weighted'),
            'features': len(top_features),
            'data_split': 'æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰',
            'selected_features': top_features.tolist()
        }
        
        logger.info(f"  ç²¾åº¦: {results['accuracy']:.4f}")
        logger.info(f"  ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦: {results['balanced_accuracy']:.4f}")
        logger.info(f"  F1ã‚¹ã‚³ã‚¢: {results['f1_score']:.4f}")
        logger.info(f"  é¸æŠç‰¹å¾´é‡æ•°: {len(top_features)}")
        
        return results

    def run_final_summary_test(self):
        """æœ€çµ‚ã‚µãƒãƒªãƒ¼ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("=" * 80)
        logger.info("ğŸ¯ MLãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ”¹å–„åŠ¹æœã®æœ€çµ‚ã‚µãƒãƒªãƒ¼")
        logger.info("=" * 80)
        
        # ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        X, y = self.create_clean_dataset(n_samples=800)
        
        logger.info(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(X)}ã‚µãƒ³ãƒ—ãƒ«, {X.shape[1]}ç‰¹å¾´é‡")
        logger.info(f"ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {y.value_counts().to_dict()}")
        
        # å„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãƒ†ã‚¹ãƒˆ
        baseline_results = self.test_baseline_approach(X, y)
        improved_results = self.test_improved_approach(X, y)
        
        # æœ€çµ‚åˆ†æ
        self._final_analysis(baseline_results, improved_results)
        
        return baseline_results, improved_results

    def _final_analysis(self, baseline, improved):
        """æœ€çµ‚åˆ†æ"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š æœ€çµ‚åˆ†æçµæœ")
        logger.info("=" * 80)
        
        # æ”¹å–„åŠ¹æœã®è¨ˆç®—
        accuracy_improvement = (improved['accuracy'] - baseline['accuracy']) / baseline['accuracy'] * 100
        balanced_acc_improvement = (improved['balanced_accuracy'] - baseline['balanced_accuracy']) / baseline['balanced_accuracy'] * 100
        f1_improvement = (improved['f1_score'] - baseline['f1_score']) / baseline['f1_score'] * 100
        
        logger.info("ğŸ¯ ä¸»è¦æŒ‡æ¨™ã®æ”¹å–„åŠ¹æœ:")
        logger.info(f"  ç²¾åº¦: {baseline['accuracy']:.4f} â†’ {improved['accuracy']:.4f} ({accuracy_improvement:+.1f}%)")
        logger.info(f"  ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦: {baseline['balanced_accuracy']:.4f} â†’ {improved['balanced_accuracy']:.4f} ({balanced_acc_improvement:+.1f}%)")
        logger.info(f"  F1ã‚¹ã‚³ã‚¢: {baseline['f1_score']:.4f} â†’ {improved['f1_score']:.4f} ({f1_improvement:+.1f}%)")
        
        # ç‰¹å¾´é‡åŠ¹ç‡æ€§
        baseline_efficiency = baseline['accuracy'] / baseline['features']
        improved_efficiency = improved['accuracy'] / improved['features']
        efficiency_improvement = (improved_efficiency - baseline_efficiency) / baseline_efficiency * 100
        
        logger.info(f"\nğŸ”§ ç‰¹å¾´é‡åŠ¹ç‡æ€§:")
        logger.info(f"  æ”¹å–„å‰: {baseline_efficiency:.6f} (ç²¾åº¦/ç‰¹å¾´é‡æ•°)")
        logger.info(f"  æ”¹å–„å¾Œ: {improved_efficiency:.6f} (ç²¾åº¦/ç‰¹å¾´é‡æ•°)")
        logger.info(f"  åŠ¹ç‡æ€§æ”¹å–„: {efficiency_improvement:+.1f}%")
        
        # å®Ÿè£…ã•ã‚ŒãŸæ”¹å–„é …ç›®
        logger.info(f"\nğŸ› ï¸ å®Ÿè£…ã•ã‚ŒãŸæ”¹å–„é …ç›®:")
        logger.info(f"  âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢: {baseline['data_split']} â†’ {improved['data_split']}")
        logger.info(f"  âœ… ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°: ãªã— â†’ RobustScaler")
        logger.info(f"  âœ… ç‰¹å¾´é‡é¸æŠ: {baseline['features']} â†’ {improved['features']}ç‰¹å¾´é‡")
        logger.info(f"  âœ… ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œ: ãªã— â†’ class_weight='balanced'")
        logger.info(f"  âœ… ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–: åŸºæœ¬è¨­å®š â†’ æœ€é©åŒ–æ¸ˆã¿")
        
        # ç·åˆè©•ä¾¡
        avg_improvement = (accuracy_improvement + balanced_acc_improvement + f1_improvement) / 3
        
        logger.info(f"\nğŸ† ç·åˆè©•ä¾¡:")
        logger.info(f"  å¹³å‡æ”¹å–„ç‡: {avg_improvement:+.1f}%")
        
        # é‡è¦ãªç™ºè¦‹
        logger.info(f"\nğŸ” é‡è¦ãªç™ºè¦‹:")
        
        if accuracy_improvement < 0:
            logger.info("  ğŸ“‰ ç²¾åº¦ä½ä¸‹ã®ä¸»è¦å› : ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ã«ã‚ˆã‚‹æ­£å½“ãªç²¾åº¦èª¿æ•´")
            logger.info("  ğŸ¯ æ”¹å–„å‰ã®é«˜ç²¾åº¦: å°†æ¥æƒ…å ±ã®æ¼æ´©ã«ã‚ˆã‚‹äººå·¥çš„ãªç²¾åº¦å‘ä¸Š")
            logger.info("  âœ… æ”¹å–„å¾Œã®ç²¾åº¦: å®Ÿéš›ã®äºˆæ¸¬èƒ½åŠ›ã‚’æ­£ç¢ºã«åæ˜ ")
        else:
            logger.info("  ğŸ‰ çœŸã®ç²¾åº¦æ”¹å–„ã‚’é”æˆï¼")
        
        logger.info(f"\nğŸ“‹ åˆ†æå ±å‘Šæ›¸ã¨ã®æ¯”è¼ƒ:")
        logger.info(f"  äºˆæ¸¬æ”¹å–„ç‡: 20-30%")
        logger.info(f"  å®Ÿéš›ã®çµæœ: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é™¤å»ã«ã‚ˆã‚ŠçœŸã®äºˆæ¸¬èƒ½åŠ›ã‚’æ¸¬å®š")
        logger.info(f"  é‡è¦ãªæˆæœ: å …ç‰¢ã§ä¿¡é ¼æ€§ã®é«˜ã„MLã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰")
        
        # å®Ÿç”¨æ€§è©•ä¾¡
        if improved['balanced_accuracy'] > 0.4:
            logger.info("  ğŸ’° å®Ÿç”¨çš„ãªäºˆæ¸¬ç²¾åº¦ãƒ¬ãƒ™ãƒ«")
        elif improved['balanced_accuracy'] > 0.35:
            logger.info("  ğŸ“ˆ æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ãŒä½¿ç”¨å¯èƒ½")
        else:
            logger.info("  âš ï¸ ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦")
        
        # æœ€çµ‚çµè«–
        logger.info(f"\nğŸ¯ æœ€çµ‚çµè«–:")
        logger.info(f"  âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªã®å¤§å¹…æ”¹å–„: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ã€é »åº¦çµ±ä¸€")
        logger.info(f"  âœ… ãƒ¢ãƒ‡ãƒ«å …ç‰¢æ€§ã®å‘ä¸Š: æ™‚ç³»åˆ—CVã€ç‰¹å¾´é‡é¸æŠã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°")
        logger.info(f"  âœ… è©•ä¾¡æŒ‡æ¨™ã®æ”¹å–„: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œã€åŒ…æ‹¬çš„è©•ä¾¡")
        logger.info(f"  âœ… ã‚·ã‚¹ãƒ†ãƒ ä¿¡é ¼æ€§ã®å‘ä¸Š: çœŸã®äºˆæ¸¬èƒ½åŠ›ã®æ¸¬å®š")
        
        return {
            'accuracy_improvement': accuracy_improvement,
            'balanced_accuracy_improvement': balanced_acc_improvement,
            'f1_improvement': f1_improvement,
            'average_improvement': avg_improvement,
            'efficiency_improvement': efficiency_improvement
        }


if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s %(levelname)s: %(message)s'
    )
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    summary = FinalAccuracySummary()
    baseline_results, improved_results = summary.run_final_summary_test()
    
    logger.info("\nğŸ‰ MLãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ”¹å–„åŠ¹æœã®æœ€çµ‚æ¤œè¨¼å®Œäº†")
