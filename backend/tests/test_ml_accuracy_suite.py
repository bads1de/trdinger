"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

è¨ˆç®—æ­£ç¢ºæ€§ã€å‰å‡¦ç†æ­£ç¢ºæ€§ã€ç‰¹å¾´é‡è¨ˆç®—ã€ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã€ãƒ©ãƒ™ãƒ«ç”Ÿæˆã®
ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’çµ±åˆå®Ÿè¡Œã—ã€MLã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ä¿¡é ¼æ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import logging
import sys
import os
import time
from typing import Dict, List, Tuple, Any
import traceback
import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å„ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tests.calculations.test_ml_calculations import run_all_calculation_tests
from tests.preprocessing.test_preprocessing_accuracy import run_all_preprocessing_tests
from tests.feature_engineering.test_feature_calculations import run_all_feature_calculation_tests
from tests.data_transformations.test_data_transformations import run_all_data_transformation_tests
from tests.label_generation.test_label_generation import run_all_label_generation_tests
from tests.enhanced.test_error_handling import run_all_error_handling_tests
from tests.enhanced.test_performance import run_all_performance_tests

# çµ±åˆãƒ†ã‚¹ãƒˆé–¢æ•°ã‚’ç›´æ¥å®šç¾©
def run_integration_tests():
    """çµ±åˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    logger.info("ğŸ”— çµ±åˆãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ä¿®æ­£ç‰ˆï¼‰")

    try:
        # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from app.utils.data_processing import DataProcessor
        from app.utils.label_generation import LabelGenerator, ThresholdMethod
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
        from app.utils.index_alignment import MLWorkflowIndexManager

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†å™¨ã‚’åˆæœŸåŒ–
        index_manager = MLWorkflowIndexManager()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        np.random.seed(42)
        dates = pd.date_range('2023-01-01', periods=500, freq='1h')
        base_price = 50000
        returns = np.random.normal(0, 0.02, 500)
        prices = [base_price]

        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))

        raw_data = pd.DataFrame({
            'timestamp': dates,
            'Open': prices,
            'High': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
            'Low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
            'Close': [p * (1 + np.random.normal(0, 0.005)) for p in prices],
            'Volume': np.random.lognormal(10, 1, 500)
        }).set_index('timestamp')

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆæœŸåŒ–
        index_manager.initialize_workflow(raw_data)

        # Step 1: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½è·¡ä»˜ãï¼‰
        processor = DataProcessor()

        def preprocess_func(data):
            return processor.preprocess_features(
                data[['Close', 'Volume']].copy(),
                scale_features=False,
                remove_outliers=True
            )

        processed_data = index_manager.process_with_index_tracking(
            "å‰å‡¦ç†", raw_data, preprocess_func
        )

        # Step 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½è·¡ä»˜ãï¼‰
        fe_service = FeatureEngineeringService()

        def feature_engineering_func(data):
            # å‰å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª¿æ•´
            aligned_ohlcv = raw_data.loc[data.index]
            return fe_service.calculate_advanced_features(aligned_ohlcv)

        features = index_manager.process_with_index_tracking(
            "ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°", processed_data, feature_engineering_func
        )

        # Step 3: ãƒ©ãƒ™ãƒ«ç”Ÿæˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ã‚’è€ƒæ…®ï¼‰
        label_generator = LabelGenerator()

        # ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åˆã‚ã›ã¦ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª¿æ•´
        aligned_price_data = raw_data.loc[features.index, 'Close']

        labels, _ = label_generator.generate_labels(
            aligned_price_data,
            method=ThresholdMethod.FIXED,
            threshold_up=0.02,
            threshold_down=-0.02
        )

        # Step 4: æœ€çµ‚çš„ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆ
        final_features, final_labels = index_manager.finalize_workflow(
            features, labels, alignment_method="intersection"
        )

        # çµ±åˆæ¤œè¨¼
        assert len(final_features) > 0, "æœ€çµ‚ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
        assert len(final_labels) > 0, "æœ€çµ‚ãƒ©ãƒ™ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ã®æ¤œè¨¼
        validation_result = index_manager.alignment_manager.validate_alignment(
            final_features, final_labels, min_alignment_ratio=0.95
        )

        logger.info(f"æœ€çµ‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§æ¤œè¨¼:")
        logger.info(f"  ç‰¹å¾´é‡è¡Œæ•°: {validation_result['features_rows']}")
        logger.info(f"  ãƒ©ãƒ™ãƒ«è¡Œæ•°: {validation_result['labels_rows']}")
        logger.info(f"  å…±é€šè¡Œæ•°: {validation_result['common_rows']}")
        logger.info(f"  æ•´åˆç‡: {validation_result['alignment_ratio']*100:.1f}%")

        # é«˜ã„æ•´åˆæ€§ã‚’è¦æ±‚ï¼ˆ95%ä»¥ä¸Šï¼‰
        assert validation_result["is_valid"], \
            f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ãŒä¸ååˆ†: {validation_result['alignment_ratio']*100:.1f}% < 95%"

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚µãƒãƒªãƒ¼
        workflow_summary = index_manager.get_workflow_summary()
        logger.info(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†:")
        logger.info(f"  å…ƒãƒ‡ãƒ¼ã‚¿: {workflow_summary['original_rows']}è¡Œ")
        logger.info(f"  æœ€çµ‚ãƒ‡ãƒ¼ã‚¿: {workflow_summary['final_rows']}è¡Œ")
        logger.info(f"  ãƒ‡ãƒ¼ã‚¿ä¿æŒç‡: {workflow_summary['data_retention_rate']*100:.1f}%")

        logger.info("âœ… çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ä¿®æ­£ç‰ˆï¼‰")
        return True

    except Exception as e:
        logger.error(f"âŒ çµ±åˆãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_extreme_edge_case_tests():
    """æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("ğŸ”¥ æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from app.utils.data_processing import DataProcessor
        from app.utils.label_generation import LabelGenerator, ThresholdMethod
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService

        # ãƒã‚¤ã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
        logger.info("ãƒã‚¤ã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ...")
        micro_data = pd.DataFrame({
            'Close': [100, 101, 102],
            'Volume': [1000, 1001, 1002]
        })

        processor = DataProcessor()
        try:
            processed = processor.preprocess_features(
                micro_data.copy(),
                scale_features=True,
                remove_outliers=False
            )
            logger.info(f"ãƒã‚¤ã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {len(processed)}è¡Œ")
        except Exception as e:
            logger.info(f"ãƒã‚¤ã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿ã§æœŸå¾…é€šã‚Šã‚¨ãƒ©ãƒ¼: {e}")

        # å…¨åŒå€¤ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        logger.info("å…¨åŒå€¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ†ã‚¹ãƒˆ...")
        identical_data = pd.DataFrame({
            'Close': [100.0] * 50,
            'Volume': [1000.0] * 50
        })

        try:
            processed = processor.preprocess_features(
                identical_data.copy(),
                scale_features=True,
                remove_outliers=True
            )
            logger.info(f"åŒå€¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: std={processed['Close'].std():.6f}")
        except Exception as e:
            logger.info(f"åŒå€¤ãƒ‡ãƒ¼ã‚¿ã§æœŸå¾…é€šã‚Šã‚¨ãƒ©ãƒ¼: {e}")

        # ãƒ‡ãƒ¼ã‚¿ç ´æã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
        logger.info("ãƒ‡ãƒ¼ã‚¿ç ´æã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ...")
        corrupted_data = pd.DataFrame({
            'Close': [100, np.inf, 102, -np.inf, 104],
            'Volume': [1000, 1001, np.inf, 1003, 1004]
        })

        try:
            processed = processor.preprocess_features(
                corrupted_data.copy(),
                scale_features=True,
                remove_outliers=True
            )

            has_invalid = (processed.isnull().any().any() or
                          np.isinf(processed.select_dtypes(include=[np.number])).any().any())

            if not has_invalid:
                logger.info("ç ´æãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ã«ä¿®å¾©ã•ã‚Œã¾ã—ãŸ")
            else:
                logger.warning("ç„¡åŠ¹ãªå€¤ãŒæ®‹ã£ã¦ã„ã¾ã™")

        except Exception as e:
            logger.info(f"ç ´æãƒ‡ãƒ¼ã‚¿ã§æœŸå¾…é€šã‚Šã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def run_real_environment_simulation_tests():
    """å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("ğŸŒ å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from app.utils.data_processing import DataProcessor
        from app.utils.label_generation import LabelGenerator, ThresholdMethod
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService

        # å®Ÿéš›ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        logger.info("å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")

        # ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®å®Ÿéš›ã®ä¾¡æ ¼å‹•ä½œã‚’æ¨¡å€£
        np.random.seed(42)
        size = 1000

        # ã‚ˆã‚Šç¾å®Ÿçš„ãªä¾¡æ ¼å‹•ä½œï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ + ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼‰
        base_price = 50000
        prices = [base_price]
        volatility = 0.02

        for i in range(1, size):
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åŠ¹æœ
            if i > 20:
                recent_volatility = np.std([prices[j]/prices[j-1] - 1 for j in range(i-20, i)])
                volatility = 0.01 + recent_volatility * 2

            # ä¾¡æ ¼å¤‰å‹•
            change = np.random.normal(0, volatility)
            new_price = prices[-1] * (1 + change)
            prices.append(max(new_price, base_price * 0.3))  # ä¾¡æ ¼ä¸‹é™

        # ç¾å®Ÿçš„ãªOHLCVãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        market_data = pd.DataFrame({
            'Open': prices,
            'High': [p * (1 + abs(np.random.normal(0, 0.005))) for p in prices],
            'Low': [p * (1 - abs(np.random.normal(0, 0.005))) for p in prices],
            'Close': [p * (1 + np.random.normal(0, 0.002)) for p in prices],
            'Volume': np.random.lognormal(10, 0.8, size)  # ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒœãƒªãƒ¥ãƒ¼ãƒ åˆ†å¸ƒ
        })

        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        processor = DataProcessor()
        processed_data = processor.preprocess_features(
            market_data[['Close', 'Volume']].copy(),
            scale_features=True,
            remove_outliers=True
        )

        logger.info(f"å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {len(processed_data)}è¡Œ")

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        fe_service = FeatureEngineeringService()
        features = fe_service.calculate_advanced_features(market_data)

        logger.info(f"å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡: {features.shape[1]}å€‹")

        # ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
        label_generator = LabelGenerator()
        labels, _ = label_generator.generate_labels(
            market_data['Close'],
            method=ThresholdMethod.FIXED,
            threshold_up=0.02,
            threshold_down=-0.02
        )

        label_distribution = pd.Series(labels).value_counts()
        logger.info(f"å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {label_distribution.to_dict()}")

        # ãƒ‡ãƒ¼ã‚¿å“è³ªã®æ¤œè¨¼
        price_volatility = market_data['Close'].pct_change().std()
        volume_consistency = market_data['Volume'].std() / market_data['Volume'].mean()

        logger.info(f"ä¾¡æ ¼ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {price_volatility:.4f}")
        logger.info(f"ãƒœãƒªãƒ¥ãƒ¼ãƒ å¤‰å‹•ä¿‚æ•°: {volume_consistency:.4f}")

        # é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§ãƒ†ã‚¹ãƒˆ
        logger.info("é•·æ™‚é–“å®Ÿè¡Œå®‰å®šæ€§ãƒ†ã‚¹ãƒˆ...")

        start_time = time.time()
        iterations = 10

        for i in range(iterations):
            # ç¹°ã‚Šè¿”ã—å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚„æ€§èƒ½åŠ£åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
            test_data = market_data.sample(n=100).copy()

            processed = processor.preprocess_features(
                test_data[['Close', 'Volume']].copy(),
                scale_features=True,
                remove_outliers=True
            )

            if i % 3 == 0:
                logger.info(f"  åå¾© {i+1}/{iterations} å®Œäº†")

        total_time = time.time() - start_time
        avg_time_per_iteration = total_time / iterations

        logger.info(f"é•·æ™‚é–“å®Ÿè¡Œãƒ†ã‚¹ãƒˆå®Œäº†: å¹³å‡ {avg_time_per_iteration:.3f}ç§’/åå¾©")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ã®æ¤œå‡º
        if avg_time_per_iteration > 1.0:
            logger.warning(f"å‡¦ç†æ™‚é–“ãŒé•·ã™ãã¾ã™: {avg_time_per_iteration:.3f}ç§’")

        # I/Oã‚¨ãƒ©ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        logger.info("I/Oã‚¨ãƒ©ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")

        # ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ï¼ˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        incomplete_data = market_data.iloc[:50].copy()  # ãƒ‡ãƒ¼ã‚¿ãŒé€”ä¸­ã§åˆ‡ã‚Œã‚‹

        try:
            processed = processor.preprocess_features(
                incomplete_data[['Close', 'Volume']].copy(),
                scale_features=True,
                remove_outliers=True
            )
            logger.info(f"ä¸å®Œå…¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†æˆåŠŸ: {len(processed)}è¡Œ")
        except Exception as e:
            logger.info(f"ä¸å®Œå…¨ãƒ‡ãƒ¼ã‚¿ã§æœŸå¾…é€šã‚Šã‚¨ãƒ©ãƒ¼: {e}")

        # ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        logger.info("ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")

        # å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†
        large_data = pd.concat([market_data] * 5, ignore_index=True)  # 5å€ã®ãƒ‡ãƒ¼ã‚¿
        chunk_size = 500

        processed_chunks = []
        for i in range(0, len(large_data), chunk_size):
            chunk = large_data.iloc[i:i+chunk_size]
            processed_chunk = processor.preprocess_features(
                chunk[['Close', 'Volume']].copy(),
                scale_features=True,
                remove_outliers=True
            )
            processed_chunks.append(processed_chunk)

        final_result = pd.concat(processed_chunks, ignore_index=True)
        logger.info(f"ãƒãƒ£ãƒ³ã‚¯å‡¦ç†æˆåŠŸ: {len(final_result)}è¡Œ")

        logger.info("âœ… å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def run_advanced_performance_optimization_tests():
    """é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("âš¡ é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        import psutil
        import gc
        from app.utils.data_processing import DataProcessor
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService

        process = psutil.Process(os.getpid())

        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ
        logger.info("ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ...")

        initial_memory = process.memory_info().rss
        memory_measurements = []

        processor = DataProcessor()

        for i in range(20):
            # ç¹°ã‚Šè¿”ã—å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º
            test_data = pd.DataFrame({
                'Close': np.random.normal(100, 10, 1000),
                'Volume': np.random.lognormal(10, 1, 1000)
            })

            processed = processor.preprocess_features(
                test_data.copy(),
                scale_features=True,
                remove_outliers=True
            )

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®š
            current_memory = process.memory_info().rss
            memory_increase = current_memory - initial_memory
            memory_measurements.append(memory_increase)

            # æ˜ç¤ºçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            del test_data, processed
            gc.collect()

            if i % 5 == 0:
                logger.info(f"  åå¾© {i+1}: ãƒ¡ãƒ¢ãƒªå¢—åŠ  {memory_increase/1e6:.1f}MB")

        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®åˆ†æ
        memory_trend = np.polyfit(range(len(memory_measurements)), memory_measurements, 1)[0]

        logger.info(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒˆãƒ¬ãƒ³ãƒ‰: {memory_trend/1e6:.3f}MB/åå¾©")

        if memory_trend > 1e6:  # 1MB/åå¾©ä»¥ä¸Šã®å¢—åŠ 
            logger.warning(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§: {memory_trend/1e6:.1f}MB/åå¾©")
        else:
            logger.info("âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

        # CPUä½¿ç”¨ç‡ç›£è¦–ãƒ†ã‚¹ãƒˆ
        logger.info("CPUä½¿ç”¨ç‡ç›£è¦–ãƒ†ã‚¹ãƒˆ...")

        cpu_measurements = []
        start_time = time.time()

        fe_service = FeatureEngineeringService()

        # CPUé›†ç´„çš„ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
        for i in range(5):
            cpu_before = psutil.cpu_percent(interval=0.1)

            # è¤‡é›‘ãªç‰¹å¾´é‡è¨ˆç®—
            complex_data = pd.DataFrame({
                'Open': np.random.normal(100, 10, 2000),
                'High': np.random.normal(105, 10, 2000),
                'Low': np.random.normal(95, 10, 2000),
                'Close': np.random.normal(100, 10, 2000),
                'Volume': np.random.lognormal(10, 1, 2000)
            })

            features = fe_service.calculate_advanced_features(complex_data)

            cpu_after = psutil.cpu_percent(interval=0.1)
            cpu_usage = max(cpu_after - cpu_before, 0)
            cpu_measurements.append(cpu_usage)

            logger.info(f"  ã‚¿ã‚¹ã‚¯ {i+1}: CPUä½¿ç”¨ç‡ {cpu_usage:.1f}%")

        avg_cpu_usage = np.mean(cpu_measurements)
        logger.info(f"å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu_usage:.1f}%")

        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šãƒ†ã‚¹ãƒˆ
        logger.info("ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šãƒ†ã‚¹ãƒˆ...")

        # å„å‡¦ç†æ®µéšã®æ™‚é–“æ¸¬å®š
        bottleneck_data = pd.DataFrame({
            'Close': np.random.normal(100, 10, 5000),
            'Volume': np.random.lognormal(10, 1, 5000)
        })

        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
        start = time.time()
        processed = processor.preprocess_features(
            bottleneck_data.copy(),
            scale_features=False,
            remove_outliers=False
        )
        preprocessing_time = time.time() - start

        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
        start = time.time()
        scaled = processor.preprocess_features(
            bottleneck_data.copy(),
            scale_features=True,
            remove_outliers=False
        )
        scaling_time = time.time() - start

        # å¤–ã‚Œå€¤é™¤å»ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
        start = time.time()
        outlier_removed = processor.preprocess_features(
            bottleneck_data.copy(),
            scale_features=False,
            remove_outliers=True
        )
        outlier_removal_time = time.time() - start

        # å®Œå…¨å‡¦ç†ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
        start = time.time()
        full_processed = processor.preprocess_features(
            bottleneck_data.copy(),
            scale_features=True,
            remove_outliers=True
        )
        full_processing_time = time.time() - start

        logger.info("å‡¦ç†æ™‚é–“åˆ†æ:")
        logger.info(f"  åŸºæœ¬å‰å‡¦ç†: {preprocessing_time:.3f}ç§’")
        logger.info(f"  ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°: {scaling_time:.3f}ç§’")
        logger.info(f"  å¤–ã‚Œå€¤é™¤å»: {outlier_removal_time:.3f}ç§’")
        logger.info(f"  å®Œå…¨å‡¦ç†: {full_processing_time:.3f}ç§’")

        # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š
        processing_times = {
            'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°': scaling_time - preprocessing_time,
            'å¤–ã‚Œå€¤é™¤å»': outlier_removal_time - preprocessing_time,
            'çµ±åˆå‡¦ç†': full_processing_time - max(scaling_time, outlier_removal_time)
        }

        bottleneck = max(processing_times, key=processing_times.get)
        bottleneck_time = processing_times[bottleneck]

        logger.info(f"æœ€å¤§ãƒœãƒˆãƒ«ãƒãƒƒã‚¯: {bottleneck} ({bottleneck_time:.3f}ç§’)")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ¹ç‡ã®è¨ˆç®—
        data_throughput = len(bottleneck_data) / full_processing_time
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {data_throughput:.0f}è¡Œ/ç§’")

        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ¸¬å®š
        memory_efficiency = len(bottleneck_data) / (process.memory_info().rss / 1e6)
        logger.info(f"ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: {memory_efficiency:.0f}è¡Œ/MB")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ææ¡ˆ
        optimization_suggestions = []

        if bottleneck_time > 0.1:
            optimization_suggestions.append(f"{bottleneck}ã®æœ€é©åŒ–ãŒå¿…è¦")

        if avg_cpu_usage > 80:
            optimization_suggestions.append("CPUä½¿ç”¨ç‡ãŒé«˜ã™ãã¾ã™")

        if memory_trend > 5e5:  # 0.5MB/åå¾©
            optimization_suggestions.append("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–ãŒå¿…è¦")

        if data_throughput < 1000:
            optimization_suggestions.append("ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æ”¹å–„ãŒå¿…è¦")

        if optimization_suggestions:
            logger.warning("æœ€é©åŒ–ææ¡ˆ:")
            for suggestion in optimization_suggestions:
                logger.warning(f"  - {suggestion}")
        else:
            logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯è‰¯å¥½ã§ã™")

        logger.info("âœ… é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ é«˜åº¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def run_code_coverage_verification_tests():
    """ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("ğŸ“‹ ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from app.utils.data_processing import DataProcessor
        from app.utils.label_generation import LabelGenerator, ThresholdMethod
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService

        # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ
        logger.info("è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ...")

        processor = DataProcessor()
        test_data = pd.DataFrame({
            'Close': np.random.normal(100, 10, 100),
            'Volume': np.random.lognormal(10, 1, 100)
        })

        # ç•°ãªã‚‹è¨­å®šã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ
        configurations = [
            {'scale_features': True, 'remove_outliers': True, 'outlier_method': 'iqr'},
            {'scale_features': True, 'remove_outliers': True, 'outlier_method': 'zscore'},
            {'scale_features': True, 'remove_outliers': False},
            {'scale_features': False, 'remove_outliers': True, 'outlier_method': 'iqr'},
            {'scale_features': False, 'remove_outliers': False},
        ]

        for i, config in enumerate(configurations):
            try:
                result = processor.preprocess_features(test_data.copy(), **config)
                logger.info(f"  è¨­å®š {i+1}: æˆåŠŸ ({len(result)}è¡Œ)")
            except Exception as e:
                logger.info(f"  è¨­å®š {i+1}: ã‚¨ãƒ©ãƒ¼ - {e}")

        # ãƒ©ãƒ™ãƒ«ç”Ÿæˆã®ç•°ãªã‚‹æ‰‹æ³•ãƒ†ã‚¹ãƒˆ
        logger.info("ãƒ©ãƒ™ãƒ«ç”Ÿæˆæ‰‹æ³•ç¶²ç¾…ãƒ†ã‚¹ãƒˆ...")

        label_generator = LabelGenerator()
        price_series = pd.Series(np.random.normal(100, 10, 100), name='Close')

        # ç•°ãªã‚‹é–¾å€¤è¨­å®š
        threshold_configs = [
            {'method': ThresholdMethod.FIXED, 'threshold_up': 0.01, 'threshold_down': -0.01},
            {'method': ThresholdMethod.FIXED, 'threshold_up': 0.05, 'threshold_down': -0.05},
            {'method': ThresholdMethod.FIXED, 'threshold_up': 0.1, 'threshold_down': -0.1},
        ]

        for i, config in enumerate(threshold_configs):
            try:
                labels, info = label_generator.generate_labels(price_series, **config)
                label_dist = pd.Series(labels).value_counts()
                logger.info(f"  é–¾å€¤è¨­å®š {i+1}: æˆåŠŸ - åˆ†å¸ƒ {label_dist.to_dict()}")
            except Exception as e:
                logger.info(f"  é–¾å€¤è¨­å®š {i+1}: ã‚¨ãƒ©ãƒ¼ - {e}")

        # ä¾‹å¤–å‡¦ç†ã®ç¶²ç¾…æ€§ãƒ†ã‚¹ãƒˆ
        logger.info("ä¾‹å¤–å‡¦ç†ç¶²ç¾…æ€§ãƒ†ã‚¹ãƒˆ...")

        # ç©ºãƒ‡ãƒ¼ã‚¿ã§ã®ä¾‹å¤–å‡¦ç†
        empty_data = pd.DataFrame()
        try:
            processor.preprocess_features(empty_data)
            logger.info("  ç©ºãƒ‡ãƒ¼ã‚¿: å‡¦ç†æˆåŠŸ")
        except Exception as e:
            logger.info(f"  ç©ºãƒ‡ãƒ¼ã‚¿: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # ä¸æ­£ãªå‹ã§ã®ä¾‹å¤–å‡¦ç†
        invalid_data = "invalid_data"
        try:
            processor.preprocess_features(invalid_data)
            logger.info("  ä¸æ­£å‹: å‡¦ç†æˆåŠŸ")
        except Exception as e:
            logger.info(f"  ä¸æ­£å‹: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # NaNã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§ã®ä¾‹å¤–å‡¦ç†
        nan_data = pd.DataFrame({'Close': [np.nan] * 10, 'Volume': [np.nan] * 10})
        try:
            result = processor.preprocess_features(nan_data)
            logger.info(f"  NaNãƒ‡ãƒ¼ã‚¿: å‡¦ç†æˆåŠŸ ({len(result)}è¡Œ)")
        except Exception as e:
            logger.info(f"  NaNãƒ‡ãƒ¼ã‚¿: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ
        logger.info("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ...")

        fe_service = FeatureEngineeringService()

        # ä¸å®Œå…¨ãªOHLCVãƒ‡ãƒ¼ã‚¿
        incomplete_ohlcv = pd.DataFrame({
            'Open': [100, 101],
            'High': [102, 103]
            # Close, Low, VolumeãŒä¸è¶³
        })

        try:
            features = fe_service.calculate_advanced_features(incomplete_ohlcv)
            logger.info(f"  ä¸å®Œå…¨OHLCV: å‡¦ç†æˆåŠŸ ({features.shape[1]}ç‰¹å¾´é‡)")
        except Exception as e:
            logger.info(f"  ä¸å®Œå…¨OHLCV: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # æ¥µå°ãƒ‡ãƒ¼ã‚¿ã§ã®ç‰¹å¾´é‡è¨ˆç®—
        tiny_ohlcv = pd.DataFrame({
            'Open': [100],
            'High': [102],
            'Low': [99],
            'Close': [101],
            'Volume': [1000]
        })

        try:
            features = fe_service.calculate_advanced_features(tiny_ohlcv)
            logger.info(f"  æ¥µå°OHLCV: å‡¦ç†æˆåŠŸ ({features.shape[1]}ç‰¹å¾´é‡)")
        except Exception as e:
            logger.info(f"  æ¥µå°OHLCV: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã§ã®ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
        logger.info("ãƒ©ãƒ™ãƒ«ç”Ÿæˆã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ...")

        # å˜èª¿å¢—åŠ ãƒ‡ãƒ¼ã‚¿
        monotonic_series = pd.Series(range(100), name='Close')
        try:
            labels, _ = label_generator.generate_labels(
                monotonic_series,
                method=ThresholdMethod.FIXED,
                threshold_up=0.02,
                threshold_down=-0.02
            )
            label_dist = pd.Series(labels).value_counts()
            logger.info(f"  å˜èª¿å¢—åŠ : æˆåŠŸ - åˆ†å¸ƒ {label_dist.to_dict()}")
        except Exception as e:
            logger.info(f"  å˜èª¿å¢—åŠ : ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # å˜èª¿æ¸›å°‘ãƒ‡ãƒ¼ã‚¿
        monotonic_decreasing = pd.Series(range(100, 0, -1), name='Close')
        try:
            labels, _ = label_generator.generate_labels(
                monotonic_decreasing,
                method=ThresholdMethod.FIXED,
                threshold_up=0.02,
                threshold_down=-0.02
            )
            label_dist = pd.Series(labels).value_counts()
            logger.info(f"  å˜èª¿æ¸›å°‘: æˆåŠŸ - åˆ†å¸ƒ {label_dist.to_dict()}")
        except Exception as e:
            logger.info(f"  å˜èª¿æ¸›å°‘: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã®ç¶²ç¾…æ€§ãƒ†ã‚¹ãƒˆ
        logger.info("ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ç¶²ç¾…æ€§ãƒ†ã‚¹ãƒˆ...")

        # ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿å‹ã§ã®å‡¦ç†
        data_types_test = {
            'int32': pd.DataFrame({'Close': np.array([100, 101, 102], dtype=np.int32)}),
            'int64': pd.DataFrame({'Close': np.array([100, 101, 102], dtype=np.int64)}),
            'float32': pd.DataFrame({'Close': np.array([100.0, 101.0, 102.0], dtype=np.float32)}),
            'float64': pd.DataFrame({'Close': np.array([100.0, 101.0, 102.0], dtype=np.float64)}),
        }

        for dtype_name, dtype_data in data_types_test.items():
            try:
                result = processor.preprocess_features(dtype_data.copy())
                logger.info(f"  {dtype_name}: å‡¦ç†æˆåŠŸ ({result.dtypes['Close']})")
            except Exception as e:
                logger.info(f"  {dtype_name}: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        # å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ
        logger.info("å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ...")

        # æœ€å°å€¤ãƒ»æœ€å¤§å€¤ã§ã®å‡¦ç†
        boundary_data = pd.DataFrame({
            'Close': [sys.float_info.min, 0, sys.float_info.max],
            'Volume': [1, 1000, sys.float_info.max]
        })

        try:
            result = processor.preprocess_features(boundary_data.copy())
            logger.info(f"  å¢ƒç•Œå€¤: å‡¦ç†æˆåŠŸ ({len(result)}è¡Œ)")
        except Exception as e:
            logger.info(f"  å¢ƒç•Œå€¤: ä¾‹å¤–å‡¦ç†ç¢ºèª - {e}")

        logger.info("âœ… ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def run_automl_comprehensive_tests():
    """AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("ğŸ¤– AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from app.services.ml.ml_training_service import MLTrainingService
        from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
        from app.services.ml.feature_engineering.automl_features.automl_config import AutoMLConfig
        from app.utils.index_alignment import MLWorkflowIndexManager
        from app.utils.label_generation import LabelGenerator, ThresholdMethod

        # BTCå¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–¢æ•°
        def create_btc_market_data(timeframe="1h", size=300):
            np.random.seed(42)
            dates = pd.date_range('2023-01-01', periods=size, freq='1h')

            base_price = 50000
            volatility = 0.02
            prices = [base_price]

            for i in range(1, size):
                change = np.random.normal(0, volatility)
                new_price = prices[-1] * (1 + change)
                prices.append(max(new_price, base_price * 0.5))

            return pd.DataFrame({
                'timestamp': dates,
                'Open': prices,
                'High': [p * 1.01 for p in prices],
                'Low': [p * 0.99 for p in prices],
                'Close': [p * (1 + np.random.normal(0, 0.003)) for p in prices],
                'Volume': np.random.lognormal(10, 0.6, size)
            }).set_index('timestamp')

        # AutoMLã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ãƒ†ã‚¹ãƒˆ
        logger.info("AutoMLã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ãƒ†ã‚¹ãƒˆ...")
        btc_data = create_btc_market_data("1h", 200)

        try:
            # AutoMLè¨­å®šï¼ˆè»½é‡ç‰ˆï¼‰
            automl_config = {
                "tsfresh": {"enabled": True, "feature_count_limit": 20},
                "autofeat": {"enabled": False}
            }

            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
            ensemble_config = {
                "method": "bagging",
                "bagging_params": {
                    "n_estimators": 2,
                    "bootstrap_fraction": 0.8,
                    "base_model_type": "lightgbm"
                }
            }

            ml_service = MLTrainingService(
                trainer_type="ensemble",
                ensemble_config=ensemble_config,
                automl_config=automl_config
            )

            result = ml_service.train_model(
                training_data=btc_data,
                threshold_up=0.02,
                threshold_down=-0.02,
                save_model=False
            )

            logger.info(f"AutoMLã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’æˆåŠŸ: ç²¾åº¦={result.get('accuracy', 'N/A')}")

        except Exception as e:
            logger.info(f"AutoMLã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")

        # AutoMLç‰¹å¾´é‡é¸æŠãƒ†ã‚¹ãƒˆ
        logger.info("AutoMLç‰¹å¾´é‡é¸æŠãƒ†ã‚¹ãƒˆ...")

        try:
            # AutoMLè¨­å®šã§ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            automl_config_obj = AutoMLConfig.get_financial_optimized_config()
            fe_service = FeatureEngineeringService(automl_config=automl_config_obj)

            # åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—
            basic_features = fe_service.calculate_advanced_features(btc_data)

            logger.info(f"åŸºæœ¬ç‰¹å¾´é‡: {basic_features.shape[1]}å€‹")

            # ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert basic_features.shape[1] > 0, "ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

            logger.info("âœ… AutoMLç‰¹å¾´é‡é¸æŠãŒæ­£å¸¸ã«å‹•ä½œã—ã¾ã—ãŸ")

        except Exception as e:
            logger.info(f"AutoMLç‰¹å¾´é‡é¸æŠã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")

        # AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ
        logger.info("AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ...")

        try:
            index_manager = MLWorkflowIndexManager()
            index_manager.initialize_workflow(btc_data)

            # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            def automl_feature_func(data):
                fe_service = FeatureEngineeringService()
                return fe_service.calculate_advanced_features(data)

            features = index_manager.process_with_index_tracking(
                "AutoMLç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°", btc_data, automl_feature_func
            )

            # ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
            label_generator = LabelGenerator()
            aligned_price_data = btc_data.loc[features.index, 'Close']
            labels, _ = label_generator.generate_labels(
                aligned_price_data,
                method=ThresholdMethod.FIXED,
                threshold_up=0.02,
                threshold_down=-0.02
            )

            # æœ€çµ‚æ•´åˆ
            final_features, final_labels = index_manager.finalize_workflow(
                features, labels, alignment_method="intersection"
            )

            # æ¤œè¨¼
            assert len(final_features) > 0, "æœ€çµ‚ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            assert len(final_labels) > 0, "æœ€çµ‚ãƒ©ãƒ™ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

            workflow_summary = index_manager.get_workflow_summary()
            logger.info(f"AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†: ãƒ‡ãƒ¼ã‚¿ä¿æŒç‡={workflow_summary['data_retention_rate']*100:.1f}%")

        except Exception as e:
            logger.info(f"AutoMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")

        logger.info("âœ… AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False


def run_optuna_bayesian_optimization_tests():
    """Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    logger.info("ğŸ” Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    try:
        from app.services.optimization.optuna_optimizer import OptunaOptimizer, ParameterSpace

        # Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ
        logger.info("Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–åŸºæœ¬ãƒ†ã‚¹ãƒˆ...")

        # ç°¡å˜ãªç›®çš„é–¢æ•°ï¼ˆäºŒæ¬¡é–¢æ•°ã®æœ€å¤§åŒ–ï¼‰
        def simple_objective(params):
            x = params['x']
            y = params['y']
            # æœ€å¤§å€¤ãŒ(2, 3)ã§å€¤ãŒ10ã¨ãªã‚‹äºŒæ¬¡é–¢æ•°
            return 10 - (x - 2)**2 - (y - 3)**2

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“å®šç¾©
        parameter_space = {
            'x': ParameterSpace(type="real", low=0.0, high=5.0),
            'y': ParameterSpace(type="real", low=0.0, high=5.0)
        }

        # Optunaæœ€é©åŒ–å®Ÿè¡Œ
        optimizer = OptunaOptimizer()
        result = optimizer.optimize(
            objective_function=simple_objective,
            parameter_space=parameter_space,
            n_calls=20  # ãƒ†ã‚¹ãƒˆç”¨ã«å°‘ãªãè¨­å®š
        )

        # çµæœæ¤œè¨¼
        assert result.best_score > 8.0, f"æœ€é©åŒ–çµæœãŒä¸ååˆ†: {result.best_score}"
        assert abs(result.best_params['x'] - 2.0) < 1.0, "xãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ãŒä¸ååˆ†"
        assert abs(result.best_params['y'] - 3.0) < 1.0, "yãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ãŒä¸ååˆ†"

        logger.info(f"Optunaæœ€é©åŒ–æˆåŠŸ: ã‚¹ã‚³ã‚¢={result.best_score:.3f}, "
                   f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿={result.best_params}")

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        optimizer.cleanup()

        # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        logger.info("LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ...")

        # LightGBMç”¨ã®ç›®çš„é–¢æ•°ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        def lightgbm_objective(params):
            # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ä»£ã‚ã‚Šã«ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ã‚¹ã‚³ã‚¢åŒ–
            score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢èª¿æ•´
            if 0.01 <= params['learning_rate'] <= 0.3:
                score += 0.1
            if 10 <= params['num_leaves'] <= 100:
                score += 0.1
            if 0.5 <= params['feature_fraction'] <= 1.0:
                score += 0.1
            if 5 <= params['min_data_in_leaf'] <= 50:
                score += 0.1

            # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‚’è¿½åŠ ï¼ˆå®Ÿéš›ã®å­¦ç¿’çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
            import random
            score += random.uniform(-0.1, 0.1)

            return score

        # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“
        lgb_parameter_space = OptunaOptimizer.get_default_parameter_space()

        # æœ€é©åŒ–å®Ÿè¡Œ
        optimizer2 = OptunaOptimizer()
        lgb_result = optimizer2.optimize(
            objective_function=lightgbm_objective,
            parameter_space=lgb_parameter_space,
            n_calls=15
        )

        # çµæœæ¤œè¨¼
        assert lgb_result.best_score > 0.5, f"LightGBMæœ€é©åŒ–çµæœãŒä¸ååˆ†: {lgb_result.best_score}"
        assert 'learning_rate' in lgb_result.best_params, "learning_rateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³"
        assert 'num_leaves' in lgb_result.best_params, "num_leavesãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä¸è¶³"

        logger.info(f"LightGBMæœ€é©åŒ–æˆåŠŸ: ã‚¹ã‚³ã‚¢={lgb_result.best_score:.3f}")

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        optimizer2.cleanup()

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        logger.info("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ...")

        try:
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“
            ensemble_parameter_space = OptunaOptimizer.get_ensemble_parameter_space(
                ensemble_method="bagging",
                enabled_models=["lightgbm", "random_forest"]
            )

            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ç›®çš„é–¢æ•°
            def ensemble_objective(params):
                score = 0.6  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                if 'n_estimators' in params and 2 <= params['n_estimators'] <= 10:
                    score += 0.1
                if 'bootstrap_fraction' in params and 0.5 <= params['bootstrap_fraction'] <= 1.0:
                    score += 0.1

                return score + np.random.uniform(-0.05, 0.05)

            # æœ€é©åŒ–å®Ÿè¡Œ
            optimizer3 = OptunaOptimizer()
            ensemble_result = optimizer3.optimize(
                objective_function=ensemble_objective,
                parameter_space=ensemble_parameter_space,
                n_calls=10
            )

            logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€é©åŒ–æˆåŠŸ: ã‚¹ã‚³ã‚¢={ensemble_result.best_score:.3f}")
            optimizer3.cleanup()

        except Exception as e:
            logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€é©åŒ–ã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")

        # æœ€é©åŒ–åŠ¹ç‡æ€§ãƒ†ã‚¹ãƒˆ
        logger.info("æœ€é©åŒ–åŠ¹ç‡æ€§ãƒ†ã‚¹ãƒˆ...")

        # è¤‡é›‘ãªç›®çš„é–¢æ•°ï¼ˆå¤šå³°æ€§é–¢æ•°ï¼‰
        def complex_objective(params):
            x, y = params['x'], params['y']
            # Rastriginé–¢æ•°ã®å¤‰å½¢ï¼ˆæœ€å¤§åŒ–ç”¨ï¼‰
            return -(10 * 2 + (x**2 - 10 * np.cos(2 * np.pi * x)) +
                    (y**2 - 10 * np.cos(2 * np.pi * y)))

        # åŠ¹ç‡æ€§æ¸¬å®š
        start_time = time.time()
        optimizer4 = OptunaOptimizer()
        complex_result = optimizer4.optimize(
            objective_function=complex_objective,
            parameter_space={
                'x': ParameterSpace(type="real", low=-5.0, high=5.0),
                'y': ParameterSpace(type="real", low=-5.0, high=5.0)
            },
            n_calls=25
        )
        optimization_time = time.time() - start_time

        # åŠ¹ç‡æ€§æ¤œè¨¼
        assert optimization_time < 30, f"æœ€é©åŒ–æ™‚é–“ãŒé•·ã™ãã¾ã™: {optimization_time:.2f}ç§’"
        assert complex_result.total_evaluations == 25, "è©•ä¾¡å›æ•°ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“"

        logger.info(f"è¤‡é›‘é–¢æ•°æœ€é©åŒ–å®Œäº†: æ™‚é–“={optimization_time:.2f}ç§’, "
                   f"ã‚¹ã‚³ã‚¢={complex_result.best_score:.3f}")

        optimizer4.cleanup()

        # ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        logger.info("ç•°ãªã‚‹æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ†ã‚¹ãƒˆ...")

        try:
            import optuna

            # TPESampler vs RandomSampler ã®æ¯”è¼ƒ
            samplers = {
                "TPE": optuna.samplers.TPESampler(seed=42),
                "Random": optuna.samplers.RandomSampler(seed=42)
            }

            sampler_results = {}

            for sampler_name, sampler in samplers.items():
                # ã‚«ã‚¹ã‚¿ãƒ Optunaã‚¹ã‚¿ãƒ‡ã‚£ä½œæˆ
                study = optuna.create_study(
                    direction="maximize",
                    sampler=sampler
                )

                def optuna_objective(trial):
                    x = trial.suggest_float('x', 0.0, 5.0)
                    y = trial.suggest_float('y', 0.0, 5.0)
                    return simple_objective({'x': x, 'y': y})

                study.optimize(optuna_objective, n_trials=15)

                sampler_results[sampler_name] = {
                    "best_score": study.best_value,
                    "best_params": study.best_params
                }

                logger.info(f"{sampler_name}ã‚µãƒ³ãƒ—ãƒ©ãƒ¼: ã‚¹ã‚³ã‚¢={study.best_value:.3f}")

            # TPEã®æ–¹ãŒè‰¯ã„çµæœã‚’å‡ºã™ã“ã¨ã‚’æœŸå¾…ï¼ˆå¿…é ˆã§ã¯ãªã„ï¼‰
            if sampler_results["TPE"]["best_score"] > sampler_results["Random"]["best_score"]:
                logger.info("âœ… TPEã‚µãƒ³ãƒ—ãƒ©ãƒ¼ãŒRandomã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã‚ˆã‚Šè‰¯ã„çµæœã‚’å‡ºã—ã¾ã—ãŸ")
            else:
                logger.info("â„¹ï¸ ã“ã®è©¦è¡Œã§ã¯Randomã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã®æ–¹ãŒè‰¯ã„çµæœã§ã—ãŸ")

        except Exception as e:
            logger.info(f"ã‚µãƒ³ãƒ—ãƒ©ãƒ¼æ¯”è¼ƒãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ï¼ˆæœŸå¾…ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰: {e}")

        logger.info("âœ… Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True

    except Exception as e:
        logger.error(f"âŒ Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return False

logger = logging.getLogger(__name__)


class MLAccuracyTestSuite:
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.test_results = {}
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.start_time = None
        self.end_time = None

    def run_test_module(self, test_name: str, test_function) -> bool:
        """å€‹åˆ¥ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª {test_name} ã‚’é–‹å§‹")
        logger.info(f"{'='*60}")
        
        start_time = time.time()
        
        try:
            success = test_function()
            execution_time = time.time() - start_time
            
            if success:
                logger.info(f"âœ… {test_name} æˆåŠŸ (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")
                self.passed_tests += 1
            else:
                logger.error(f"âŒ {test_name} å¤±æ•— (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")
                self.failed_tests += 1
            
            self.test_results[test_name] = {
                'success': success,
                'execution_time': execution_time,
                'error': None
            }
            
            return success
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"{test_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            
            self.test_results[test_name] = {
                'success': False,
                'execution_time': execution_time,
                'error': error_msg
            }
            
            self.failed_tests += 1
            return False

    def run_all_tests(self) -> bool:
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’é–‹å§‹")
        logger.info("=" * 80)
        
        self.start_time = time.time()
        
        # ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®šç¾©
        test_modules = [
            ("è¨ˆç®—æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_calculation_tests),
            ("å‰å‡¦ç†æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_preprocessing_tests),
            ("ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ", run_all_feature_calculation_tests),
            ("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ†ã‚¹ãƒˆ", run_all_data_transformation_tests),
            ("ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ", run_all_label_generation_tests),
            ("çµ±åˆãƒ†ã‚¹ãƒˆ", run_integration_tests),
            ("æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ", run_extreme_edge_case_tests),
            ("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ", run_real_environment_simulation_tests),
            ("é«˜åº¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼", run_advanced_performance_optimization_tests),
            ("ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª", run_code_coverage_verification_tests),
            ("AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ", run_automl_comprehensive_tests),
            ("Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ", run_optuna_bayesian_optimization_tests),
            ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", run_all_error_handling_tests),
            ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", run_all_performance_tests),
        ]
        
        self.total_tests = len(test_modules)
        
        # å„ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
        all_passed = True
        for test_name, test_function in test_modules:
            success = self.run_test_module(test_name, test_function)
            if not success:
                all_passed = False
        
        self.end_time = time.time()
        
        # çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        self._display_summary()
        
        return all_passed

    def _display_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        total_time = self.end_time - self.start_time
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 80)
        
        logger.info(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        logger.info(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {self.total_tests}")
        logger.info(f"æˆåŠŸ: {self.passed_tests}")
        logger.info(f"å¤±æ•—: {self.failed_tests}")
        logger.info(f"æˆåŠŸç‡: {(self.passed_tests/self.total_tests)*100:.1f}%")
        
        logger.info("\nğŸ“‹ è©³ç´°çµæœ:")
        for test_name, result in self.test_results.items():
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
            time_str = f"{result['execution_time']:.2f}ç§’"
            logger.info(f"  {test_name}: {status} ({time_str})")
            
            if result['error']:
                logger.info(f"    ã‚¨ãƒ©ãƒ¼: {result['error']}")
        
        if self.failed_tests == 0:
            logger.info("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            logger.info("MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨ˆç®—ã¨å‰å‡¦ç†ã®æ­£ç¢ºæ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
        else:
            logger.warning(f"\nâš ï¸ {self.failed_tests}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
            logger.warning("å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‚’ç¢ºèªã—ã€å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")

    def run_specific_test(self, test_name: str) -> bool:
        """ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã®ã¿ã‚’å®Ÿè¡Œ"""
        test_mapping = {
            "calculations": ("è¨ˆç®—æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_calculation_tests),
            "preprocessing": ("å‰å‡¦ç†æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_preprocessing_tests),
            "features": ("ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ", run_all_feature_calculation_tests),
            "transformations": ("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ†ã‚¹ãƒˆ", run_all_data_transformation_tests),
            "labels": ("ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ", run_all_label_generation_tests),
            "integration": ("çµ±åˆãƒ†ã‚¹ãƒˆ", run_integration_tests),
            "extreme": ("æ¥µç«¯ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ", run_extreme_edge_case_tests),
            "realenv": ("å®Ÿç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ", run_real_environment_simulation_tests),
            "advperf": ("é«˜åº¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æ¤œè¨¼", run_advanced_performance_optimization_tests),
            "coverage": ("ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª", run_code_coverage_verification_tests),
            "automl": ("AutoMLåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ", run_automl_comprehensive_tests),
            "optuna": ("Optunaãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ", run_optuna_bayesian_optimization_tests),
            "errors": ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", run_all_error_handling_tests),
            "performance": ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", run_all_performance_tests),
        }
        
        if test_name not in test_mapping:
            logger.error(f"ä¸æ˜ãªãƒ†ã‚¹ãƒˆå: {test_name}")
            logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆ: {list(test_mapping.keys())}")
            return False
        
        self.start_time = time.time()
        self.total_tests = 1
        
        test_display_name, test_function = test_mapping[test_name]
        success = self.run_test_module(test_display_name, test_function)
        
        self.end_time = time.time()
        self._display_summary()
        
        return success

    def validate_test_environment(self) -> bool:
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼"""
        logger.info("ğŸ” ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’æ¤œè¨¼ä¸­...")
        
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
            import numpy as np
            import pandas as pd
            import sklearn
            import scipy
            import talib
            
            logger.info("âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºèª
            from app.utils.data_processing import DataProcessor
            from app.utils.label_generation import LabelGenerator
            from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
            
            logger.info("âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            # åŸºæœ¬çš„ãªå‹•ä½œç¢ºèª
            processor = DataProcessor()
            label_generator = LabelGenerator()
            fe_service = FeatureEngineeringService()
            
            logger.info("âœ… åŸºæœ¬çš„ãªã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ãŒæˆåŠŸã—ã¾ã—ãŸ")
            
            return True
            
        except ImportError as e:
            logger.error(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            return False

    def generate_test_report(self, output_file: str = None):
        """ãƒ†ã‚¹ãƒˆçµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.test_results:
            logger.warning("ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        report_lines = [
            "# MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ",
            f"å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"ç·å®Ÿè¡Œæ™‚é–“: {(self.end_time - self.start_time):.2f}ç§’",
            "",
            "## ã‚µãƒãƒªãƒ¼",
            f"- ç·ãƒ†ã‚¹ãƒˆæ•°: {self.total_tests}",
            f"- æˆåŠŸ: {self.passed_tests}",
            f"- å¤±æ•—: {self.failed_tests}",
            f"- æˆåŠŸç‡: {(self.passed_tests/self.total_tests)*100:.1f}%",
            "",
            "## è©³ç´°çµæœ"
        ]
        
        for test_name, result in self.test_results.items():
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
            report_lines.append(f"### {test_name}")
            report_lines.append(f"- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
            report_lines.append(f"- å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
            
            if result['error']:
                report_lines.append(f"- ã‚¨ãƒ©ãƒ¼: {result['error']}")
            
            report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                logger.info(f"ğŸ“„ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            except Exception as e:
                logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            logger.info("\n" + report_content)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    test_suite = MLAccuracyTestSuite()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    if len(sys.argv) > 1:
        test_name = sys.argv[1]
        if test_name == "validate":
            success = test_suite.validate_test_environment()
            sys.exit(0 if success else 1)
        else:
            success = test_suite.run_specific_test(test_name)
    else:
        # ç’°å¢ƒæ¤œè¨¼
        if not test_suite.validate_test_environment():
            logger.error("ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            sys.exit(1)
        
        # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        success = test_suite.run_all_tests()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    test_suite.generate_test_report()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
