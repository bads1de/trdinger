"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

è¨ˆç®—æ­£ç¢ºæ€§ã€å‰å‡¦ç†æ­£ç¢ºæ€§ã€ç‰¹å¾´é‡è¨ˆç®—ã€ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã€ãƒ©ãƒ™ãƒ«ç”Ÿæˆã®
ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’çµ±åˆå®Ÿè¡Œã—ã€MLã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ä¿¡é ¼æ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import logging
import sys
import os
import time
from typing import Dict, List, Tuple, Any
import traceback

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å„ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tests.calculations.test_ml_calculations import run_all_calculation_tests
from tests.preprocessing.test_preprocessing_accuracy import run_all_preprocessing_tests
from tests.feature_engineering.test_feature_calculations import run_all_feature_calculation_tests
from tests.data_transformations.test_data_transformations import run_all_data_transformation_tests
from tests.label_generation.test_label_generation import run_all_label_generation_tests
from tests.enhanced.test_error_handling import run_all_error_handling_tests
from tests.enhanced.test_performance import run_all_performance_tests

logger = logging.getLogger(__name__)


class MLAccuracyTestSuite:
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.test_results = {}
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.start_time = None
        self.end_time = None

    def run_test_module(self, test_name: str, test_function) -> bool:
        """å€‹åˆ¥ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª {test_name} ã‚’é–‹å§‹")
        logger.info(f"{'='*60}")
        
        start_time = time.time()
        
        try:
            success = test_function()
            execution_time = time.time() - start_time
            
            if success:
                logger.info(f"âœ… {test_name} æˆåŠŸ (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")
                self.passed_tests += 1
            else:
                logger.error(f"âŒ {test_name} å¤±æ•— (å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’)")
                self.failed_tests += 1
            
            self.test_results[test_name] = {
                'success': success,
                'execution_time': execution_time,
                'error': None
            }
            
            return success
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"{test_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            
            self.test_results[test_name] = {
                'success': False,
                'execution_time': execution_time,
                'error': error_msg
            }
            
            self.failed_tests += 1
            return False

    def run_all_tests(self) -> bool:
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’é–‹å§‹")
        logger.info("=" * 80)
        
        self.start_time = time.time()
        
        # ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®šç¾©
        test_modules = [
            ("è¨ˆç®—æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_calculation_tests),
            ("å‰å‡¦ç†æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_preprocessing_tests),
            ("ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ", run_all_feature_calculation_tests),
            ("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ†ã‚¹ãƒˆ", run_all_data_transformation_tests),
            ("ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ", run_all_label_generation_tests),
            ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", run_all_error_handling_tests),
            ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", run_all_performance_tests),
        ]
        
        self.total_tests = len(test_modules)
        
        # å„ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
        all_passed = True
        for test_name, test_function in test_modules:
            success = self.run_test_module(test_name, test_function)
            if not success:
                all_passed = False
        
        self.end_time = time.time()
        
        # çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        self._display_summary()
        
        return all_passed

    def _display_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        total_time = self.end_time - self.start_time
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 80)
        
        logger.info(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        logger.info(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {self.total_tests}")
        logger.info(f"æˆåŠŸ: {self.passed_tests}")
        logger.info(f"å¤±æ•—: {self.failed_tests}")
        logger.info(f"æˆåŠŸç‡: {(self.passed_tests/self.total_tests)*100:.1f}%")
        
        logger.info("\nğŸ“‹ è©³ç´°çµæœ:")
        for test_name, result in self.test_results.items():
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
            time_str = f"{result['execution_time']:.2f}ç§’"
            logger.info(f"  {test_name}: {status} ({time_str})")
            
            if result['error']:
                logger.info(f"    ã‚¨ãƒ©ãƒ¼: {result['error']}")
        
        if self.failed_tests == 0:
            logger.info("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            logger.info("MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨ˆç®—ã¨å‰å‡¦ç†ã®æ­£ç¢ºæ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
        else:
            logger.warning(f"\nâš ï¸ {self.failed_tests}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
            logger.warning("å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‚’ç¢ºèªã—ã€å•é¡Œã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")

    def run_specific_test(self, test_name: str) -> bool:
        """ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã®ã¿ã‚’å®Ÿè¡Œ"""
        test_mapping = {
            "calculations": ("è¨ˆç®—æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_calculation_tests),
            "preprocessing": ("å‰å‡¦ç†æ­£ç¢ºæ€§ãƒ†ã‚¹ãƒˆ", run_all_preprocessing_tests),
            "features": ("ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ", run_all_feature_calculation_tests),
            "transformations": ("ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ†ã‚¹ãƒˆ", run_all_data_transformation_tests),
            "labels": ("ãƒ©ãƒ™ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ", run_all_label_generation_tests),
            "errors": ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", run_all_error_handling_tests),
            "performance": ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", run_all_performance_tests),
        }
        
        if test_name not in test_mapping:
            logger.error(f"ä¸æ˜ãªãƒ†ã‚¹ãƒˆå: {test_name}")
            logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ†ã‚¹ãƒˆ: {list(test_mapping.keys())}")
            return False
        
        self.start_time = time.time()
        self.total_tests = 1
        
        test_display_name, test_function = test_mapping[test_name]
        success = self.run_test_module(test_display_name, test_function)
        
        self.end_time = time.time()
        self._display_summary()
        
        return success

    def validate_test_environment(self) -> bool:
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼"""
        logger.info("ğŸ” ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’æ¤œè¨¼ä¸­...")
        
        try:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
            import numpy as np
            import pandas as pd
            import sklearn
            import scipy
            import talib
            
            logger.info("âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç¢ºèª
            from app.utils.data_processing import DataProcessor
            from app.utils.label_generation import LabelGenerator
            from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
            
            logger.info("âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            # åŸºæœ¬çš„ãªå‹•ä½œç¢ºèª
            processor = DataProcessor()
            label_generator = LabelGenerator()
            fe_service = FeatureEngineeringService()
            
            logger.info("âœ… åŸºæœ¬çš„ãªã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ãŒæˆåŠŸã—ã¾ã—ãŸ")
            
            return True
            
        except ImportError as e:
            logger.error(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            return False

    def generate_test_report(self, output_file: str = None):
        """ãƒ†ã‚¹ãƒˆçµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.test_results:
            logger.warning("ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        report_lines = [
            "# MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç³»ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ",
            f"å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"ç·å®Ÿè¡Œæ™‚é–“: {(self.end_time - self.start_time):.2f}ç§’",
            "",
            "## ã‚µãƒãƒªãƒ¼",
            f"- ç·ãƒ†ã‚¹ãƒˆæ•°: {self.total_tests}",
            f"- æˆåŠŸ: {self.passed_tests}",
            f"- å¤±æ•—: {self.failed_tests}",
            f"- æˆåŠŸç‡: {(self.passed_tests/self.total_tests)*100:.1f}%",
            "",
            "## è©³ç´°çµæœ"
        ]
        
        for test_name, result in self.test_results.items():
            status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
            report_lines.append(f"### {test_name}")
            report_lines.append(f"- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
            report_lines.append(f"- å®Ÿè¡Œæ™‚é–“: {result['execution_time']:.2f}ç§’")
            
            if result['error']:
                report_lines.append(f"- ã‚¨ãƒ©ãƒ¼: {result['error']}")
            
            report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                logger.info(f"ğŸ“„ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            except Exception as e:
                logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            logger.info("\n" + report_content)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    test_suite = MLAccuracyTestSuite()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    if len(sys.argv) > 1:
        test_name = sys.argv[1]
        if test_name == "validate":
            success = test_suite.validate_test_environment()
            sys.exit(0 if success else 1)
        else:
            success = test_suite.run_specific_test(test_name)
    else:
        # ç’°å¢ƒæ¤œè¨¼
        if not test_suite.validate_test_environment():
            logger.error("ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            sys.exit(1)
        
        # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        success = test_suite.run_all_tests()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    test_suite.generate_test_report()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
