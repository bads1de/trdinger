"""
MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼ãƒ†ã‚¹ãƒˆ - å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œã¨å•é¡Œæ¤œå‡ºã‚’é‡è¦–
"""

import gc
import os
import tempfile
from datetime import datetime, timedelta
from unittest.mock import MagicMock, Mock, patch

import numpy as np
import pandas as pd
import pytest

from backend.app.services.ml.base_ml_trainer import BaseMLTrainer
from backend.app.services.ml.ml_training_service import MLTrainingService
from backend.app.services.ml.orchestration.ml_training_orchestration_service import (
    MLTrainingOrchestrationService,
)


@pytest.mark.skip(reason="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼ã¯å®Ÿè£…ãŒä¸å®Œå…¨ã€‚å®Ÿè£…å®Œäº†å¾Œã«æœ‰åŠ¹åŒ–")
class TestMLTrainingValidation:
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼ã®ãŸã‚ã®å®Ÿè·µçš„ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def sample_training_data(self):
        """å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿"""
        np.random.seed(42)
        dates = pd.date_range(start="2023-01-01", end="2023-06-30", freq="D")

        data = pd.DataFrame(
            {
                "timestamp": dates,
                "open": 10000 + np.random.randn(len(dates)) * 200,
                "high": 10000 + np.random.randn(len(dates)) * 300,
                "low": 10000 + np.random.randn(len(dates)) * 300,
                "close": 10000 + np.random.randn(len(dates)) * 200,
                "volume": 500 + np.random.randint(100, 1000, len(dates)),
                "returns": np.random.randn(len(dates)) * 0.02,
                "volatility": 0.01 + np.random.rand(len(dates)) * 0.02,
                "rsi": 30 + np.random.rand(len(dates)) * 40,
                "macd": np.random.randn(len(dates)) * 0.01,
                "signal": np.random.randn(len(dates)) * 0.005,
                "histogram": np.random.randn(len(dates)) * 0.005,
            }
        )

        # OHLCã®é–¢ä¿‚ã‚’ç¢ºä¿
        data["high"] = data[["open", "close", "high"]].max(axis=1)
        data["low"] = data[["open", "close", "low"]].min(axis=1)

        # ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆï¼ˆä¸Šæ˜‡:1, ä¸‹é™:0ï¼‰
        data["target"] = (data["close"].shift(-1) > data["close"]).astype(int)

        return data.dropna()

    @pytest.fixture
    def real_ml_training_service(self):
        """å®Ÿéš›ã®MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹"""
        return MLTrainingService(trainer_type="single", single_model_type="lightgbm")

    def test_real_model_training_execution(
        self, sample_training_data, real_ml_training_service
    ):
        """å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ...")

        # å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        result = real_ml_training_service.train_model(
            sample_training_data, save_model=False, optimization_settings=None
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert result["success"] is True
        assert "f1_score" in result
        assert "accuracy" in result
        assert result["f1_score"] >= 0.0
        assert result["accuracy"] >= 0.0

        print(
            f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆåŠŸ - F1ã‚¹ã‚³ã‚¢: {result['f1_score']:.4f}, ç²¾åº¦: {result['accuracy']:.4f}"
        )

    def test_real_training_with_optimization(
        self, sample_training_data, real_ml_training_service
    ):
        """æœ€é©åŒ–ã‚ã‚Šã®å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” æœ€é©åŒ–ã‚ã‚Šã®å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ...")

        from backend.app.services.ml.ml_training_service import OptimizationSettings

        # æœ€é©åŒ–è¨­å®š
        optimization_settings = OptimizationSettings(
            enabled=True,
            n_calls=10,  # å°‘ãªã„å›æ•°ã«ã—ã¦ãƒ†ã‚¹ãƒˆã‚’é«˜é€ŸåŒ–
            parameter_space={
                "learning_rate": {"type": "real", "low": 0.01, "high": 0.1},
                "n_estimators": {"type": "integer", "low": 50, "high": 100},
            },
        )

        # å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        result = real_ml_training_service.train_model(
            sample_training_data,
            save_model=False,
            optimization_settings=optimization_settings,
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æœ€é©åŒ–ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert result["success"] is True
        assert "optimization_result" in result
        assert "best_score" in result["optimization_result"]
        assert "best_params" in result["optimization_result"]

        print(
            f"âœ… æœ€é©åŒ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆåŠŸ - æœ€è‰¯ã‚¹ã‚³ã‚¢: {result['optimization_result']['best_score']:.4f}"
        )

    def test_memory_leakage_detection(self, sample_training_data):
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º...")

        initial_objects = len(gc.get_objects())
        gc.collect()

        # è¤‡æ•°å›ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        for i in range(3):
            training_service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = training_service.train_model(
                sample_training_data, save_model=False
            )
            assert result["success"] is True

            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒãªã„ã“ã¨
            current_objects = len(gc.get_objects())
            assert (
                current_objects - initial_objects
            ) < 500, f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°{i+1}å›ç›®ã§ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"

        gc.collect()
        final_objects = len(gc.get_objects())
        print(
            f"âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãªã— - åˆæœŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {initial_objects}, æœ€çµ‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {final_objects}"
        )

    def test_model_convergence_validation(self, sample_training_data):
        """ãƒ¢ãƒ‡ãƒ«åæŸæ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«åæŸã‚’æ¤œè¨¼...")

        training_service = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        )

        # è¤‡æ•°å›ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦åæŸã‚’ç¢ºèª
        scores = []
        for i in range(5):
            result = training_service.train_model(
                sample_training_data, save_model=False
            )
            scores.append(result["f1_score"])

        # ã‚¹ã‚³ã‚¢ãŒå®‰å®šã—ã¦ã„ã‚‹ã“ã¨ï¼ˆåæŸã—ã¦ã„ã‚‹ï¼‰
        score_std = np.std(scores)
        assert (
            score_std < 0.1
        ), f"ãƒ¢ãƒ‡ãƒ«ãŒåæŸã—ã¦ã„ã¾ã›ã‚“ - ã‚¹ã‚³ã‚¢æ¨™æº–åå·®: {score_std:.4f}"

        print(f"âœ… ãƒ¢ãƒ‡ãƒ«åæŸç¢ºèª - ã‚¹ã‚³ã‚¢æ¨™æº–åå·®: {score_std:.4f}")

    def test_data_preprocessing_effectiveness(self, sample_training_data):
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†åŠ¹æœã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†åŠ¹æœã‚’æ¤œè¨¼...")

        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        raw_data = sample_training_data.copy()
        raw_result = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        ).train_model(raw_data, save_model=False)

        # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        processed_data = sample_training_data.copy()
        # æ¨™æº–åŒ–ã‚’é©ç”¨
        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns
        processed_data[numeric_cols] = (
            processed_data[numeric_cols] - processed_data[numeric_cols].mean()
        ) / processed_data[numeric_cols].std()

        processed_result = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        ).train_model(processed_data, save_model=False)

        # å‰å‡¦ç†ã«ã‚ˆã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨
        improvement = processed_result["f1_score"] - raw_result["f1_score"]
        print(
            f"âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†åŠ¹æœ - ç”Ÿãƒ‡ãƒ¼ã‚¿F1ã‚¹ã‚³ã‚¢: {raw_result['f1_score']:.4f}, "
            f"å‰å‡¦ç†å¾ŒF1ã‚¹ã‚³ã‚¢: {processed_result['f1_score']:.4f}, "
            f"å‘ä¸Šå¹…: {improvement:.4f}"
        )

    def test_model_overfitting_detection(self, sample_training_data):
        """ãƒ¢ãƒ‡ãƒ«éå­¦ç¿’æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«éå­¦ç¿’ã‚’æ¤œå‡º...")

        training_service = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        )

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        train_data = sample_training_data[: int(len(sample_training_data) * 0.8)]
        test_data = sample_training_data[int(len(sample_training_data) * 0.8) :]

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        result = training_service.train_model(train_data, save_model=False)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
        test_result = training_service.evaluate_model(test_data)

        # éå­¦ç¿’ãŒèµ·ãã¦ã„ãªã„ã“ã¨ï¼ˆãƒ†ã‚¹ãƒˆç²¾åº¦ãŒå­¦ç¿’ç²¾åº¦ã¨å¤§ããç•°ãªã‚‹ã“ã¨ï¼‰
        train_score = result["f1_score"]
        test_score = test_result["f1_score"]
        overfitting_threshold = 0.15  # 15%ä»¥ä¸Šã®å·®ã¯éå­¦ç¿’ã¨ã¿ãªã™

        if abs(train_score - test_score) > overfitting_threshold:
            print(
                f"âš ï¸ éå­¦ç¿’ã®å…†å€™ã‚ã‚Š - å­¦ç¿’F1ã‚¹ã‚³ã‚¢: {train_score:.4f}, ãƒ†ã‚¹ãƒˆF1ã‚¹ã‚³ã‚¢: {test_score:.4f}"
            )
        else:
            print(
                f"âœ… éå­¦ç¿’ãªã— - å­¦ç¿’F1ã‚¹ã‚³ã‚¢: {train_score:.4f}, ãƒ†ã‚¹ãƒˆF1ã‚¹ã‚³ã‚¢: {test_score:.4f}"
            )

    def test_training_failure_recovery(self, sample_training_data):
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—ã‹ã‚‰ã®å›å¾©ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—ã‹ã‚‰ã®å›å¾©ã‚’ãƒ†ã‚¹ãƒˆ...")

        training_service = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        )

        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦è¡Œ
        invalid_data = sample_training_data.copy()
        invalid_data.loc[:, "close"] = np.nan  # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’NaNã«

        try:
            result = training_service.train_model(invalid_data, save_model=False)
            # å¤±æ•—ã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨
            assert not result["success"]
            print("âœ… ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
        except Exception as e:
            print(f"âœ… ä¾‹å¤–ãŒé©åˆ‡ã«ã‚­ãƒ£ãƒƒãƒã•ã‚Œã¾ã—ãŸ: {type(e).__name__}")

        # å†ã³æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        valid_result = training_service.train_model(
            sample_training_data, save_model=False
        )
        assert valid_result["success"] is True
        print("âœ… å¤±æ•—å¾Œã®å›å¾©ãŒæˆåŠŸ")

    def test_model_persistence_and_loading(self, sample_training_data):
        """ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ã¨èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ã¨èª­ã¿è¾¼ã¿ã‚’ãƒ†ã‚¹ãƒˆ...")

        training_service = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ä¿å­˜
        with tempfile.TemporaryDirectory() as temp_dir:
            model_path = os.path.join(temp_dir, "test_model.pkl")

            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            train_result = training_service.train_model(
                sample_training_data, save_model=True, model_path=model_path
            )
            assert train_result["success"] is True

            # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ç¢ºèª
            assert os.path.exists(model_path)

            # æ–°ã—ã„ã‚µãƒ¼ãƒ“ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            new_service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            loaded_model = new_service.load_model(model_path)
            assert loaded_model is not None

            # èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
            features = sample_training_data.drop(["target"], axis=1, errors="ignore")
            if hasattr(loaded_model, "predict"):
                predictions = loaded_model.predict(features)
                assert len(predictions) == len(sample_training_data)
                print("âœ… ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ã¨èª­ã¿è¾¼ã¿æˆåŠŸ")

    def test_training_with_different_model_types(self, sample_training_data):
        """ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ...")

        model_types = ["lightgbm", "xgboost", "randomforest"]
        results = {}

        for model_type in model_types:
            print(f"  - {model_type} ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")

            training_service = MLTrainingService(
                trainer_type="single", single_model_type=model_type
            )
            result = training_service.train_model(
                sample_training_data, save_model=False
            )

            assert result["success"] is True
            results[model_type] = result["f1_score"]
            print(f"    âœ… F1ã‚¹ã‚³ã‚¢: {result['f1_score']:.4f}")

        # ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert len(results) == len(model_types)
        print(f"âœ… ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§æˆåŠŸ - {results}")

    def test_ensemble_training_validation(self, sample_training_data):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ¤œè¨¼...")

        training_service = MLTrainingService(trainer_type="ensemble")

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        result = training_service.train_model(sample_training_data, save_model=False)

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert result["success"] is True
        assert "f1_score" in result
        assert "ensemble_metrics" in result or "individual_model_metrics" in result

        print(f"âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆåŠŸ - F1ã‚¹ã‚³ã‚¢: {result['f1_score']:.4f}")

    def test_training_time_monitoring(self, sample_training_data):
        """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ç›£è¦–ã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’ç›£è¦–...")

        training_service = MLTrainingService(
            trainer_type="single", single_model_type="lightgbm"
        )

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹æ™‚é–“
        start_time = datetime.now()

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        result = training_service.train_model(sample_training_data, save_model=False)

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†æ™‚é–“
        end_time = datetime.now()
        training_duration = (end_time - start_time).total_seconds()

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert result["success"] is True

        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ãŒé©åˆ‡ãªç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ï¼ˆ10åˆ†ä»¥å†…ï¼‰
        assert (
            training_duration < 600
        ), f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ãŒé•·ã™ãã¾ã™: {training_duration:.2f}ç§’"

        print(f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ç›£è¦–æˆåŠŸ - æ‰€è¦æ™‚é–“: {training_duration:.2f}ç§’")

    def test_final_comprehensive_validation(self, sample_training_data):
        """æœ€çµ‚åŒ…æ‹¬çš„æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ æœ€çµ‚åŒ…æ‹¬çš„æ¤œè¨¼ã‚’å®Ÿè¡Œ...")

        # ã™ã¹ã¦ã®ä¸»è¦æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        validation_checks = []

        # 1. åŸºæœ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(sample_training_data, save_model=False)
            validation_checks.append(("åŸºæœ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", result["success"]))
        except Exception as e:
            validation_checks.append(("åŸºæœ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", False))

        # 2. æœ€é©åŒ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        try:
            from backend.app.services.ml.ml_training_service import OptimizationSettings

            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            optimization_settings = OptimizationSettings(enabled=True, n_calls=5)
            result = service.train_model(
                sample_training_data,
                save_model=False,
                optimization_settings=optimization_settings,
            )
            validation_checks.append(("æœ€é©åŒ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", result["success"]))
        except Exception as e:
            validation_checks.append(("æœ€é©åŒ–ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", False))

        # 3. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(sample_training_data, save_model=False)
            eval_result = service.evaluate_model(sample_training_data)
            validation_checks.append(("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡", True))
        except Exception as e:
            validation_checks.append(("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡", False))

        # 4. äºˆæ¸¬æ©Ÿèƒ½
        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(sample_training_data, save_model=False)
            features = sample_training_data.drop(["target"], axis=1, errors="ignore")
            predictions = service.predict(features)
            validation_checks.append(("äºˆæ¸¬æ©Ÿèƒ½", "predictions" in predictions))
        except Exception as e:
            validation_checks.append(("äºˆæ¸¬æ©Ÿèƒ½", False))

        # æ¤œè¨¼çµæœã®é›†è¨ˆ
        passed_checks = sum(1 for _, passed in validation_checks if passed)
        total_checks = len(validation_checks)

        print(f"\nğŸ“Š æ¤œè¨¼çµæœ:")
        for check_name, passed in validation_checks:
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {check_name}: {'æˆåŠŸ' if passed else 'å¤±æ•—'}")

        print(f"\nğŸ¯ ç·åˆè©•ä¾¡: {passed_checks}/{total_checks} ã®ãƒã‚§ãƒƒã‚¯ãŒæˆåŠŸ")

        # å¤§å¤šæ•°ã®ãƒã‚§ãƒƒã‚¯ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert (
            passed_checks >= total_checks * 0.75
        ), "MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã›ã‚“"

        print(f"ğŸ‰ MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¤œè¨¼ãŒæˆåŠŸã—ã¾ã—ãŸï¼")


# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
@pytest.mark.skip(reason="MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯å®Ÿè£…ãŒä¸å®Œå…¨ã€‚å®Ÿè£…å®Œäº†å¾Œã«æœ‰åŠ¹åŒ–")
class TestMLTrainingPipeline:
    """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""

    def test_end_to_end_training_pipeline(self, sample_training_data):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ...")

        # 1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        print("  1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†...")
        processed_data = sample_training_data.copy()
        # æ¨™æº–åŒ–
        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns
        processed_data[numeric_cols] = (
            processed_data[numeric_cols] - processed_data[numeric_cols].mean()
        ) / processed_data[numeric_cols].std()

        # 2. ç‰¹å¾´é‡é¸æŠ
        print("  2. ç‰¹å¾´é‡é¸æŠ...")
        feature_cols = ["close", "volume", "rsi", "macd", "returns", "volatility"]
        features = processed_data[feature_cols]
        target = processed_data["target"]

        # 3. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        print("  3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²...")
        split_idx = int(len(features) * 0.8)
        X_train, X_test = features[:split_idx], features[split_idx:]
        y_train, y_test = target[:split_idx], target[split_idx:]

        # 4. ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        print("  4. ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°...")
        from sklearn.ensemble import RandomForestClassifier

        model = RandomForestClassifier(n_estimators=50, random_state=42)
        model.fit(X_train, y_train)

        # 5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        print("  5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡...")
        from sklearn.metrics import accuracy_score, f1_score

        train_pred = model.predict(X_train)
        test_pred = model.predict(X_test)

        train_accuracy = accuracy_score(y_train, train_pred)
        test_accuracy = accuracy_score(y_test, test_pred)
        test_f1 = f1_score(y_test, test_pred)

        # 6. çµæœæ¤œè¨¼
        print(f"    å­¦ç¿’ç²¾åº¦: {train_accuracy:.4f}")
        print(f"    ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.4f}")
        print(f"    F1ã‚¹ã‚³ã‚¢: {test_f1:.4f}")

        # éå­¦ç¿’ãŒèµ·ãã¦ã„ãªã„ã“ã¨
        assert abs(train_accuracy - test_accuracy) < 0.15, "éå­¦ç¿’ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™"
        assert test_f1 > 0.5, "ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒä¸ååˆ†ã§ã™"

        print("âœ… ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸ")

    def test_ml_training_robustness(self, sample_training_data):
        """MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ã‚’ãƒ†ã‚¹ãƒˆ...")

        robustness_tests = []

        # 1. æ¬ æå€¤ã«å¯¾ã™ã‚‹å …ç‰¢æ€§
        print("  1. æ¬ æå€¤ã«å¯¾ã™ã‚‹å …ç‰¢æ€§...")
        data_with_missing = sample_training_data.copy()
        data_with_missing.loc[::10, "close"] = np.nan  # 10%ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¬ æã«

        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(data_with_missing, save_model=False)
            robustness_tests.append(("æ¬ æå€¤å …ç‰¢æ€§", result["success"]))
        except Exception:
            robustness_tests.append(("æ¬ æå€¤å …ç‰¢æ€§", False))

        # 2. å¤–ã‚Œå€¤ã«å¯¾ã™ã‚‹å …ç‰¢æ€§
        print("  2. å¤–ã‚Œå€¤ã«å¯¾ã™ã‚‹å …ç‰¢æ€§...")
        data_with_outliers = sample_training_data.copy()
        data_with_outliers.loc[::20, "close"] *= 10  # 5%ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¤–ã‚Œå€¤ã«

        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(data_with_outliers, save_model=False)
            robustness_tests.append(("å¤–ã‚Œå€¤å …ç‰¢æ€§", result["success"]))
        except Exception:
            robustness_tests.append(("å¤–ã‚Œå€¤å …ç‰¢æ€§", False))

        # 3. ãƒã‚¤ã‚ºã«å¯¾ã™ã‚‹å …ç‰¢æ€§
        print("  3. ãƒã‚¤ã‚ºã«å¯¾ã™ã‚‹å …ç‰¢æ€§...")
        data_with_noise = sample_training_data.copy()
        data_with_noise["close"] += np.random.normal(0, 0.1, len(data_with_noise))

        try:
            service = MLTrainingService(
                trainer_type="single", single_model_type="lightgbm"
            )
            result = service.train_model(data_with_noise, save_model=False)
            robustness_tests.append(("ãƒã‚¤ã‚ºå …ç‰¢æ€§", result["success"]))
        except Exception:
            robustness_tests.append(("ãƒã‚¤ã‚ºå …ç‰¢æ€§", False))

        # çµæœã®è©•ä¾¡
        passed_robustness = sum(1 for _, passed in robustness_tests if passed)
        print(f"\nå …ç‰¢æ€§ãƒ†ã‚¹ãƒˆçµæœ: {passed_robustness}/{len(robustness_tests)} æˆåŠŸ")

        # å¤šãã®å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert (
            passed_robustness >= len(robustness_tests) * 0.6
        ), "MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ãŒä¸ååˆ†ã§ã™"

        print("âœ… MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ç¢ºèªæˆåŠŸ")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
