"""
MLã‚·ã‚¹ãƒ†ãƒ åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ - æ½œåœ¨çš„å•é¡Œã¨å …ç‰¢æ€§ã‚’æ¤œè¨¼
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import tempfile
import os
import gc
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from backend.app.services.ml.ml_training_service import MLTrainingService
from backend.app.services.auto_strategy.core.hybrid_predictor import HybridPredictor
from backend.app.services.ml.base_ml_trainer import BaseMLTrainer
from backend.app.services.ml.exceptions import MLPredictionError, MLModelError
from backend.app.services.ml.model_manager import model_manager


@pytest.mark.skip(reason="ã‚·ã‚¹ãƒ†ãƒ å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆã¯å®Ÿè£…ãŒä¸å®Œå…¨ã€‚å®Ÿè£…å®Œäº†å¾Œã«æœ‰åŠ¹åŒ–")
class TestMLSystemRobustness:
    """MLã‚·ã‚¹ãƒ†ãƒ ã®å …ç‰¢æ€§ã¨æ½œåœ¨çš„å•é¡Œã‚’æ¤œè¨¼"""

    @pytest.fixture
    def sample_training_data(self):
        """ã‚µãƒ³ãƒ—ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿"""
        np.random.seed(42)
        dates = pd.date_range(start="2023-01-01", end="2023-06-30", freq="D")

        data = pd.DataFrame(
            {
                "timestamp": dates,
                "Open": 10000 + np.random.randn(len(dates)) * 200,
                "High": 10000 + np.random.randn(len(dates)) * 300,
                "Low": 10000 + np.random.randn(len(dates)) * 300,
                "Close": 10000 + np.random.randn(len(dates)) * 200,
                "Volume": 500 + np.random.randint(100, 1000, len(dates)),
                "returns": np.random.randn(len(dates)) * 0.02,
                "volatility": 0.01 + np.random.rand(len(dates)) * 0.02,
                "rsi": 30 + np.random.rand(len(dates)) * 40,
                "macd": np.random.randn(len(dates)) * 0.01,
                "signal": np.random.randn(len(dates)) * 0.005,
                "histogram": np.random.randn(len(dates)) * 0.005,
            }
        )

        # OHLCã®é–¢ä¿‚ã‚’ç¢ºä¿
        data["High"] = data[["Open", "Close", "High"]].max(axis=1)
        data["Low"] = data[["Open", "Close", "Low"]].min(axis=1)

        # ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆï¼ˆä¸Šæ˜‡:1, ä¸‹é™:0ï¼‰
        data["target"] = (data["Close"].shift(-1) > data["Close"]).astype(int)

        return data.dropna()

    @pytest.fixture
    def hybrid_predictor(self):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬å™¨"""
        return HybridPredictor(
            trainer_type="single", model_type="lightgbm", use_time_series_cv=True
        )

    def test_hybrid_integration_with_edge_cases(
        self, sample_training_data, hybrid_predictor
    ):
        """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’å«ã‚€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’å«ã‚€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰çµ±åˆã‚’ãƒ†ã‚¹ãƒˆ...")

        # 1. ä¸æ­£ãªDRLé‡ã¿ã®ãƒ†ã‚¹ãƒˆ
        hybrid_predictor._drl_weight = 1.5  # ç¯„å›²å¤–ã®å€¤
        features_df = sample_training_data[["Close", "Volume", "rsi"]]

        try:
            prediction = hybrid_predictor.predict(features_df)
            assert isinstance(prediction, dict)
            assert "up" in prediction and "down" in prediction and "range" in prediction
            print("âœ… ç¯„å›²å¤–DRLé‡ã¿ã®è‡ªå‹•èª¿æ•´ãŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ ç¯„å›²å¤–DRLé‡ã¿ã§ã‚¨ãƒ©ãƒ¼: {e}")

        # 2. ãƒ¢ãƒ‡ãƒ«æœªå­¦ç¿’æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        hybrid_predictor.services[0].trainer.is_trained = False
        default_pred = hybrid_predictor.predict(features_df)
        assert default_pred == {"up": 0.33, "down": 0.33, "range": 0.34}
        print("âœ… ãƒ¢ãƒ‡ãƒ«æœªå­¦ç¿’æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬ãŒæˆåŠŸ")

        # 3. ç‰¹å¾´é‡ä¸è¶³æ™‚ã®äºˆæ¸¬
        incomplete_features = pd.DataFrame({"Close": [10000]})
        prediction = hybrid_predictor.predict(incomplete_features)
        assert isinstance(prediction, dict)
        assert sum(prediction.values()) == pytest.approx(1.0)
        print("âœ… ä¸å®Œå…¨ç‰¹å¾´é‡ã§ã®äºˆæ¸¬ãŒæˆåŠŸ")

    def test_data_pipeline_reliability(self, sample_training_data):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¿¡é ¼æ€§ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä¿¡é ¼æ€§ã‚’ãƒ†ã‚¹ãƒˆ...")

        # 1. æ™‚ç³»åˆ—åˆ†å‰²ã®æ•´åˆæ€§
        trainer = BaseMLTrainer()
        X = sample_training_data[["Close", "Volume", "rsi"]]
        y = sample_training_data["target"]

        X_train, X_test, y_train, y_test = trainer._split_data(
            X, y, use_time_series_split=True
        )

        # æ™‚é–“é †åºãŒä¿æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨
        assert len(X_train) + len(X_test) == len(X)
        assert X_train.index.max() < X_test.index.min()
        print("âœ… æ™‚ç³»åˆ—åˆ†å‰²ã®æ•´åˆæ€§ãŒç¢ºèª")

        # 2. ç‰¹å¾´é‡è¨ˆç®—ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            features = trainer._calculate_features(sample_training_data)
            assert isinstance(features, pd.DataFrame)
            assert len(features) == len(sample_training_data)
            print("âœ… ç‰¹å¾´é‡è¨ˆç®—ãŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾´é‡è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™ºå‹•ï¼‰: {e}")

        # 3. æ¬ æå€¤å‡¦ç†
        data_with_missing = sample_training_data.copy()
        data_with_missing.loc[::10, "Close"] = np.nan

        try:
            features_with_missing = trainer._calculate_features(data_with_missing)
            assert isinstance(features_with_missing, pd.DataFrame)
            print("âœ… æ¬ æå€¤å‡¦ç†ãŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ æ¬ æå€¤å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")

    def test_error_handling_comprehensive(self, sample_training_data):
        """åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ...")

        trainer = BaseMLTrainer()

        # 1. ç©ºãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’
        with pytest.raises(Exception):
            trainer.train_model(pd.DataFrame(), save_model=False)

        # 2. ä¸æ­£ãªã‚«ãƒ©ãƒ å
        invalid_data = sample_training_data.copy()
        invalid_data = invalid_data.rename(columns={"Close": "close"})  # å°æ–‡å­—ã«

        try:
            result = trainer.train_model(invalid_data, save_model=False)
            print("âœ… ä¸æ­£ã‚«ãƒ©ãƒ åã®å‡¦ç†ãŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ ä¸æ­£ã‚«ãƒ©ãƒ åã§ã‚¨ãƒ©ãƒ¼: {e}")

        # 3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        original_validate = trainer._validate_training_data

        def memory_error_validate(data):
            raise MemoryError("ãƒ¡ãƒ¢ãƒªä¸è¶³")

        trainer._validate_training_data = memory_error_validate

        try:
            trainer.train_model(sample_training_data, save_model=False)
        except MemoryError:
            print("âœ… ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã®é©åˆ‡ãªå‡¦ç†")
        finally:
            trainer._validate_training_data = original_validate

        # 4. ãƒ¢ãƒ‡ãƒ«ä¿å­˜å¤±æ•—
        original_save = trainer.save_model

        def failing_save(model_name, metadata=None):
            raise Exception("ä¿å­˜å¤±æ•—")

        trainer.save_model = failing_save

        try:
            result = trainer.train_model(sample_training_data, save_model=True)
            # å­¦ç¿’ã¯æˆåŠŸã™ã‚‹ãŒä¿å­˜ã¯å¤±æ•—
            assert result["success"] is True
            print("âœ… ä¿å­˜å¤±æ•—æ™‚ã®å­¦ç¿’ç¶™ç¶šãŒæˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¤±æ•—å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            trainer.save_model = original_save

    def test_performance_and_scalability(self, sample_training_data):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ãƒ†ã‚¹ãƒˆ...")

        # 1. å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        large_data = pd.concat([sample_training_data] * 10, ignore_index=True)

        trainer = BaseMLTrainer()
        start_time = time.time()

        result = trainer.train_model(large_data, save_model=False)
        elapsed = time.time() - start_time

        assert result["success"] is True
        assert elapsed < 300  # 5åˆ†ä»¥å†…
        print(f"âœ… å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒæˆåŠŸ - æ‰€è¦æ™‚é–“: {elapsed:.2f}ç§’")

        # 2. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º
        initial_objects = len(gc.get_objects())
        gc.collect()

        # è¤‡æ•°å›å­¦ç¿’ã‚’å®Ÿè¡Œ
        for i in range(3):
            trainer = BaseMLTrainer()
            trainer.train_model(sample_training_data, save_model=False)

        gc.collect()
        final_objects = len(gc.get_objects())
        growth = final_objects - initial_objects

        assert growth < 1000, f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å…†å€™ã‚ã‚Š: ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¢—åŠ æ•° {growth}"
        print(f"âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãªã— - ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¢—åŠ æ•°: {growth}")

        # 3. ä¸¦åˆ—å‡¦ç†ã®å …ç‰¢æ€§
        def train_model_thread(data_chunk):
            trainer = BaseMLTrainer()
            return trainer.train_model(data_chunk, save_model=False)

        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        chunks = np.array_split(sample_training_data, 3)

        start_time = time.time()
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(train_model_thread, chunk) for chunk in chunks]
            results = [future.result() for future in as_completed(futures)]

        elapsed = time.time() - start_time
        assert len(results) == 3
        assert all(result["success"] for result in results)
        print(f"âœ… ä¸¦åˆ—å‡¦ç†ãŒæˆåŠŸ - æ‰€è¦æ™‚é–“: {elapsed:.2f}ç§’")

    def test_model_cache_optimization(self, sample_training_data):
        """ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã‚’ãƒ†ã‚¹ãƒˆ...")

        trainer = BaseMLTrainer()

        # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        trainer._cleanup_cache(BaseCleanupLevel.STANDARD)
        print("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒæˆåŠŸ")

        # 2. ãƒ¢ãƒ‡ãƒ«å†åˆ©ç”¨
        trainer.train_model(sample_training_data, save_model=False)

        # åŒã˜ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã§å†åº¦å­¦ç¿’
        start_time = time.time()
        result2 = trainer.train_model(sample_training_data, save_model=False)
        elapsed2 = time.time() - start_time

        assert result2["success"] is True
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«å†åˆ©ç”¨ãŒæˆåŠŸ - å†å­¦ç¿’æ™‚é–“: {elapsed2:.2f}ç§’")

    def test_multimodal_prediction_consistency(self, sample_training_data):
        """ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®ä¸€è²«æ€§ã‚’ãƒ†ã‚¹ãƒˆ...")

        # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬å™¨
        multi_predictor = HybridPredictor(
            model_types=["lightgbm", "xgboost", "randomforest"], trainer_type="single"
        )

        features_df = sample_training_data[["Close", "Volume", "rsi"]]

        # ä¸€è²«æ€§ã®ã‚ã‚‹äºˆæ¸¬ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨
        predictions = []
        for _ in range(5):
            pred = multi_predictor.predict(features_df)
            predictions.append(pred)

        # äºˆæ¸¬çµæœãŒå®‰å®šã—ã¦ã„ã‚‹ã“ã¨
        up_std = np.std([p["up"] for p in predictions])
        down_std = np.std([p["down"] for p in predictions])
        range_std = np.std([p["range"] for p in predictions])

        assert up_std < 0.1, f"ä¸Šæ˜‡äºˆæ¸¬ã®ã°ã‚‰ã¤ããŒå¤§ãã„: {up_std:.4f}"
        assert down_std < 0.1, f"ä¸‹é™äºˆæ¸¬ã®ã°ã‚‰ã¤ããŒå¤§ãã„: {down_std:.4f}"
        assert range_std < 0.1, f"ãƒ¬ãƒ³ã‚¸äºˆæ¸¬ã®ã°ã‚‰ã¤ããŒå¤§ãã„: {range_std:.4f}"

        print("âœ… ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã®ä¸€è²«æ€§ãŒç¢ºèª")

    def test_drl_integration_edge_cases(self, sample_training_data):
        """DRLçµ±åˆã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” DRLçµ±åˆã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ...")

        # DRLç„¡åŠ¹æ™‚ã®ãƒ†ã‚¹ãƒˆ
        predictor_no_drl = HybridPredictor(automl_config={"drl": {"enabled": False}})

        features_df = sample_training_data[["Close", "Volume", "rsi"]]
        pred_no_drl = predictor_no_drl.predict(features_df)
        assert isinstance(pred_no_drl, dict)
        print("âœ… DRLç„¡åŠ¹æ™‚ã®äºˆæ¸¬ãŒæˆåŠŸ")

        # DRLé‡ã¿ãŒ0ã®ãƒ†ã‚¹ãƒˆ
        predictor_zero_weight = HybridPredictor(
            automl_config={"drl": {"enabled": True, "policy_weight": 0.0}}
        )

        pred_zero_weight = predictor_zero_weight.predict(features_df)
        assert isinstance(pred_zero_weight, dict)
        print("âœ… DRLé‡ã¿0æ™‚ã®äºˆæ¸¬ãŒæˆåŠŸ")

        # DRLäºˆæ¸¬å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        with patch.object(
            predictor_zero_weight.drl_policy_adapter,
            "predict_signals",
            side_effect=Exception("DRLäºˆæ¸¬å¤±æ•—"),
        ):
            pred_fallback = predictor_zero_weight.predict(features_df)
            assert isinstance(pred_fallback, dict)
            print("âœ… DRLäºˆæ¸¬å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæˆåŠŸ")

    def test_real_time_prediction_stability(self, sample_training_data):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã®å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã®å®‰å®šæ€§ã‚’ãƒ†ã‚¹ãƒˆ...")

        predictor = HybridPredictor()

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        stream_predictions = []
        for i in range(10):
            # å°ã•ãªãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯
            chunk = sample_training_data.iloc[i : i + 5][["Close", "Volume", "rsi"]]

            if len(chunk) == 5:  # ãƒ‡ãƒ¼ã‚¿ãŒååˆ†ãªå ´åˆã®ã¿
                pred = predictor.predict(chunk)
                stream_predictions.append(pred)

        # äºˆæ¸¬ãŒå®‰å®šã—ã¦ã„ã‚‹ã“ã¨
        if len(stream_predictions) > 1:
            up_values = [p["up"] for p in stream_predictions]
            stability = np.std(up_values) < 0.1
            print(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã®å®‰å®šæ€§: {'è‰¯å¥½' if stability else 'ä¸å®‰å®š'}")

    def test_model_drift_detection(self, sample_training_data):
        """ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‚’ãƒ†ã‚¹ãƒˆ...")

        trainer = BaseMLTrainer()
        trainer.train_model(sample_training_data, save_model=False)

        # ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã“ã¨
        if hasattr(trainer, "detect_model_drift"):
            try:
                drift_result = trainer.detect_model_drift(sample_training_data)
                assert isinstance(drift_result, dict)
                print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹")
            except Exception as e:
                print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("â„¹ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã¯æœªå®Ÿè£…")

    def test_final_system_validation(self, sample_training_data):
        """æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼"""
        print("\nğŸ æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã‚’å®Ÿè¡Œ...")

        validation_results = []

        # 1. åŸºæœ¬æ©Ÿèƒ½ã®æ¤œè¨¼
        try:
            trainer = BaseMLTrainer()
            result = trainer.train_model(sample_training_data, save_model=False)
            validation_results.append(("åŸºæœ¬å­¦ç¿’æ©Ÿèƒ½", result["success"]))
        except Exception as e:
            validation_results.append(("åŸºæœ¬å­¦ç¿’æ©Ÿèƒ½", False))

        # 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬ã®æ¤œè¨¼
        try:
            predictor = HybridPredictor()
            features = sample_training_data[["Close", "Volume", "rsi"]]
            prediction = predictor.predict(features)
            validation_results.append(("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬", True))
        except Exception as e:
            validation_results.append(("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰äºˆæ¸¬", False))

        # 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¤œè¨¼
        try:
            trainer = BaseMLTrainer()
            # æ„å›³çš„ã«ã‚¨ãƒ©ãƒ¼ã‚’èª˜ç™º
            trainer.train_model(pd.DataFrame(), save_model=False)
        except Exception:
            validation_results.append(("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", True))

        # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ¤œè¨¼
        try:
            start_time = time.time()
            trainer = BaseMLTrainer()
            result = trainer.train_model(sample_training_data, save_model=False)
            elapsed = time.time() - start_time
            validation_results.append(("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", elapsed < 60))  # 1åˆ†ä»¥å†…
        except Exception as e:
            validation_results.append(("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", False))

        # æ¤œè¨¼çµæœã®é›†è¨ˆ
        passed = sum(1 for _, passed in validation_results if passed)
        total = len(validation_results)

        print(f"\nğŸ“Š æœ€çµ‚æ¤œè¨¼çµæœ: {passed}/{total} ã®æ¤œè¨¼ãŒæˆåŠŸ")

        for test_name, passed in validation_results:
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {test_name}: {'æˆåŠŸ' if passed else 'å¤±æ•—'}")

        # å¤šæ•°ã®æ¤œè¨¼ãŒæˆåŠŸã—ã¦ã„ã‚‹ã“ã¨
        assert passed >= total * 0.75, "MLã‚·ã‚¹ãƒ†ãƒ ã«é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™"

        print(f"\nğŸ‰ MLã‚·ã‚¹ãƒ†ãƒ åŒ…æ‹¬çš„æ¤œè¨¼ãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("âœ¨ MLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã¯å …ç‰¢ã§ä¿¡é ¼æ€§ãŒã‚ã‚Šã¾ã™ï¼")


# BaseCleanupLevelã®å®šç¾©ï¼ˆå®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
class BaseCleanupLevel:
    STANDARD = "standard"
    THOROUGH = "thorough"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
