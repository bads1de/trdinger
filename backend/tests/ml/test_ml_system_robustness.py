"""
MLシステム包括的テスト - 潜在的問題と堅牢性を検証
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import tempfile
import os
import gc
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from backend.app.services.ml.ml_training_service import MLTrainingService
from backend.app.services.auto_strategy.core.hybrid_predictor import HybridPredictor
from backend.app.services.ml.base_ml_trainer import BaseMLTrainer
from backend.app.services.ml.exceptions import MLPredictionError, MLModelError
from backend.app.services.ml.model_manager import model_manager


class TestMLSystemRobustness:
    """MLシステムの堅牢性と潜在的問題を検証"""

    @pytest.fixture
    def sample_training_data(self):
        """サンプル学習データ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', end='2023-06-30', freq='D')

        data = pd.DataFrame({
            'timestamp': dates,
            'Open': 10000 + np.random.randn(len(dates)) * 200,
            'High': 10000 + np.random.randn(len(dates)) * 300,
            'Low': 10000 + np.random.randn(len(dates)) * 300,
            'Close': 10000 + np.random.randn(len(dates)) * 200,
            'Volume': 500 + np.random.randint(100, 1000, len(dates)),
            'returns': np.random.randn(len(dates)) * 0.02,
            'volatility': 0.01 + np.random.rand(len(dates)) * 0.02,
            'rsi': 30 + np.random.rand(len(dates)) * 40,
            'macd': np.random.randn(len(dates)) * 0.01,
            'signal': np.random.randn(len(dates)) * 0.005,
            'histogram': np.random.randn(len(dates)) * 0.005,
        })

        # OHLCの関係を確保
        data['High'] = data[['Open', 'Close', 'High']].max(axis=1)
        data['Low'] = data[['Open', 'Close', 'Low']].min(axis=1)

        # ラベルを生成（上昇:1, 下降:0）
        data['target'] = (data['Close'].shift(-1) > data['Close']).astype(int)

        return data.dropna()

    @pytest.fixture
    def hybrid_predictor(self):
        """ハイブリッド予測器"""
        return HybridPredictor(
            trainer_type="single",
            model_type="lightgbm",
            use_time_series_cv=True
        )

    def test_hybrid_integration_with_edge_cases(self, sample_training_data, hybrid_predictor):
        """エッジケースを含むハイブリッド統合テスト"""
        print("🔍 エッジケースを含むハイブリッド統合をテスト...")

        # 1. 不正なDRL重みのテスト
        hybrid_predictor._drl_weight = 1.5  # 範囲外の値
        features_df = sample_training_data[['Close', 'Volume', 'rsi']]

        try:
            prediction = hybrid_predictor.predict(features_df)
            assert isinstance(prediction, dict)
            assert 'up' in prediction and 'down' in prediction and 'range' in prediction
            print("✅ 範囲外DRL重みの自動調整が成功")
        except Exception as e:
            print(f"⚠️ 範囲外DRL重みでエラー: {e}")

        # 2. モデル未学習時のフォールバック
        hybrid_predictor.services[0].trainer.is_trained = False
        default_pred = hybrid_predictor.predict(features_df)
        assert default_pred == {"up": 0.33, "down": 0.33, "range": 0.34}
        print("✅ モデル未学習時のデフォルト予測が成功")

        # 3. 特徴量不足時の予測
        incomplete_features = pd.DataFrame({'Close': [10000]})
        prediction = hybrid_predictor.predict(incomplete_features)
        assert isinstance(prediction, dict)
        assert sum(prediction.values()) == pytest.approx(1.0)
        print("✅ 不完全特徴量での予測が成功")

    def test_data_pipeline_reliability(self, sample_training_data):
        """データパイプラインの信頼性テスト"""
        print("🔍 データパイプラインの信頼性をテスト...")

        # 1. 時系列分割の整合性
        trainer = BaseMLTrainer()
        X = sample_training_data[['Close', 'Volume', 'rsi']]
        y = sample_training_data['target']

        X_train, X_test, y_train, y_test = trainer._split_data(
            X, y, use_time_series_split=True
        )

        # 時間順序が保持されていること
        assert len(X_train) + len(X_test) == len(X)
        assert X_train.index.max() < X_test.index.min()
        print("✅ 時系列分割の整合性が確認")

        # 2. AutoML特徴量計算のフォールバック
        try:
            features = trainer._calculate_features(sample_training_data)
            assert isinstance(features, pd.DataFrame)
            assert len(features) == len(sample_training_data)
            print("✅ AutoML特徴量計算が成功")
        except Exception as e:
            print(f"⚠️ AutoML特徴量計算でエラー（フォールバック発動）: {e}")

        # 3. 欠損値処理
        data_with_missing = sample_training_data.copy()
        data_with_missing.loc[::10, 'Close'] = np.nan

        try:
            features_with_missing = trainer._calculate_features(data_with_missing)
            assert isinstance(features_with_missing, pd.DataFrame)
            print("✅ 欠損値処理が成功")
        except Exception as e:
            print(f"⚠️ 欠損値処理でエラー: {e}")

    def test_error_handling_comprehensive(self, sample_training_data):
        """包括的エラーハンドリングテスト"""
        print("🔍 包括的エラーハンドリングをテスト...")

        trainer = BaseMLTrainer()

        # 1. 空データでの学習
        with pytest.raises(Exception):
            trainer.train_model(pd.DataFrame(), save_model=False)

        # 2. 不正なカラム名
        invalid_data = sample_training_data.copy()
        invalid_data = invalid_data.rename(columns={'Close': 'close'})  # 小文字に

        try:
            result = trainer.train_model(invalid_data, save_model=False)
            print("✅ 不正カラム名の処理が成功")
        except Exception as e:
            print(f"⚠️ 不正カラム名でエラー: {e}")

        # 3. メモリ不足シミュレーション
        original_validate = trainer._validate_training_data

        def memory_error_validate(data):
            raise MemoryError("メモリ不足")

        trainer._validate_training_data = memory_error_validate

        try:
            trainer.train_model(sample_training_data, save_model=False)
        except MemoryError:
            print("✅ メモリ不足エラーの適切な処理")
        finally:
            trainer._validate_training_data = original_validate

        # 4. モデル保存失敗
        original_save = trainer.save_model

        def failing_save(model_name, metadata=None):
            raise Exception("保存失敗")

        trainer.save_model = failing_save

        try:
            result = trainer.train_model(sample_training_data, save_model=True)
            # 学習は成功するが保存は失敗
            assert result["success"] is True
            print("✅ 保存失敗時の学習継続が成功")
        except Exception as e:
            print(f"⚠️ 保存失敗処理でエラー: {e}")
        finally:
            trainer.save_model = original_save

    def test_performance_and_scalability(self, sample_training_data):
        """パフォーマンスとスケーラビリティテスト"""
        print("🔍 パフォーマンスとスケーラビリティをテスト...")

        # 1. 大規模データ処理
        large_data = pd.concat([sample_training_data] * 10, ignore_index=True)

        trainer = BaseMLTrainer()
        start_time = time.time()

        result = trainer.train_model(large_data, save_model=False)
        elapsed = time.time() - start_time

        assert result["success"] is True
        assert elapsed < 300  # 5分以内
        print(f"✅ 大規模データ処理が成功 - 所要時間: {elapsed:.2f}秒")

        # 2. メモリリーク検出
        initial_objects = len(gc.get_objects())
        gc.collect()

        # 複数回学習を実行
        for i in range(3):
            trainer = BaseMLTrainer()
            trainer.train_model(sample_training_data, save_model=False)

        gc.collect()
        final_objects = len(gc.get_objects())
        growth = final_objects - initial_objects

        assert growth < 1000, f"メモリリークの兆候あり: オブジェクト増加数 {growth}"
        print(f"✅ メモリリークなし - オブジェクト増加数: {growth}")

        # 3. 並列処理の堅牢性
        def train_model_thread(data_chunk):
            trainer = BaseMLTrainer()
            return trainer.train_model(data_chunk, save_model=False)

        # データを分割
        chunks = np.array_split(sample_training_data, 3)

        start_time = time.time()
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(train_model_thread, chunk) for chunk in chunks]
            results = [future.result() for future in as_completed(futures)]

        elapsed = time.time() - start_time
        assert len(results) == 3
        assert all(result["success"] for result in results)
        print(f"✅ 並列処理が成功 - 所要時間: {elapsed:.2f}秒")

    def test_model_cache_optimization(self, sample_training_data):
        """モデルキャッシュ最適化テスト"""
        print("🔍 モデルキャッシュ最適化をテスト...")

        trainer = BaseMLTrainer()

        # 1. キャッシュクリーンアップ
        trainer._cleanup_cache(BaseCleanupLevel.STANDARD)
        print("✅ キャッシュクリーンアップが成功")

        # 2. モデル再利用
        trainer.train_model(sample_training_data, save_model=False)

        # 同じトレーナーで再度学習
        start_time = time.time()
        result2 = trainer.train_model(sample_training_data, save_model=False)
        elapsed2 = time.time() - start_time

        assert result2["success"] is True
        print(f"✅ モデル再利用が成功 - 再学習時間: {elapsed2:.2f}秒")

    def test_multimodal_prediction_consistency(self, sample_training_data):
        """マルチモデル予測の一貫性テスト"""
        print("🔍 マルチモデル予測の一貫性をテスト...")

        # 複数モデルのハイブリッド予測器
        multi_predictor = HybridPredictor(
            model_types=["lightgbm", "xgboost", "randomforest"],
            trainer_type="single"
        )

        features_df = sample_training_data[['Close', 'Volume', 'rsi']]

        # 一貫性のある予測が得られること
        predictions = []
        for _ in range(5):
            pred = multi_predictor.predict(features_df)
            predictions.append(pred)

        # 予測結果が安定していること
        up_std = np.std([p['up'] for p in predictions])
        down_std = np.std([p['down'] for p in predictions])
        range_std = np.std([p['range'] for p in predictions])

        assert up_std < 0.1, f"上昇予測のばらつきが大きい: {up_std:.4f}"
        assert down_std < 0.1, f"下降予測のばらつきが大きい: {down_std:.4f}"
        assert range_std < 0.1, f"レンジ予測のばらつきが大きい: {range_std:.4f}"

        print("✅ マルチモデル予測の一貫性が確認")

    def test_drl_integration_edge_cases(self, sample_training_data):
        """DRL統合のエッジケーステスト"""
        print("🔍 DRL統合のエッジケースをテスト...")

        # DRL無効時のテスト
        predictor_no_drl = HybridPredictor(
            automl_config={"drl": {"enabled": False}}
        )

        features_df = sample_training_data[['Close', 'Volume', 'rsi']]
        pred_no_drl = predictor_no_drl.predict(features_df)
        assert isinstance(pred_no_drl, dict)
        print("✅ DRL無効時の予測が成功")

        # DRL重みが0のテスト
        predictor_zero_weight = HybridPredictor(
            automl_config={"drl": {"enabled": True, "policy_weight": 0.0}}
        )

        pred_zero_weight = predictor_zero_weight.predict(features_df)
        assert isinstance(pred_zero_weight, dict)
        print("✅ DRL重み0時の予測が成功")

        # DRL予測失敗時のフォールバック
        with patch.object(predictor_zero_weight.drl_policy_adapter, 'predict_signals',
                        side_effect=Exception("DRL予測失敗")):
            pred_fallback = predictor_zero_weight.predict(features_df)
            assert isinstance(pred_fallback, dict)
            print("✅ DRL予測失敗時のフォールバックが成功")

    def test_real_time_prediction_stability(self, sample_training_data):
        """リアルタイム予測の安定性テスト"""
        print("🔍 リアルタイム予測の安定性をテスト...")

        predictor = HybridPredictor()

        # リアルタイムデータストリームをシミュレート
        stream_predictions = []
        for i in range(10):
            # 小さなデータチャンク
            chunk = sample_training_data.iloc[i:i+5][['Close', 'Volume', 'rsi']]

            if len(chunk) == 5:  # データが十分な場合のみ
                pred = predictor.predict(chunk)
                stream_predictions.append(pred)

        # 予測が安定していること
        if len(stream_predictions) > 1:
            up_values = [p['up'] for p in stream_predictions]
            stability = np.std(up_values) < 0.1
            print(f"✅ リアルタイム予測の安定性: {'良好' if stability else '不安定'}")

    def test_model_drift_detection(self, sample_training_data):
        """モデルドリフト検出テスト"""
        print("🔍 モデルドリフト検出をテスト...")

        trainer = BaseMLTrainer()
        trainer.train_model(sample_training_data, save_model=False)

        # ドリフト検出が実装されていること
        if hasattr(trainer, 'detect_model_drift'):
            try:
                drift_result = trainer.detect_model_drift(sample_training_data)
                assert isinstance(drift_result, dict)
                print("✅ モデルドリフト検出が実装されている")
            except Exception as e:
                print(f"⚠️ モデルドリフト検出でエラー: {e}")
        else:
            print("ℹ️ モデルドリフト検出は未実装")

    def test_final_system_validation(self, sample_training_data):
        """最終システム検証"""
        print("\n🏁 最終システム検証を実行...")

        validation_results = []

        # 1. 基本機能の検証
        try:
            trainer = BaseMLTrainer()
            result = trainer.train_model(sample_training_data, save_model=False)
            validation_results.append(("基本学習機能", result["success"]))
        except Exception as e:
            validation_results.append(("基本学習機能", False))

        # 2. ハイブリッド予測の検証
        try:
            predictor = HybridPredictor()
            features = sample_training_data[['Close', 'Volume', 'rsi']]
            prediction = predictor.predict(features)
            validation_results.append(("ハイブリッド予測", True))
        except Exception as e:
            validation_results.append(("ハイブリッド予測", False))

        # 3. エラーハンドリングの検証
        try:
            trainer = BaseMLTrainer()
            # 意図的にエラーを誘発
            trainer.train_model(pd.DataFrame(), save_model=False)
        except Exception:
            validation_results.append(("エラーハンドリング", True))

        # 4. パフォーマンスの検証
        try:
            start_time = time.time()
            trainer = BaseMLTrainer()
            result = trainer.train_model(sample_training_data, save_model=False)
            elapsed = time.time() - start_time
            validation_results.append(("パフォーマンス", elapsed < 60))  # 1分以内
        except Exception as e:
            validation_results.append(("パフォーマンス", False))

        # 検証結果の集計
        passed = sum(1 for _, passed in validation_results if passed)
        total = len(validation_results)

        print(f"\n📊 最終検証結果: {passed}/{total} の検証が成功")

        for test_name, passed in validation_results:
            status = "✅" if passed else "❌"
            print(f"  {status} {test_name}: {'成功' if passed else '失敗'}")

        # 多数の検証が成功していること
        assert passed >= total * 0.75, "MLシステムに重大な問題があります"

        print(f"\n🎉 MLシステム包括的検証が成功しました！")
        print("✨ MLトレーニングと関連システムは堅牢で信頼性があります！")


# BaseCleanupLevelの定義（実際のコードに合わせて調整）
class BaseCleanupLevel:
    STANDARD = "standard"
    THOROUGH = "thorough"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])