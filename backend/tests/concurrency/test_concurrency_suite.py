"""
ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã€ç«¶åˆçŠ¶æ…‹ã€ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã€ãƒ‡ãƒ¼ã‚¿ã®ä¸æ•´åˆãªã©ã‚’æ¤œè¨¼ã—ã€
ä¸¦è¡Œå‡¦ç†ã«ãŠã‘ã‚‹æ½œåœ¨çš„ãªå•é¡Œã‚’ç™ºè¦‹ã—ã¾ã™ã€‚
"""

import logging
import os
import sys
import threading
import time
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
backend_path = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore")

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class ConcurrencyTestResult:
    """ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆçµæœ"""

    test_name: str
    component_name: str
    success: bool
    execution_time: float
    thread_count: int
    race_conditions_detected: int
    deadlocks_detected: int
    data_inconsistencies: int
    concurrency_score: float
    error_message: Optional[str] = None
    detailed_metrics: Optional[Dict[str, Any]] = None


class ConcurrencyTestSuite:
    """ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.results: List[ConcurrencyTestResult] = []
        self.shared_data = {}
        self.lock = threading.Lock()

    def create_concurrency_test_data(self, size: int = 500) -> pd.DataFrame:
        """ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range("2024-01-01", periods=size, freq="1H")

        # åŸºæœ¬çš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        base_price = 100
        price_changes = np.random.normal(0, 0.02, size)
        prices = [base_price]

        for change in price_changes[1:]:
            prices.append(prices[-1] * (1 + change))

        prices = np.array(prices)

        return pd.DataFrame(
            {
                "timestamp": dates,
                "Open": prices,
                "High": prices * (1 + np.abs(np.random.normal(0, 0.01, size))),
                "Low": prices * (1 - np.abs(np.random.normal(0, 0.01, size))),
                "Close": prices * (1 + np.random.normal(0, 0.005, size)),
                "Volume": np.random.lognormal(10, 1, size),
            }
        )

    def feature_engineering_worker(
        self, worker_id: int, data: pd.DataFrame
    ) -> Dict[str, Any]:
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from app.services.ml.feature_engineering.feature_engineering_service import (
                FeatureEngineeringService,
            )

            fe_service = FeatureEngineeringService()
            start_time = time.time()

            # ç‰¹å¾´é‡è¨ˆç®—
            result = fe_service.calculate_advanced_features(data)

            execution_time = time.time() - start_time

            # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã«çµæœã‚’ä¿å­˜ï¼ˆç«¶åˆçŠ¶æ…‹ã‚’ãƒ†ã‚¹ãƒˆï¼‰
            with self.lock:
                self.shared_data[f"worker_{worker_id}"] = {
                    "result_shape": result.shape,
                    "execution_time": execution_time,
                    "feature_count": len(result.columns),
                    "success": True,
                }

            return {
                "worker_id": worker_id,
                "success": True,
                "execution_time": execution_time,
                "result_shape": result.shape,
                "feature_count": len(result.columns),
            }

        except Exception as e:
            with self.lock:
                self.shared_data[f"worker_{worker_id}"] = {
                    "error": str(e),
                    "success": False,
                }

            return {
                "worker_id": worker_id,
                "success": False,
                "error": str(e),
            }

    def data_processing_worker(
        self, worker_id: int, data: pd.DataFrame
    ) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼"""
        try:
            from app.utils.data_processing import DataProcessor

            processor = DataProcessor()
            start_time = time.time()

            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            processed_data = processor.preprocess_features(
                data,
                imputation_strategy="median",
                scale_features=True,
                remove_outliers=True,
            )

            execution_time = time.time() - start_time

            # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã«çµæœã‚’ä¿å­˜
            with self.lock:
                self.shared_data[f"processor_{worker_id}"] = {
                    "result_shape": processed_data.shape,
                    "execution_time": execution_time,
                    "success": True,
                }

            return {
                "worker_id": worker_id,
                "success": True,
                "execution_time": execution_time,
                "result_shape": processed_data.shape,
            }

        except Exception as e:
            with self.lock:
                self.shared_data[f"processor_{worker_id}"] = {
                    "error": str(e),
                    "success": False,
                }

            return {
                "worker_id": worker_id,
                "success": False,
                "error": str(e),
            }

    def test_concurrent_feature_engineering(self):
        """ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        concurrency_score = 100.0
        race_conditions = 0
        deadlocks = 0
        data_inconsistencies = 0
        detailed_metrics = {}

        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            test_data = self.create_concurrency_test_data(300)
            thread_count = 4

            # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
            self.shared_data.clear()

            # ä¸¦è¡Œå®Ÿè¡Œ
            with ThreadPoolExecutor(max_workers=thread_count) as executor:
                # å„ã‚¹ãƒ¬ãƒƒãƒ‰ã§ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
                futures = [
                    executor.submit(self.feature_engineering_worker, i, test_data)
                    for i in range(thread_count)
                ]

                # çµæœã‚’åé›†
                results = []
                completed_count = 0
                timeout_count = 0

                for future in as_completed(futures, timeout=60):
                    try:
                        result = future.result(timeout=30)
                        results.append(result)
                        completed_count += 1
                    except Exception as e:
                        timeout_count += 1
                        logger.warning(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")

            # çµæœã®åˆ†æ
            successful_workers = [r for r in results if r.get("success", False)]
            failed_workers = [r for r in results if not r.get("success", False)]

            detailed_metrics["completed_workers"] = completed_count
            detailed_metrics["successful_workers"] = len(successful_workers)
            detailed_metrics["failed_workers"] = len(failed_workers)
            detailed_metrics["timeout_workers"] = timeout_count

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if len(successful_workers) > 1:
                # ç‰¹å¾´é‡æ•°ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
                feature_counts = [w["feature_count"] for w in successful_workers]
                if len(set(feature_counts)) > 1:
                    data_inconsistencies += 1
                    concurrency_score -= 20.0
                    logger.warning(f"âš ï¸ ç‰¹å¾´é‡æ•°ã®ä¸æ•´åˆ: {set(feature_counts)}")

                # å®Ÿè¡Œæ™‚é–“ã®åˆ†æ•£ãƒã‚§ãƒƒã‚¯
                execution_times = [w["execution_time"] for w in successful_workers]
                time_variance = np.var(execution_times)
                detailed_metrics["execution_time_variance"] = time_variance

                if time_variance > 100:  # å®Ÿè¡Œæ™‚é–“ã®åˆ†æ•£ãŒå¤§ãã„
                    race_conditions += 1
                    concurrency_score -= 15.0
                    logger.warning(f"âš ï¸ å®Ÿè¡Œæ™‚é–“ã®å¤§ããªåˆ†æ•£: {time_variance:.2f}")

            # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            shared_data_keys = list(self.shared_data.keys())
            expected_keys = [f"worker_{i}" for i in range(thread_count)]
            missing_keys = set(expected_keys) - set(shared_data_keys)

            if missing_keys:
                data_inconsistencies += len(missing_keys)
                concurrency_score -= 10.0 * len(missing_keys)
                logger.warning(f"âš ï¸ å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã®æ¬ æ: {missing_keys}")

            # å¤±æ•—ç‡ã®è©•ä¾¡
            failure_rate = len(failed_workers) / thread_count
            detailed_metrics["failure_rate"] = failure_rate

            if failure_rate > 0.25:  # 25%ä»¥ä¸Šã®å¤±æ•—ç‡
                concurrency_score -= 30.0
                logger.warning(f"âš ï¸ é«˜ã„å¤±æ•—ç‡: {failure_rate:.2f}")

            execution_time = time.time() - start_time

            self.results.append(
                ConcurrencyTestResult(
                    test_name="ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°",
                    component_name="FeatureEngineeringService",
                    success=concurrency_score > 70.0,
                    execution_time=execution_time,
                    thread_count=thread_count,
                    race_conditions_detected=race_conditions,
                    deadlocks_detected=deadlocks,
                    data_inconsistencies=data_inconsistencies,
                    concurrency_score=concurrency_score,
                    detailed_metrics=detailed_metrics,
                )
            )

            logger.info(
                f"âœ… ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†: ã‚¹ã‚³ã‚¢ {concurrency_score:.1f}%"
            )

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                ConcurrencyTestResult(
                    test_name="ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°",
                    component_name="FeatureEngineeringService",
                    success=False,
                    execution_time=execution_time,
                    thread_count=0,
                    race_conditions_detected=0,
                    deadlocks_detected=0,
                    data_inconsistencies=0,
                    concurrency_score=0.0,
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ ä¸¦è¡Œç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def test_concurrent_data_processing(self):
        """ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ”„ ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")

        start_time = time.time()
        concurrency_score = 100.0
        race_conditions = 0
        deadlocks = 0
        data_inconsistencies = 0
        detailed_metrics = {}

        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            test_data = self.create_concurrency_test_data(400)
            thread_count = 3

            # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
            self.shared_data.clear()

            # ä¸¦è¡Œå®Ÿè¡Œ
            with ThreadPoolExecutor(max_workers=thread_count) as executor:
                # å„ã‚¹ãƒ¬ãƒƒãƒ‰ã§ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œ
                futures = [
                    executor.submit(self.data_processing_worker, i, test_data)
                    for i in range(thread_count)
                ]

                # çµæœã‚’åé›†
                results = []
                for future in as_completed(futures, timeout=45):
                    try:
                        result = future.result(timeout=20)
                        results.append(result)
                    except Exception as e:
                        logger.warning(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")

            # çµæœã®åˆ†æ
            successful_workers = [r for r in results if r.get("success", False)]
            failed_workers = [r for r in results if not r.get("success", False)]

            detailed_metrics["successful_workers"] = len(successful_workers)
            detailed_metrics["failed_workers"] = len(failed_workers)

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if len(successful_workers) > 1:
                # çµæœã®å½¢çŠ¶ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
                result_shapes = [w["result_shape"] for w in successful_workers]
                unique_shapes = set(result_shapes)

                if len(unique_shapes) > 1:
                    data_inconsistencies += 1
                    concurrency_score -= 25.0
                    logger.warning(f"âš ï¸ å‡¦ç†çµæœã®å½¢çŠ¶ä¸æ•´åˆ: {unique_shapes}")

            # å¤±æ•—ç‡ã®è©•ä¾¡
            failure_rate = len(failed_workers) / thread_count
            detailed_metrics["failure_rate"] = failure_rate

            if failure_rate > 0.33:  # 33%ä»¥ä¸Šã®å¤±æ•—ç‡
                concurrency_score -= 35.0
                logger.warning(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®é«˜ã„å¤±æ•—ç‡: {failure_rate:.2f}")

            execution_time = time.time() - start_time

            self.results.append(
                ConcurrencyTestResult(
                    test_name="ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†",
                    component_name="DataProcessor",
                    success=concurrency_score > 70.0,
                    execution_time=execution_time,
                    thread_count=thread_count,
                    race_conditions_detected=race_conditions,
                    deadlocks_detected=deadlocks,
                    data_inconsistencies=data_inconsistencies,
                    concurrency_score=concurrency_score,
                    detailed_metrics=detailed_metrics,
                )
            )

            logger.info(f"âœ… ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆå®Œäº†: ã‚¹ã‚³ã‚¢ {concurrency_score:.1f}%")

        except Exception as e:
            execution_time = time.time() - start_time

            self.results.append(
                ConcurrencyTestResult(
                    test_name="ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†",
                    component_name="DataProcessor",
                    success=False,
                    execution_time=execution_time,
                    thread_count=0,
                    race_conditions_detected=0,
                    deadlocks_detected=0,
                    data_inconsistencies=0,
                    concurrency_score=0.0,
                    error_message=str(e),
                )
            )

            logger.error(f"âŒ ä¸¦è¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    def run_all_tests(self):
        """ã™ã¹ã¦ã®ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        logger.info("ğŸš€ ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")

        self.test_concurrent_feature_engineering()
        self.test_concurrent_data_processing()

        # çµæœã®é›†è¨ˆ
        total_tests = len(self.results)
        successful_tests = sum(1 for result in self.results if result.success)
        total_execution_time = sum(result.execution_time for result in self.results)
        total_threads = sum(result.thread_count for result in self.results)
        total_race_conditions = sum(
            result.race_conditions_detected for result in self.results
        )
        total_deadlocks = sum(result.deadlocks_detected for result in self.results)
        total_data_inconsistencies = sum(
            result.data_inconsistencies for result in self.results
        )
        average_concurrency = (
            sum(result.concurrency_score for result in self.results) / total_tests
            if total_tests > 0
            else 0
        )

        logger.info("=" * 80)
        logger.info("ğŸ”„ ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆçµæœ")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        logger.info(f"âœ… æˆåŠŸ: {successful_tests}")
        logger.info(f"âŒ å¤±æ•—: {total_tests - successful_tests}")
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {successful_tests / total_tests * 100:.1f}%")
        logger.info(f"ğŸ¯ å¹³å‡ä¸¦è¡Œæ€§ã‚¹ã‚³ã‚¢: {average_concurrency:.1f}%")
        logger.info(f"ğŸ§µ ç·ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {total_threads}")
        logger.info(f"âš ï¸ ç«¶åˆçŠ¶æ…‹æ¤œå‡º: {total_race_conditions}ä»¶")
        logger.info(f"ğŸ”’ ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯æ¤œå‡º: {total_deadlocks}ä»¶")
        logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ: {total_data_inconsistencies}ä»¶")
        logger.info(f"â±ï¸ ç·å®Ÿè¡Œæ™‚é–“: {total_execution_time:.2f}ç§’")

        logger.info("\nğŸ”„ ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆè©³ç´°:")
        for result in self.results:
            status = "âœ…" if result.success else "âŒ"

            logger.info(f"{status} {result.test_name}")
            logger.info(f"   ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {result.component_name}")
            logger.info(f"   å®Ÿè¡Œæ™‚é–“: {result.execution_time:.2f}ç§’")
            logger.info(f"   ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {result.thread_count}")
            logger.info(f"   ä¸¦è¡Œæ€§ã‚¹ã‚³ã‚¢: {result.concurrency_score:.1f}%")
            logger.info(f"   ç«¶åˆçŠ¶æ…‹: {result.race_conditions_detected}ä»¶")
            logger.info(f"   ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯: {result.deadlocks_detected}ä»¶")
            logger.info(f"   ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ: {result.data_inconsistencies}ä»¶")

            if result.detailed_metrics:
                logger.info("   è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
                for key, value in result.detailed_metrics.items():
                    if isinstance(value, float):
                        logger.info(f"     {key}: {value:.3f}")
                    else:
                        logger.info(f"     {key}: {value}")

            if result.error_message:
                logger.info(f"   ã‚¨ãƒ©ãƒ¼: {result.error_message[:100]}...")

        # ä¸¦è¡Œæ€§ã®ç·åˆè©•ä¾¡
        if (
            total_race_conditions == 0
            and total_deadlocks == 0
            and total_data_inconsistencies == 0
        ):
            logger.info("\nğŸ‰ ä¸¦è¡Œæ€§ã«é–¢ã™ã‚‹å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
        else:
            logger.warning("\nâš ï¸ ä¸¦è¡Œæ€§ã«é–¢ã™ã‚‹å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
            if total_race_conditions > 0:
                logger.warning(f"   - ç«¶åˆçŠ¶æ…‹: {total_race_conditions}ä»¶")
            if total_deadlocks > 0:
                logger.warning(f"   - ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯: {total_deadlocks}ä»¶")
            if total_data_inconsistencies > 0:
                logger.warning(f"   - ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ: {total_data_inconsistencies}ä»¶")

        logger.info("=" * 80)
        logger.info("ğŸ¯ ä¸¦è¡Œæ€§ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Œäº†")

        return self.results


if __name__ == "__main__":
    suite = ConcurrencyTestSuite()
    results = suite.run_all_tests()
