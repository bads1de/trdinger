"""
MLãƒ¬ãƒãƒ¼ãƒˆå•é¡Œä¿®æ­£ã®ãƒ†ã‚¹ãƒˆ

ãƒ¬ãƒãƒ¼ãƒˆã§ç‰¹å®šã•ã‚ŒãŸå•é¡Œç‚¹ã®ä¿®æ­£ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pytest
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)


class TestMLIssuesFixes:
    """MLå•é¡Œä¿®æ­£ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®æº–å‚™"""
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        self.test_data = self.create_test_data()
    
    def create_test_data(self, size: int = 1000) -> pd.DataFrame:
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=size, freq='H')
        
        # åŸºæœ¬ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        close_prices = 50000 + np.cumsum(np.random.randn(size) * 100)
        
        data = pd.DataFrame({
            'timestamp': dates,
            'Open': close_prices + np.random.randn(size) * 50,
            'High': close_prices + np.abs(np.random.randn(size)) * 100,
            'Low': close_prices - np.abs(np.random.randn(size)) * 100,
            'Close': close_prices,
            'Volume': np.random.exponential(1000, size),
        })
        
        data.set_index('timestamp', inplace=True)
        return data
    
    def test_fear_greed_service_import_fix(self):
        """Fear & Greed ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¿®æ­£ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” Fear & Greed ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            # ä¿®æ­£ã•ã‚ŒãŸã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚¹ãƒˆ
            from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
            
            service = FeatureEngineeringService()
            
            # Fear & Greed ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ
            fear_greed_data = service._get_fear_greed_data(self.test_data)
            
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªãã¦ã‚‚OKï¼‰
            assert fear_greed_data is None or isinstance(fear_greed_data, pd.DataFrame)
            
            logger.info("âœ… Fear & Greed ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¿®æ­£æˆåŠŸ")
            
        except ImportError as e:
            pytest.fail(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ãŒä¿®æ­£ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
        except Exception as e:
            logger.warning(f"ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ï¼ˆè¨±å®¹ç¯„å›²ï¼‰: {e}")
    
    def test_missing_features_generation(self):
        """ä¸è¶³ç‰¹å¾´é‡ã®ç–‘ä¼¼ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” ä¸è¶³ç‰¹å¾´é‡ç–‘ä¼¼ç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
            
            service = FeatureEngineeringService()
            
            # ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆç–‘ä¼¼ç‰¹å¾´é‡ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            lookback_periods = {"short": 24, "medium": 168, "long": 720}
            result_df = service._generate_pseudo_funding_rate_features(self.test_data, lookback_periods)
            
            # å¿…è¦ãªç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            expected_fr_features = [
                "FR_MA_24", "FR_MA_168", "FR_Change", "FR_Change_Rate",
                "Price_FR_Divergence", "FR_Normalized", "FR_Trend", "FR_Volatility"
            ]
            
            for feature in expected_fr_features:
                assert feature in result_df.columns, f"FRç‰¹å¾´é‡ {feature} ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # å»ºç‰æ®‹é«˜ç–‘ä¼¼ç‰¹å¾´é‡ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            result_df = service._generate_pseudo_open_interest_features(result_df, lookback_periods)
            
            expected_oi_features = [
                "OI_Change_Rate", "OI_Change_Rate_24h", "OI_Surge", "Volatility_Adjusted_OI",
                "OI_MA_24", "OI_MA_168", "OI_Trend", "OI_Price_Correlation", "OI_Normalized"
            ]
            
            for feature in expected_oi_features:
                assert feature in result_df.columns, f"OIç‰¹å¾´é‡ {feature} ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # NaNå€¤ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            for feature in expected_fr_features + expected_oi_features:
                nan_count = result_df[feature].isna().sum()
                total_count = len(result_df)
                nan_ratio = nan_count / total_count
                assert nan_ratio < 0.1, f"ç‰¹å¾´é‡ {feature} ã®NaNç‡ãŒé«˜ã™ãã¾ã™: {nan_ratio:.2%}"
            
            logger.info("âœ… ä¸è¶³ç‰¹å¾´é‡ç–‘ä¼¼ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"ä¸è¶³ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_outlier_removal_optimization(self):
        """å¤–ã‚Œå€¤é™¤å»æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” å¤–ã‚Œå€¤é™¤å»æœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.utils.data_processing import DataProcessor
            
            processor = DataProcessor()
            
            # å¤–ã‚Œå€¤ã‚’å«ã‚€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            test_data = self.test_data.copy()
            
            # æ„å›³çš„ã«å¤–ã‚Œå€¤ã‚’è¿½åŠ 
            outlier_indices = np.random.choice(len(test_data), size=50, replace=False)
            test_data.iloc[outlier_indices, test_data.columns.get_loc('Close')] *= 10
            
            # å‡¦ç†æ™‚é–“ã‚’æ¸¬å®š
            start_time = time.time()
            
            # æœ€é©åŒ–ã•ã‚ŒãŸå¤–ã‚Œå€¤é™¤å»ã‚’å®Ÿè¡Œ
            cleaned_data = processor._remove_outliers(
                test_data,
                columns=['Open', 'High', 'Low', 'Close', 'Volume'],
                threshold=3.0,
                method='iqr'
            )
            
            processing_time = time.time() - start_time
            
            # å‡¦ç†æ™‚é–“ãŒæ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆåŸºæº–å€¤ã¯ç’°å¢ƒä¾å­˜ï¼‰
            assert processing_time < 5.0, f"å¤–ã‚Œå€¤é™¤å»å‡¦ç†æ™‚é–“ãŒé•·ã™ãã¾ã™: {processing_time:.2f}ç§’"
            
            # å¤–ã‚Œå€¤ãŒé©åˆ‡ã«é™¤å»ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            original_outliers = (test_data['Close'] > test_data['Close'].quantile(0.99)).sum()
            remaining_outliers = (cleaned_data['Close'] > cleaned_data['Close'].quantile(0.99)).sum()
            
            # å¤–ã‚Œå€¤ãŒæ¸›å°‘ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert remaining_outliers <= original_outliers, "å¤–ã‚Œå€¤é™¤å»ãŒæ©Ÿèƒ½ã—ã¦ã„ã¾ã›ã‚“"
            
            logger.info(f"âœ… å¤–ã‚Œå€¤é™¤å»æœ€é©åŒ–æˆåŠŸ: {processing_time:.3f}ç§’")
            
        except Exception as e:
            pytest.fail(f"å¤–ã‚Œå€¤é™¤å»æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_tsfresh_feature_expansion(self):
        """TSFreshç‰¹å¾´é‡æ‹¡å……ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” TSFreshç‰¹å¾´é‡æ‹¡å……ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.feature_engineering.automl_features.automl_config import TSFreshConfig
            
            # è¨­å®šãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            config = TSFreshConfig()
            
            assert config.fdr_level == 0.1, f"FDRé–¾å€¤ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“: {config.fdr_level}"
            assert config.feature_count_limit == 200, f"ç‰¹å¾´é‡æ•°åˆ¶é™ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“: {config.feature_count_limit}"
            assert config.performance_mode == "comprehensive", f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“: {config.performance_mode}"
            
            logger.info("âœ… TSFreshè¨­å®šæ›´æ–°ç¢ºèªæˆåŠŸ")
            
        except Exception as e:
            pytest.fail(f"TSFreshè¨­å®šç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_market_regime_detection(self):
        """å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.adaptive_learning.market_regime_detector import MarketRegimeDetector, MarketRegime
            
            detector = MarketRegimeDetector()
            
            # ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºã‚’å®Ÿè¡Œ
            result = detector.detect_regime(self.test_data)
            
            # çµæœã®æ¤œè¨¼
            assert isinstance(result.regime, MarketRegime), "ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºçµæœãŒç„¡åŠ¹ã§ã™"
            assert 0 <= result.confidence <= 1, f"ä¿¡é ¼åº¦ãŒç¯„å›²å¤–ã§ã™: {result.confidence}"
            assert isinstance(result.indicators, dict), "æŒ‡æ¨™è¾æ›¸ãŒç„¡åŠ¹ã§ã™"
            assert isinstance(result.timestamp, datetime), "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒç„¡åŠ¹ã§ã™"
            
            # æŒ‡æ¨™ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            expected_indicators = ['trend_strength', 'volatility', 'rsi', 'volume_ratio']
            for indicator in expected_indicators:
                assert indicator in result.indicators, f"æŒ‡æ¨™ {indicator} ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            
            logger.info(f"âœ… å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºæˆåŠŸ: {result.regime.value} (ä¿¡é ¼åº¦: {result.confidence:.2f})")
            
        except Exception as e:
            pytest.fail(f"å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_adaptive_learning_service(self):
        """é©å¿œçš„å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” é©å¿œçš„å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.adaptive_learning.adaptive_learning_service import AdaptiveLearningService
            
            service = AdaptiveLearningService()
            
            # é©å¿œå‡¦ç†ã‚’å®Ÿè¡Œ
            current_performance = {'accuracy': 0.65, 'precision': 0.62, 'recall': 0.68}
            result = service.adapt_to_market_changes(self.test_data, current_performance)
            
            # çµæœã®æ¤œè¨¼
            assert result is not None, "é©å¿œçµæœãŒå–å¾—ã§ãã¾ã›ã‚“"
            assert hasattr(result, 'action_taken'), "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            assert hasattr(result, 'regime_detected'), "ãƒ¬ã‚¸ãƒ¼ãƒ æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            assert hasattr(result, 'confidence'), "ä¿¡é ¼åº¦æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            assert hasattr(result, 'model_updated'), "ãƒ¢ãƒ‡ãƒ«æ›´æ–°æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            
            # è¦ç´„æƒ…å ±ã‚’å–å¾—
            summary = service.get_adaptation_summary()
            assert isinstance(summary, dict), "è¦ç´„æƒ…å ±ãŒç„¡åŠ¹ã§ã™"
            assert 'current_regime' in summary, "ç¾åœ¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
            
            logger.info(f"âœ… é©å¿œçš„å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹æˆåŠŸ: {result.action_taken}")
            
        except Exception as e:
            pytest.fail(f"é©å¿œçš„å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_comprehensive_integration(self):
        """åŒ…æ‹¬çš„çµ±åˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ğŸ” åŒ…æ‹¬çš„çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        try:
            from app.services.ml.feature_engineering.feature_engineering_service import FeatureEngineeringService
            
            service = FeatureEngineeringService()
            
            # çµ±åˆçš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
            # ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã§ã‚‚ç–‘ä¼¼ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
            result_df = service.calculate_advanced_features(
                ohlcv_data=self.test_data,
                funding_rate_data=None,  # æ„å›³çš„ã«Noneã‚’æ¸¡ã™
                open_interest_data=None,  # æ„å›³çš„ã«Noneã‚’æ¸¡ã™
                fear_greed_data=None,    # æ„å›³çš„ã«Noneã‚’æ¸¡ã™
                lookback_periods={"short": 24, "medium": 168, "long": 720}
            )
            
            # åŸºæœ¬çš„ãªç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(result_df.columns) > len(self.test_data.columns), "ç‰¹å¾´é‡ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # ç–‘ä¼¼ç‰¹å¾´é‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            pseudo_features = ['FR_Normalized', 'OI_Change_Rate', 'OI_Trend']
            for feature in pseudo_features:
                assert feature in result_df.columns, f"ç–‘ä¼¼ç‰¹å¾´é‡ {feature} ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ç¢ºèª
            total_nan_ratio = result_df.isna().sum().sum() / (len(result_df) * len(result_df.columns))
            assert total_nan_ratio < 0.1, f"NaNç‡ãŒé«˜ã™ãã¾ã™: {total_nan_ratio:.2%}"
            
            logger.info(f"âœ… åŒ…æ‹¬çš„çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ: {len(result_df.columns)}å€‹ã®ç‰¹å¾´é‡ç”Ÿæˆ")
            
        except Exception as e:
            pytest.fail(f"åŒ…æ‹¬çš„çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_instance = TestMLIssuesFixes()
    test_instance.setup_method()
    
    # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    tests = [
        test_instance.test_fear_greed_service_import_fix,
        test_instance.test_missing_features_generation,
        test_instance.test_outlier_removal_optimization,
        test_instance.test_tsfresh_feature_expansion,
        test_instance.test_market_regime_detection,
        test_instance.test_adaptive_learning_service,
        test_instance.test_comprehensive_integration,
    ]
    
    passed = 0
    failed = 0
    
    for test in tests:
        try:
            test()
            passed += 1
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test.__name__}: {e}")
            failed += 1
    
    print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ: æˆåŠŸ {passed}, å¤±æ•— {failed}")
    print(f"æˆåŠŸç‡: {passed / (passed + failed) * 100:.1f}%")
