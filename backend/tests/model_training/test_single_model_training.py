"""
å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿèƒ½ã‚’ã‚ªãƒ•ã«ã—ã¦å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒ
æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚
"""

import pytest
import pandas as pd
import numpy as np
import logging
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.ml.single_model.single_model_trainer import SingleModelTrainer
from app.services.ml.ml_training_service import MLTrainingService

logger = logging.getLogger(__name__)


class TestSingleModelTraining:
    """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def generate_test_data(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        np.random.seed(42)
        n_samples = 200
        
        # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        features = pd.DataFrame({
            'feature1': np.random.normal(0, 1, n_samples),
            'feature2': np.random.normal(0, 1, n_samples),
            'feature3': np.random.normal(0, 1, n_samples),
            'feature4': np.random.normal(0, 1, n_samples),
            'feature5': np.random.normal(0, 1, n_samples),
        })
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆ3ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
        target = np.random.choice([0, 1, 2], size=n_samples, p=[0.3, 0.4, 0.3])
        target = pd.Series(target)
        
        return features, target

    def test_single_model_trainer_initialization(self):
        """SingleModelTrainerã®åˆæœŸåŒ–ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== SingleModelTraineråˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ ===")
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        available_models = SingleModelTrainer.get_available_models()
        logger.info(f"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {available_models}")
        
        assert len(available_models) > 0, "åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        # å„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§åˆæœŸåŒ–ã‚’ãƒ†ã‚¹ãƒˆ
        for model_type in available_models:
            try:
                trainer = SingleModelTrainer(model_type=model_type)
                assert trainer.model_type == model_type
                logger.info(f"âœ… {model_type.upper()}ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ {model_type.upper()}ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–å¤±æ•—: {e}")
                raise
        
        return available_models

    def test_single_model_training(self):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        X, y = self.generate_test_data()
        
        # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        split_idx = int(len(X) * 0.8)
        X_train = X[:split_idx]
        X_test = X[split_idx:]
        y_train = y[:split_idx]
        y_test = y[split_idx:]
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        available_models = SingleModelTrainer.get_available_models()
        
        # æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
        if available_models:
            model_type = available_models[0]
            logger.info(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ãƒ‡ãƒ«: {model_type.upper()}")
            
            try:
                # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–
                trainer = SingleModelTrainer(model_type=model_type)
                
                # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
                result = trainer._train_model_impl(X_train, X_test, y_train, y_test)
                
                # çµæœã‚’æ¤œè¨¼
                assert "model_type" in result
                assert result["model_type"] == model_type
                assert "training_samples" in result
                assert result["training_samples"] == len(X_train)
                assert "test_samples" in result
                assert result["test_samples"] == len(X_test)
                
                logger.info(f"âœ… {model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆåŠŸ")
                logger.info(f"   - è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {result['training_samples']}")
                logger.info(f"   - ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {result['test_samples']}")
                logger.info(f"   - ç‰¹å¾´é‡æ•°: {result['feature_count']}")
                
                # äºˆæ¸¬ã‚’ãƒ†ã‚¹ãƒˆ
                predictions = trainer.predict(X_test)
                assert predictions.shape == (len(X_test), 3), f"äºˆæ¸¬å½¢çŠ¶ãŒä¸æ­£: {predictions.shape}"
                
                # äºˆæ¸¬ç¢ºç‡ã®åˆè¨ˆãŒ1ã«è¿‘ã„ã“ã¨ã‚’ç¢ºèª
                prob_sums = np.sum(predictions, axis=1)
                assert np.allclose(prob_sums, 1.0, atol=1e-6), "äºˆæ¸¬ç¢ºç‡ã®åˆè¨ˆãŒ1ã«ãªã£ã¦ã„ã¾ã›ã‚“"
                
                logger.info(f"âœ… {model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æˆåŠŸ")
                
                return result
                
            except Exception as e:
                logger.error(f"âŒ {model_type.upper()}ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—: {e}")
                raise
        else:
            pytest.skip("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

    def test_ml_training_service_single_mode(self):
        """MLTrainingServiceã§ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ¢ãƒ¼ãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== MLTrainingServiceå˜ä¸€ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ ===")
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        available_models = MLTrainingService.get_available_single_models()
        logger.info(f"MLTrainingServiceåˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {available_models}")
        
        if available_models:
            model_type = available_models[0]
            
            # å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š
            single_model_config = {"model_type": model_type}
            
            try:
                # MLTrainingServiceã‚’å˜ä¸€ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–
                ml_service = MLTrainingService(
                    trainer_type="single",
                    single_model_config=single_model_config
                )
                
                assert ml_service.trainer_type == "single"
                assert isinstance(ml_service.trainer, SingleModelTrainer)
                assert ml_service.trainer.model_type == model_type
                
                logger.info(f"âœ… MLTrainingServiceå˜ä¸€ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–æˆåŠŸ: {model_type.upper()}")
                
                return ml_service
                
            except Exception as e:
                logger.error(f"âŒ MLTrainingServiceå˜ä¸€ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–å¤±æ•—: {e}")
                raise
        else:
            pytest.skip("åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

    def test_trainer_type_determination(self):
        """ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•æ±ºå®šã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—è‡ªå‹•æ±ºå®šãƒ†ã‚¹ãƒˆ ===")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ‰åŠ¹ã®å ´åˆ
        ensemble_config_enabled = {"enabled": True}
        trainer_type = MLTrainingService.determine_trainer_type(ensemble_config_enabled)
        assert trainer_type == "ensemble", f"æœŸå¾…å€¤: ensemble, å®Ÿéš›: {trainer_type}"
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ‰åŠ¹æ™‚: ensembleãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼é¸æŠ")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹ã®å ´åˆ
        ensemble_config_disabled = {"enabled": False}
        trainer_type = MLTrainingService.determine_trainer_type(ensemble_config_disabled)
        assert trainer_type == "single", f"æœŸå¾…å€¤: single, å®Ÿéš›: {trainer_type}"
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹æ™‚: singleãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼é¸æŠ")
        
        # è¨­å®šãªã—ã®å ´åˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        trainer_type = MLTrainingService.determine_trainer_type(None)
        assert trainer_type == "ensemble", f"æœŸå¾…å€¤: ensemble, å®Ÿéš›: {trainer_type}"
        logger.info("âœ… è¨­å®šãªã—æ™‚: ensembleãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")

    def test_model_info_and_compatibility(self):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨äº’æ›æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»äº’æ›æ€§ãƒ†ã‚¹ãƒˆ ===")
        
        available_models = SingleModelTrainer.get_available_models()
        
        if available_models:
            model_type = available_models[0]
            
            # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–
            trainer = SingleModelTrainer(model_type=model_type)
            
            # åˆæœŸçŠ¶æ…‹ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç¢ºèª
            info = trainer.get_model_info()
            assert info["model_type"] == model_type
            assert info["is_trained"] == False
            assert info["trainer_type"] == "single_model"
            
            logger.info(f"âœ… åˆæœŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª: {info}")
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            X, y = self.generate_test_data()
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            trainer._train_model_impl(X_train, X_test, y_train, y_test)
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç¢ºèª
            info_after = trainer.get_model_info()
            assert info_after["is_trained"] == True
            assert info_after["feature_count"] == len(X.columns)
            
            logger.info(f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œãƒ¢ãƒ‡ãƒ«æƒ…å ±ç¢ºèª: {info_after}")

    def test_overall_single_model_functionality(self):
        """å…¨ä½“çš„ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å…¨ä½“çš„ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
        
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        available_models = self.test_single_model_trainer_initialization()
        training_result = self.test_single_model_training()
        ml_service = self.test_ml_training_service_single_mode()
        self.test_trainer_type_determination()
        self.test_model_info_and_compatibility()
        
        # ç·åˆè©•ä¾¡
        functionality_score = 0
        
        # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°ï¼ˆæœ€å¤§20ç‚¹ï¼‰
        if len(available_models) >= 3:
            functionality_score += 20
        elif len(available_models) >= 2:
            functionality_score += 15
        elif len(available_models) >= 1:
            functionality_score += 10
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆåŠŸï¼ˆæœ€å¤§30ç‚¹ï¼‰
        if training_result and "model_type" in training_result:
            functionality_score += 30
        
        # MLTrainingServiceçµ±åˆï¼ˆæœ€å¤§25ç‚¹ï¼‰
        if ml_service and ml_service.trainer_type == "single":
            functionality_score += 25
        
        # è‡ªå‹•æ±ºå®šæ©Ÿèƒ½ï¼ˆæœ€å¤§15ç‚¹ï¼‰
        functionality_score += 15  # test_trainer_type_determinationãŒæˆåŠŸã—ãŸå ´åˆ
        
        # äº’æ›æ€§ï¼ˆæœ€å¤§10ç‚¹ï¼‰
        functionality_score += 10  # test_model_info_and_compatibilityãŒæˆåŠŸã—ãŸå ´åˆ
        
        logger.info(f"å˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ã‚¹ã‚³ã‚¢: {functionality_score}/100")
        
        if functionality_score >= 90:
            logger.info("ğŸ‰ å„ªç§€ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif functionality_score >= 70:
            logger.info("âœ… è‰¯å¥½ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif functionality_score >= 50:
            logger.info("âš ï¸ åŸºæœ¬çš„ãªå˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        else:
            logger.warning("âŒ å˜ä¸€ãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        
        return {
            'functionality_score': functionality_score,
            'available_models': available_models,
            'training_result': training_result,
            'ml_service_initialized': ml_service is not None
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
    import logging
    logging.basicConfig(level=logging.INFO)
    
    test_instance = TestSingleModelTraining()
    
    # å…¨ä½“çš„ãªæ©Ÿèƒ½ã‚’æ¤œè¨¼
    results = test_instance.test_overall_single_model_functionality()
    
    print(f"\n=== å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµæœ ===")
    print(f"æ©Ÿèƒ½ã‚¹ã‚³ã‚¢: {results['functionality_score']}/100")
    print(f"åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {len(results['available_models'])}")
    print(f"åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {results['available_models']}")
    print(f"MLTrainingServiceçµ±åˆ: {'æˆåŠŸ' if results['ml_service_initialized'] else 'å¤±æ•—'}")
