"""
å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°APIæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒå˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ­£ã—ãå‡¦ç†ã—ã€
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–æ™‚ã«å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚
"""

import logging
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.api.ml_training import SingleModelConfig, EnsembleConfig
from app.services.ml.ml_training_service import MLTrainingService

logger = logging.getLogger(__name__)


class TestSingleModelAPI:
    """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°APIæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def test_single_model_config_validation(self):
        """SingleModelConfigã®æ¤œè¨¼ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== SingleModelConfigæ¤œè¨¼ãƒ†ã‚¹ãƒˆ ===")
        
        # æœ‰åŠ¹ãªè¨­å®š
        valid_config = SingleModelConfig(model_type="lightgbm")
        assert valid_config.model_type == "lightgbm"
        logger.info("âœ… æœ‰åŠ¹ãªSingleModelConfigä½œæˆæˆåŠŸ")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆ
        model_types = ["lightgbm", "xgboost", "catboost", "tabnet"]
        for model_type in model_types:
            config = SingleModelConfig(model_type=model_type)
            assert config.model_type == model_type
            logger.info(f"âœ… {model_type.upper()}è¨­å®šä½œæˆæˆåŠŸ")
        
        return True

    def test_ensemble_config_disabled(self):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–è¨­å®šã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–è¨­å®šãƒ†ã‚¹ãƒˆ ===")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–è¨­å®š
        ensemble_config = EnsembleConfig(enabled=False)
        assert ensemble_config.enabled == False
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–è¨­å®šä½œæˆæˆåŠŸ")
        
        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—ã®è‡ªå‹•æ±ºå®šã‚’ãƒ†ã‚¹ãƒˆ
        trainer_type = MLTrainingService.determine_trainer_type(
            ensemble_config.dict()
        )
        assert trainer_type == "single"
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–æ™‚ã®è‡ªå‹•æ±ºå®š: single")
        
        return True

    def test_api_request_structure(self):
        """API ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ ãƒ†ã‚¹ãƒˆ ===")
        
        # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        request_data = {
            "symbol": "BTC",
            "timeframe": "1h",
            "start_date": "2023-01-01",
            "end_date": "2023-12-31",
            "save_model": True,
            "train_test_split": 0.8,
            "random_state": 42,
            "ensemble_config": {
                "enabled": False,  # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–
                "method": "stacking",
                "bagging_params": {
                    "n_estimators": 5,
                    "bootstrap_fraction": 0.8,
                    "base_model_type": "lightgbm",
                    "mixed_models": ["lightgbm"],
                    "random_state": 42
                },
                "stacking_params": {
                    "base_models": ["lightgbm"],
                    "meta_model": "lightgbm",
                    "cv_folds": 5,
                    "use_probas": True,
                    "random_state": 42
                }
            },
            "single_model_config": {
                "model_type": "lightgbm"  # å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š
            }
        }
        
        # è¨­å®šã®æ¤œè¨¼
        ensemble_config = EnsembleConfig(**request_data["ensemble_config"])
        single_model_config = SingleModelConfig(**request_data["single_model_config"])
        
        assert ensemble_config.enabled == False
        assert single_model_config.model_type == "lightgbm"
        
        logger.info("âœ… APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ æ¤œè¨¼æˆåŠŸ")
        logger.info(f"   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ‰åŠ¹: {ensemble_config.enabled}")
        logger.info(f"   - å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {single_model_config.model_type}")
        
        return request_data

    def test_ml_training_service_integration(self):
        """MLTrainingServiceã¨ã®çµ±åˆã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== MLTrainingServiceçµ±åˆãƒ†ã‚¹ãƒˆ ===")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ– + å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š
        ensemble_config = {"enabled": False}
        single_model_config = {"model_type": "xgboost"}
        
        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
        trainer_type = MLTrainingService.determine_trainer_type(ensemble_config)
        assert trainer_type == "single"
        
        # MLTrainingServiceã‚’åˆæœŸåŒ–
        ml_service = MLTrainingService(
            trainer_type=trainer_type,
            ensemble_config=ensemble_config,
            single_model_config=single_model_config
        )
        
        assert ml_service.trainer_type == "single"
        assert ml_service.trainer.model_type == "xgboost"
        
        logger.info("âœ… MLTrainingServiceçµ±åˆæˆåŠŸ")
        logger.info(f"   - ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚¿ã‚¤ãƒ—: {ml_service.trainer_type}")
        logger.info(f"   - ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {ml_service.trainer.model_type}")
        
        return ml_service

    def test_available_models_api_simulation(self):
        """åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«å–å¾—APIã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        logger.info("=== åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«å–å¾—APIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ===")
        
        # MLTrainingServiceã‹ã‚‰åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        available_models = MLTrainingService.get_available_single_models()
        
        # API ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        api_response = {
            "success": True,
            "available_models": available_models,
            "message": f"{len(available_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™"
        }
        
        assert api_response["success"] == True
        assert len(api_response["available_models"]) > 0
        assert "lightgbm" in api_response["available_models"]
        
        logger.info("âœ… åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«å–å¾—APIã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ")
        logger.info(f"   - åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {len(available_models)}")
        logger.info(f"   - ãƒ¢ãƒ‡ãƒ«ä¸€è¦§: {available_models}")
        
        return api_response

    def test_different_model_types(self):
        """ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§ã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§ã®å‹•ä½œãƒ†ã‚¹ãƒˆ ===")
        
        available_models = MLTrainingService.get_available_single_models()
        test_results = {}
        
        for model_type in available_models:
            try:
                # å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨­å®š
                single_model_config = {"model_type": model_type}
                
                # MLTrainingServiceã‚’åˆæœŸåŒ–
                ml_service = MLTrainingService(
                    trainer_type="single",
                    single_model_config=single_model_config
                )
                
                # åˆæœŸåŒ–æˆåŠŸã‚’ç¢ºèª
                assert ml_service.trainer_type == "single"
                assert ml_service.trainer.model_type == model_type
                
                test_results[model_type] = "æˆåŠŸ"
                logger.info(f"âœ… {model_type.upper()}ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æˆåŠŸ")
                
            except Exception as e:
                test_results[model_type] = f"å¤±æ•—: {e}"
                logger.error(f"âŒ {model_type.upper()}ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
        
        # æˆåŠŸç‡ã‚’è¨ˆç®—
        success_count = sum(1 for result in test_results.values() if result == "æˆåŠŸ")
        success_rate = success_count / len(test_results) if test_results else 0
        
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãƒ†ã‚¹ãƒˆæˆåŠŸç‡: {success_rate*100:.1f}% ({success_count}/{len(test_results)})")
        
        return test_results

    def test_configuration_priority(self):
        """è¨­å®šã®å„ªå…ˆé †ä½ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== è¨­å®šå„ªå…ˆé †ä½ãƒ†ã‚¹ãƒˆ ===")
        
        # ã‚±ãƒ¼ã‚¹1: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ‰åŠ¹ â†’ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        ensemble_enabled = {"enabled": True}
        single_model_config = {"model_type": "lightgbm"}
        
        trainer_type = MLTrainingService.determine_trainer_type(ensemble_enabled)
        assert trainer_type == "ensemble"
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ‰åŠ¹æ™‚: ensembleãŒå„ªå…ˆ")
        
        # ã‚±ãƒ¼ã‚¹2: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹ â†’ å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        ensemble_disabled = {"enabled": False}
        
        trainer_type = MLTrainingService.determine_trainer_type(ensemble_disabled)
        assert trainer_type == "single"
        logger.info("âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹æ™‚: singleãŒé¸æŠ")
        
        # ã‚±ãƒ¼ã‚¹3: è¨­å®šãªã— â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
        trainer_type = MLTrainingService.determine_trainer_type(None)
        assert trainer_type == "ensemble"
        logger.info("âœ… è¨­å®šãªã—æ™‚: ensembleãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ")
        
        return True

    def test_overall_api_functionality(self):
        """å…¨ä½“çš„ãªAPIæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å…¨ä½“çš„ãªAPIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
        
        # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        config_validation = self.test_single_model_config_validation()
        ensemble_disabled = self.test_ensemble_config_disabled()
        request_structure = self.test_api_request_structure()
        ml_service_integration = self.test_ml_training_service_integration()
        available_models_api = self.test_available_models_api_simulation()
        model_types_test = self.test_different_model_types()
        priority_test = self.test_configuration_priority()
        
        # ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        api_score = 0
        
        # è¨­å®šæ¤œè¨¼ï¼ˆæœ€å¤§15ç‚¹ï¼‰
        if config_validation:
            api_score += 15
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–ï¼ˆæœ€å¤§15ç‚¹ï¼‰
        if ensemble_disabled:
            api_score += 15
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ ï¼ˆæœ€å¤§20ç‚¹ï¼‰
        if request_structure:
            api_score += 20
        
        # MLTrainingServiceçµ±åˆï¼ˆæœ€å¤§20ç‚¹ï¼‰
        if ml_service_integration:
            api_score += 20
        
        # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«APIï¼ˆæœ€å¤§10ç‚¹ï¼‰
        if available_models_api and available_models_api["success"]:
            api_score += 10
        
        # ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆæœ€å¤§15ç‚¹ï¼‰
        success_count = sum(1 for result in model_types_test.values() if result == "æˆåŠŸ")
        total_models = len(model_types_test)
        if total_models > 0:
            model_score = (success_count / total_models) * 15
            api_score += model_score
        
        # è¨­å®šå„ªå…ˆé †ä½ï¼ˆæœ€å¤§5ç‚¹ï¼‰
        if priority_test:
            api_score += 5
        
        logger.info(f"APIæ©Ÿèƒ½ã‚¹ã‚³ã‚¢: {api_score:.1f}/100")
        
        if api_score >= 90:
            logger.info("ğŸ‰ å„ªç§€ãªAPIæ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif api_score >= 80:
            logger.info("âœ… è‰¯å¥½ãªAPIæ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        elif api_score >= 70:
            logger.info("âœ… åŸºæœ¬çš„ãªAPIæ©Ÿèƒ½ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")
        else:
            logger.warning("âš ï¸ APIæ©Ÿèƒ½ã«æ”¹å–„ãŒå¿…è¦ã§ã™")
        
        return {
            'api_score': api_score,
            'config_validation': config_validation,
            'ensemble_disabled': ensemble_disabled,
            'request_structure': request_structure is not None,
            'ml_service_integration': ml_service_integration is not None,
            'available_models_count': len(available_models_api["available_models"]) if available_models_api else 0,
            'model_types_success_rate': success_count / total_models if total_models > 0 else 0,
            'priority_test': priority_test
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
    import logging
    logging.basicConfig(level=logging.INFO)
    
    test_instance = TestSingleModelAPI()
    
    # å…¨ä½“çš„ãªAPIæ©Ÿèƒ½ã‚’æ¤œè¨¼
    results = test_instance.test_overall_api_functionality()
    
    print(f"\n=== å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°APIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµæœ ===")
    print(f"APIæ©Ÿèƒ½ã‚¹ã‚³ã‚¢: {results['api_score']:.1f}/100")
    print(f"è¨­å®šæ¤œè¨¼: {'æˆåŠŸ' if results['config_validation'] else 'å¤±æ•—'}")
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç„¡åŠ¹åŒ–: {'æˆåŠŸ' if results['ensemble_disabled'] else 'å¤±æ•—'}")
    print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ : {'æˆåŠŸ' if results['request_structure'] else 'å¤±æ•—'}")
    print(f"MLTrainingServiceçµ±åˆ: {'æˆåŠŸ' if results['ml_service_integration'] else 'å¤±æ•—'}")
    print(f"åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {results['available_models_count']}")
    print(f"ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—æˆåŠŸç‡: {results['model_types_success_rate']*100:.1f}%")
    print(f"è¨­å®šå„ªå…ˆé †ä½: {'æˆåŠŸ' if results['priority_test'] else 'å¤±æ•—'}")
